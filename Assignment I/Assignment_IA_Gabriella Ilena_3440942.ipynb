{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_regression_task_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjlEFdXpMgvw"
      },
      "source": [
        "# Deep learning programming I-A: Regression\n",
        "Felix Wiewel, Institute of Signal Processing and System Theory, University of Stuttgart, 24.04.2020\n",
        "\n",
        "## Introduction\n",
        "This programming exercise is the first of a series of exercises, which are intended as a supplement to the theoretical part of the Deep Learning course offered by the ISS. The goal is to introduce you to basic tasks and applications of methods you have encountered in the lecture. After completing the exercise you should be familiar with the basic ideas and one, possibly simple, way of solving the respective task. It is worth mentioning that most of the tasks can be solved in many different, not necessarily deep learning based, ways and the solution presented here is just one of them.\n",
        "\n",
        "## Regression\n",
        "\n",
        "In this exercise we consider the problem of regression, where we are interested in modeling a functional dependence between different variables with, possibly noisy, observations of input-output pairs. Mathematically such a dependence can be formulated as\n",
        "\n",
        "$\\mathbf{y}=f(\\mathbf{x})+\\boldsymbol{\\epsilon}$,\n",
        "\n",
        "where $\\mathbf{y}\\in\\mathbb{R}^{M}$ and $\\mathbf{x}\\in\\mathbb{R}^{N}$ are the input and output observations, $f:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ is the function mapping inputs to outputs and $\\boldsymbol{\\epsilon}\\in\\mathbb{R}^{M}$ is a random vector, which models noise in our observations. Note that this assumes additive noise that only acts on the output and not on the input variable, which might not be true in all practical applications but is a reasonable approximation. For regression we are now interested in estimating the functional relationship $f$ between the inputs and outputs. This can be done in many different ways, not just with neural networks, but for this exercise we focus on approximating this relationship with a neural network $g_{\\boldsymbol{\\theta}}:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ with parameter vector $\\boldsymbol{\\theta}$. The task is now to choose the parameters of the neural network in a way that results in a \"good\" approximation of $f$ with $g_{\\boldsymbol{\\theta}}$.\n",
        "\n",
        "In order to quantify how \"good\" our neural network can approximate $f$, we adopt a probabilistic view. For this we make the assumption that the noise $\\boldsymbol{\\epsilon}$ is a random vector drawn from a known dustribution, which enables us to derive a suitable cost function for training our neural network and also for quantifying a \"good\" approximation.\n",
        "\n",
        "### Mathematical formulation\n",
        "If we assume that the noise $\\boldsymbol{\\epsilon}$ is drawn from a gaussian distribution, e.g. $\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$, we can use\n",
        "\n",
        "$\\mathbf{y}=g_{\\boldsymbol{\\theta}}(\\mathbf{x})+\\boldsymbol{\\epsilon}\\Rightarrow \\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})=\\boldsymbol{\\epsilon}$\n",
        "\n",
        "to derive a log likelihood. Since the probability density function (pdf) of a multivariate normal distribution is given by\n",
        "\n",
        "$p(\\mathbf{x})=\\dfrac{1}{\\sqrt{(2\\pi)^{D}\\vert\\mathbf{C}\\vert}}\\mathrm{e}^{-\\dfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})\\mathbf{C}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})^{T}}$,\n",
        "\n",
        "we get\n",
        "\n",
        "$\\ln{p(\\boldsymbol{\\epsilon})}=\\ln{\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}}}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$.\n",
        "\n",
        "Replacing $\\boldsymbol{\\epsilon}$ by $\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})$ yields the log likelihood for one particular input-output pair:\n",
        "\n",
        "$\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})=\\ln {p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$\n",
        "\n",
        "This log likelihood measures how likely the input-output pair is and we can use it to train our neural network. For this we maximize the expected log likelihood over all input-output pairs under the assumption that the noise is idependent and identically distributed (i.i.d.) over all input-output pairs. This corresponds to finding the parameters $\\boldsymbol{\\theta}^{\\star}$ of our neural network, which maximize the the expected probability for observing the corresponding input-output pairs. Mathematically the optimal parameters for our neural network are given by\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[-\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}\\right]\\approx\\arg\\min_{\\boldsymbol{\\theta}}\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where all terms, which are independent of $\\boldsymbol{\\theta}$, are ignored and the expectation operator is approximated by the mean over all $N_{D}$ input-output pairs. In other words we are maximizing the log likelihood by minimizing the mean squared error loss over all input-output pairs in our dataset, hence this approach is called Maximum Likelihood (ML) estimation. For solving this optimization problem and obtaining the optimal network parameters, stochastic gradient descent (SGD) or one of it's many variants is typically used.\n",
        "\n",
        "It is worth noting, that choosing different distributions for the noise $\\boldsymbol{\\epsilon}$ leads to different log likelihoods and therefore different cost functions for training the neural network. Another commonly used distribution for modelling the noise in regression tasks is the laplace distribution. Deriving the log likelihood and the corresponding costfunction leads to the mean absolute error, which is given by the $l_{1}$-norm of the difference between observations predictions of the neural network. This cost function is considered more robust against outliers since these have less influence on the averall loss compared to the mean squared error.\n",
        "\n",
        "###  Implementation\n",
        "\n",
        "In the following we consider a simple regression task, implement a neural network and train it based on the mathematical fomrulation above. For this we first need to create a set of input-output pairs, which then needs to be partitioned into a training, validation and test set. We also define some constants to be used for partitioning the data and the hyperparameters for our neural network.\n",
        "\n",
        "But before we can start, we need to import the necessary packages tensorflow, numpy and matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPuVp2lyNK2J",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J84v9uucMgv5"
      },
      "source": [
        "Next we define our constants and set the random seeds of tensorflow and numpy in order to get reproducable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwC-1OnHMgv7",
        "colab": {}
      },
      "source": [
        "N_train_samples = 600\n",
        "N_validation_samples = 100\n",
        "N_test_samples = 100\n",
        "N_samples = N_train_samples + N_validation_samples + N_test_samples\n",
        "noise_sig = 0.1\n",
        "N_epochs = 150\n",
        "batch_size = 8\n",
        "learning_rate = 0.01\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngFFSyG-MgwA"
      },
      "source": [
        "We create $600$ training samples, $100$ validation samples to optimize our hyperparameters and $100$ test samples, which are used to check if our model can generalize to unseen data. Furthermore we set the level of noise added to the observations. For training the model we plan to train it for $150$ epochs with a batch size of $8$ and a learning rate of $0.01$. Next we create the actual input-output pairs $\\mathbf{x},\\mathbf{y}$ for which we want to learn the regression model and plot them. In this simple example we choose scalar inputs as well as output but in general $\\mathbf{x}$ and $\\mathbf{y}$ can be vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4s8AtsdQMgwB",
        "outputId": "a6567920-4404-4151-a55e-d254d63b9b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = np.linspace(0.0, 3.0, N_samples, dtype=np.float32)\n",
        "y = np.expand_dims(np.sin(1.0+x*x) + noise_sig*np.random.randn(N_samples).astype(np.float32), axis=-1)\n",
        "y_true = np.sin(1.0+x*x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.legend([\"Observation\", \"Ground truth\"])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3wx8vJlMgwI"
      },
      "source": [
        "With the input-output pairs created, your first task is now to partition the data in the training, validation and test sets. Keep in mind that we have created the data in a structured way, i.e. the input-output pairs are ordered. This means you need to shuffle the data before partitioning it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDIMUZs0MgwK",
        "colab": {}
      },
      "source": [
        "\"\"\" Shuffle and partition the data set accordingly. you can use the predefined constants \"N_train_samples\", \"N_validation_samples\" and \"N_test_samples\". Use the variable names that are already in the below code \n",
        "to store the final shuffled and partitioned data. Hint: Shuffle the data and the labels in such a way that the pairing between an image and it's label is preserved.\"\"\"\n",
        "# Shuffle the data\n",
        "c = np.column_stack((x, y))\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(c)\n",
        "\n",
        "# Partition the data\n",
        "x_train = c[:N_train_samples, 0]\n",
        "y_train = c[:N_train_samples, 1]\n",
        "x_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 0]\n",
        "y_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 1]\n",
        "x_test = c[(N_train_samples + N_validation_samples):N_samples, 0]\n",
        "y_test = c[(N_train_samples + N_validation_samples):N_samples, 1]\n",
        "\n",
        "# Cell testing\n",
        "assert np.array_equal(c[:,0], np.concatenate((x_train, x_validation, x_test))), \"Column 0 of c (x) does not have the same shape and/or elements as its splits.\"\n",
        "assert np.array_equal(c[:,1], np.concatenate((y_train, y_validation, y_test))), \"Column 1 of c (y) does not have the same shape and/or elements as its splits.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ucvKRhOMgwN"
      },
      "source": [
        "In order to feed the data to our model, we will use the Dataset class provided by Tensorflow. This class is simple to use and provides all the functionality we need for shuffling, batching and feeding the data to our model. It is also tightly integrated into the Tensorflow framework, which makes it very performant. Performance is not an aspect we need to worry about in this exercise, but it is important in more demanding applications.\n",
        "\n",
        "In this exercise we instantiate a separate Dataset object for the training, validation and test data sets, where we shuffle and repeat just the training data set. Shuffling the validation and test data sets is not necessary, since we only evaluate the loss on those data sets and do not perform SGD on it. Please fill in the missing part of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HifQ63iPMgwP",
        "colab": {}
      },
      "source": [
        "\"\"\" Create three tensorflow Dataset objects that can be used to feed the training test and validation data to a neural network. Hint: For the training data set use shuffling, batching with the size according to\n",
        "the predefined constant \"batch_size\" and repeat the data set indefinetly. For the validation and test data sets no shuffling or batching is needed.\"\"\"\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(N_train_samples).batch(batch_size).repeat()\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \n",
        "\n",
        "# print(list(validation_ds.as_numpy_iterator()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Crr6fIkMgwT"
      },
      "source": [
        "In this exercise we will create a a simple neural network with two hidden layers containing $10$ neurons. For creating a model and keeping track of its weights a class called MyModel is used. When initializing an instance of this class the necessary variables are created and stored in a list called \"trainable_variables\". This makes it easy to get all trainable variables of the model. We also override the \\__call__ method of this class in order to implement the forward pass of the neural network. This method should accept the inputs to the neural network and should return the result of the forward pass as an output. Please fill in the missing part of the code and select suitable activation functions for the different layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nq8ri416MgwX",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a neural network with two hidden dense layers containing 10 neurons each. As an activation function use the tangens hyperbolicus (tf.nn.tanh()). Since we are not using Keras, we need to create and \n",
        "manage all the variables that we need ourselves. The varaibles are created in the constructor of our model class. Since we want to be able to just call the class with some inputs in order to make a prediction, \n",
        "we implement a __call__ method which computes the forward pass and returns the output of the network.\"\"\"\n",
        "\n",
        "class MyModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,10]), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.random.truncated_normal([10]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([10,10]), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.random.truncated_normal([10]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([10,1]), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.random.truncated_normal([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uf6m8zXoMgwb"
      },
      "source": [
        "Now after the model class is defined we can instantiate a MyModel object by running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSfI8wjLMgwb",
        "colab": {}
      },
      "source": [
        "mdl = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KraeH6MsMgwh"
      },
      "source": [
        "We can now use the model to make predictions by calling it. In the following we predict on the inputs an plot the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1at5RObMgwi",
        "outputId": "ce26ed01-dc62-4602-e6ba-f1a4a2ef92ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We want to plot a prediction on the complete data set with a model before training. For this make a prediction on the variable \"x\". \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hT1RvHPyerezA6oIyyQfZegoAiCMjUn4oLBHGAGxEQUVEBwYUDEBUBFXAiew/Ze+9ZdgctdLdJbs7vj6Rp0sFq2nTcz/P0aXLuuTlvm+R7z33Pe95XSClRUVFRUSn+aNxtgIqKiopKwaAKvoqKikoJQRV8FRUVlRKCKvgqKioqJQRV8FVUVFRKCDp3G3AzypYtK8PDw91thoqKikqRYc+ePdeklEE5HSvUgh8eHs7u3bvdbYaKiopKkUEIcT63Y6pLR0VFRaWEoAq+ioqKSglBFXwVFRWVEoIq+CoqKiolBFXwVVRUVEoIquCrqKiolBBcIvhCiJlCiGghxOFcjncQQsQLIfbbfsa6YlwVFRUVldvHVTP8WUDXW/TZJKVsZPsZ56Jxc2T6gekcjDmYn0OoqKioFDlcIvhSyo1AnCteK6/Ep8fz58k/eWrZU3y8/WMSjAnuNklFRUWlUFCQPvzWQogDQojlQoi6uXUSQgwRQuwWQuyOiYm540ECPAJY2GshT9Z5kj9P/knPBT1ZenYpaqEXFRWVko5wlRAKIcKBJVLKejkc8wcsUsokIUQ3YIqUssatXrNZs2YyL6kVjsUeY9y2cRyOPUzLci0Z03IM4QHhd/16KioqKoUdIcQeKWWznI4VyAxfSpkgpUyyPV4G6IUQZfN73Dpl6vBrt18Z03IMR68dpe+ivkzdP5V0JT2/h1ZRUVEpdBSI4AshQoUQwva4hW3c2IIYW6vR8ljtx1jUZxGdK3dm2oFp9F3Yl+1XtxfE8CoqKiqFBleFZc4DtgG1hBCXhBCDhBAvCiFetHV5BDgshDgAfA08LgvYqV7Wqyyftv+UGZ1nAPD8quf5YOsH6qKuiopKicFlPvz8IK8+/NxIM6cx9cBUZh+ZTVnPsoxpNYaOlTq6fBwVFRWVgsbtPvzChqfOkzebvsncbnMJ8Azg1fWvMuK/EcSlFYrIUhUVFZV8oUQKfgZ1y9bl9+6/M7TRUFZfWE3vf3uz7OwyNYRTRUWlWFKiBR9Ar9XzYsMX+bPHn1T0q8g7m97hlXWvEJUc5W7TVFRUVFxKiRf8DKqXqs6ch+bwdrO32XF1B30W9VE3bKmoqBQrVMF3QKvR8kzdZ/ir519UDajKyE0jGf7fcG6k3XC3aSoqKip5RhX8HKjsX5nZXWfzWpPXWHdxHX0W9WHjpY3uNktFRUUlT6iCnwtajZbB9Qczv/t8SnmWYujaoXyw9QOSTcnuNk1FRUXlrlAF/xbUKl2L+d3n81y951hwegH9FvVjd6Tr9wa4i4txKaw4fDXX41+sOsGGE9EFaJGKSv4we2sENd4t2VF4quDfBgatgTeavsGsrrPQCA3PrXyOr/d+jcliKlA7FIvkw8VHuBiX4rLX7DN1Ky/+uhfFkvOX4Ot1pxnw8y6Xjaei4g4sFsn7i45gUiTpZovTsRORibz82x6MWdqLI6rg3wGNgxvz18N/0adGH3449AMDVgzgUuKlAhv/6JUEft4SwWvz92U7dj3ZyIXYO78QXEuyJpKLSzbm2T4VlcLKEz9k5s5KMylOx0b8dYBlhyI5erX4p1lRBf8O8dZ782GbD5ncfjJnb5zl0cWPsvzc8gK1Ic2UfSbS+cv/aD95/W2dfzo6kYQ0692JNaVdpvA7YlKK/4xHpWSw41zmLvqs3x+DziqD6gxfJVe6VunKXz3/olpgNUZsHMF7W94jxeQ6V0tOmC3WD6RFSk5EJjJ24WEsNlfMtaTbn6E/8MVGnvxhBwAetg97TGJ2wU8xKtnaVFSKOqlZZvgZgp+1vTiiCn4eCPMNY1bXWQxpMISFpxfy2JLHOBp79JbnxaeYuHwjleiENDaciCbimnPkz6h/DhI+cmm281JtAqxYJM/N2sWcbee5Ep/q1CfdfPMPbcaC1aHL8QB46LQAHLuakG2Gk/XW15GkdDPhI5cyZ1vETcdTUSlspBoVUo0KikWiWCR6rVUG41MLdk3OHejcbUBRR6fR8UrjV2hVrhUjN43kyWVPMrzZcPrX7o/I8JfYWHboKuUDvej93ZZsrxMxsbv98bydFwGrODu+RsaM2yIlRpu7JesYN1JMPDtzC0+0qMSzbcKzjZN1wcpiuwBMWH6cg5fj+a5/E2IS0/H30t10hp9xkZq38yLPtM4+jopKYWXHuVi6fb0pW/ur8/bRICyA8LI+brCqYCixM/yzMUlcuZF66463SfPQ5vz98N+0Ld+WiTsn0m3eEHvMvpSS5p+s4eXf9uYo9o44ulay3mKm2J6fiUm293t3wSGnu4EbKSaORyby/qIjLNx/Odvrpzv4L5PTzSSmme3Plx68are11pgVxCXnXhksxubzL+trsL6uWWHOtgiS0s25ngOw5mgU4SOXcul6CjdSjEQnpN20v4rK3XIxLoUTkYnZ2j9cnPtd+ML9V/hl+3lORmU/rzhQbAW/37StPD8n93j5Tp//R5uJ63I8lmI035UQBXoG8nWnr0mP7spF4w4eX/I4p6+fJs1kydFHnpWr8ak0/2SN/XlCqrN4phqzi+mGE86F3rt8lbkj+LX5+xnx1wG7m+fvPZfYfPqa/fgPm85me70TDh/0b9edztXWa4kZgu8BwJ7z1xm78AjD5u7N9RyAf/ZZo5r2X7xBi/FraTF+7U37q6jcLe0mrafLVxt5dPrW2z7HbLHw3r+H6Z7DHUBxwFUVr2YKIaKFEIdzOS6EEF8LIU4LIQ4KIZq4Ytybsef8dVYfvbuMl499v/2uhUgjNBhjO5B6YTDx6Qn0X9aff08vuq1zL8Y533Fk9SnezSLqH7svsWCvdab/1p8HGOogyF+tOZWt/97zmXmDHN0/n644zmGb3x/geop1kXjBvstsOBFt73sqKumm9mSsGaSbLDlGRWw8GcPaY2qmUhXXsSvi+m333X/R+vk3KcVzc5arZvizgK43Of4QUMP2MwSY5qJxc+TtPw/YHyffwsWQE4cchO1uUVKq8XqdaejNlRi/ayweoQtA5L4oVG30Mp6dudOpLT7VxL4L1/l0xXHMiuWuo2ay+u1vxugFh+yPHd090zacod+0rRyPTCA6MY3xy47bjw35JXPTimKRSCnZdCqG6znE9mdEBeVm0zMzdzJodvHZyaziHlLv8ruy6VTmHfCMjWdcZU6hwSWLtlLKjUKI8Jt06QXMsdWx3S6ECBRClJNS5r6nPw+sOBxpf5xiVDDoNEgJ564lE+ClJzTA03588OzdvNO1FjVC/O5qrPgUExevp1AvLADAadv2m/POAc9gCFqNR9kNaD0vkXrpKaS5VLbXUSySVIvzh3TQrF2U8jFwIS6Fw5fjnT6MN0fiTzJBIp4gEQ9HTnA1Ed7QHcKbNHxIw0ek4U0aHmS/CKXgSTKeJEV50lXnRawMIFKWIlIpzXNfRfNs1zZO/YN8PeyCH5mQRusJ64hMSKNJpUA+6FmXBhUC7X0zBT/zb/3f9G180qfeXb8HKipZSUzLaXIlaSJO0V57kDriAj6kcgM/DlvCWWFpToQs59R7/LLj9G4cRrCfp1O7WbGg0xZNb3hBRemEARcdnl+ytWUTfCHEEKx3AVSqVOmuBtNqMyNXjIqF1hPWotNoiExIQ6cRnB7fzX58zbEorqcY+eOF1vyz9xL31ihrP3Y7b+yj32/lZFQSERO7I6Xks1UnslqDMaYrSmolvMr/gXeVb0m7/CRKStVb/h2J6WYSbXco2cVeEswNqmquUkVcJVxEUlVEUkVcpaKIwcPxbuKy9ec1HSRLD1LwJEl6koInRvQ43rwKIJgb+IpUfEnFhzT0wvlCZPzPgzaGcpyUFThpqch58z0oaRXtxyNt6x97L9yg57dbmPNcC9rXDALAU29z6TjM8HdGxDF+2TF+Htjilv8TFZXbIWvAQwfNft7RzaeO5gIWKTgryxGPDxU5Sw/9dkYyn9VKU8ab+3POQfizunb+3nOJt/48wKYRHalY2rtA/hZXUujCMqWUM4AZYC1ifnevkfnYaLY4bUoy55AzJt2ssPNcHG//dZAWVUo7tN9c8KWUnLT5rC0WyYW4FL5bn/NtoJJ0D8kRQ/GqMAevSj+SHvUwpuutsEps7gSQRFVhE3VNpqiHi0h8ROZCcLrUc06GckqGscbShBpVq7PwtIlrBHBNWn9u4Islixevf8tKzN1xwaktxN8DnUbD5RupgCSQJELFdUJFHOVFLNXEFWqIS7TRHKWfdjOYQVn+AeGGcLZZ7mGd0pi9sgYKVnE/H5vML9tTOHolwR7Vk9V/H5mQzno1SZuKi7ieYp3w+JLCRP2P9NBu54ylHCNNg1mitCKJTLEOIY7vah2gZcRvLDeMZIK5P7OVBwFhD5Q4FZVIxdLeLDxwBYAzMUmq4N+Ey0BFh+cVbG35gsVB8Zcdyu41yroYalakPZdMlEN0zu+7LvJww/IE+XnkOM4i25sP1otDThcTR6QxiJSIoXiV/x3P0IVoPC+THtkbL2mmioikioi0ztQdZu2lReYiqFlqiNSEcMoczA5LHc7KcpyToZyzlOMqpZEOYj66em0WnTyekxlOPNq0Ap3rhJCYbubVedYcPZXL+HDVtqGrRrAfp6IFN6Qfx2X2O65SJNBYc5pmmpM005xgsHYZL+kWc0P6sN7SiIVKG6RSk7FLTgKZuxqzbuo6djWBgWqSNpU88NSPO2hdrQxDO1an93dbqCwimamfTGURxWTT/5ih9MCUg+RFUZoGT0+i7ZhGTND/yIf62VQXl/nA/CzJ6QpGs4XOX27kvppBdpetRtx8olZYKSjBXwQME0LMB1oC8fnlvwfnBZvJK7O6WKD9JOecM4pF2qNO9A4z+nFLjrLk4BX+ebktFotEiMyNTscjE3ht/n573582n6VDreBcbdJjppKIogqRVL5ahkvGUmwts5tGnjv4NvoqQQ55a67K0pyzhLLc0pKzMpQIGco5WY6LMpga5UrfVpKn0j45X6Sy4uOho3GlUk4z7oqlvO0ZOVtWLc2p6Nwjb67jzzpLE9ZZrIFXfqTQTnOQTtr93K/ZSx/tFhLX/4Cia8lc5X5OmSsAMHXDrRfENp2K4emfdrLy9fbUClX9+yo3Z/Ppa2w+fY2eDctTXVziN8N49Jh50vguO2Sdm56r1wpiKMXzprcYIX/nJd1iPDGSkt7a7h7672QM91a3unxLtOALIeYBHYCyQohLwPuAHkBKOR1YBnQDTgMpwEBXjJsbt5ppZ53hmxSLvU2ncX4j9164weSVx/lu/RlKeevZMfoBJJLHZ2x36vfZqpNU8NNQXVwiXERRWURSWURbZ+zaaMrJaLQi0664eF/+MAUzI1jQvXwVal1uw7XUe4iQIaTivEjkiLdBe1v/g+Bc7kqy4mXzqesd1j0+7FWXZ37awdX4NKoF+Tr1D/TWcyMl92ijRLxZZmnFMksr9JjpoNlPH+1m+mvXMlC3kk1KPWYqD7HB0tDpjiQr4SOX8mRL6x3FjnOxquCr3BTHYIlL544zz/AJEsFjxrGckhVyPMfPU2ePRMuYyEk0fGp+gjRp4A393yz79x22dvnEfk6G96CI6r3LonSeuMVxCQx1xVj5QURsCv/us3qYcrpYZPjlzSnxbNqykf1HjtA1/SzldLGUJ5YwcY3KmijKLYmjt0fm+QnSm3MylNA6bTgnQ9iZWIY/zxo4J0O5gR+kgyblKj4V53Cs6nZunK+AObHyTW31uk3Bz4iGAVj9Rns6f5lziUadTegdUzT4euj4pn8TVhyO5LHmFdl06hrrjlv96+1qBLHYwZUFsHBoW3pl2UHcs2F5Fh24wmpLM1ZbmlGKBJ7Qrudp3Wp+1k7mtKU8U8x9WWJplavwZ1x8zcU0JlrFdWSELPuTRMiipzBgop/xA07nIva1Q/0Y0r4qb/5xgPAyVl/8zwOaM3CW1a04RelLoEhiYNLfvDEvGGgHZOpDiRb8wsaCl9swe2sE/+6/kuNxLYo1NJE0fEQqvqThcy2VWpokqqSkotPFUZoESosEyohEypBAqIjDT6TCergfQA+KFERTiiuyDNstdThvCSVChnBBhhAhQ7iBLyCIeKw71YGf/jnEvjOZC6QaAZb0crxR9zvWX5/EfuU30qO7Yoy9j75NKvDP3ss8UCeY4V1q0fUr686/R5pWsEfsrHi9HdcSjTz10w70WoHZIu0L1gadhv/e7kBSujlbWFkGox6qTah/zsfCAr0YdG8VAGYOaG5P36BYssfPN6wY6PT86VaVqVjay2mN4zr+TFV6MUPpTjfNTl7WLeQbw7e8bFnIV+ZHWGlpRtYFbKNN6HMrzqKikkF8qgkNFqbqpxBGFM8YR3FaVmBC3/rcSDHx6Qrrepavh46kdDMeOo39rv6e8v4AdKwdzNaRnVh84AoTlh/nY/NT1BYXmaD/kWPGyhyXlThtc2+WaJdOYaPxsp7ck5LIm4YkdEJBhwUtCjoUDJjxEjdJJWwGi1ZwAx/ipD+x+HNalmezpR5XZBn8gyuzIdLAVVmGaAIx3+Jf2KRSphg6uk0AMnTMQ+PPj11+pOF3g/AIXkHv5h6MbT2G59tVpU45f6e89L0ahdnXDmoG+1E7VPBRr7qUC/CijK+BPlOt28gl1sVXIFtJt2WvtsPPU3dXUQY+BuvfO6R9VWZszJ6aAayZNHNa6J7yeCNem7+fRZY2LDa2oodmO6/r/uZ7w5fssNTmfdMAp4XheTutF0elBJekU7k9EtJMvKJdwL3aI4wwPW/32XeqHWzfPQvg72kVfI1G0KyyNSJvaMfq9uPlA71oa/PTK2gZZnqFFR4j+UI/jV7Gj4izJbYtqh/JYin4BNchPSWNXddjMVt0VCrrR+saISw8FM3VJAvJthj0JLxIlp6ka72JNxu4jh9x0o/r+GULX7Rzh0vNX/yvUY7tjSsF8lGverw2fx9d6obiofUg7crjWIxlWM5C4tIj+aLjF4DzQjLAC+2rMmfbeTQ2l8fTDtkqRz1UmwnLj+Pvqbe3CSEY2Dacn7dEAFAr1A+tJvsMZWDbcOqE+udo7ztda7PnfBxjut9DpdLevNyxeq6CH5dspFyAV7Z2b0Pmx02iYbGlDcuMLXlU+x8jdPNZYhjNL0pnvjQ/QgKZGQuPXU3AYpGYLJYcX/tqfCq/bj/PW51r2f8nKiWHZ2buxHR6A7/p/+FvpR1/KB3sx3QaYd/7AdC4UimuHLpKZHwa9SsEOGWpzaBeWAC73n2Aa0npPDRlE6NNg/jB8AXDdAv40vwoUHTvOoun4PedQey1ZN46vAGAE8O6gk5L0zYp3Pupc4TOiK61+GHjWa6bTIT6exLr4uyNjh82xw/Ji/dVo15YAGvf6mBvmzu4FcH+93E0cT3vb32fp5Y9xXf3f0dFv4oYdBp7JM2obnUY1S3nqIMh7avSrX65bLN3g+2iMaJrrRzFHuD9h+vm+ne81KEaUA2AV+6vkfsfDNQM8aVcQHZXkac+88IV4KUnPtWEgpb5SieWKy14S/cnz2hX0U27g3dMz7PB0hiwZjCsVNqbXRFxbD8bx5nx3Zz+htfn72fHuTi61i1H/QoBN7VNpfix9+R5VnpM55wM5T3TQDJcgx/2rEsZXw88HdazPulTj0BvPd3rl8vl1awE+XkQ5OfBm51r8sVq+Fu5l6HahaxUmnNUhmO2WJBScuRKgn2XfVGgaO4Pvg0y4r1LeevtCbsqlPIm0Fvv1K92qJ99c9WQ9lXx9cj9Gjjl8Zxn6zlR2se6wchR5Bx3/7UIL53tnDbVy1I92I+e1Xoyo/MMYlNjeWrZUxyKOcS2kZ1YP7zDLccVQuToqsm4S8ivBdAnW1aialkfFg1ry/AutSgfmDkLr2LLL+7lcPH77NGGTufH48tY80B6GT/iuvRjlmEyE3Uz8MUaHvrNutNsP2stU5c1hl+tzFWyGambRzniGG56kRRbhFvlMt72ehAZgQ5VyvoQ6G3gkz71aVO9bG4v54Sfp1UPPjQ9Qzw+vK+fA1gLp8zeGkGPbzaz9cztpjxxP8VW8PW2GWDW2ayj6IDVJ50RDeLjoXXKs5OVXo3C+HVQS6e2yY80AKBDrSD6NcmMCPikdz1WvdGeQG+Dve3Be0KpXMabnaPvp5SPgZvRPLQ5v3X7DS+dF4NWDeJY/C67cN4NHWtb9wi0vc0P+u1g0DrOnOqzbngHGlQIxEOnRa/V0LdxGN3rl7NfRB13LWe8D6V9DLzrcLdyWFalp/Fjppp78qj2P1Z4jKSJOOk0bm5FXIroOprKHfDSr3t4+qcdmQ3nNvGUbi0/KQ+xT2beeQZ4ZU7sMu6y76ZmrZ/NNZqAL5+b/0dLzXG6a3YwaPZujtty7Z+Pzd/Spq6k2Ap+htBnne06hiuC9eqfEZrobdDl6IpwpHQWoe58TwhlfAy80qkGE/vVp7FtkVarEdTMkgysa71Q/nu7I8G5RMZkJTwgnF+7/Upl/8q8svYVFp9ZfFvn5UTTyqWImNidppWzJ267W3a+ez87Rt+f6/EvHmvEd082sQux4+Kxl8H6PoQFevFYi4pO5xnRM8n8OI8YP8AiBb8bPmKgdjnYsv5kneEXUXeqyl2w/HAkm05d49y1ZL5ddRi5+FUuyBA+t/nWM3ASfNsdvmPww+2SMcMHmK905IilMqP1v+FJuj2U2VKEVnCLreCX8fVgyuON+OGZZk7tWRdADToNeo21zcdDS8MKziGGAH+/1IaFQ9sCmRWeMgj0NrDnvc40rVwKvVbD+w/XpayvgeY5uGzuhrJeZfm5y880DWnK6M2jmXV4lkte1xUEehsIuY2LVxnbRdLxf+/h8CX0ts3AHm9e0b7Z6qF6oeyTNehh/IQNlka8r/+F7/RT8CUlm+BnXEju5gutUjTp+NkGUv77GhF3ljHm53isdU2n444bFDPcqrfakJkTji7ee8ICGWd6hjARy1PaNWR8nC1FaMZRbAUfrC6YjIpMGWRNhuah09rvBrwNOpqFW2fANYIzd5g2rVzKHmvu6IrJKfSwUcVAdo/pfEuXzZ3ga/Bl6gNT6RLehc/3fM7kXZOxyKIjbp//rxHvP3wPdctnRgBlrLGYbBlJD4x9kI971yPBtvOxS91QwHor/bzpTcabnqCLZjf/GN5HiY1wulvImGHdzS27StEkhDiG6v5lp0cbNir1Cfb3dNol7xgn75GHGX5G7egH6oQQnZDODlmHjUp9XtItQme2unKKUsROsRb8nDDY3Dcf9arLq52qE17G234R8NJr7S4PrUYwpnsdnmrlnDBMr9XQp3EYXz7WkP/e7lCAdhuY1H4ST9Z5kjlH5zBq0yhMSu4pDgoTpX0MDGxbxWk3r30Xre3LEuCtR6fV8EL7qoQFenGfLZ2yFcEM5WGeNo0iRFyn1LyH+OXPv+xHM75vt5NjSKXo4nhn945+PjosvJVgdeV46bVOab4dJ2Methl+q6pl7njMNtXK8ESLinzcux4f9a4HwOfmRykjEml6dT5QtFyKxTMs8yZkuBWqBfna49czNkRJrIs03z/dlHvK+ee6MenLx24/WseVaISGd5q/Q1mvskzZO4UkUxKf3/c5nrrbWxMoTPjafKNZF6LrhQWwZWSnHM8559uUPonjmKmfzGNHXiJ+l8Lc5Ob2mduHi4/yTOtwtBrB/6Zvo0IpL75w03ul4npqv7cCgAbiDH21m/nW3IuLMgSwinrGnd5njzbkoXqh9vM89VrWvHkfYYHZ94bcCg+dlgl9rYEZoQHW1zwgq7Naacp91+bjRxvVh1+Y0Wmzh3JkRNeUty3YdqkbWmhzXQshGFx/MGNbj2XTpU0MXTuUZFOyu826Y4L9PJn9XAu+fqLxLfs+09qaXyjQW89ZWZ4+xg85IKsSsPQFrq6e4hQl8cdua52dnRFx/LMv3zJwq7iREbr5XJP+TDP3tLfFp5qoZQuS6NM4DJ8s4dXVg31vOw/V7fCVuS/+IoX+2rWqS6cwkzHDNzm8Sc+0rszxj7redvRMYeDRmo8yvt149kTtYciqIcSn570Ob0FzX80gpx3BWRnQJpyOtYIItEVc+Nt+X8efp42jWKk0Y5x+NkO1/5IRwTPqn0Pq4m0x480/9jPgZ2u95zaaw9yrPcJ35l4kY52xv9KpOv1bVOLXwS35dVDLXDcWuoJ/XraW9zwiq7BJqcdzuuV8vvyQPZ14YafkCr7DAp8Qztuviwo9qvbg8w6fcyzuGINWDiI2NdbdJt2SlztUY4BtQ8yt+KBnXX4e2MK+l8HsIOTfD2zLy6bX+Fu5l7f1fzBKN5cM0d9yOnMjTFGafalk50aKkX/2XmbDiRhAMkL3O5dlGeYqmeHAbz1Yi0BvA2V9PZxKlOYHjunCv1ceJkTcoLd2M+0mrSfdrJCQZsqWu6owUeIEv00168JNWKk79+cVRu6vdD/fdvqW8wnnGbBiAJHJkbc+yY2M6FqbD3rmnsIhJ1rb3rOMUNcmlQIpF+CFgpbhpheZbe7MC7qlfKibBUgGOFTOupFyk0R5KoWeftO22h930eymkeYMX5n7kY7rouDuBMdIoM2Wehy2hPOCdgkCC3sirtPgg1X2nFWFkRK3aDvo3iqF2kd/N7QJa8P0ztMZunYoA1YM4IcHf6CiX8Vbn1hEqFPOn6PjuuCl11I+0IueDcujt4V1SjS8bx5AGgZe0C3FjI6PzE+RkU8lxahw57EZKoWFMzHW9SkNFt7S/cFpS3n+Uay56bePuj/bnoz8xtldJPje3INvDN9yv2YfM7dYF3XXHIviOVtq8cKGS2b4QoiuQogTQojTQoiRORwfIISIEULst/0MdsW4d0NuuWaKOk1DmvLTgz+RZEriuZXPcTHxortNcineBh1CCJ5tE04pHwO+Hjr6Ng6zHRVMMPdnprkrg3TLGambT4Z7R82zUzzoodlGTc1lvjA/goLV/Roa4El4HtKN3A1ZK+Its7TkitYCfH8AACAASURBVCzNM9pVrDlmLRKUdTd/YSLPlgkhtMB3wEPAPcATQoh7cuj6u5Syke3nx7yOq5KdumXr8kPnH0g1pxZL0c+Kc8ilYJz5aX4xP8CLusW8obPG6ScbzfYeo/45yK/bzxewlSp5RWBhmO5fTlgqsNzSwq22ZF0QVtAy13w/7bWHqCqsBX8yNnoVRlxxKWoBnJZSnpVSGoH5QC8XvK7KXVCnTJ0SJfoZWL+HgrHmAcw3d+A13QKe1a4kOT1T8OftvMiYfw+7zUaVOyNjwf1BzR5qai7znbkXU55o6labHDcPjuluTfo3X+mEUWp5WrsacM6QW9hwhWVhgKOqXLK1ZaWfEOKgEOIvIUSuDmYhxBAhxG4hxO6YmBgXmFfyqFOmDj8++GOJEP25g1vyfLsqnJ1gLWQh0TDaPJiVSjPe183B98wSzsYkMXrBITdbqnKnxCalA5Khun+JsISw1NIq15KcBcnQjtX468XWDG5XlV3vPsCAB5uzzNKSftqNeJNmTxtSGCkoyxYD4VLKBsBqYHZuHaWUM6SUzaSUzYKCgnLrpnILapeuXSJEv031srzb3dmDaEHDq6Zh7JE1aLDzbeb9Ppe5Oy7k8goqhZXIhDTu0xykgeYcU5WeKGgJ8c+ev6qgebtLbZrZIsaC/DxoU70sc8wP4i9S6a3dwh+7L5GQVjjTnrhC8C8DjjP2CrY2O1LKWClluu3pj4B778tKCCVF9HMiHQODjcNJ9K7E67HvU1uogl/UWHM0imG6BcRqg1hgi8zJmgyxMGDQatgra3DEUpmntasAyaojUe42K0dcIfi7gBpCiCpCCAPwOLDIsYMQwrGeWE/gmAvGVbkNHEV/8MrBhT5OPy9817+J0/N4fBloGkm8xZOZhkkEcd1NlqncDvGpJsJHLmXd8ShiEtPZsX4xzTUnMbZ8FZMtgrwwbpC0RuUIflE6U0dzkUbiTKHdeZtnwZdSmoFhwEqsQv6HlPKIEGKcECIj2cWrQogjQogDwKvAgLyOq3L71C5dm+87f0+CMYHnVz3PtdSiU5LtTniwbojT8+bhpdgX78Mg49sEkMwPhi/wQN2IVVg5GWWtIPXtutNciEvmZd1CYqQ/+ubP0KBCAC2qlLZHyVR3SF/ubjJ89kuUVqRID/6n3UB8avF16SClXCalrCmlrCal/MTWNlZKucj2eJSUsq6UsqGUsqOU8rgrxlW5feqWqcvUB6YSlRLFkNVDuJF2w90muZysxW0ysiNe9qjG25ZhNNKcYZJ+BteT0unxzSbCRy5lycEr7jBV5Sbsv3iD0dN/5z7tQX42d8XPz4+FQ9syd7C1vOg/L7fhjxdau9nKTDLCMJPwZpmlJQ9rt2FMTXKzVTlTeJeTVVxO4+DGfN3pa87Hn+fFNS+SZCycH0pXobHNBkc+VIej/u341PQ4vbRbSVw9gcOXrbnzxy0+6k4TVRwwK9YwTIuEwdplpEgPflMewEOnRQhhr1vRpFKpbKVG3YljVM4f5vvwE6nUilvnRotyRxX8Ekarcq34vMPnnIg7wdC1Q0kxFU5fY15pWCHAXp/Yz1OHp17LNOVh/lbupdKBL+misWZfvJuydyr5Q6rJumciiOv00m7hT6U98RQe101uOAr+TlmbK5rytLixzI0W5Y4q+CWQDhU7MKHdBPbH7Of19a9jVIqfX/vXwS15pVMNPupdj271y+Gh1wKC0abBxATU53P9dKqJy04ZOFXcS3K6NQ3GAN1KdFj4SenmZotuD+dUCoJFmk7UST/Ivv17iElMz/U8d6AKfgmla5WufNjmQ7Zd3caIjSNQLMUr54yfpx5PvZanW1VGqxEE2HLpp2Pg4aghpGFguv4rlPTi7dYqSqQYzXiRxpPatay0NEOWCufhhuXdbdYt0Ws17Hr3Afvzn5NaoUjBlr+m0PyTNdxIMfLn7sIREq0Kfgmmd/XejGwxkrUX1vLR9o8KdR7vvJJRRAUgkjK8YnqFquIKn+pm8N+JaMyKhT92XVTz57uR5HSFR7X/ESiS+UU8zKYRnfjmNiqiFQYyaug2rBBAFKXZYGnEI9qNaLDw6vz9vP3XQU5Hu39yoQp+CefJOk/yfP3n+fvU33y3/zt3m5NnmlUuRZ1y/tnaS3k7V9Y67dOEiEZv0UO7nRMLJzFv5wVG/H2QX7ZFFIyhKtlITU9nkHY5eyw12Gqs7m5z7pgjH3bhzxfbULG0F38p7QkV12mjOcLGk9YUMWaL+92HquCr8ErjV+hboy/fH/yeucfmutucPPHXS21Y/lq7bO0dawcDmcL/6v01qNrrXTbrWjIo5ScWLfobgOhC5nMt7iSnm7lgq0lcPnIdlTXR/GDu7mar7g4fDx0GnYa/XmzDOktjEqQ3fbSb3W2WE6rgqyCE4L1W79GhYgcm7pzIiogV7jbJ5XSoFcyBsQ/Sooo1B4q/pw6h0bC38QTOW4L5xvANpUlgd8R1TkQmutnakkP/H3fQfvJ6AJpe+Y2LhBB+76OFKs7+TinjYyAdA0uVlnTR7MKLNADSTeoMX6WQoNPomNx+Mo2DGzNq0yi2X93ubpNcToC3noxliozIikY1KjHM9CqlSOQz/XR2RsTS5auNVB9dOMPqihsHLlo3AE76YTaVkg/zh+5hRnarZ78wF0Uy9gv8q9yLr0ijs2YvQIFX58oJVfBV7HjqPPm609eE+4fz2rrXOBJ7xN0muZzMNVnrpqzW1cpwVIbziflJOmn3M0i7HMiMz78an0r4yKWsPVY4k2EVF+pf+IUk4ct6rwfdbYrL2ClrEaMJoo92EwDpZnWGr1LICPAI4PvO3xPoEcjLa14udhk2QwOs0RT+ntZkXHqthsplvJmjPMhKpRnv6OZRX5y19z9i25H7m5peOd+oJKLootnNbFMnjse6fxbsKiQatnh3pJ3mEGWJV2f4KoWTYO9gpneejtli5uU1LxOfHu9uk1zG6G51mPxIA1pXyyxtbs3BIxhhGkIMgXyj/wZfUjh6JcFeLN2kbtDKNwZqV2BGw2xzl2K383mdoSM6YaGHdps6w1cpvFQJqMKUjlO4nHSZ19a/Vmx243obdDzarKJTqbqMwtTx+LKkxkdUEDF8op9Jt683otdajxkLwZe1OOJPMv/TbmCRpS3RlHK3OS5j1sDmLBzalq0JwRy2hNNbu1md4asUbpqFNuOjth+xJ2oPY7eOLbYbs9rXzKysFhXQmC/Nj9BLu5V+mk329uI283Q3v24/T/jIpTyuXYePSOcn80PuNsmldKgVTMOKgSSmmVigtKWR5iweN8642yxbVQEVlVzoXrU7V5Ku8PW+r6ngW4FhjYe52ySXM6JLLaoF+eCh03IiKpFpSk/aaw/ygX42e689AqguHVczbslRdJgZoFvJFqUuYbWb80TNIKoFFf5kaXdCutnCYtowWjeXCpeWAB3cao86w1e5JYPrD7ZvzFpwaoG7zXE5Oq2Gx5pXonfjMBSLxIKGN40vIQGvpUPRYOHgpXiklMQmpfPtulNqCoY8YjRbeEizk/Iijp+UhwDBM63DaVu9rLtNcymh/p5EU4otlnpUubIU3HyX7BLBF0J0FUKcEEKcFkKMzOG4hxDid9vxHUKIcFeMq1IwCCEY02oMrcu1Zty2cWy7ss3dJuUbGX7WywTxvmkALTQneEG7BIDzsSk8P2c3n606yeHLxWch2z1IBuuWccZSjvWWRu42Jt/4++U2Vn++0pZSxiuc2L3WrfbkWfCFEFrgO+Ah4B7gCSHEPVm6DQKuSymrA18Cn+Z1XJWCRa/R83mHzwkPCOfNDW9y6vopd5uULzgurC2w3MsSpSVv6P6krjhHdGI6ey9YNwpdS1JTMOSFZuIEDTVn+VnpikSDwxp6sSIs0IsOtYJZaWlGqjSwY+F0t66FuWKG3wI4LaU8K6U0AvOBXln69AJm2x7/BdwvRHF9i4svfgY/pj0wDS+dF6+se4W4tDh3m+Ry0py2vwveNQ0iDn++0k/l2IXMzVeRCWkFb1wx4kWPlVyXvoTd9xyQsQ2u+DKwUwPWWJrQQ7uNhKRU5u284JbNfK4Q/DDAcXfOJVtbjn1sRc/jgTLkgBBiiBBitxBid0xMjAvMU3EloT6hTOk4hZiUGN7c8CYmpXAWa75bDDrnr0Q8vgw3vUgNzWVqH/7M3h4Vrwr+XRN3lk5yJ0fL9yW8nDVCqrhP/wbdW4V/lbaUFkkkH13JqH8OMWj27gK3o9At2kopZ0gpm0kpmwUFBd36BJUCp35Qfca1HceeqD18suOTYhWuOaZ7HUL9PZ3aNlvq87O5Cy1j/qKd5iAACWlmd5hXLJDbp2NGw+Gwx6hY2huAZpWLbu6c28HPU89GS0OuS1/0R/9ymx2uEPzLQEWH5xVsbTn2EULogAAg1gVjq7iJ7lW72/Pozz1etFMqOxLobWBYp+y52P8IHMRJSxif6acTQBKztkYwdcNpN1hYtDl36TJpu+awxNIas08o9cICWPfWfQxuV8XdpuUrWo3AhI4lSisCL6zGh1S32OEKwd8F1BBCVBFCGIDHgUVZ+iwCnrU9fgRYJ4vTtLCEMqzxMDpW7MikXZPYenmru81xGd3ql8vWVrdyKG+YhlKKRD7WzwRg0ooTBW1akefY0m/xkqn8ZH4IL70WgKpBvpSUJb1/lbboZToPagrenQMuEHybT34YsBI4BvwhpTwihBgnhOhp6/YTUEYIcRp4E8gWuqlS9NAIDRPaTaBaYDWG/zecc/Hn3G2SSyjtY6BxpUCntkAvPUdkOF+Z+/Gwdjs9NdYL3KPTt3IjxciZmCTCRy4tFGXsCi2KmfZx/7BNuYcjsgqeNsEvKRz5sAt7ZE0uWoLcVhjFJT58KeUyKWVNKWU1KeUntraxUspFtsdpUspHpZTVpZQtpJRnb/6KKkUFH70P33T6Bp1Gx6vrXi02idZSjc55T/w8rZWyvlce5piuNh/pZxJKLLsirrP59DWWHLgKwML9Wb2ZKhlc3DoP3/RI20Yr8DIUuiXEfMXboAUECy1taKs5TBA3SEov2LWgkvUfV8kXwnzD+LLjl1xKusSIjSMwW4r+gmaGw/HdbnX4eWBzbPnVUNDyc/BIdChM0s9AYMEiQa/LTLKmJlrLzgcLDxO7+kvOWUJYa7EWJvfUlawZfobb6l+lLVoh6aHdxrKDVwvUBlXwVVxC05CmjGk5hq1XtvLNvm/cbU6emfpUE17uUI3B7arQsVawvXDKA3WCSfapzCfmp2ivPcTT2tXM23HB7s//fuNZao5ZTnSiGraZQbpZ4dj2FTTSnOEnpRvSJjveHiUzlddpWYHDlnB6abcQl1KwWWhVwVdxGf1q9uPRmo8y8/BMVkWscrc5eaJakC8juta2z8ostin/PeUDEALmKp1YrzRklG4eUecOZTv/YlxKgdpbmEkzWXhRt4hr0p8/lfvs7WGBnjc5q3jzry2D5tnjBwp0XFXwVVzKyBYjaRDUgDFbxnCmEKSDdRVlfA0ABPkaCPDSk1EwJQ0DX+inosXZ538tqXjUD3AF5isH6ag9wCxzF9Ix2NvDAr3daJV7Way0xiIFYRcXs/5EdIGNqwq+iksxaA18cd8XeOu8eW39ayQaE91tkkvo36ISk/o1oH/LypT2sYpWDKV41/QcjTRnGapd6NQ/LlkV/Aw8dn5LsvTgF6WzU7uXoWT58B2JojTbLPfQS7OFr9ecLLBxVcFXcTkhPiF83uFzLideZvTm0Vhk0V/E1Gk1/K95RbQa4ZSzfZmlFQuUtryq+8epFm6smlwNxSLZc+AgXif+ZZ7SiXgy/2/73ut8kzOLL18/0dj++F9LW8I1UchLe0guoGgdVfBV8oWmIU0Z3nw4Gy5uYMbBGe42x6X0alSeIe2r2p+/bxpANIF8qZ+KB9aZ/eUb7tlJWZj4dMVxDv75MRYp+MnczelYKR9DLmcVb3o2LG9/vEJpQbrU01u7mX22LKz5jSr4KvlG/9r96VG1B1P3T2XjpY3uNsdlCCHo16SC/XkCPgw3vUh1zRVG6uYBcDJK3YC1+eAJHtNuYKGlLVcdciVuGtHRjVa5nxZVrHmDEvFmjaUxPbTbuZaQaC2+k8+FdVTBV8k3hBCMbT2WWqVrMXLTSC4mXLz1SUUET73zV2erpR6bSvdjoG4lbTWHOB+bTFRCGhdiS2a0zrrjUTyYtAhvkc50cw8AnmpVib9fam1PmFZS+WVQCw5+8CAAC5W2lBUJBFzdSrXRyxgwa1e+jq0Kvkq+4qXz4ssOX6IRGt78703SleLh29ZprV8dL4f0AO1e/BaldHWm+vyE3pRIy/FraT95vbtMdBtnY5J4ddZGBmhXsFppymlpvRt6okUlmhbzrJi3g4dOi79t5/YGSyNuSB8qXrJWVdt4Mn9TwquCr5LvVPCrwPh7x3M87jif7iwexc48bXnz29VwqMFq8EbbbwZ+plhGyp/cZJn7iUs28qx2FYEimSnmPvZ2vVaVm6wY0bNMaUmFyLV4k/+b9dR3QKVAaF+hPYPqDeLPk3+y5OwSd5uTZ8r4evDni6358rEs9VjDmrK94iB6aTbTTbPdPca5kTSTwrI9pxisW8ZapTHVGt5LWV8PAMyKmiDXkSplfQDrJixP0ulcABk0VcFXKTCGNR5Gk+AmjNs2rlhsymoeXhofDx06jSAs0MvefiD8OfZbqvKJfiZBXOdCbAofLDqCWSn64ak3Iz7VxIeLj+KxdyalRBJTzH1JTDPz79A2vNC+KrVD/dxtYqFi5evtOf5RV3bJWlyWZeit3ZLvY6qCr1Jg6DQ6Jt83GS+dF29teIsUU/FY0Dz8YRfWD+9gf67Te/Cm6WU8MTJJP4NHpm1h1tYIdp+/7j4j8xEpJSbFQsMPV7Fw50me1y1hvdKQg7IaCakmKpTyZlS3Omg0JSPn/e1i0Gnw1GuRaFiotKWd5hBlyN9ss6rgqxQowd7BTGw3kbPxZ/l4+8fFojyip17rVAvXoNNwVpZngvkJOmoP8EDqcgB2R8QRk1g8Fq0d+XlLBDXetf6NT2tXU1okMcXcD4BEtRTkbfGv0hadsNBDm79uQFXwVQqc1uVb81LDl1h8djELTi9wtzkuJ0P8f1E6s1Gpzxjdr1QWkXy26iStJqzN91jrgmbuzgsAeJPG87ql/Kc0YL+0lokcVMxLF7qKk7IiRyyV6afN3/0qeRJ8IURpIcRqIcQp2+9SufRThBD7bT9Zyx+qlECGNBhCq3KtGL9jPCfiilepwIxoFImGEaYhmNDyhX4aWhQUi+T7jcWr/k+ayZo4bpB2GWVFAl/ZZvfr3rqP/zWreLNTVRz4XelAA805uJp/GTTzOsMfCayVUtYA1pJ76cJUKWUj20/PXPqolCC0Gi0T203E3+DPW/+9RZKxeO5MjaQM75kG0lRzihe0iwFYcyzKzVa5lnSzhdIk8IJuCcuV5uyTNQA1DPN2+W1wSxpUCOBfpS3pUs/G37/It7Hy+o70AmbbHs8Geufx9VRKEGW8yjD5vslcSrzEuO3jioU/HzJz52ewyNKGJUor3tD9TV0RgU4j2H42lmNXE+x9Pl1xnP9N31bQprqENJPCK7oFeGJksvkxe7tOqy7S3g5tq5flseYVScCX5ZbmNLq+Ckz5k4spr4IfIqXMqNEVCYTk0s9TCLFbCLFdCHHTi4IQYoit7+6YmPzddabifpqGNOWlhi+x/NxyFp5ZeOsTigDZL1yCd03PEYcfX+in4qUx8fiM7Tw0ZZO9x7QNZ9gZEVewhuaRuGQjl66nEGSK5EntGv5QOnBWZiYH02nUGf7t0r9FJe4p58/vSkf8RQocW5wv49zyHRFCrBFCHM7hp5djP2n9lOc2RasspWwG9Ae+EkJUy208KeUMKWUzKWWzoKCgO/lbVIoog+sPpnloc8bvGM+5+HPuNifP5LQmG48vI0wvUEtzib5xt96Fu+54FHsvFO4wzncXHOLeT9fziuZ3FLR8Ze7H211q2Y8bVJfObSOEoEvdULZb6nDeEgx75+TLOLd8R6SUD0gp6+XwsxCIEkKUsxlcDsixdIuU8rLt91lgA9A4p34qJROtRsuEeyfgofVgxMYRGJWiXTwkq0sng/8sDdlcqg89U//lAc0eABLSTDn2fW7WbvpO3ZpvNt4poxccouNnG5zalh+OpL44Sx/tFn5SHiKaUoSX8bEfV106d0bz8FJINMxXOpEqdWB2fQhvXi/Bi4BnbY+fBbLdkwshSgkhPGyPywJtgaN5HFelmBHiE8JHbT/ieNxxvtiTf4tWBUGTStZgtQYVArId21dnOActVfhcP40KIprhfxzg+Tn5v6U+r8zdcYFz15Kd2gQWxulnESMDmG5+GAC9g8irgn9ntKlelvphAUxTHua+K8NA5+HyMfIq+BOBzkKIU8ADtucIIZoJIX609akD7BZCHADWAxOllKrgq2SjQ8UOPFnnSX479hsbLm5wtzl3TZ1y/pwd34221cs6tYf4e1C+TCBDTa8igO/0X7Ph6CVWH82M2ikKMfrpZoVhc/fyiHYjjTWnmWB6giSsKY+THCo36VUf/h1jTT8hiM6nDXp5ekeklLFSyvullDVsrp84W/tuKeVg2+OtUsr6UsqGtt8lN42gyi15s+mb1C5dm/e2vEdUctENX9RoBIpNvBtXCmTWwObsGP0Awf4eXJQhDDe9QEPNWcZ7z3c6z1jI8+1IKWk5fi0bD55mhG4+eyw1WGC51368W/1y9sdqKoU7p045/3x9ffUSrFKoMGgNTGo/iXQlnVGbR6FYFHebdNdkZIfsVq8cHWoFA1DGx3qbvsrSnBnm7jxiWU5PTaavPt1cuAX/0vVUbqSYeF33N2VIZKxpANJBRjz1JbcwuSsY0Cac+2sHE14mf4rEqIKvUuioElCFUS1GsStyFz8e+vHWJxRSFItVvB192WX9Mmu5/u4/kJ2WWnyqn0FdYY1OSjcX7gvcjnNxNBKneVa7krlKJ45INXWCK9FoBD8+24wNb+dPGUhV8FUKJb2r9+ahKg8x7cA09kXvc7c5d4XJ5tLROYQnlva2Cr6nXoMidLxsfJ04/Jjp8QVB3MBotmSL4z90KZ7/Td9mT2GQlfhUE4m5RPvklS9Xn6SmLTEawPojF5ik/55oSvGp+QmnMEwV1yBE/rnCVMFXKZQIIRjbaiyhPqG8s/EdEowJtz6pkPFQvVAAWlXJLOun02r4pE89Fg27l7hkI9cI4HnjW5TWJDPd8CVL9kVgylIoZNySI+yMiGPfhRs5jtPww1U0/WhNvvwNU9aeclpXaBIxk5qay3xueIlEvLmnnD9Hx3UBIMNl/3aXWtQPyx6hpOJ+VMFXKbT4GnyZ1H4S0SnRfLyt6KVSblcjiIiJ3akR4lz448mWlakZ4oeXwervPirD2dVoPE01pyi7/h2uXHeuE5BR/zS3mH0omMXe+uIszyj/sMPvAbZqmgJWn72Hzvp3DOtozZA5tGN1Fr9yb66vo+I+VMFXKdQ0CGpgTb0QsbxYlEZ0ZGLfBvbHSdW686WpH49oN3J92YdO/fy9rIL/wi978t2mvReuk25WWHzgCp+tzMxi6kMq3+i/IZpAVlZ8w76l3lOvQasRREzszpsPqu6dwo7O3QaoqNyKwfUHs/XKVj7Z8QmNgxtTwa+Cu01yCR1rB2PQaTCaLfh66Jii9KW8iOWxczN4SmviV6UzAH6emV/TiGvJhJf1QUqJlK4NfTwbk0TfqVvtNjkyTv8zFUU0jxvfo4lfGeAKgP0uRaVooM7wVQo9Wo2W8e3GIxCM2jQKs6X4VFFa+Xp7vn6iMZ4GLSAYbR7EaqUJ43SzeEizg0vXU5xy0nSwpTeo/d4K+kzdYo/1dwXXU6wpLbKK/aPaDfTTbuZrc192ydoEehnI8K55qWGYRQpV8FWKBGG+YYxpNYb9Mfv54dAP7jbHZVQp60PPhuXtwqmg5RXTK+yRNZii/5b3J3/G1jOxTuc8/dMO0s0WDlyKd9rZmh80E8f5RPcTm5R6fKtYE90GeuuRNqeOmvO+aKG+WypFhu5Vu9O9ane+P/A9+6P3u9scl+Lt4BpJw4NBxrc5KiszTf8VFaLWOvXddOqa/fHtCn50Yhr9f9jOtaTct+xnjQ6qIGKYbviKSzKIoaZXUbDaGOilt+8IVTdaFS1UwVcpUrzb8l1CvEMYuWlksaqSldUXnoAPTxtHc1hW4Tv913TT5Fzcet9tplCetSWCrWdimbfjAqeiEgkfuZRftp8nfORSLt+wFttINWbG+ZcmgVn6TzFgZrBpOAn42o8FeOn55onGzH2+JaV9DNnGUim8qIKvUqTwM/gxod0EriZfZcLOCe42x2Vk9YX3blSeRLx5xjiS/bIa3+q/YbB2KVlLTuyOsAq+Tw6Lp1+uPkmPbzaRkGZCsTndtVrBP/suA/Dev4cB2HLaeseQatvY5U8SvxgmECauMdj4llNRE4AAbz1+nnraVHNODqdS+FEFX6XI0SSkCc/Xf55FZxaxImKFu81xCd6GzEic/WM7E1bKC4AkvHnKOJrlluaM0f/GR7qf0ZI5E49KSAPAbFu87Tt1C12/2sj1ZCNT1p7i8OUEtp6+xqXr1lm8VgguxDnH+XvorDKQYlQI4gZzDeOpIS7xgukNdso62WwN9FZn9UUVVfBViiQvNHyBBmUbMG7bOCKTI91tTp7ROoRXBnobKB/oZX+ejoFhpleZZn6Yp3VrmGf4mHJYF3JPR1vdWkbFmpJh74UbHI9MdErC5mXQsfTgVfs417Kk3jUpkjMxSXz71wr+MnxAVXGV503D2WhpSPkAz2y2Btj2BagUPVTBVymS6DV6JrabiGJRGLWpaGfVzIn+LSo5PZdo+NT8BK8ah3KPOM9yj5E8rNnKqehE63GZOcsH5yRsZ6Iz1zo0QmDKsis3Mc3E5oU/stgwBj+RQn/ju/xnaQjAx33q5EmMMAAAIABJREFU2ft90qceD9QJztF9pFI0UAVfpchS0b8io1qOYnfUbmYdmeVuc1xK1gRaHWpZ6zuvEO3obhzPeRnCN4ZvmaOfSFVh3QS1y6EIuuMMP+OiANY7AccLQxniabl/NM9eep9TMowe6ePZL60pEsb3qY/GZkfF0l482bIyPz7bPF+Te6nkL3kSfCHEo0KII0IIixCi2U36dRVCnBBCnBZCjMzLmCoqjvSq1osHKz/It/u+5UjsEXebkyfmPNeCVW+0z/FYwwqBgDWVwXkZSh/jOMaanqWR5gyrDCP4Qj+Vj378w94/3ZQp+Icux9sfn4pK4uCleAJJ5FXtP6zzeIvq0Sv5xtybx4xjuULmQmzne0LsG6yqlM2M0lEpuuQ1tcJhoC/wfW4dhBBa4DugM3AJ2CWEWKSWOVRxBUIIxrYey4GYA4zcOJLfe/yOtz5/ikfkN+1rBuV6bFC7KlyNT0Ug+H33RSxomKN0YZnSihd0i3lSu5a+Hps5ZqnECqU5nDNTlmRi8ePw5QT0mKkirsL+jUzT76GD5gBewshqpQkTzU8ggmphinYOc9Vrhb0gu1qetniQJ8GXUh6DW+ZvbgGcllKetfWdD/RCLWSu4iICPAIYf+94Bq8azOTdk3m/9fvuNsnl+HvqmfRIQ75Ze8qp/RoB/BYwhO9ie9FTu5U+2i28pvsHzdq/2e0JZqlBItALh8geGcifyn38onTmlLTmJXqjQXm+XHPS6bV1Wg0Z3h+N6sYpFhRE8rQw4KLD80tAy9w6CyGGAEMAKlWqlFs3FRUnWpRrwcB6A5l5eCb3ht3L/ZXud7dJ+cIL91Vj38UbrDsebW+rU86f5bEpzFG6sL1sPyKjoni9TjznTh4mRFxHIKlVIYTNsb5sSwrhpKzgVJYQoHY5v6xDoXOoy6vWpy0e3FLwhRBrgNAcDr0rpVzoaoOklDOAGQDNmjUrWgnQVdzKsEbD2HZlGx9s/YD6ZesT7B3sbpNcwvAHa9ofG3Qa2lYv6yT4tUP9WX7YGpr6SNMKzNxsZtwxHyBzw9SbNWqyzxzFicRMf74j5Wzhlx46jX3BV6/VUD7Q2t6oYuD/27vz8CiK9IHj3zeTyUkukkASQiBAkNtwReSWWwRZEFZWVPJTVxBwUUSBFWWR9cSHxUWBDYIcuqKAHKuAHAuiiwgEIgn3qQQQwhFykZP6/TFhTGBCjkkymUl9nmeememumX6rG97pVFdXlWudNNso9qKtUqqXUqqFhUdJk/05oG6B96H5yzStXBkNRt7t+i6ZuZlM/WEqN1XVnhC8OOvGdeLTp+9jXI8Ii+ubh5jGs3moVZB5bBsXgxPdLFwLCKjhSm3vO/vU31Lb243NL3bl+0m/z6VqcBJahfqy8YUuPNetoTVV0aqIyuiWuQeIEJFwEXEBhgPrKmG7WjUU7hPOK1Gv8OOFH1l6cKmtw7FKq1BfOkfcOXzBrcaV9vVrcuadh2hUy4thbU1t8Z6uztT2dr3jMzU9jeazeEv8PV2IqO1FLa87yzQJ8tZNOg7C2m6Zg0UkEbgf+EZEvs1fHiIi6wGUUrnAOOBb4DDwpVLKvvvPaVXa0Iih9ArrxQf7P+Dg5erxT21kx/r849F7GdImFB8LQx94uRmpnZ/wG9Uq3MVy5tBWhSZa1xyXVUdZKbVaKRWqlHJVStVWSvXNX35eKdW/QLn1SqnGSqmGSqk3rQ1a0+5GRPhbx7/h7+bPKzteIT0n3dYhlatbHWYKzvFrcBIGtw7F4CT4Whj6wMvNmaD8Jp2CI1wG+7gxrF3dO8prjkn/rGsOycfVh3e6vENiWiJv/fSWrcMpV7caV4rq0eDnaSnhG83NNTcL3GlrqaHmD5EhFpZqjkAnfM1htQtqx7OtnmXdyXV8c+obW4dTaQJqmNrw7w31MS/zcnPG18P0QxBUoC3f0j00s4e35sw7D1VwlJot6ISvObRRrUbRulZrZuyawdnUs8V/wA7cStKqiFP8lnV8iHmiLUuf/v12Fy83Z5qHePPeI614c3DLyghTq4J0wtccmrOTM+90eQcnnJi8YzI5N3NsHZLVejWrjZPA8CjLbe8iQp/mQfi4G2kQ6AmAq7MBEeGP7esWGt74wRaWbrHRHJVO+JrDC6kRwrSO0zhw+QBz4+baOhyr1fF159TbD9E8xKfYsl8915Gvn+9scZ2LsxNT+t85wYnmuCpjaAVNs7m+9fuy8/xOFsYvpENwB+4LLnJ0D4fi6+FicYaqhOl9cXaSQhOvaI5Pn+Fr1cak9pOo512PKd9P4VpmySb/dlQ1XJ1xM+qJTKobnfC1asPD6MF7Xd8jOSuZ1//3eqF+7JpWHeiEr1UrTf2bMqHtBLYnbmfpIfseekHTSksnfK3aGdF0BL3CevGP2H+w/9J+W4ejaZVGJ3yt2hER3uj0BiE1Qpj43USuZl4t/kOa5gB0wteqJS8XL2Z1n0VyZjJTvp9C3s284j+kaXZOJ3yt2mpSswlT7pvCzvM7WRC/wNbhaFqF0wlfq9YeiXiEAQ0GMDduLrsu7LJ1OJpWoXTC16o1EeG1Dq/RwKcBk3ZM4mL6RVuHpGkVRid8rdrzMHowq/ssMnMzeXH7i2TlZdk6JE2rENbOeDVMRA6KyE0RaXeXcmdEJF5E4kRkrzXb1LSK0MC3AW91fov4y/G8uetNfVOW5pCsPcNPAIYAO0pQ9gGlVKRSqsgfBk2zpZ71ejKq1ShWn1jN8qPLbR2OppU7qwZPU0odBsuTKGiaPRoTOYYjV4/w3u73aOTbiPZB7W0dkqaVm8pqw1fAJhGJFZFn71ZQRJ4Vkb0isjcpKamSwtM0Eydx4u0ubxPqFcpL21/iQtoFW4ekaeWm2IQvIltEJMHCY1ApttNZKdUGeBAYKyJdiyqolIpRSrVTSrULDAwsxSY0rXx4uXjxzx7/JOdmDn/Z9hcycjJsHZKmlYtiE75SqpdSqoWFx9qSbkQpdS7/+RKwGogqe8iaVvHCfcJ5t+u7HLt2jFd2vKLvxNUcQoU36YiIp4h43XoN9MF0sVfTqrSuoV2ZEjWF7xK/470979k6HE2zmlUXbUVkMDAHCAS+EZE4pVRfEQkBPlZK9QdqA6vzL+w6A/9WSm0s6zZzcnJITEwkMzPTmtC1MnBzcyM0NBSj0Vh8YQcxvMlwzqaeZemhpYR5hzGi6Qhbh6RpZWZtL53VmJpobl9+Huif//oUcK812ykoMTERLy8v6tevr3sHVSKlFFeuXCExMZHw8HBbh1OpJrSdwLm0c7y7+11CPEN4IOwBW4ekaWVid3faZmZm4u/vr5N9JRMR/P39q+VfVgYnA293eZvm/s2Z9P0k4i7F2TokTSsTu0v4oPv920p13u/uzu7M6TmHQPdAxmwdw7Frx2wdkqaVml0mfE2zhQD3AGL6xODu7M7ozaM5m3rW1iFpWqnohF8GiYmJDBo0iIiICBo2bMj48ePJzs5m8eLFjBs3ztbhsWbNGg4dOmR+//rrr7NlyxYbRuQ46tSoQ0zvGLJvZjNq8ygu37hs65A0rcR0wi8lpRRDhgzhD3/4A8ePH+fYsWOkpaXx6quvVsj2cnNzS/2Z2xP+G2+8Qa9evcozrGqtoW9D5vWcx+Ubl/nzpj9z5cYVW4ekaSUiVXlUwHbt2qm9ewsPrnn48GGaNm0KwPT/HOTQ+ZRy3WazEG+mDWxe5PqtW7cyffp0duz4fby4lJQUwsPDmTFjBt9++y3Xr1/n3LlzPP7440ybNo309HT++Mc/kpiYSF5eHq+99hqPPvoosbGxTJgwgbS0NAICAli8eDHBwcF0796dyMhIfvjhBwYOHMiiRYs4ffo0Tk5OpKen06RJE06dOsXixYuJiYkhOzubRo0asWzZMuLi4hgwYAA+Pj74+PiwatUqZsyYwYABAxg6dChbt25l4sSJ5Obm0r59e+bNm4erqyv169dn5MiR/Oc//yEnJ4cVK1bQpEmTO+pfcP9Xd7sv7Gbs1rGEeoXycZ+P8Xf3t3VImoaIxBY1SKU+wy+lgwcP0rZt20LLvL29CQsLIzc3l927d7Nq1SoOHDjAihUr2Lt3Lxs3biQkJISff/6ZhIQE+vXrR05ODs8//zwrV64kNjaWp556qtBfCdnZ2ezdu5dp06YRGRnJd999B8DXX39N3759MRqNDBkyhD179vDzzz/TtGlTFi5cSMeOHXn44YeZOXMmcXFxNGzY0PydmZmZREdH88UXXxAfH09ubi7z5s0zrw8ICGDfvn0899xzvP/++xW8J+1fVHAUH/X8iMTURJ7Z9Iw+09eqPKv64dva3c7EbaV37974+5vO9IYMGcIPP/xA//79eemll5g0aRIDBgygS5cuJCQkkJCQQO/evQHIy8sjODjY/D2PPvpooddffPEFDzzwAMuXL2fMmDEAJCQkMHXqVJKTk0lLS6Nv3753je3o0aOEh4fTuHFjAEaOHMlHH33ECy+8YI4XoG3btnz11VfltEccW1RwFHN7zWXs1rE8/e3TfNz3YwLcA2wdlqZZpM/wS6lZs2bExsYWWpaSksKvv/6Ks7PzHV0XRYTGjRuzb98+WrZsydSpU3njjTdQStG8eXPi4uKIi4sjPj6eTZs2mT/n6elpfv3www+zceNGrl69SmxsLD169AAgOjqaDz/8kPj4eKZNm2Z1H3lXV1cADAZDma4dVFftg9rzUc+POJ9+nuiN0SSmJto6JE2zSCf8UurZsycZGRksXboUMJ2Zv/TSS0RHR+Ph4cHmzZu5evUqN27cYM2aNXTq1Inz58/j4eHB448/zssvv8y+ffu45557SEpK4scffwRMQ0YcPHjQ4jZr1KhB+/btGT9+PAMGDMBgMACQmppKcHAwOTk5fPbZZ+byXl5epKam3vE999xzD2fOnOHEiRMALFu2jG7dupXr/qmu2ge1J6Z3DNcyr/HEhic4evWorUPStDvohF9KIsLq1atZsWIFERERNG7cGDc3N9566y0AoqKieOSRR2jVqhWPPPII7dq1Iz4+nqioKCIjI5k+fTpTp07FxcWFlStXMmnSJO69914iIyPZuXNnkdt99NFH+fTTTws19cyYMYP77ruPTp06FbrAOnz4cGbOnEnr1q05efKkebmbmxuffPIJw4YNo2XLljg5OTF69OgK2EvVU2StSJY+uBSDGIjeGM2e3/bYOiRNK8Sue+lolU/v/+L9lv4bozaPIjE1kTc7v0m/8H62DkmrRnQvHU2rREGeQSzpt4QWAS14ecfLzNk/h5vqpq3D0jSd8DWtIvi6+bKgzwIGNxpMzIEYJmyfoGfO0mxOJ3xNqyAuBhemd5zOpPaT2HZ2GyPWj+DU9VO2DkurxnTC17QKJCI83uxx5vWax9XMqwz/ejjrTq6zdVhaNWVVwheRmSJyREQOiMhqEfEtolw/ETkqIidEZLI129Q0e9QxpCMrBq6guX9zXv3hVab+MFU38WiVztoz/M1AC6VUK+AYMOX2AiJiAD4CHgSaAX8SkWZWblfT7E4tj1os6LOA0feOZt3JdQxZN0R33dQqlVUJXym1SSl165bMXUCohWJRwAml1CmlVDawHBhkzXZt5cqVK0RGRhIZGUlQUBB16tQxv8/Ozi7XbSUnJzN37txy/U7N9pydnBkbOZbF/RZjEANPffsUb//0tj7b1ypFebbhPwVssLC8DlBwpojE/GUWicizIrJXRPYmJSWVY3jW8/f3Nw+FMHr0aF588UXzexcXlyI/V5ZhCnTCd2xtardhxcAVjGg6gn8f+TeD1w5m669bqcr3xWj2r9jB00RkCxBkYdWrSqm1+WVeBXKBzyyUKxWlVAwQA6Ybr+5aeMNk+C3e2k0WFtQSHnynxMUXLFhwxxDFHh4eREdH4+bmxv79++nUqRNjx45lxIgRpKenM2jQIGbPnk1aWhoAM2fO5MsvvyQrK4vBgwczffp0Jk+ezMmTJ4mMjKR3797MnDmzfOup2ZyH0YPJUZPpXa83f9/1d17Y9gKd6nRiStQU6nnXs3V4mgMq9gxfKdVLKdXCwuNWso8GBgAjlOXTk3NA3QLvQ/OXOQRLQxTfkpiYyM6dO5k1axbjx49n/PjxxMfHExr6e8vXpk2bOH78OLt37yYuLo7Y2Fh27NjBO++8Q8OGDYmLi9PJ3sG1rd2WLwd+ySvtXyHuUhyD1w7m/T3vk5yZbOvQNAdj1fDIItIPeAXoppQqqhFyDxAhIuGYEv1w4DFrtmtWijPxinK3IYqHDRtmHujsxx9/ZM2aNQA89thjTJw4ETAl/E2bNtG6dWsA0tLSOH78OGFhYZVcE82WjE5Gnmj2BA+GP8js2NksPbSUlcdXMrL5SJ5s9iSeRs/iv0TTimFtG/6HgBewWUTiRGQ+gIiEiMh6gPyLuuOAb4HDwJdKKcvDQtqhuw1RXHCI46IopZgyZYr5WsCJEyd4+umnKzJkrQoLcA/g753/zlcPf0WH4A7MjZtL/6/6s+DAAq5nXbd1eJqds7aXTiOlVF2lVGT+Y3T+8vNKqf4Fyq1XSjVWSjVUSr1pbdBVSVFDFN+uQ4cOrFq1CoDly5ebl/ft25dFixaZ2/PPnTvHpUuXihziWKseGvk1YvYDs/n8oc9p6t+Uf+7/J31W9mHmnpn8lv6brcPT7JS+09ZKRQ1RfLvZs2cza9YsWrVqxYkTJ/Dx8QGgT58+PPbYY9x///20bNmSoUOHkpqair+/P506daJFixa8/PLLlVUdrYppEdCC+b3ms3LgSh4Ie4DPDn9Gv1X9eGHbC/zv3P/0oGxaqejhkStJRkYG7u7uiAjLly/n888/Z+3atbYOq9Tsdf87ivNp5/n8yOesPbGWa1nXqFOjDkMbD2VAgwEEeVrqTKdVN3cbHtmu57S1J7GxsYwbNw6lFL6+vixatMjWIWl2KKRGCC+1e4nnWz/P1l+3suLYCj7Y9wEf7PuANrXa8GD4g/Sp34eabjVtHapWBekzfK1U9P6ven5N+ZUNpzew4fQGTl4/iUEMtAtqR/fQ7nQN7UqYt+7xVZ3c7QxfJ3ytVPT+r7qUUhxPPs6G0xvY+utWTl8/DUB97/p0Ce1C5zqdiQyMxMPoYeNItYqkm3Q0rRoQERr7NaaxX2PGtxnP2dSz7EjcwfeJ37P8yHKWHVqGszjTIqAF7YPa0652OyJr6R+A6kQnfE1zUHW96jKi6QhGNB1BRk4G+y7tY+9ve9lzcQ+LEhaxIH4BBjEQ4RdBc//mtAxoSYuAFjT0bYizk04NjkgfVU2rBjyMHnSu05nOdToDkJGTQdylOPZe3MvBKwfZ9MsmVh033SfiZnCjqX9TGvs1JsI3ggi/CBr5NcLbxduWVdDKgU74ZWAwGGjZsiW5ubk0bdqUJUuW4OFRtj+Lo6OjGTBgAEOHDuWZZ55hwoQJNGtmebqA7du34+LiQseOHQGYP38+Hh4ePPnkk2Wui1Y9eRg96FinIx3rmP4tKaU4m3qW+MvxJFxO4OCVg3xz6hvSctLMnwnyDKKRbyMifCOo71OfMK8w6nnXI8A9ABGxVVW0UtAJvwzc3d2Ji4sDYMSIEcyfP58JEyaY1+fm5uLsXPpd+/HHH991/fbt26lRo4Y54Y8ePbrU29A0S0SEMO8wwrzDeKjBQ4DpR+C39N84nnyc49eOm59/uvATOTdzzJ/1cPagnnc90+fzfwRCaoQQ7BlMbc/aGJ2MtqqWdhu7Tvjv7n6XI1ePlOt3NqnZhElRk0pcvkuXLhw4cIDt27fz2muv4efnx5EjRzh8+DCTJ09m+/btZGVlMXbsWEaNGoVSiueff57NmzdTt27dQuPod+/enffff5927dqxceNG/vrXv5KXl0dAQAALFy5k/vz5GAwGPv30U+bMmcPWrVupUaMGEydONI/Rn5GRQcOGDVm0aBF+fn50796d++67j23btpGcnMzChQvp0qVLue4zzTGJCME1ggmuEUzX0K7m5Xk387iQfoFfUn7hl5Rf+DX1V35J+YVDVw6x5Zct5Kk8c1kncSLQPdD8A3DrOdgzmCDPIALdA/Fx9dF/IVQSu074tpabm8uGDRvo168fAPv27SMhIYHw8HBiYmLw8fFhz549ZGVl0alTJ/r06cP+/fs5evQohw4d4uLFizRr1oynnnqq0PcmJSXx5z//mR07dhAeHs7Vq1epWbMmo0ePNid4gK1bt5o/8+STTzJnzhy6devG66+/zvTp05k9e7Y5zt27d7N+/XqmT5/Oli1bKmkPaY7I4GQg1CuUUK9QOtXpVGhdTl4O59PPcz7tPBfSL5ifL6Rf4Oekn9l0ZhO5qvCEQEYnI4HugQR4BFDLvRYB7gEEegQS6B5ofvZ398fX1VdfTLaSXe+90pyJl6cbN24QGRkJmM7wn376aXbu3ElUVBTh4eGAadjjAwcOsHLlSgCuX7/O8ePH2bFjB3/6058wGAyEhITQo0ePO75/165ddO3a1fxdNWve/a7J69evk5ycTLdu3QAYOXIkw4YNM68fMmQIAG3btuXMmTPWVV7T7sJoMFLPu16RE7jk3cwj6UYSF9IvcDHjIpczLpN0I4mkjCSSbiRx+vppdv+2m5TsFIuf93bxpqZbTfzc/PB19bX42s/NDz9XP7xdvPE0euq/Hgqw64RvKwXb8AsqOByyUoo5c+YUGh8fYP369RUe3+1cXV0B08Xmsky3qGnlxeBkIMgzqNhxfzJzM7l84zKXb1zmUsYlrmZe5VrmNdNz1jWSM5NJTEsk/nI8yZnJd/zVcIuTOOHl4oW3i/cdz94u3ni7euNl9DI9u3jh5eKFh7MHnkZPPI2eeBg9HOoahE74FaRv377MmzePHj16YDQaOXbsGHXq1KFr167861//YuTIkVy6dIlt27bx2GOF54Pp0KEDY8aM4fTp04WadLy8vEhJufPMx8fHBz8/P77//nu6dOnCsmXLzGf7mmaP3JzdzM1GxVFKkZqTyrXMa78/sq6RkpVCSrbpkZqdan6+mHHR9D4rheyb2cV+v9HJWOgHoNAPgrMHHkbTe3dnd1wNruZnV2dX3AxuuBpccXP+/fn2ZZXZTGXtjFczgYFANnAS+D+l1B3zsonIGSAVyANyi7rt15E888wznDlzhjZt2qCUIjAwkDVr1jB48GD++9//0qxZM8LCwrj//vvv+GxgYCAxMTEMGTKEmzdvUqtWLTZv3szAgQMZOnQoa9euZc6cOYU+s2TJEvNF2wYNGvDJJ59UVlU1zaZExHzGXtq5gLPyskjJ+v0HISU7hYzcDDJyMkjPSTc956bf8T41O5WL6RdJz003Ly94sbo0nMUZV2dXXA2uuBhccHFyIcA9gCUPLinT992NVWPpiEgf4L9KqVwReRdAKXVHw3p+wm+nlLpcmu/XY+lUPXr/a9qdlFLk3MwhMy+TrNws83NWXhY3cm+QlVd4WaFyeVlk5pqes/Oyyb6ZjYezB3/r+LcyxVJhY+kopTYVeLsLGGrN92maptkjETGdnRtcwKX48rZSnjNePQVsKGKdAjaJSKyIPFuO29Q0TdNKqNgzfBHZAli6pP6qUmptfplXgVygqEldOyulzolILUwTnh9RSu0oYnvPAs8ChIVZHsdbKaW7WtlAVR5KW9O04hWb8JVSve62XkSigQFAT1VERlBKnct/viQiq4EowGLCV0rFADFgasO/fb2bmxtXrlzB399fJ/1KpJTiypUruLm52ToUTdPKyNpeOv2AV4BuSqmMIsp4Ak5KqdT8132AN8q6zdDQUBITE0lKSirrV2hl5ObmRmho8d3kNE2rmqztAPoh4IqpmQZgl1JqtIiEAB8rpfoDtYHV+eudgX8rpTaWdYNGo9F8B6qmaZpWctb20mlUxPLzQP/816eAe63ZjqZpmma98uylo2maplVhOuFrmqZVE1bdaVvRRCQJ+KWMHw8ASnVnbxXmKHVxlHqArktV5Cj1AOvqUk8pFWhpRZVO+NYQkb2OMmaPo9TFUeoBui5VkaPUAyquLrpJR9M0rZrQCV/TNK2acOSEH2PrAMqRo9TFUeoBui5VkaPUAyqoLg7bhq9pmqYV5shn+JqmaVoBOuFrmqZVE3af8EWkn4gcFZETIjLZwnpXEfkif/1PIlK/8qMsXgnqES0iSSISl/94xhZxFkdEFonIJRFJKGK9iMg/8+t5QETaVHaMJVWCunQXkesFjsnrlR1jSYlIXRHZJiKHROSgiIy3UKbKH5sS1sMujouIuInIbhH5Ob8u0y2UKd/8pZSy2wdgwDSXbgNM88z8DDS7rcwYYH7+6+HAF7aOu4z1iAY+tHWsJahLV6ANkFDE+v6YJsoRoAPwk61jtqIu3YGvbR1nCesSDLTJf+0FHLPwb6zKH5sS1sMujkv+fq6R/9oI/AR0uK1MueYvez/DjwJOKKVOKaWygeXAoNvKDAJuzQa8EugpVW8g/ZLUwy4o08Q2V+9SZBCwVJnsAnxFJLhyoiudEtTFbiilLiil9uW/TgUOA3VuK1blj00J62EX8vdzWv5bY/7j9l405Zq/7D3h1wHOFnifyJ0H31xGKZULXAf8KyW6kitJPQAeyf9Te6WI1K2c0MpdSetqL+7P/5N8g4g0t3UwJZHfLNAa0xllQXZ1bO5SD7CT4yIiBhGJAy4Bm5VSRR6T8shf9p7wq5P/APWVUq2Azfz+q6/Zzj5M45bcC8wB1tg4nmKJSA1gFfCCUirF1vGUVTH1sJvjopTKU0pFAqFAlIi0qMjt2XvCPwcUPNMNzV9msYyIOAM+wJVKia7kiq2HUuqKUior/+3HQNtKiq28leSY2QWlVMqtP8mVUusBo4gE2DisIomIEVOS/Ewp9ZWFInZxbIqrh70dFwClVDKwDeh326pyzV/2nvD3ABEiEi4iLpguaqy7rcw6YGT+66HAf1X+FZAqpNh63NaW+jCmtkt7tA54Mr9HSAfgulK1ELkNAAABDklEQVTqgq2DKgsRCbrVnioiUZj+P1W1kwnA1AMHWAgcVkrNKqJYlT82JamHvRwXEQkUEd/81+5Ab+DIbcXKNX9ZO8WhTSmlckVkHPAtpp4ui5RSB0XkDWCvUmodpn8cy0TkBKYLcMNtF7FlJazHX0TkYSAXUz2ibRbwXYjI55h6SQSISCIwDdPFKJRS84H1mHqDnAAygP+zTaTFK0FdhgLPiUgucAMYXgVPJm7pBDwBxOe3GQP8FQgDuzo2JamHvRyXYGCJiBgw/Sh9qZT6uiLzlx5aQdM0rZqw9yYdTdM0rYR0wtc0TasmdMLXNE2rJnTC1zRNqyZ0wtc0TasmdMLXNE2rJnTC1zRNqyb+H8wnW4vclZUrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "utFkv4F3NULQ"
      },
      "source": [
        "Since we have initialized the variables of the neural network randomly, it's prediction is also random. In order to fit the model we need to minimize the expected mean squared error over all input-ouput pairs in our training data set. For this we need to create a function, that performs a training step when provided with the model, an optimizer and a batch of input-ouput pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4zFN0-kOdu7",
        "colab": {}
      },
      "source": [
        "\"\"\" For training we need to implement a function that executes one training step. Fill in the missing code pieces for this function.\"\"\"\n",
        "\n",
        "def train_step(model, optimizer, x, y):\n",
        "    y = tf.reshape(y, [-1, 1]) # Reshaping to ensure y.shape = y_pred.shape to prevent wrong broadcasting\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.square(y_pred - y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "    grads = tape.gradient(loss_val, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ax-Kfd-tOm7I"
      },
      "source": [
        "This function uses the GradientTape to record the operations for which gradients have to be calculated. In our case this is the forward pass through our model and the computation of the loss function. After these operations are recoded we can get their gradients and apply these through the use of an optimizer. Finally we return the loss value in order to print it.\n",
        "\n",
        "With the training step function defined we now need to choose a suitable optimizer. Tensorflow offers a wide variety of optimizers but in this exercise we will use the RMSprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PahsqMscPcKD",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.RMSprop(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8_WjHrAwQB9e"
      },
      "source": [
        "We now have everything we need to start training the model. For this we repeatedly sample a batch of input-output pairs from our training data set and use the train_step function to minimize the loss function over this batch. We repeat this until we have iterated over the complete training data set once. After this we compute the loss on the validation data set, print it and repeat with another epoch until we have reached $N\\_epochs$ epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3LqS3d_QrX6",
        "outputId": "b566fc2d-97eb-48b5-947e-e9ef289dc5b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" We can now use the train_step function to perform the training. Fill in the missing code parts.\"\"\"\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_ds:\n",
        "    train_loss += train_step(mdl, opt, x_t, y_t) # Perform a training step with the model \"mdl\" and the optimizer \"opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters == int(N_train_samples/batch_size): # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = mdl(x_v) # Compute a prediction with \"mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0.27207 Validation loss: 0.09653\n",
            "Epoch: 1 Train loss: 0.15441 Validation loss: 0.10493\n",
            "Epoch: 2 Train loss: 0.12611 Validation loss: 0.080325\n",
            "Epoch: 3 Train loss: 0.12021 Validation loss: 0.083434\n",
            "Epoch: 4 Train loss: 0.10796 Validation loss: 0.052595\n",
            "Epoch: 5 Train loss: 0.094702 Validation loss: 0.061393\n",
            "Epoch: 6 Train loss: 0.090064 Validation loss: 0.09087\n",
            "Epoch: 7 Train loss: 0.084773 Validation loss: 0.037398\n",
            "Epoch: 8 Train loss: 0.080517 Validation loss: 0.039037\n",
            "Epoch: 9 Train loss: 0.077089 Validation loss: 0.041347\n",
            "Epoch: 10 Train loss: 0.073165 Validation loss: 0.051984\n",
            "Epoch: 11 Train loss: 0.072477 Validation loss: 0.033797\n",
            "Epoch: 12 Train loss: 0.067822 Validation loss: 0.028401\n",
            "Epoch: 13 Train loss: 0.0609 Validation loss: 0.032525\n",
            "Epoch: 14 Train loss: 0.055267 Validation loss: 0.043709\n",
            "Epoch: 15 Train loss: 0.05094 Validation loss: 0.032858\n",
            "Epoch: 16 Train loss: 0.046363 Validation loss: 0.072367\n",
            "Epoch: 17 Train loss: 0.04384 Validation loss: 0.027105\n",
            "Epoch: 18 Train loss: 0.039645 Validation loss: 0.045709\n",
            "Epoch: 19 Train loss: 0.043087 Validation loss: 0.02851\n",
            "Epoch: 20 Train loss: 0.034861 Validation loss: 0.025124\n",
            "Epoch: 21 Train loss: 0.036588 Validation loss: 0.019646\n",
            "Epoch: 22 Train loss: 0.033858 Validation loss: 0.027236\n",
            "Epoch: 23 Train loss: 0.030269 Validation loss: 0.018398\n",
            "Epoch: 24 Train loss: 0.031991 Validation loss: 0.025142\n",
            "Epoch: 25 Train loss: 0.029639 Validation loss: 0.022344\n",
            "Epoch: 26 Train loss: 0.029887 Validation loss: 0.022664\n",
            "Epoch: 27 Train loss: 0.028146 Validation loss: 0.054689\n",
            "Epoch: 28 Train loss: 0.031945 Validation loss: 0.038204\n",
            "Epoch: 29 Train loss: 0.030051 Validation loss: 0.012966\n",
            "Epoch: 30 Train loss: 0.032652 Validation loss: 0.014797\n",
            "Epoch: 31 Train loss: 0.025874 Validation loss: 0.029876\n",
            "Epoch: 32 Train loss: 0.027712 Validation loss: 0.012913\n",
            "Epoch: 33 Train loss: 0.028383 Validation loss: 0.012113\n",
            "Epoch: 34 Train loss: 0.026973 Validation loss: 0.015297\n",
            "Epoch: 35 Train loss: 0.024138 Validation loss: 0.016338\n",
            "Epoch: 36 Train loss: 0.027422 Validation loss: 0.033774\n",
            "Epoch: 37 Train loss: 0.027172 Validation loss: 0.027166\n",
            "Epoch: 38 Train loss: 0.027622 Validation loss: 0.019115\n",
            "Epoch: 39 Train loss: 0.025325 Validation loss: 0.013365\n",
            "Epoch: 40 Train loss: 0.028532 Validation loss: 0.018868\n",
            "Epoch: 41 Train loss: 0.025945 Validation loss: 0.025063\n",
            "Epoch: 42 Train loss: 0.02514 Validation loss: 0.016437\n",
            "Epoch: 43 Train loss: 0.026375 Validation loss: 0.014926\n",
            "Epoch: 44 Train loss: 0.028304 Validation loss: 0.014003\n",
            "Epoch: 45 Train loss: 0.02555 Validation loss: 0.026948\n",
            "Epoch: 46 Train loss: 0.026016 Validation loss: 0.014548\n",
            "Epoch: 47 Train loss: 0.022318 Validation loss: 0.021047\n",
            "Epoch: 48 Train loss: 0.022207 Validation loss: 0.02068\n",
            "Epoch: 49 Train loss: 0.025291 Validation loss: 0.018568\n",
            "Epoch: 50 Train loss: 0.021015 Validation loss: 0.045548\n",
            "Epoch: 51 Train loss: 0.024217 Validation loss: 0.028948\n",
            "Epoch: 52 Train loss: 0.023529 Validation loss: 0.017045\n",
            "Epoch: 53 Train loss: 0.023698 Validation loss: 0.023658\n",
            "Epoch: 54 Train loss: 0.023397 Validation loss: 0.014656\n",
            "Epoch: 55 Train loss: 0.02201 Validation loss: 0.022616\n",
            "Epoch: 56 Train loss: 0.022292 Validation loss: 0.014625\n",
            "Epoch: 57 Train loss: 0.02375 Validation loss: 0.012014\n",
            "Epoch: 58 Train loss: 0.022745 Validation loss: 0.011481\n",
            "Epoch: 59 Train loss: 0.022972 Validation loss: 0.011241\n",
            "Epoch: 60 Train loss: 0.022155 Validation loss: 0.019895\n",
            "Epoch: 61 Train loss: 0.022557 Validation loss: 0.014357\n",
            "Epoch: 62 Train loss: 0.023009 Validation loss: 0.01692\n",
            "Epoch: 63 Train loss: 0.02312 Validation loss: 0.041525\n",
            "Epoch: 64 Train loss: 0.024974 Validation loss: 0.020235\n",
            "Epoch: 65 Train loss: 0.021023 Validation loss: 0.017744\n",
            "Epoch: 66 Train loss: 0.019244 Validation loss: 0.055348\n",
            "Epoch: 67 Train loss: 0.022697 Validation loss: 0.011261\n",
            "Epoch: 68 Train loss: 0.022071 Validation loss: 0.031023\n",
            "Epoch: 69 Train loss: 0.022217 Validation loss: 0.01261\n",
            "Epoch: 70 Train loss: 0.020932 Validation loss: 0.012519\n",
            "Epoch: 71 Train loss: 0.022334 Validation loss: 0.015274\n",
            "Epoch: 72 Train loss: 0.022555 Validation loss: 0.023642\n",
            "Epoch: 73 Train loss: 0.020829 Validation loss: 0.013089\n",
            "Epoch: 74 Train loss: 0.022326 Validation loss: 0.03667\n",
            "Epoch: 75 Train loss: 0.021358 Validation loss: 0.025554\n",
            "Epoch: 76 Train loss: 0.020753 Validation loss: 0.014665\n",
            "Epoch: 77 Train loss: 0.020283 Validation loss: 0.021248\n",
            "Epoch: 78 Train loss: 0.022274 Validation loss: 0.018501\n",
            "Epoch: 79 Train loss: 0.021606 Validation loss: 0.013458\n",
            "Epoch: 80 Train loss: 0.020166 Validation loss: 0.019503\n",
            "Epoch: 81 Train loss: 0.021168 Validation loss: 0.013651\n",
            "Epoch: 82 Train loss: 0.020234 Validation loss: 0.032462\n",
            "Epoch: 83 Train loss: 0.021809 Validation loss: 0.018832\n",
            "Epoch: 84 Train loss: 0.019539 Validation loss: 0.018271\n",
            "Epoch: 85 Train loss: 0.0222 Validation loss: 0.011644\n",
            "Epoch: 86 Train loss: 0.021803 Validation loss: 0.016195\n",
            "Epoch: 87 Train loss: 0.019862 Validation loss: 0.01482\n",
            "Epoch: 88 Train loss: 0.021004 Validation loss: 0.016522\n",
            "Epoch: 89 Train loss: 0.021642 Validation loss: 0.017903\n",
            "Epoch: 90 Train loss: 0.021389 Validation loss: 0.019457\n",
            "Epoch: 91 Train loss: 0.020636 Validation loss: 0.015443\n",
            "Epoch: 92 Train loss: 0.020519 Validation loss: 0.019337\n",
            "Epoch: 93 Train loss: 0.018701 Validation loss: 0.018007\n",
            "Epoch: 94 Train loss: 0.020037 Validation loss: 0.058429\n",
            "Epoch: 95 Train loss: 0.022748 Validation loss: 0.014526\n",
            "Epoch: 96 Train loss: 0.01917 Validation loss: 0.020824\n",
            "Epoch: 97 Train loss: 0.020034 Validation loss: 0.032517\n",
            "Epoch: 98 Train loss: 0.019867 Validation loss: 0.018762\n",
            "Epoch: 99 Train loss: 0.020109 Validation loss: 0.014835\n",
            "Epoch: 100 Train loss: 0.020131 Validation loss: 0.020127\n",
            "Epoch: 101 Train loss: 0.020549 Validation loss: 0.023704\n",
            "Epoch: 102 Train loss: 0.02138 Validation loss: 0.012023\n",
            "Epoch: 103 Train loss: 0.019636 Validation loss: 0.020517\n",
            "Epoch: 104 Train loss: 0.020585 Validation loss: 0.016057\n",
            "Epoch: 105 Train loss: 0.018836 Validation loss: 0.014797\n",
            "Epoch: 106 Train loss: 0.021786 Validation loss: 0.017887\n",
            "Epoch: 107 Train loss: 0.022298 Validation loss: 0.011244\n",
            "Epoch: 108 Train loss: 0.018785 Validation loss: 0.020423\n",
            "Epoch: 109 Train loss: 0.01953 Validation loss: 0.020125\n",
            "Epoch: 110 Train loss: 0.019447 Validation loss: 0.013664\n",
            "Epoch: 111 Train loss: 0.018489 Validation loss: 0.017688\n",
            "Epoch: 112 Train loss: 0.018996 Validation loss: 0.015285\n",
            "Epoch: 113 Train loss: 0.019779 Validation loss: 0.02284\n",
            "Epoch: 114 Train loss: 0.020613 Validation loss: 0.01203\n",
            "Epoch: 115 Train loss: 0.020459 Validation loss: 0.018805\n",
            "Epoch: 116 Train loss: 0.02031 Validation loss: 0.012156\n",
            "Epoch: 117 Train loss: 0.019411 Validation loss: 0.035371\n",
            "Epoch: 118 Train loss: 0.019604 Validation loss: 0.012425\n",
            "Epoch: 119 Train loss: 0.018723 Validation loss: 0.024662\n",
            "Epoch: 120 Train loss: 0.018066 Validation loss: 0.01121\n",
            "Epoch: 121 Train loss: 0.01988 Validation loss: 0.012307\n",
            "Epoch: 122 Train loss: 0.020607 Validation loss: 0.01136\n",
            "Epoch: 123 Train loss: 0.019676 Validation loss: 0.014014\n",
            "Epoch: 124 Train loss: 0.018725 Validation loss: 0.025527\n",
            "Epoch: 125 Train loss: 0.017048 Validation loss: 0.020196\n",
            "Epoch: 126 Train loss: 0.022139 Validation loss: 0.012927\n",
            "Epoch: 127 Train loss: 0.01817 Validation loss: 0.017531\n",
            "Epoch: 128 Train loss: 0.020626 Validation loss: 0.015227\n",
            "Epoch: 129 Train loss: 0.019373 Validation loss: 0.013684\n",
            "Epoch: 130 Train loss: 0.019482 Validation loss: 0.025106\n",
            "Epoch: 131 Train loss: 0.018573 Validation loss: 0.025932\n",
            "Epoch: 132 Train loss: 0.020406 Validation loss: 0.014734\n",
            "Epoch: 133 Train loss: 0.018876 Validation loss: 0.012715\n",
            "Epoch: 134 Train loss: 0.018346 Validation loss: 0.026565\n",
            "Epoch: 135 Train loss: 0.018596 Validation loss: 0.016018\n",
            "Epoch: 136 Train loss: 0.019219 Validation loss: 0.016488\n",
            "Epoch: 137 Train loss: 0.018617 Validation loss: 0.016393\n",
            "Epoch: 138 Train loss: 0.019847 Validation loss: 0.021195\n",
            "Epoch: 139 Train loss: 0.019607 Validation loss: 0.011906\n",
            "Epoch: 140 Train loss: 0.019229 Validation loss: 0.016503\n",
            "Epoch: 141 Train loss: 0.018987 Validation loss: 0.027648\n",
            "Epoch: 142 Train loss: 0.01908 Validation loss: 0.027801\n",
            "Epoch: 143 Train loss: 0.018038 Validation loss: 0.024684\n",
            "Epoch: 144 Train loss: 0.019035 Validation loss: 0.016173\n",
            "Epoch: 145 Train loss: 0.019399 Validation loss: 0.012815\n",
            "Epoch: 146 Train loss: 0.018797 Validation loss: 0.011864\n",
            "Epoch: 147 Train loss: 0.018808 Validation loss: 0.012265\n",
            "Epoch: 148 Train loss: 0.019803 Validation loss: 0.015393\n",
            "Epoch: 149 Train loss: 0.01952 Validation loss: 0.01153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DduaR_pCQ0k-"
      },
      "source": [
        "After completion of the training process we use the test data set to test the models generalization to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ofClNnHRAUy",
        "outputId": "57879ccd-f2f7-4966-df1e-9c407b10f999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss = 0.0\n",
        "for x_t, y_t in test_ds:\n",
        "    y_pred = mdl(x_t) # Compute a prediction with \"mdl\" on the input \"x_t\"\n",
        "    test_loss += float(tf.square(y_pred - y_t)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_t\"\n",
        "print(\"Test loss: {:.5}\".format(test_loss/N_test_samples))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.010748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzJ7wOZmRbez"
      },
      "source": [
        "After we have verified that our model achieves a similar loss on the test as on the validation and training data set, we can conclude that our model is not overfitting or underfitting and generalizes to unseen data. We can now predict on the inputs again and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyvFN03bR8ez",
        "outputId": "7cb4c565-c3e4-4e43-d536-411c7cc1e91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" Now we want to plot the prediction after training. Predict on the variable \"x\" again. \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WKmuAAmLSmiR"
      },
      "source": [
        "Now our model has learned to approximate the function mapping from the input to the output. The capability of neural networks to learn from input-ouput pairs alone and approximate an arbitrary function, see universal approximation theorem, can be very useful if the mapping between the input and output is too complex to be captured with model based approaches. But learning from input-ouput pairs alone implies that the model will only be able to make accurate predictions over input ranges it has seen during training. In order to demonstrate this we will predict on an interval that exeeds the $\\left[0,3\\right]$ interval the model was trained on, i.e. we will predict on the interval $\\left[-2,5\\right]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRF8hAmmVFcH",
        "outputId": "3550c169-89ad-467a-b03a-bd62eaaf989a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x_generalize = np.linspace(-2.0, 5.0, N_samples, dtype=np.float32)\n",
        "y_generalize = np.sin(1.0+x_generalize*x_generalize) + noise_sig*np.random.randn(N_samples).astype(np.float32)\n",
        "y_truey_generalize = np.sin(1.0+x_generalize*x_generalize)\n",
        "y_pred = mdl(x_generalize)\n",
        "plt.plot(x_generalize, y_generalize)\n",
        "plt.plot(x_generalize, y_truey_generalize)\n",
        "plt.plot(x_generalize, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3zV1fnH3+d7d/YmCUlIGAHChjAUGbIERVoR6qgCrdVStdXaWrW1jtphq78OrXtW66oL3IgIIkPZQoBAAoSQRfbOnd/z++OSSCQJGTcJSc779coryfee8dyb3M99vs95znOElBKFQqFQ9Fy07jZAoVAoFB1DCblCoVD0cJSQKxQKRQ9HCblCoVD0cJSQKxQKRQ/H2B2TRkREyMTExO6YWqFQKHosO3fuLJZSRn73ercIeWJiIjt27OiOqRUKhaLHIoQ43tR1FVpRKBSKHo4ScoVCoejhKCFXKBSKHk63xMgVCsW5jcvlIicnB7vd3t2m9EmsVitxcXGYTKZWtVdCrlAoziAnJ4fAwEASExMRQnS3OX0KKSUlJSXk5OSQlJTUqj4qtKJQKM7AbrcTHh6uRLwbEEIQHh7eprshJeQKhaJJlIh3H2197VVopQcjpSS/Jp/DZYc5UXWCalc1/kZ/4gLjmBQ9iQBzQHebqFAougAl5D0Ml+7iq7yv+CLnCzblbiK3OrfJdmbNzBXDruDGMTcqQVf0WHJycrjppps4cOAAuq6zcOFCHnroIV599VV27NjBv//97261b9WqVSQnJ5OSkgLAPffcw/Tp05kzZ06X2qGEvIdwuOwwqzNX8+HRDymxl2Az2pgcM5nlI5YzPGw4iUGJBJgDqHHVkFGWweojq3nl4Ctsyd3Csxc9S4QtorufgkLRJqSULF68mJ/97GesXr0aj8fDDTfcwO9+9ztGjBjh8/ncbjdGY9skcdWqVSxcuLBByP/whz/43K5WIaXs8q8JEyZIxdkpt5fLVw68Ipe+t1SOfHGkHPvSWHnr57fKz49/Lh1ux1n7b83bKlNfTpVXf3i1dHlcXWCxordw4MCB7jZBfvbZZ3LatGmNrlVUVMiwsDD52GOPyUWLFskZM2bIwYMHy/vuu09KKWV1dbW8+OKL5ejRo+WIESPk66+/LqWUcseOHXL69Oly/Pjxct68eTIvL09KKeWMGTPkLbfcIidMmCDvu+8+mZCQID0eT8NYcXFx0ul0yqefflqmpqbK0aNHy8WLF8uamhq5efNmGRoaKhMTE+WYMWNkZmamXL58uXzzzTcb7B87dqwcOXKk/NGPfiTtdruUUsoBAwbIe+65R44bN06OHDlSHjx4sMnn39TfANghm9BU5ZGfY+hS56v8r3g3413WZa/DpbsYHjacOyfdycVJFxNqDW31WFNipnD/+fdzx5d38MrBV1g+YnknWq7ordz//n4O5FX6dMyU2CDuvbRlr3r//v1MmDCh0bWgoCASEhJwu91s27aNtLQ0/Pz8mDhxIpdccgnHjx8nNjaWDz/8EICKigpcLhc///nPWb16NZGRkbzxxhv87ne/4/nnnwfA6XQ21H7atWsXX3zxBRdeeCEffPABF110ESaTicWLF3P99dcDcPfdd/Pcc8/x85//nEWLFrFw4UKWLFnSyE673c6KFStYt24dycnJLFu2jCeeeIJbb70VgIiICHbt2sXjjz/Oww8/zLPPPtuh17PDWStCCKsQYpsQ4hshxH4hxP0dHbOvIaXkQMkB/rXrX8x/ez4/XftTtuRtYWnyUt689E3+d+n/+OHwH7ZJxOtZkLSA82PP5/m056lz13WC9QpF9zB37lzCw8Ox2WwsXryYTZs2MWrUKNauXcsdd9zBl19+SXBwMIcOHSItLY25c+cyduxY/vjHP5KTk9MwzhVXXNHo5zfeeAOA119/veGxtLQ0pk2bxqhRo3jllVfYv39/i7YdOnSIpKQkkpOTAVi+fDkbN25seHzx4sUATJgwgaysrA6/Fr7wyB3ALClltRDCBGwSQnwspfzKB2P3Wmpdtewu3M3WvK18lv0ZudW5GISByTGTuW3CbVyYcCEWg6XD8wghuGH0Daz4ZAUfHv2QJclLzt5JoTiNs3nOnUVKSgpvvfVWo2uVlZVkZ2djNBrPSNETQpCcnMyuXbv46KOPuPvuu5k9ezaXXXYZI0aMYOvWrU3O4+/v3/DzokWL+O1vf0tpaSk7d+5k1qxZAKxYsYJVq1YxZswYXnzxRTZs2NCh52axeN/bBoMBt9vdobHAB0J+Km5TfepX06kv2dFxexN17jqyK7M5WHqQ9NJ0DpQcYF/xPty6G6NmZErMFH46+qdcGH8hIdYQn88/Pmo8iUGJfHzsYyXkih7D7NmzufPOO3nppZdYtmwZHo+HX/3qV6xYsQI/Pz/Wrl1LaWkpNpuNVatW8fzzz5OXl0dYWBjXXHMNISEhPPvss9x5550UFRWxdetWzjvvPFwuF4cPH25ywTQgIICJEydyyy23sHDhQgwGAwBVVVXExMTgcrl45ZVX6N+/PwCBgYFUVVWdMc7QoUPJysoiMzOTwYMH8/LLLzNjxoxOe618EiMXQhiAncBg4DEp5ddNtLkBuAEgISHBF9P6FI/uweFx4PQ4sXvsOD1OHB7Ht1/uU9/1037+zpfT48Tu9vatcdVQUFtAfnU+ZY6yhnlsRhtDQ4dybcq1TImewrh+47AZbZ363IQQzE+az1PfPEVxXbHKYFH0CIQQvPvuu9x444088MAD6LrOxRdfzJ///Gdee+01Jk2axOWXX05OTg7XXHMNqamprFmzhttvvx1N0zCZTDzxxBOYzWbeeustfvGLX1BRUYHb7ebWW29tNvPliiuuYOnSpY287gceeIDJkycTGRnJ5MmTG8T7yiuv5Prrr+eRRx5pdPdgtVp54YUXWLp0KW63m4kTJ7Jy5crOe628DrWPBhMiBHgX+LmUMq25dqmpqbI9B0scrThKblVuI7Ft+O62nyHELQry6eLrsePWO3Z7YzFYMBvMWAwWLAYLNqONfv79iPWPJTYglriAOIaGDSUhMAGDZujQXO0hrTiNqz68ioemP8T8pPldPr+iZ3Hw4EGGDx/e3Wb0aZr6GwghdkopU7/b1qdZK1LKciHEemA+0KyQt5dXD77KG4feaPZxTWgNQlr/ZTaYsRqsmA1mAkwBhFnDGn5v1NZoOaNvc4+dPqbVaMWkmdDEuV3tYFjYMPxN/uw4uUMJuULRy+iwkAshIgHXKRG3AXOBv3bYsiZYlrKMSwdd2qwQG8WZCyAKL0bNyNiosewoUEfsKRS9DV945DHAf07FyTXgf1LKD3ww7hkkBCWQwLkXX+8pjI4YzZbcLdS56zo9Lq9QKLoOX2St7AXG+cAWRSczJHQIEsnRiqOMCO+elDKFQuF7zu3ArsKnDA4ZDEBGWUY3W6JQKHyJEvI+REJgAhaDRQm5QtHLUELehzBoBpKCkzhacbS7TVEoWqSkpISxY8cyduxYoqOj6d+/f8PvTqfTp3OVl5fz+OOP+3TMrkYJeR8j1j+W/Or87jZDoWiR8PBw9uzZw549e1i5ciW//OUvG343m83N9mvPdncl5IoeR2xALHk1efhyI5hC0RU888wzTJw4kTFjxnD55ZdTW1sLeOugrFy5ksmTJ/Ob3/yGI0eOMGXKFEaNGsXdd99NQMC3B6s89NBDTJw4kdGjR3PvvfcCcOedd3LkyBHGjh3L7bff3i3PraOoMrZ9jP4B/alz11HuKG9XNUVFH+TjO6Fgn2/HjB4FCx5sU5fmSsmC9yShLVu2YDAYWLhwIbfccgtXXXUVTz75ZEP/Tz/9lIyMDLZt24aUkkWLFrFx40YefPBB0tLS2LNnj++eXxejPPI+RmxALAB51XndbIlC0TZaKiW7dOnShgJXW7duZenSpQBcffXVDW0+/fRTPv30U8aNG8f48eNJT08nI6N3LPwrj7yP0T/AW7UttzqXEREql1zRCtroOXcWLZWSPb0UbXNIKbnrrrv46U9/2ui6L+qBdzfKI+9jRPtHA5BfoxY8FT2L75aSbY4pU6bw9ttvA97DIeq56KKLeP7556mu9lbdzs3NpbCwsNlStD0JJeR9jCBzEGbNTEldSXebolC0ifpSslOnTmXYsGHNtvvnP//J3//+d0aPHk1mZibBwcEAzJs3j6uvvprzzjuPUaNGsWTJEqqqqggPD2fq1KmMHDmyxy52+rSMbWtpbxlbhW+Y99Y8JkZP5E8X/Km7TVGco/TkMra1tbXYbDaEELz++uu89tprrF69urvNajPdVsZW0TMIt4Yrj1zRa9m5cyc333wzUkpCQkIaDlnuzSgh74OE28I5WXuyu81QKDqFadOm8c0333S3GV2KipH3QSJsERTXFXe3GQqFwkcoIe+DhFnDKLOXoUu9u01RKBQ+QAl5HyTcFo5Heih3lHe3KQqFwgcoIe+DhNvCAdSCp0LRS1BC3gcJs4QBKI9ccU5jMBgYO3YsI0eOZOnSpQ1FstrDihUreOuttwD4yU9+woEDB5ptu2HDBrZs2dLw+5NPPslLL73U7rm7AiXkfZAgSxAAlY7KbrZEoWgem83Gnj17SEtLw2w2NyqABe0rWQvw7LPPkpKS0uzj3xXylStXsmzZsnbN1VUoIe+DBJu9O90qnBXdbIlC0TqmTZtGZmYmGzZsYNq0aSxatIiUlBQ8Hg+33357Q2nap556CvDWVbn55psZOnQoc+bMobCwsGGsmTNnUr8h8ZNPPmH8+PGMGTOG2bNnk5WVxZNPPsk//vEPxo4dy5dffsl9993Hww8/DMCePXuYMmUKo0eP5rLLLqOsrKxhzDvuuINJkyaRnJzMl19+2aWvj8oj74MEW04JuUMJueLs/HXbX0kvTffpmMPChnHHpDta1dbtdvPxxx8zf/58AHbt2kVaWhpJSUk8/fTTBAcHs337dhwOB1OnTmXevHns3r2bQ4cOceDAAU6ePElKSgo//vGPG41bVFTE9ddfz8aNG0lKSqK0tJSwsDBWrlxJQEAAv/71rwFYt25dQ59ly5bx6KOPMmPGDO655x7uv/9+/vnPfzbYuW3bNj766CPuv/9+PvvsM1+8VK1CCXkfxGa0YdSMSsgV5zR1dXWMHTsW8Hrk1113HVu2bGHSpEkkJSUB3tK0e/fubYh/V1RUkJGRwcaNG7nqqqswGAzExsYya9asM8b/6quvmD59esNYYWFhLdpTUVFBeXk5M2bMAGD58uUN5XLBWy8dYMKECV1eUVEJeR9ECEGwOViFVhStorWes6+pj5F/l9NL1kopefTRR7nooosatfnoo4863b7vYrFYAO8ibXvj9+1Fxcj7KMGWYOWRK3o8F110EU888QQulwuAw4cPU1NTw/Tp03njjTfweDzk5+ezfv36M/pOmTKFjRs3cuzYMQBKS0sBmi1rGxwcTGhoaEP8++WXX27wzrsb5ZH3UYLMQSprRdHj+clPfkJWVhbjx49HSklkZCSrVq3isssu4/PPPyclJYWEhATOO++8M/pGRkby9NNPs3jxYnRdJyoqirVr13LppZeyZMkSVq9ezaOPPtqoz3/+8x9WrlxJbW0tAwcO5IUXXuiqp9oiqoxtH+XmdTdzsvYkb176ZnebojgH6cllbHsLbSljq0IrfRQVWlEoeg9KyPsoQeYgJeQKRS9BCXkfJcgcRK27Frfetavrip5Dd4RdFV7a+tp3WMiFEPFCiPVCiANCiP1CiFs6Oqai86nfpl/trO5mSxTnIlarlZKSEiXm3YCUkpKSEqxWa6v7+CJrxQ38Skq5SwgRCOwUQqyVUjZflUbR7QSaAwGoclYRYg3pZmsU5xpxcXHk5ORQVFTU3ab0SaxWK3Fxca1u32Ehl1LmA/mnfq4SQhwE+gNKyM9hAk1eIa90qhRExZmYTKaGHY+Kcx+fxsiFEInAOODrJh67QQixQwixQ33Kdz/1HrkScoWi5+MzIRdCBABvA7dKKc9QBynl01LKVCllamRkpK+mVbST00MrCoWiZ+MTIRdCmPCK+CtSynd8Maaicwkyexc7lZArFD0fX2StCOA54KCU8u8dN0nRFSiPXKHoPfjCI58KXAvMEkLsOfV1sQ/GVXQi/iZ/NKGpGLlC0QvwRdbKJkD4wBZFFyKEINAcqDxyhaIXoHZ29mECTYFUuZSQKxQ9HSXkfZhAc6AqZatQ9AKUkPdhgsxBKrSiUPQClJD3YVSMXKHoHSgh78MoIVcoegdKyPswQeYgtdipUPQClJD3YQLNgdS563B5XN1tikKh6ABKyPswDbs7lVeuUPRolJD3YdQ2fYWid6CEvA9TXzhL5ZIrFD0bJeR9GOWRKxS9AyXkfZgGj9ylPHKFoiejhLwPozxyhaJ3oIS8D6OEXKHoHSgh78PYjDaMwqiEXKHo4Sgh78OomuQKRe9ACXkfJ9AcqE4JUih6OErI+zhKyBWKno8S8j6OqkmuUPR8lJD3cdQpQQpFz0cJeR8n1BpKmaOsu81QKBQdQAl5HyfCFkGFowKnx9ndpigUinaihLyPE2mLBKC4rribLVEoFO1FCXkvoaDCzl3v7MPp1tvUL9LPK+RFdUWdYZZCoegClJD3Eu5ZncZr27LZcKiwTf3qPfKiWiXkCkVPRQn5OUil3UVJtaNNfYTwfvfosk39fOGRX/HUVv7v00Pt7t8S35wo5+N9+Z0ydm/kyS+OsHpPLvtyKnj2y6PdbY6iizB2twGKM7ngwc+ptLvJevCSJh+vtLtwuXXCAywN1wyaV8k9sm1CHmoJRRNahzzyr4+V8vWxUn41b2i7x2iO7z22GYA/XTYSt0ey/PxEn8/Rm3jw43QAAixGqh1urp6cgJ9Zvc17O8ojP4f46mgJz206RqXdDcCj6zKoqD3zYOSL/rGRCX/8rNE17ZRL3laP3KAZiLBGUFjbtpBMa5BS8tCadNJyKxquFVbZm3xO3+V/20806ve7d9O49739Prext2I1ed/ah09Wd7Mliq5AfVR3IXaXB5NBw6AJCivtpBdUsez5bfxqbjLldS6e23SsUfv/W3uYnLI6/rpkdKPr+RV2AJxuHbPR+4Y1au0TcoABwQM4WuH723C7S+ex9Ud4bP0Rnl+Ryqxh/Zj0p3VYTRrpDyw4o73bo/PI55l8cbiIb06U+9ye3sy2Y6Xc8fbeht+Lq73ppMdLahgbH9JdZrWI26Mz8r413L9oBFdMTOhuc3o0PvHIhRDPCyEKhRBpvhivtzLs959w+1vf8P43eUz68zpe/uo44BXs74p4PTVOd7PjbT1awt8+SefhNYdYtScPAHc7hDw5NJnM8kx02XTGi9Otc+MrO0kvaNsO0NrTbP/xizsafra7Gs9z33v7eXd3DmsPnOSRdRktivhTXxyhzulpkx19gTvf3sux4pozrlfa3XyZUcRNr+zqBqtaptrhxu7Sue+9A91mg65LpJTsy6ngD+8fYHtWabfZ0hF85ZG/CPwbeMlH4/U63B6veL2zK5eMU7e7aw+cPGs/s0FDSsnjG46QX1HH4vFxDY8tf37bGe3104Tco0sG/fYjfjFrMLe1EL8eEjKEOncduVW5xAfFn/F4ZmE1H+0rYOPhYqodbl6+bhLThkQ2O57D7WH1njzOGxje6PqHe79dtNydXcaw6CAyCqt4cUsWAH/43ohmx6znLx+nU+1wd0o8viei6xKPlBRU2pt8vMru4trnvP8n//LoGA3nTjS15tQHst7GdR1fct1/trM3p4KSGu8dzPObjzW7NnUu4xMhl1JuFEIk+mKs3sQLm49x//sHePtn5zGkX2DD9bK8DBZr6QzU8ukvivHDgRUntViolP4UEMpRPYajMhaLiOL9vfk8tMabFfL6thMtzulw63ySlk9RtZPvjY0F4JHPM7nugoEE+5ma7DMkdAgAh8sONynk2qn3frXD62E/vOYQ04ZEcu1zX/Nlxrcbib45Uc6Y+BAe+zyTRz7P5NY5QxqNc9OrXq9QQ+fWJ97h4qgyxlgK+IMxi3BRge0jJ8+YNByYKJBhZMlodutDOCgT0E+7edyd/a3H7nB7eOWrbK6enIDVZGjxtemNrHhxOxsPF+Fvloz1X8d0wx5i7DbedM1ll0zmpS3HEQKk9P5vnCtCLqVkzScf8ITpKQ7LOIbc6eTRayYzf2R0l9ngcHtYf6iIISKH+0zvsE9P4mnPQv7y8UHuWjC8y+zwBV0WIxdC3ADcAJCQ0DvjYTuPlzIg3J+IAAv//jyDhz89DMCNr+zi/eVDuMmwissNGxmoFQDgkgbyZRg1WHFgIoYSgrUaIqjAYPR6Ka4DJvalDeBu4xC26cP4mpFUYGvWhjqXh5X/9QpmclRAw/XnNh/jxpmDmhS75NBkrAYrXxd8zewBswHvG23tgZPMGBrZcAdRz/HSWk5W2huJOHgzTD67bQZFp1InX97qDR2h1THAsp9Bln30M50g0FhMjUGnWAjWIHDEGhG6EbNuwF+XjDQbGFa5n8uctYTrOiUykA88U3jDcyEHZCKbMoupsrsItJpYtTuXP3xwgEq7i1vnJLf6b9Vb2Hi4CIPfUQJiX+SIyckRIMytc3/RX1lduYJ3K6c1tHW4dfwtzY/VFby0NYt7Vu/nPwvM/PDgSuyamQViO5FU8Mb2GOLDbARaTCSE+3WqHVJKntxwFH/qeMn8IJGUc6nhK6rx46kvhBLy5pBSPg08DZCamtp991KdhJSSy5/YSlKEP5/+cnqDiAdTzY2OVwl++hNuN7nZ6knhJdc8tugjOCpjcJ/2Jzh/UDhbjpRgxsVQczHDjPkMcqYzXsvgGsNn/MT4MW6psVsO5kvPaDbqo9krBzbyVrcf+zbGd8XTXzX8/Mb2bB5Zl8H6X88kKcIf8N4x+JuNDO4XwLS4aXxw9ANWjr6R/Tkuqu1ufvbKLobHBHEwv3Fs3OnWKapqOs99f14FlfpxwkPXEuJ/AEtsMVVGD6VAvWVG3R+jx4JHt+CUFsIDbdjddqpd1QhDHauFB/zDgDD8nP6MqJMsr93Ce/a1fO6ZwEPuK8ivsGMxGiio8Nqx83gZUkpEfUJ9L2fV7lweWZeBwZaFf/yzRLkdnJ8fzX/c8zEO2swvojX+xX9Ir0jgoBwAeD3Q7uae1fsByeCv76aCAC5yPMhPjR+w0vgBhdoPuOQRbxpsZ4c3vswo5h+fHeZHhg3EiFIWO+7jLtOr3GhczRuemZ06d2egslZ8RH3Y4VhxDftOpc3N1XbwV9PThFDDW57pPOFZxDEZ06jfuIQQdmd7QxK3zklmy5GtODERPXgsifEzefBUSMWEm3Eig+mGvUzT9nGr8W1uE29RLv3Zoo9gsz6SzfoI1qVL4EwxO1npFbzNmcWE+ZsJtpm4//1vF5nu/N73Wetcy9Xv/I70fQsaxviuiIPXs3N8pxRAoDWDmOCN/H3XcUoNTogGk8vN6DodzRFBsWMwh+xjKHAngm5uZOMd3x9JTmktT208Cuhs+u140kuO8rM338ftd4xtAcfYHhyOzR3NssosXq/8LVWb8xm3awI1bu+H2JcZxby09XifyDN3e3RufWMPaHYCB75KrNvNvbkGPk/9F+kLx7D5SC4rP1vG76J0/uJ4huV1DwACh6tt5Rs6i/O0A/SvTec37uspI4hH3ZdxhWEDFxa+zD+5qQstkVxl+Jw9+iB2yWSedi/kGfPfmantARZ1oR0dRwm5jyg/LTe6sKyK+40vsNy4ln16Ile77iZdNh1Oig6yAmAzaQyL+TaObnd5mDO8X0Ns3IWRbXI429zDeZgrCKWSC7Q0pmn7mGpI42KDd0ErR0awxTOCTfpIduhDySOc00Xz7lVp3L3qzOSiioooLo67lo9yXsYaV4Q9bynoTd/eenSJu6aMmYbthAV9xbGQXDKtUCQlE+ucJFaFUlUzkt3OVFbJOORZkqMCLUaCbPXxe424oP7EBfXnh8PCvAuhwoUx4BAJQ9J4yriH/wQHcNuxZ3hW+4ib+CWlBAHw/jd5fULIc8rqADCHbwBjJX/LL+T3jrsZdepDbUhUODW51yAG/oPPw8uZl7eDT/WJZ3z4dhfXGtZSIgNZ7ZkKQA02vgxcwCXVbxPGtQ1/z87EZjYwWOSSrOXyO9ePAdigj6VS2pij7aLa4SbA0nPk0SeWCiFeA2YCEUKIHOBeKeVzvhi7p1BR5xVyG3bGbr6JaONGnnFfzPPWZeQ7m38DRQd7hdygCYKsJl69fjJXP/M1dU4Pyf0CuGpSPK81scBZRhDv6+fzvn4+uCWJooALtDTO1/Yzz7CDHxi/AKBYBrFXH8g+OZBMPZYsGc1x2Y9K/BuNl1Vcw7yUq3lnRxmWfh/jP/CfOE5eiqlqMPGimHhRSLLIZYR2jHBTFpvXOjgyyJ+dBgPRTsG1Yjjzh13JkncFTppeVK3nZzMH8cSGIw2/B1qNFLdUkkCacFeNZPXlt3Ow9CA/ePNu/hwhSQmo4MmT93BX3e0ckf0bNkUBlNY48TMbeuUCaFZJDcJQgyVsM7NrHOTXjuYbOZiIcm/mSmSABd0ZhanmAlYHbOSP1o/4tHbiORFa8aeO2dpuXvXMwoEZgEN/nM8//2tnUfWbXGL4ipc987C7PJ36t3N7JDO0bwBY7xkLeJ2ljfoYZht28/WRImanxLQ0xDmFr7JWrvLFOD2R4yU1FFc7qXN6sGHnZfODRBVmcpfrOq6/9Q9U78njX+symu1f75HXb+QJtHhFsNbpQQjBXxaP5lfzhpJ6aifnjORIvjhcRHK/AAIsRnZllwOCLBlDlieG/3rmoqEz1phNisxgtDjKaO0oM7RvGhZQAaqllXICKJMBVEp/PIc0UioDeb66kiI3vBhZwbG4Vxhnt3NRTS2Rbg+5JiOvW4PYa7MghJWAqjhcpbPIqB3GdYtHM3pSAqsTKlnwry/PeJ7J/QLoF2Tly4xiLMbGHnqg1cTUQRG8sDmLz26b0XD9tnnJTE4K4/zBERwtqsZo0BgVOYIF4ffy3pGPSI9+m1viHNxV9CD/LL8LIcIa+o5/YC2pA0J562fnt/Eveu5TaXdjCt0CwsXPy0t4ut/dRFVY+OmMQQAIIXhz5XlYrSO5ds0mDl46m8AAACAASURBVIacZEhdTrd75HaXh9nabizCxYeeyay+aSpGg8BiNFAeNIQjegyztd287JnHPavT+NuSMZ1mi9OjM0Pby2G9P3lENFz/Qh/NQsNXlBxPg74m5H2ZGQ9tAODRpSk8ZfoH40QGNzpv4RN9EncGWPC3NPYqnr52Aje8vLPh99PrpYD3lg+82Sf1RJzW5pErxzHmD59y8agYrp6cwKQ/rTvDJh2NC6bP4T9bh/DfOhc/uSCJlzcdIkEUkiTySRQF9BPlhIhqQqgmSNSgIZEOgb+wI+0B/PiEHxuD3HwVUsXucGvD2B5HFO7iUbjKJ1HhDm64Xp/WFhfqzai5cGgks4f345opA8ivqCMm2Maj6zL4MqMYl6exoJiNGnNS+pH5pwWN0uOCrCYWjPK+mcYlhDZcf3jpGOI+s/Hol/FocS/w+36F/Er7Kzs9DzUad8fx3nnyUbXdgSlkB+PqdModSRQFDGfbzRMbtZmY6F0sHh4wkQ/cW7nW8BkO1+XdY/ApymtdzDB8Q4kM5Nof/IAxp+04La1x8oU+hqsN67DgZG9ORQsjdRyXy81kLZNVp8I7AGPigtmZ6818CinZA8ztVBt8iRJynyAZsPk3jDbs43bXDXyiTwLAZjJg+07BokGnUgIjAsz8et7Qhg089Z55fJiNIVEB3L0wpVG/F340EadbJ9jPRNr9F+FnMjTs+jQZBC5P40SgW+ckMywmiFtf38PI/sE4MJMh48iQ324oqs8vrudnwxuHPCgBSiTCWIkw1CDdQUjPtymNp2MyeMMagVYTe+6ZS7DN1JBBEhPsFXfTKU/8uzXT6/u2NsdZ0wRBNhPSFUZZ1s8ZlPwiD0Ud5abSe8A+mx+9lt6qcXoqhyp2o5kquLqslNc917S403VyzKU8V72NiMBdOJzdewpUWY2DqVoajvhpfG9c4/0K108byKMHx/Bj4ydM0tIpN0xrZhTfcDR9N3NEHXv0wQ3XZg/vx99zyimTAUSW7/HpfNUONx/tzWdpalynZFadG7sDejg/NnzC6NJPecj1A948LXXJZBD4nRbnu/fSFAZG+PP7hSm8d/MFXDkpgSCbV+jPH+S9vbMYDay9bQYzkhvvnLxwaBQXjfBulgiwGNE0ge3U2JeM+vYWcGi/QBaOjkHTBBePiuHwnxY08ujrCbIamXDKy70i1fumKjhVw2VuSr/TWgqkOxjdEdukiNePbdS+/VcK8TM3+c9qOiXULo/kg59fwI0zB/Hbi4eREtP2xa36OxekmcsSHyRBT+LxUMm6t67gi0Nn3zHbk9lX8TlWj8YFdvjQM4VaV/NCfl7M+ZjcFjYFSPxO7mi2XVfgLEgnWpRR03/qGY+lJoaxQ0/GIwWp2uEzwm8+tcOtc3jXBgCuu3IJl4+P44/fH3mqbpFglz6E2CrfVhu5/739PPLOOiqf/T7k7jx7hzaihLyDTBTp/Nb4Cms8qbxgWNzoMSFEQ4jkyonx/GhqEkIIrrsgidgQr5d60Yho3lx5HktT484Y+2wYDRpf/3Y2f1syhpevm8QLKyay5pfT+ffV4xu1axA94K4FwwCwmgwNW6OTIr0Ln+9/463X4neq/R++N4Idd89p0YYwf9MpW87uZVw8KppQPxM/nJzAyP7B/Gb+MG6YPqhdHor5NO99QFgw48LuI8wRzJ2ubJb4v9rw2JbM3nWEnVt3c7xuO7Nra6hJvIRarNhb8Mijg/xxVI1gk5+N0BMfdqGlZ2LN8a6dOBOmN/l4DTbSZQITxKGGYnCdwf68CsaKTCqljcD+w/m/H4zhmikDGpyngzKBcHs2+477ziEoqLSTLE4QnLsBdN+vVSgh7wj2Ch4xP0a2jOKpsF/zk2mDzmhSf9sbHmBucgghBBMTw9p9u9UvyIrZqDFtSCQXDotqso3faUJ+3QVJzBnej8d/OJ76sixh/l7b6gtu1XtDJoNGoPXb0NAD3xvB3JR+jTZr1IdNWlMuIybYxu575jUqV9Be6uuvA4zqH0xUQCDHs39OmGZld+weUgzeHPmrn/26w3OdS+wu3I1T1jK7thr70O8DjddTvktkoAVH9QhqNI384i9a94fqJAILtpEjIzBHJDXbZoeezFjtCAY6L8Nm5/EyxmhH2KsPxGT89v97eEwQWQ9eQo5pIEah8/B/3/fZnEIIBgmvo2QPHuizcetRQt4GKupcZBXXUFBhZ+XLO9n9zI1EUcqXo/7IO79cwC/nDOHxHzb2hq+cFM9VkxIaMgq6g/oYdFKEP0aDxrPLU0lNDEOeelPHhzbOFxen5Z2bTguZXHteIs8sS23UNjLQG1opr+3a+Gu9kI9LCCExwp9QfzPSE0jesWsoMhjoH/siVpouJNWTWZu1Hk3CiFoN0yCvZ9uSkPuZjbhrBqPpGttMdVCS2VWmNsLt0SF3Ozv1ZPxbyM/eqScTILzea2exN7uYoeIE++TAhvfG6Wy3e2sUjbHk+WxOAQwSeRTJIHYW+v7DVAl5G7jm2a+Z+fAG/vZJOvaDHzOu5AOe9FyKId67uCmENy59OoFWE39ZPIoga8u51Z1JYrg/V09O4IUVjTMbrprk3aQ0NDqQjbdf2HD9ktHe55A6IBRNa/pO4YUVE7l6cgKDTy3eNteus6i/g6kPUQ0I834YVdmTiSyawFcBGnPDnu1Sm7qCjSe+YEKdky2eCQQFeJ9z/UJ5c1yYHIdWG89mm42yvR93hZlnsGnXXmJFKbv1wS0K+S7pzRpJquu8Q0SMZUcxCw+H9PgmQzhTJ03EIU0M5bhP5x2k5XFUxpIY4X/2xm1EZa20gfqt99mFJfzd+CKH9f78y305+yc2XoF//YYpXe6htoTRoPHny0adcf3KSQlceUrMTw+/TE+OPGutiwuHRXHhsCjcHp1QPxOXj297jL8jGE4JeX3Wz5TTSuZmlCxhVMABdkRkM6gynaueDuepZRN4c0cOP56a2CPrsWQV13DvRxvJldlcW1fNx56JLLEYefKa8YwfENpi3xd+NIn/+3ohL6Y/xtF9HzBh1i+6yOpv8WRvB/AKubnpjT6zh0WxLl1SKYLob29+70VHCa/1ZmYdlnENC/Cn84fLxnH84ABiHEfOeKwjDBT5rPGkMjmk+aJ37UV55G2g/jbsvIJXSdCKuNe9gj8tmXDGP8OUgeHMH9lzNhOAd/HzF7OH8NbK89rUz2jQuGJiQqOYdVdw/qBwogIt3DjTmz5mNmoc+fPFDIsOBDRO5C/HoQmSol/iq6NF3PXOPh744AC7sntmbvnvV6exJc9bBG1CrYf7f3kzAPNHxhAV2LJHDjBvoDdTJN+ZDu62HezdUYqqHFRkbsEhTRyQic2mmT517QTSH1hAtnkg8Y7OCwFFO7LwSMERGdukkAOctA1mgCvLZ3MG6hWEiyqOyFifjXk6SsjbQEKYH/0p4kbje3zomcRWfQQDwn1/m9Rd3DY3mdTEsLM3PAcI9Tez7XdzGBX37aYkgyYaYvjlziQSSgfzdaDO1ID3OFxQBXi3ZvdEpASD31FC3JIy92Ciw9p2fNvw8OEYdSN7rBqc6NoF4Guf+5rYmoPslwNwtRAEMBo0rCYDOZYhJLizwHP2s13bit3lIdZ5jOOyHw7MzToglQFJhFOGp9Y3Rw5Gu7wxfyXk5wDltS4eCnkbgD+5rgFgQCfXTT5XCGnmUIpzjfgwP5ZM8IZ59hYtI8oFlVFbyC70piHWH2zd0/BIHZPfESbba6ntf0GbD4gwakb89MFst1rh+JZOsrJpDp2sZJjIJl0O4NNfNp16eDolgUMx4+Ldzzb43JZ/fHaYZJHDYXnmASqnExLn3ZD3ycbNbPZBCmuEwyvkv7zi4g6P1RRKyFuJrkti6w5xvn0juSnXN9RniArs5kr9XcCXv7mQ9b+a2d1mtJrwU+mU105JxlI0lWMWjekh3tzy+uJmPQ2HLAJTFal2B35DZ7VrjCBjCkfNJo4fXN/k+Z6dQVZxDVGyjBBRQ4F1IMmtSD2tDvUe6vDFF5+fsQu4o1RUVpEoCrDFpnD/ouaPFhw+chwAazZu4Yc+SGENceSjIxgzYmSHx2oKJeQt8On+Akbc8wk1DjeVdhe3Gf6H3RRM+NzbGtr0xIWzthIf5keof9N58Ociv5ybzP2LRnDvpSO4eeHvibcbyIo4SKCoOKcWodtCteY9qGRYHQQPTD1L66bpZ/ZmhGRW7OcnL3x1lta+4YkNRximeb3RbGPz+eOnI8OGYJcmRmhZ5JXX+dSegcZiDEIyY+oFLZY89o8ego4gSeQ326YthLlPUmkIA2PnvI+UkLfAXe/so8bpYcS9a6jO2MSFhm84MuQ6LAFti08quharycDy8xPRNEFUoA1H4QIKTAYmh73aYz3yGnGYII+k0JFMdGjT9W7OxqCgFJBw2CoIreyaejT5lXaGimwATphaJ+RhgX5kyv4MEbn8frVvt8r7VZ9KKQw7y74Ok5VSQxRJmm+EPMJTSLm5884jVULeAvUna4NEW/9HimQwZSNXYDH2vhrXvZWU2CCO1FxAUp2RY2FHyT/pmzdmV+PQDjLJXsdWfQSh7VyvWDk9BX/Zj70WC5ONh31sYdNU1rkYqp0gX4bhNLWupk5koIUM2Z/BWm6zRwq2l8Ba74cKYWf/UCmxxpMkvOfryg7uiI3SC6m0ds5CJyghbxWTRDqx5Tt53L2IkOCQLk+1U7Qfv1PVJ2uK51BoNEDpv7vZoraTX52PQysn1W5niz6i3eG8yEAL84dewDdWKyM9+zssTq1BSskwcYJDenyrF8wHRQaQofcnThRjk7U+s2XPiXIqcw9ThT/YWs69B6j0Szgl5PKM6qJtQvfQT5ZQY+28lGQl5K1gpfF9SmQgr3lm9ahYscJLbLCVI9UzSHKbOOB3gPLyoi4RMV/x3A7voSKD6oyctLQuPNEcoyNHU6UJosxHuuSgCbfbzWCRR7qM5/+Wtu6giLhQW0O55fC6LJ/Z8v3HNjNAnKTAGOut4XwW7EFJBIlawqlssVTwWccpy8UkPNj9lUfebQwV2cwy7OFF90XYsRDm5xXyxeP78/cfdN4JJgrfsermqTy7bCLTI3/ACbOBO564mXd353a3Wa3m5W8+J9AjKXYM5dPbZnZorNERowHItTqoKeq8eib1BNcexyJcHNLjiTpLKYF6NE3wqx96Dz+Odvh2m3yiKKDQ2DpBFafCL/GiqMV6Nmfj0bfXA1BlUR55l3KitJZLHvGW3Pyp8QNqpIWXPPOAb0vC/v0HY1ncxdvSFe0jKtDKnJR+zJ/wUyJcgqrQfezL7jnlbW1+GUyw11EUcV6rxbA5BoYMxCos7LWYWfXhez5P7/su0faj3u9Dxp+lZWOGDRuFW5iJ82Q3HIPYUUy46S+KKTC0TshjBgwFIF4UdkjIT2R5D1A/oUecpWX7UULeBNP+tp79eZX0p4hF2hZe88yigvZlCijOHUb2D+X7MXPYZzMQWbW6u81pFYW1hXjMFaTaHaSZO34HqAmNhIBh7LFYcBzfzmcHO+8QDrdHJ1HPQsfAHdcsaltng5EK/0SGiFyqfbSJK04UYRCSPEPrPOMBg7y1++NFYbtDK1JKEgxep2Hp3LaVv2gLSshbYLnxUwCec3fObixF17Ni1u+x6JIjNT1DyHcUeE/1Saizkq/55tZ8cMgoMsxmhmuZPs8KOZ06l4dh4gQVfglgavudhD1kMMkih4JK35QjHnAqA6XKL6FV7Y22IJyWsA6FVirtbmJkMXZTCFFh4Wfv0E6UkDeDDTtXGNbziT6JfLx/gPkjOi8PVNE1BNtCSapL4AuLg7IjZx5cfa6x8+QO/HRJkX0YvioTkxI2El2AyXqC8prOE3KHW2eoOEFF4JB29Tf2G068VsSJk0U+sSdReO8+7EEDWt3HGRjfIY+8qMpOf1GM3a/zFjpBCXmzfN+wmWBRy4vueRg1wce3TOOxH7Ytzqc4N9lfcCkOTePfa/7gPfDgHGZH7mbG2+1s9YxsOMSjo4yJ9C54ZlrBUNp5VQYdtVUM0AqpDk5uV//AeO929u07tnfYlk0ZxQwQJ6mWVpZOa/372B2U0CGP/FhxLf1FMXpw566nKSFvEskyw6cc0AewQw7F32JkeEyQyh/vJdQ6E+hf688WcyG/ePq9czYVsaSuhKM1eUywO9iqp/CnJmrKt4e44Cg0ZxB7rRZCy/f6ZMymkIUHAagJaZ+Q+8V6a67U5R3osC2ZhVUMECdxBA5gVHzrd2brIQOIFSXUOdtX2mHt/nzitGKCon1/vNvpKCFvgskineHaCV70zKN/iF+ba3Qrzm2umpRAafl0ckxGAkpfJi23srtNapKdJ72nrcfUBnDJBakE23xTgTLAYsRRl8g3FgsidxdV9s4pWyAKvQJsDxvevgHCBqKjEePueJqkpgkGiJMExLbtQ0WEJmISHrSK9h37JutKseHAGNr6cE57UELeBMuNayiTAaz2TOWWOUN8cliw4tzhL4tH8dpP7sLPI6gL2U96Xkl3m9Qkqw58gVWXFNcNazgg2xdYjBqeugQKjQZiDBmsP+SbGPR3MRUfpEZa0ENat7h4BkYLFdb+xOs5HU5BdDmdxItCCGubZ2wIS/SaUpXdrnmD7KdKQoS0XDa3oygh/w6bd+9jnraDNzwzcWAmyKpOw+uNRAQEEFg5iM3+Rj5+/+nuNqdJDpd8zRiHg6/1kVhNvqvvI4TAU+cVV4etiM/SOmdjkLk0nQwZh9XU/juJqoAkBok8apwdS0E01eRjFh608LYJuTnCuynIUt2+1yjEWXDqh3Z+mLUSJeTfYfNbj2AUOq95ZjFrWBSzhvXrbpMUnYDVpHGs7GJcQpAQvO6ci5NXOCo46TlJqt3OVj0Fl48XZdN/fx0mYeCAxUhNdufEyc0l6aTr8VhM7ZeZmqBBDBQFVNV2LLvGr8brURsjzlL18DuYwxLwSIGtnUIeWi/kwcoj7zJq7E6uMGxgqyeF4zKaW+cMafKUbUXPx2zQ8DhiiajzZ3dwFcseftVnOwh9wVv7N4KAiNoQyghiXBsW6FqD2WBmWPAg9lrMDHAc8unYHl3iqijAz1XGIRmPtQPVQp0hg7EIF/biYx2yKaDGu9VfhLdNyDWTmQLCCahrX0mHMPdJ6oStVUW6OoJPVEoIMV8IcUgIkSmEuNMXY3YHhfvWMUAr5A3PTH6QGsfoOFV3vLdSX0GwvGwaR80mBjn+R1ZJ15ya0xp2FXyNWZcU1w1n733zmDzQ95tJRkWnst9iYbAnA92HH2Lff2wzK/76IgDpMqFDHrmM8Oag1+QcoLYD4ZXg2hPUYYaAtu8FyRdRBNrbt9gZ7j5JibFfq4p0dYQOC7kQwgA8BiwAUoCrhBApHR23O7ClvUKl9ONjfRI1jvbXVlD0HMqqzsOsC+zBB0g/ce7UX8ks/YqxDgfbPKMIsnbOeamjI0dj1wQhlqNUdzAGfTr7cisYJryhiEN6PMYOpO0G9vdmvLy37gvG3r+23eME23PIJRq0tktekTGG4HYKeYSnkFJjVLv6tgVfeOSTgEwp5VEppRN4HfieD8btWurKCM36hFWeqTgwk1fh2yOmFOcouoVU/9GsDzBzePOr50SsvMxeRp7nJKl1Dv7xm5s6bZ76SogV1jIqq3ybgjlUnKBIBlFKEBEB7d/IFB0dS7EMYpDIw9mBdYIwRw55Wvt2ZuvBAwjxlICr7ZoQqRdSZur8HeG+EPL+wOkrATmnrjVCCHGDEGKHEGJHUVHnpDt1hJKt/8UiXLzhuRCAaUMiu9kiRVexbMrPqdU0HHWr+GBv958gtL3Au5MxyhFJcEhYp80TFxhHsObPHpsZZ+4+n449VPMeJvHZbdPxt7Q/88vfYiRb9GeQ1j6PGABdJ9yZS34rqx5+F1NEIgBL/voGlW3JuXdUESSrqejEI97q6bKVPCnl01LKVCllamTkuSWSx0tqKNjwDGl6IvtlIrt/P5dbZrevPoSi5zExNpVgp4X9weXsSfPtGZHtYVvOJvx0nRp9dKfOI4RgWNBotlst6Dk7fTauQegkixwOyQQGR3V8D4aMGMIg0QEhr8rDJF2cbGUd8jM4tZknoDaHb06Ut75fude/Lbf0DCHPBU7PrYk7da3HcO+TrzBCO87rp7zxUH+z2o7fR/AzGzAbDTjKJ7HHaiGm9H/dbRJbczYxwe4g05ba6XNN6D+NIqORtMyNPhtzfEA5NuEkXfom5S44YSThoopQ2hf+cRUdAWC/vX0LxsbTDphoiy6cPJEBQGUP8ci3A0OEEElCCDNwJfCeD8btMuba12CXJrJiFnDoj/O72xxFF5F2/0XsuHsOAMXl09Ek5Hg2kZZT1m02HSnNJdtRxIQ6FzkBvqmt0hIXJp0PQLY702eHTIwxe73nQ7pvhHzg0HHe76J9Ya99+3YBsN/evoMdbGH9sUsT8aIIk6H1kvn2+q3e+WuC2zVvW+iwkEsp3cDNwBrgIPA/KeX+jo7bZThruVTbQmbELP5780VYOpDzquhZBFiMDYczS08gYdX92BCo8e6qV7vNpv+leY8FC6jpx6ES32WSNMfQsIH4uU1k2+xUlPvmA2yAJwtdCu677nKfjKdFeeujDNby2rUxyn4yE6c08J9bL2vX/GEBFnJkJPGikLbcp4c4C3BII+Wic3PIwUcxcinlR1LKZCnlICnln3wxZlfw0Jp03nnlcYJELekx7fsjK3oP+eWzKTEaMFa9xaPrMvjjBx2vutdWvinYTLDHQ7Z9FMXVnVcrvB4hBBGeeLbbLLz/6RqfjDnAnUWxOZbxg8/IeWgfwfG4NQuDRB617agLHlhznDwtmkH92ucZh/qZyJZRJIhCXG0oCh/lKSJfhlPTBYdc9+lti4+tP0LssbfI0vtRFjmpu81RdDP26hH4uw3kBufwzNrdPLvpWJemI0opyanbwyS7g4ETL+alH3fN/+TcoQsoNRjYl+kbIU/0ZJFv8WHZVs1Alf8ABom8dh3wEGo/0f6FTiDEz8wJGUm8KGrTHUE/WUiOjOiSPSl9WsiHGE8yRTvI/zwzsXUgRUrRWzAQbB/LJj8Lc80bADp06G5beWTjViqoZmyth8svXdQpuzmbYmL8fDQpcQdmUu3oYDjHVUd/WUCB1bf1t2uDBjJI5LXdPl0n0pVPsbn98XqzUeOEjCJI1CLrWh9+6ieLyJWRHX9NW0GfFXKXR+dysR6PFLzlmY6/RcXGFVBrvwiPEISFbAbw2cG/raE+Pm6ojQdD5+zmbIox/eMYYDeT7V/BXe90LJ/cc/IgBnRO2tpW0+RsuEIHEy8KqayqalvHqnwsOKj069jC6wnp3Z1pqjzeqvbSZSeKMnJlBFdO7NyCWdCHhfy213eyWNvI5/o4CgnFZlIeeV/m4aVjeHDxKIQnmvC6IL4KdDBUHKeqC7ypenRtD1FuN4ccY7tsTvAu+s4JT+GoReBytE6omuPDtd4Dy7NNvvXItchhGITEXti2o+mOHPoGAGu/ju0LOSG9e1+Mla2rgli/H2Hc6FHcNrd9JyS1hT4r5HX7PyZKlPM/z0yADm3/VfR8lkyI48pJCehSUlo2jSyziQv8P+kSj3x7Vim3v7kbp/kIk+scbNY7P+3wuywcugAATa5v9xiHCqooObKLGmkhT/g2d9ocPdT7Q9HhNvU7ftgrqLPO79gpX4OSveWjrNU5rWr/f29+BoAtMqmhQFtn0ieFvLjawRWG9RTJYCwp81l+3gBmDev8wjaKcx8pobJqElYpqA5Op6a2ttPn/NEL23k7bRdOo4uhdQaOyM49cb0pkgZexCCnkyx9V7vH2JRZzHAtm0MyHpf0rXgF9h8GgKkso0396k4exomR4OikDs3/28VTKJf+2GpaJ+TxohAAGdK5R7zV06eE/GB+JW/uOMElf/wfs7TdvOmZgWYwc//3RhKgFjsVgC4l6BYmBYxhfYAJceT9Tp8z1N+E0c8rUM6awdCmbGXfIAIiuLBG44SxnOOtjAN/F6nrDBfHSdcTfH4Qhp9/ILkyAlvFkVb3qXG4sVRmUW6NA61ja2Amg0a2jCLv2EF2Z7e84CmlJEEU4pQGDME+SsE8C31KyBf860tuf2svSwwbMQjJG56ZTErqvKJEip7H9FPF0uaPuIE6TSM9+7+dPme4v4VQ/zTiXS72Ocd1+nzNMcyViCYl7x1p38Zsf8dJgkUtB+QA3G3It24NQgiO0R9ZfJgTpa27S/pwXz7xMh9zZMcXXk0GjRMykjhRxDu7Wq5A4vToxIsi7wePxXdnrbZEnxJyAIHOFYb1bPGkYIkazA8nd+5ZeoqexQPfH8nG2y9kQfJUgp1W1osCKO3Y6TRnI8RPw+WXw+Q6O5v1kZ06V0tUW0ZwXp2d9zNXo8u2e9T+ZekAHNQTOmXN6bAnhkEin3d2tm7BsbiqjgHiJP4xQzs8t9ngTUGME0XoesspqU63Tpwo5ISMwmbummy4Pifk52v7SdCKeN0zi8Rw/y5ZiFD0HMxGjYRwP4wGDUPd+ey2Wjm27fFOndNpOIHL4KF/bSAldH5djuY4GZjCZVXV5Nee5KPMdW3uH1B+EMAbI+8EIbfGDMNPOAjTW3kASGU+VuHCGDm4w3ObDIITMgqLcOPvaLkMt9Pt9chzZCR+Ssh9y8f7vAV3rjSsp0wGsEZPVRUOFS3ib5iHJuHNzPfB04Y61G3EgTdFrqzW643/IDWu0+ZqCXvESGbX1uHvMnP72kdb38/lYdnz2zAXHyBbj6Qav04R8isXeAucUdy6zBVrZRbQ9nM6m8KgiYYUxJPZLZ9x6qytJFxUkS2jsJmUkPuUn72yi1Aqmaft4F3PBTgwd/YxeooejkkGE1Qdy4d+Go70D3hu0zEO5Pn2JB0Au3s7Q5xOtjgns/7XM/nbkjE+n6M1LL9wDNl6NLPKzRj9j7G/uHW173Zll7HxcBEx9iMclN4sDV/HyAG0xuTQLAAAG59JREFUKG+IxFjausyVgOos7w9hHc9pF0I0bAoyVGRTXutstq1e6p1XhVY6icWGTViEu6HueHSQrZstUpzLeKSkoHQ+pQYD72z7Nw98cIAlT27x6RxOj5MCrYBRdZI9chDhAV2zONYU4QEW9JhxrKg+ifRYeGbfM63qp+vgTx1JooBMzZvm1yn7MvwjqdUCMJe1blOQo+AgdiwQ5Js7nId+cgk6gnhRRGlN80JOuTfr54SMxGLsGont9UJe63Tz10/SAckVhvXs0gdz+FTB++nJ7atPrOgbhNjMuGqHEOaw8bo7l1gK21V9ryVWH9iIU0iMNfFINAK7OQ3WHT2WZEowlk5iXfY60orPfmJStcPNKO0YmpBkmoYyLDqQB77XCYu2QlAZkESM68RZ65cczK8kUT/BIb1/uw5cborUQTE4/fqRoBW2KOSuYu/i+AkZ2WVrcL1ayHVdknLPGp7YcITztAMka7l8FbqI1TdNZd2vZjBzqNoEpGieh5aOBgS1xTM5ajZxftD7Pvewnvj0BTQpyaqZAtDti+/m+PEAjCqLxEQg/9r1r7P2Kat1MkZ487u/cgzgk1unM3Vw5zhJNYEDGaTlnTUF8XhJDUO0XFyhvj2y0R08kCSR36yQl9U4Wf/Vdqqkjd8tucCnc7dErxZyu/tb72mFYQ0lMpDNtpmMiQ9hUGRAN1qm6AnEBHtDb0WVUwl2C4pCD+Jn9G3IwOCfQYrDxdb/b+/O46Ou7v2Pvz6zZJmshCQkkLAEkDUQEEIQFFAUEFTQulT0iu0VF3qp1VoFBG+1WqveWv25XYvWVnEXpchVQQVFFgWBsCMQlgAhAbKvs53fH5MEAlmAzPaN5/l48GAms72J42e+c76fc45zsFef93yl9M3CqUxkyn7Kjo5ibd5avj3U9DZw/1qzn1kLtzDQtJcD7kRKJdqn+Sqj0+ggxdzwXPNL7ubnF5AkRfTLGObdAAkX0F2OUNjEWvGHiqroLAUcUgl0amfz7ms3o20Xcofnf7oUOcZY04+86xpDsb1N/5M1n7AQUTSADTYLQy1LuPfdjWw9XNLqZ92Vf4T8sEo6VcQQERXDohkjvJC1dUJs0RRE9WGYaQeOoiy6xXTjz9//mRpX44Vr3iLPCdEM0x42qR4+X/bXHutpJUxrYTNmV4GnFTKsY1+vvn5Ych9ipJLCgsan6pdUOeguR9irkgnx0/g4tPlC7nlT3WJehkJ4y3k5Rc2dpNC009S1qO4qnEykS1EZt5JPNh1m9sfnv9zr1sMl9Hr4M5748BmUCMfLh9A9IYKBqbHeit0qByMzGCh7CcXN7GGzOVR+iNe3vn7G/eo23UikiI5SSLa7O24f78PhjPMMlfSQI7iaebHIUs8JUUns49XXt9RuO1d5ZEejt58oKSFVCtirOvntRCe08UK++VAxYdRwS8g3fOEeQh7tOa4LuXYOvr5/FA+O7w3ucFIKLyA7AvrZVpIYFXrez/nP1fupcbqpcq+lncvFD5Vj6r89BoN9kYMIFSeDTbvJSs5iXNdxzN88n30lDWe4llZ5TjgONHnGx9v1zPL5rkYS141KFUo/034GPbqUnUcbbweNq9jj6ViJ8fLM7XhPIbc00TnjKNiDWRR73R2JCfffmvJttpBvPlTMXW9t4HrzN0S6y3jDOR6AWD/+cjXj69I+grtHeyaUbDlxA3FON9aEZSRGhfJTfhnu8zgEVYAZB0ciSuhlj6YSG/EBbDs83T5bOi4lDDPt4GhJNdd3nUGYJYx5q+bhOmV6+okKz3DLYNNuHMrMf029jksuSPBpNltYKNtUF9JNOZRWO/l/X59ZUI+X15BStYsD1u5e61ipF9URuymc6PJ9jX6IhBZ78uxRHYmL8N9/0zZbyHOOVWDByZ2WT8mLyWCd6kVUmIUP7mrdusTaz1e1iqJPYSp7bQ72FSziime/5e8rc875eZSCwRHLKTGbuLL3ldw8rHPAJgE1plwi2Ka6kmXaQdafv+LGl7fzUOZDbDq2iQU7FtTfr6h2Usxw03Y2qe5g9f28jDCrmS3uNPrLfsy4zlgnsrjSTuafltLZvpfc8NavsXIGk4nSiK70kMOM/9tKapwNzwlEluXgVkKOSvbb9Hxow4W80u5isnkVKXKcogt/w5u/HsYPs8fSpX1EoKNpBrbuxFTS7A5yLR+B2PnxwNnv4ZhfWk21w4VCER+9ihC34oqsmTwxJd2vR28tcbkUa919GSS7CacagElpkxidMprnNz5fv8ztiXI7UVSSLjmsdvfzSzaLSch2pxEudnrI4TPaNctrnKTJEWxSw7Eo746P16mJu4DeJs/CXZsPNTzpHVu5n8MqnmpC/dpK2mYLebXdzt3mf7PV3ZWqzpdxcc8Ev02X1dqe9+8czrM3DuQEcWTk96LE6iIxfrFn/fKzNOyJr7jjX+sxlR5ge2QlKRXtiAgLjhOcp5oyuBMr3AMJFScjTCen6c8dPpcQcwhzvpuD0+2kqNLOUNNOzOIp/P4QFxnCFuWZcj/AlEO1w9VgeMvhUgwQz7ek4hjffLgkXjCMRCkmkSIOnmjYz96+an9ANgZps4XcufEdupvyeME5mTBdwLVWyuwWx5RBnqneS8pv5MqyKmrar6PUfXZDK3WLSK3cfRwK/kGhxUxeySU+y9saWWntGXDRBMpUOJeaNgJQ43STaEtkbtZcso9l8/fNf6egtIbhpu3UKCs5of4p5NFhVub/7kZKlY1Bsptl2/P567KTi2jVOF2km/ZRqUJxtGv9qoeNsabUTpoy5VBcdXIxtV2Hj5FUs4/tqgsb517uk9duimELebdZSxrs+O1wuU+uuGav5JrC19nk7s7n7qGE+WkFMq3t2/HoeI4TQ6eCC0l0OTnAi1Q4Klp8XF0rrI1qCtvtJNppoqDMtx0erREVYWOlO51LzRsBVT8lfkK3CVyVdhUvZ7/Cs98tZazpRxypw/n0Pv8VrnYRYXzv7s1Fpu2AZwOJOtUON4NMu9miuhFlO//OomYlpaMQ0k37KDll8ayjuzcSIi62uLvRzs9DZYYt5ErBOz8crL9+yVPLGfToMs+VtS/SgUIed0wFRBdyzWvqhufm269ldkElVVLEH755qEE3Rx2lFKXVniO2uokyE8MXsc5mxVI4GKs5eDuoYm1WvnQNJkmKGCy7G2xCnRn9a1z2WKI7vk2CuYDIjCkktKId81zZQs2scvenqymfFDlGp1jPSda31h7gt/9YQbrsY627j+/a/0IjkYReDLbsp7jKwSOLtvLB+ly++upzgPqhH38yZCFXjYxL5pVUU17jZOe2DdiXP8VnrqGsU54NW+NswXMiSWsbSolkWfl1PFhYyLeHV/CnNU/Wvy8XbjjEq9/u5ZVvchjw30spKKumxuEmmgrKEn4g1A0Hiq7k6/tHB/Yf0YyoMCtfuIdSpUK4zrySslMK+QPv76LqyI24raU80T4Oek30a7YQs6l+J6WLTFvrC/nDn2wlrXpr/Zh9VJgPPyiTM+gvOeQVV/HPNQd44MPN9Fd7KFSRPHm7f38fAIbacbiwwk5+aTX5pdWN3i64KXvvLqrEwjzHtPqf65Ocmjd1iA4lv7SGd11jWFi8ghvNpby3513sbjuxlTfy4nLPxJm+yZ51R/JLagi1mpgY8wafRliJKcgkNiyG1Dj/rcVxrkwCFYTzuXsok8xrWHO8iD7JUcz/bh8Ol4Kqzlxf5Ob9uAguPr6BCVET/JZNRNitOlGgYrnYtIWNp6wYOca0iSoVwgZ3T6Y6fbhcQJeLiNv8Lvt3bgBSAMUI81bWuvsyvJP/d3kyVCF/+oudLN2Wz4lTZmcu31lAznHPGOXvLB8y1LSL++13cYx2gYqptXHLfz+a3MIqPt18hHuX38OnhbMpdUfzbxbirNiIWH+BcrSnrMYzrLJkSx67drzDzqQDJFWHs/vE1SRGBfeX4bqdbT5wjWKKeRXffPQSaw/exhur9wOe3vFZJYf4InwAj615jIyEDJIjk/2W77+v6seXnw1msnkV2Y5yAEy4GW9ex9fuDGoIIbOrDzdW73EZAKNM2ex2pdBNjtJJTvCS+xrGBmAp4la9m0TkehHZJiJuERnirVBN6RlZQ2Jlw91Bbn9jHY99up3rzSuYafmE95yj+ch9MeDZZ09vrqx5my3EQq+kKCYOSGa/Smae43aeKtnLNfntMYcdISLtWUKTPyTP8T3miJ28v+MpsuM+IsIl5OXeBViC/rzNmF6JTM7oyGp3P7a6uzJdPmHB6rpZlIoZ5k8oVZEcOzwNN24eXPkgDrfvtsM73bQR3Ugc+R/YpIai9R/x6OLtjDRtIVGK+dyVyco/jCExOsx3AWJSyAvpyjjzOgDGmTx/f+tO9+tiWXVa+4pbgWuBpte59KIrcp9jYcgjXG1ajWeiM1hx8jvLhzxtfZVvXenMdd4OtfO9nrtpEI9PSfdHNO1nqG4MdqH7Ev7q+AV/qtzIvNwIzCX9sUZnE57yNrbOb+CK+4HR5TVY9k9j/MCh3DAkhb//h8+Pe1rFZBL+dtMgXp56IYcG3U83Uz73WT4AYLJpFSPN23jeeS2h5hTmZs1lY8FGXtz4ol8zjr3iGna6U5lh+YQ3V+1mhmUReSqOL9xDCbX6vphmx09iqOkn+ksON5u/Yq27D7mqg89ftzGt+g6glNoB/lsMv2TkPPIW7OL5kBe4072YgyqRDNNekqWQj1wjmeW4AzvB2wmgtS1RYSf/93neNYUiInnE8i8mFe1g5Yk+FIZW08u0j2hHGPdX389O1YPHM1O5sIsPv/J72YT0ZFaHX8k7Py7kbstiMk07GSA5fO/uzVuusWx+5DJsIRbWHV3Ha1tfY0jSEEZ28tOGCiYTTzpv4o2Qp1kW8gBdTfk87LgdO1ZCLb7/xrM3ZTKlh1/jg5BHCRc7j9un8vBE38wmbYnfvgOIyHQRWS8i648dO3Zez5Gc0pWb7Q/zsON2yrDRUw6z2Z3GbfYHud9xzxlFvNrHayNrP29RoRZ+mVk3dCe86bqCy+1P84lrBJ3lBP3t1aypHMcNVX8hW3kmpwTzCc6mRIdbmeP8Nc86rsNGNR+4RnGH/T4GdknAFuL5MHso8yF6tuvJ7JWzya/I91u2Fe5BzHPcRhWhPOecwluusQB+2TIvLDqe3zhmslt14jnnFL5wD2VcvySfv25jpLFWvgZ3EPkSaCzdHKXUotr7rAB+r5RafzYvOmTIELV+/VndtQGlFN1m/d9Z33/Bfw7z2ZZTmlZn8GPLmtz6q2NMGEdKPF1WH919ERd2Md5JeKUUI578uv7fAfDcTRlc0TepQUdYTkkON316E33i+vDauNewmHxfTLs+tKT+cveECPYe8zQ+7H/S9y2Ax8tr+MXLq9l/yjT97Y+Oq/9w8wUR+VEpdca4XItH5EqpsUqp/o38WeSbqE0TEdqfMmOqW3wEtw3vcsb9bhvehY/vuUgXcc0vwk87cfny1JPbtr1358nVNsP8MG7rCyLCtBFdG/yse0LkGW29aTFpzM2ay4aCDby06SU/JvS0S75xu2emrL8aHOIjQ1nxwJgGHxq+LOLNMdw767sHL2XbH8fx3E0ZfH3/KOIiTs4o+/O1nhObE9KTGdTZeEc+mjG9Pm1o/eXMrnFMSD/Zhtf+lHXGg71TpTmRodbTrjdesK7qfhVTekxh/pb5rD6y2h/RAPjmgTGkxtn46U8TfpYNDq1tP5wiIoeA4cASEWl+R1QvCA8xExFq4ZqMTogIipNDQxmpsex/ciJZae19HUPT6vVKiqq//PrtnqJ+UXfPe/DUIzQjF/K4iNMKeVjTR56zhs2ie2x3Zq2cRV55XpP386akGE+rYSBa/4JBa7tWPgY+9lKW88xw8nJTRwma5i9178HXpw2t33ihzulDMEaSlhBZf/nS3om0a2bZi3BLOP8z+n+4ecnN3LviXv45/p+EWXzY041nnfJAWvCfw85pSWNvM/zHV4dTmv6jmjlK0DRf6tcxmp6JJ4tdmNVMckzDHXOMOkYO0KW9p9umV4coXp82tH5T6qakxaTx5MVPsv3Edh5d82ij6yN5kz83cWjMiB7xXNzTt9vcNce476xaNw1Nrb8coY/ItQBZMvNilt03qtHbMrt5+sb90dvsK6EWM+9Oz2LBHcPO+jGjU0czI2MGi3MWN9giTvM+w1c+k0nY+sdxHDxRidVs+M8lrQ167bYhHCysbPEoNtidz7mn6QOms+PEDp5Z/ww92/VkWPLZfxBoZ69NVL7IUAt9O0YHOoamNSoqzEq/jv5fES8YmMTEExc/Qdforty34j5yis99s2qtZW2ikGuaFrwirBG8cNkLWE1W7v7ybo5XHffacy+aMYL/vfVCrz2fUelCrmmaz6VEpfDiZS9SVFPEPV/eQ6WjsuUHnYWBqbEBmxYfTHQh1zTNL/rF9+OZUc+wq2gXv//m935d9rat04Vc0zS/uSTlEuYMm8PKwyuZs3JOo3udaufO8F0rmqYZyw29bqDcUc6zPz6L1WzlsRGPYRJ9TNkaupBrmuZ3v+r/K2pcNby06SVCzCHMy5oX8Ek9RqYLuaZpAXHXgLuwu+zM3zIfp9vJI8Mf8cvSt22R/q1pmhYQIsLMQTOxmqy8nP0yZfYy/nLJXwg1h7b8YK0BPTClaVrAiAj3ZNzDg0Mf5KuDXzHjyxmU28sDHctwdCHXNC3gbul7C4+PfJz1+eu59bNbyS3LDXQkQ9GFXNO0oHB196t55fJXKKgs4OYlN7Pu6LpARzIMXcg1TQsaWclZvD3xbWJDY5m+dDpvbn/T50vgtgW6kGuaFlS6RHdhwcQFjEwZyVPrnmLm1zMpri4OdKygpgu5pmlBJzokmufHPM9DmQ+x6sgqrlt8nV/3ADUaXcg1TQtKIsLUPlNZcOUCbBYbdy67k7mr5lJSUxLoaEFHF3JN04Jan/Z9+PDqD7kj/Q4W713M5EWTWbx3MW7lDnS0oKELuaZpQS/UHMrMwTN5d9K7dLB1YPZ3s7nl/25hU8GmQEcLCrqQa5pmGL3jevP2xLd5fOTj5Ffkc+tnt3Lfivv4qeinQEcLKAlEa8+QIUPU+vXr/f66mqa1HZWOSv6x7R+8uf1NKhwVjO08ljsH3knvuN6BjuYzIvKjUmrIGT/XhVzTNCMrqSnhrR1vsWD7AsocZQxLGsYve/+SUamj2twiXLqQa5rWppXaS3l/1/u8t+s9jlYcJTkimRt63cCktEkkRbSN7eB0Idc07WfB6XbyTe43vLPzHb4/+j2CkJmUyaTukxjbeSyRIZGBjnjedCHXNO1n52DpQZbkLGFxzmJyy3KxmqwMSx7GmNQxjE4dTaItMdARz4ku5Jqm/Wwppcg+ls2yA8tYnru8fnXFfu37kZWcRWZyJoMSBxFuCQ9w0ubpQq5pmoanqO8t3svy3OWsPLySLce24FROrCYrAxMGcmGHCxmQMID0+HTahbULdNwGfFLIReRp4CrADuwFbldKtbi6jS7kmqYFi0pHJRsKNvBD3g+szVvLrqJd9bNGUyJTSE9Ip3/7/lwQdwE9YnsQHx4fsKy+KuRXAF8rpZwi8hcApdSDLT1OF3JN04JVpaOS7Se2s+X4FrYc30L2sWwKKgvqb48Li6NnbE96tOtBj9gedInuQmpUKom2REzi2zmWTRXyVjVZKqWWnnJ1LfCL1jyfpmlaoNmsNoYkDWFI0sl6ebzqOHuK97C7aHf9n4W7F1LlrKq/T6g5lJTIFFKjU+kc1ZmUqBSSI5JJikgiyZZETGgMIuKTzN7slv8V8F5TN4rIdGA6QOfOnb34spqmab4VHx5PfHg8WclZ9T9zKzdHyo+QW5ZLblkuB0sPcrDsILlluaw5soYaV02D5wi3hNPB1oF5w+cxNGmoV/O1WMhF5EugsW76OUqpRbX3mQM4gQVNPY9S6lXgVfAMrZxXWk3TtCBhEhMpUSmkRKUwnOENbnMrNyeqTnC04ihHK496/q44Sl5FHjGhMV7P0mIhV0qNbe52EZkGTAIuU3pPJk3TNExiIsGWQIItgXTSff56rRpaEZHxwB+AUUqpSu9E0jRN085Fa0+xvgBEActEZJOIvOKFTJqmado5aG3XSg9vBdE0TdPOj95YQtM0zeB0Idc0TTM4Xcg1TdMMThdyTdM0g9OFXNM0zeACsoytiBwDDpznw+OB416M42tGymukrGCsvEbKCsbKa6Ss0Lq8XZRSCaf/MCCFvDVEZH1jq38FKyPlNVJWMFZeI2UFY+U1UlbwTV49tKJpmmZwupBrmqYZnBEL+auBDnCOjJTXSFnBWHmNlBWMlddIWcEHeQ03Rq5pmqY1ZMQjck3TNO0UupBrmqYZnCELuYg8LSI7RWSziHwsIrGBztQUEbleRLaJiFtEgrZFSkTGi8guEdkjIg8FOk9zROR1ESkQka2BztISEUkVkeUisr32ffDbQGdqioiEicgPIpJdm/WPgc7UEhExi8hGEfk00FlaIiL7RWRL7ZLfXt193pCFHFgG9FdKDQB+AmYFOE9ztgLXAt8GOkhTRMQMvAhMAPoCvxSRvoFN1aw3gPGBDnGWnMD9Sqm+QBYwI4h/tzXApUqpgUAGMF5Eslp4TKD9FtgR6BDnYIxSKkP3kQNKqaVKKWft1bVASiDzNEcptUMptSvQOVqQCexRSuUopezAu8A1Ac7UJKXUt0BhoHOcDaVUnlJqQ+3lMjxFp1NgUzVOeZTXXrXW/gnabggRSQEmAvMDnSXQDFnIT/Mr4LNAhzC4TkDuKdcPEaTFxshEpCswCPg+sEmaVjtUsQkoAJYppYI2K/A3PFtNugMd5CwpYKmI/Cgi0735xK3aIciXRORLIKmRm+YopRbV3mcOnq+uC/yZ7XRnk1X7eRORSOAj4F6lVGmg8zRFKeUCMmrPO30sIv2VUkF3LkJEJgEFSqkfRWR0oPOcpZFKqcMikohne8ydtd8uWy1oC7lSamxzt4vINGAScJkKcDN8S1kN4DCQesr1lNqfaV4gIlY8RXyBUmphoPOcDaVUsYgsx3MuIugKOTACuFpErgTCgGgReUspdUuAczVJKXW49u8CEfkYz5CmVwq5IYdWRGQ8nq9UVyulKgOdpw1YB/QUkW4iEgLcBPw7wJnaBBER4DVgh1Lqr4HO0xwRSajrABORcOByYGdgUzVOKTVLKZWilOqK5/36dTAXcRGJEJGousvAFXjxA9KQhRx4AYjC8/Vkk4i8EuhATRGRKSJyCBgOLBGRLwKd6XS1J45/A3yB52Tc+0qpbYFN1TQReQdYA/QSkUMi8utAZ2rGCOBW4NLa9+qm2qPIYJQMLBeRzXg+3JcppYK+rc8gOgDfiUg28AOwRCn1ubeeXE/R1zRNMzijHpFrmqZptXQh1zRNMzhdyDVN0wxOF3JN0zSD04Vc0zTN4HQh1zRNMzhdyDVN0wzu/wOsI558uUAhIAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J2yr-0UCVIli"
      },
      "source": [
        "As expected, the model is able to make farely accurate predictions on the interval it was trained on but makes unreliable predictions outside this interval.\n",
        "\n",
        "### Regularization\n",
        "In this section we will explore the concept of regularization. As there is no theorem that can be used to determine the required size and structure of a neural network given a certain task, one has to find a suitable neural architecture by trial and error. This can result in choosing a architecture with a capacity that is higher than required for solving the given task and hence overfitting might occur. A common way to prevent large neural networks networks from overfitting is to employ some sort of regularization, e.g. weight norm penalty, dropout, early stopping and data augmentation. In this section we will focus on weight norm penalty as a regularization and derive a probabilistic interpretation for some of those.\n",
        "\n",
        "We start by restating the conditional probability of the output $\\mathbf{y}$ given the input $\\mathbf{x}$ and the networks parameters $\\boldsymbol{\\theta}$\n",
        "\n",
        "$p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})=\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}}$,\n",
        "\n",
        "which we used to derive the log likelihood. If we have some prior knowledge about the parameters of the neural network, which is given by a pdf $p(\\boldsymbol{\\theta})$ over the weights, we can use Bayes theorem to derive a posterior distribution\n",
        "\n",
        "$p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})=\\dfrac{p(\\boldsymbol{\\theta},\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})}=\\dfrac{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p(\\mathbf{y})}$\n",
        "\n",
        "where $p(\\boldsymbol{\\theta})$ is the  prior over the networks parameters. Similar to the derivation at the beginning of the exercise, we can use this posterior distribution to derive a cost function for training the neural network. In this case, however, we are not maximizing the log likelihood but the posterior distribution over the weights, hence this approach is called Maximum A Posteori (MAP) estimation of the parameters. Mathematically we can formulate this as\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\ln{p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})}\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\ln{p(\\boldsymbol{\\theta})}+\\mathbb{E}\\left[\\ln{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}\\right]$,\n",
        "\n",
        "where we used the fact that applying a strictly increasing function, e.g. $\\ln{}$, does not change the position of the maximum of a cost function, ignored $p(\\mathbf{y})$, since it is independent of the network parameters and dropped the expectation operator for $\\ln{p(\\boldsymbol{\\theta})}$, since it is not depending on the random variable $\\mathbf{x}$. Comparing the MAP estimate of the parameters with the ML estimate we derived above, shows that the only difference is the addition of $\\ln{p(\\boldsymbol{\\theta})}$. This term is the regularization, i.e. the weight norm penalty. Depending on the distribution over $\\boldsymbol{\\theta}$ it can have different forms. If we choose a standard normal distribution, i.e. $\\boldsymbol{\\theta\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})}$,  we get\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{2}^{2}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where we have made the same simplifications as for the ML estimation and also introduced the parameter $\\lambda=\\sigma^{2}$, which is used to control the strength of the regularization. This form of regularization is commonly known as $l_{2}$-norm or weight decay regularization. Choosing a prior where the weights follow an i.i.d laplacian distribution, i.e. $p(\\boldsymbol{\\theta})=\\prod_{j}\\dfrac{1}{2}\\mathrm{e}^{\\vert\\theta_{j}\\vert}$, leads to\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{1}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where the strength of the regularization is again controlled by $\\lambda=\\sigma^{2}$. This type of regularization is known as  $l_{1}$-norm and it has the property to induce sparsity in the parameters of the network.\n",
        "\n",
        "With this theoretical background on regularization we can now implement it and observe it's effects on the regression problem covered in this exercise. For this we will define a model with a high capacity and train it for a extended time to provoke overfitting. For this, we will increase the number of hidden neurons in both hidden layers to $100$ and $50$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2Fv2J-VK_vw",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a bigger model with again two hidden layers containing 100 and 50 neurons. As an activation use the tangens hyperbolicus function where it is appropiate. \"\"\"\n",
        "\n",
        "class MyBigModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,100]), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.random.truncated_normal([100]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([100,50]), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.random.truncated_normal([50]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([50,1]), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.random.truncated_normal([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y1XpaZTNLV-p"
      },
      "source": [
        "After creating one instance of this class we can again train it on our data set. We will also create a new optimizer for training this bigger model, since some optimizers adapt the learning rates for individual parameters during a training process and we do not want to train our bigger model with learning rates adopted from an earlier training run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7Yq-a1FLi0X",
        "colab": {}
      },
      "source": [
        "big_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dBrf0I68MnMy"
      },
      "source": [
        "Now we are ready to train this bigger model using the same training step and training loop. In order to provoke overfitting we also reduce the number of samples in the training data set a lot, increase the batch size and train for a more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nz_lXM8LMwXo",
        "outputId": "09c0902f-75ec-4a4b-874b-f16a2427c352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model similar to the training of the small model before. \"\"\"\n",
        "\n",
        "N_train_samples_overfit = 30\n",
        "N_epochs = 1000\n",
        "batch_size = 30\n",
        "\n",
        "sel_idx = np.arange(0, N_train_samples)\n",
        "sel_idx = np.random.choice(sel_idx, N_train_samples_overfit)\n",
        "x_train_overfit = x_train[sel_idx]\n",
        "y_train_overfit = y_train[sel_idx]\n",
        "\n",
        "train_overfit_ds = tf.data.Dataset.from_tensor_slices((x_train_overfit, y_train_overfit)).shuffle(N_train_samples_overfit).batch(batch_size).repeat()\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += train_step(big_mdl, big_opt, x_t, y_t) # Perform a training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters == int(N_train_samples_overfit/batch_size): # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_mdl(x_v) # Compute a prediction with \"big_mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0.014321 Validation loss: 0.024855\n",
            "Epoch: 1 Train loss: 0.010803 Validation loss: 0.02409\n",
            "Epoch: 2 Train loss: 0.0096761 Validation loss: 0.024026\n",
            "Epoch: 3 Train loss: 0.0091277 Validation loss: 0.023808\n",
            "Epoch: 4 Train loss: 0.008779 Validation loss: 0.023846\n",
            "Epoch: 5 Train loss: 0.008524 Validation loss: 0.023643\n",
            "Epoch: 6 Train loss: 0.0083229 Validation loss: 0.023681\n",
            "Epoch: 7 Train loss: 0.0081574 Validation loss: 0.023475\n",
            "Epoch: 8 Train loss: 0.008017 Validation loss: 0.023511\n",
            "Epoch: 9 Train loss: 0.0078956 Validation loss: 0.023305\n",
            "Epoch: 10 Train loss: 0.0077892 Validation loss: 0.023343\n",
            "Epoch: 11 Train loss: 0.0076948 Validation loss: 0.02314\n",
            "Epoch: 12 Train loss: 0.0076105 Validation loss: 0.023181\n",
            "Epoch: 13 Train loss: 0.0075345 Validation loss: 0.022983\n",
            "Epoch: 14 Train loss: 0.0074657 Validation loss: 0.023028\n",
            "Epoch: 15 Train loss: 0.007403 Validation loss: 0.022836\n",
            "Epoch: 16 Train loss: 0.0073458 Validation loss: 0.022883\n",
            "Epoch: 17 Train loss: 0.0072932 Validation loss: 0.022697\n",
            "Epoch: 18 Train loss: 0.0072447 Validation loss: 0.022748\n",
            "Epoch: 19 Train loss: 0.0071999 Validation loss: 0.022569\n",
            "Epoch: 20 Train loss: 0.0071584 Validation loss: 0.022623\n",
            "Epoch: 21 Train loss: 0.0071198 Validation loss: 0.02245\n",
            "Epoch: 22 Train loss: 0.0070838 Validation loss: 0.022507\n",
            "Epoch: 23 Train loss: 0.0070502 Validation loss: 0.02234\n",
            "Epoch: 24 Train loss: 0.0070187 Validation loss: 0.022399\n",
            "Epoch: 25 Train loss: 0.0069892 Validation loss: 0.02224\n",
            "Epoch: 26 Train loss: 0.0069614 Validation loss: 0.022301\n",
            "Epoch: 27 Train loss: 0.0069352 Validation loss: 0.022147\n",
            "Epoch: 28 Train loss: 0.0069105 Validation loss: 0.02221\n",
            "Epoch: 29 Train loss: 0.006887 Validation loss: 0.022062\n",
            "Epoch: 30 Train loss: 0.0068648 Validation loss: 0.022127\n",
            "Epoch: 31 Train loss: 0.0068437 Validation loss: 0.021985\n",
            "Epoch: 32 Train loss: 0.0068236 Validation loss: 0.02205\n",
            "Epoch: 33 Train loss: 0.0068043 Validation loss: 0.021914\n",
            "Epoch: 34 Train loss: 0.0067859 Validation loss: 0.021979\n",
            "Epoch: 35 Train loss: 0.0067683 Validation loss: 0.021849\n",
            "Epoch: 36 Train loss: 0.0067514 Validation loss: 0.021914\n",
            "Epoch: 37 Train loss: 0.006735 Validation loss: 0.021789\n",
            "Epoch: 38 Train loss: 0.0067193 Validation loss: 0.021854\n",
            "Epoch: 39 Train loss: 0.0067041 Validation loss: 0.021735\n",
            "Epoch: 40 Train loss: 0.0066894 Validation loss: 0.021799\n",
            "Epoch: 41 Train loss: 0.0066752 Validation loss: 0.021685\n",
            "Epoch: 42 Train loss: 0.0066613 Validation loss: 0.021748\n",
            "Epoch: 43 Train loss: 0.0066478 Validation loss: 0.021639\n",
            "Epoch: 44 Train loss: 0.0066347 Validation loss: 0.021701\n",
            "Epoch: 45 Train loss: 0.006622 Validation loss: 0.021596\n",
            "Epoch: 46 Train loss: 0.0066095 Validation loss: 0.021657\n",
            "Epoch: 47 Train loss: 0.0065972 Validation loss: 0.021558\n",
            "Epoch: 48 Train loss: 0.0065853 Validation loss: 0.021617\n",
            "Epoch: 49 Train loss: 0.0065735 Validation loss: 0.021522\n",
            "Epoch: 50 Train loss: 0.006562 Validation loss: 0.021579\n",
            "Epoch: 51 Train loss: 0.0065508 Validation loss: 0.021489\n",
            "Epoch: 52 Train loss: 0.0065396 Validation loss: 0.021544\n",
            "Epoch: 53 Train loss: 0.0065287 Validation loss: 0.021459\n",
            "Epoch: 54 Train loss: 0.0065179 Validation loss: 0.021512\n",
            "Epoch: 55 Train loss: 0.0065073 Validation loss: 0.021431\n",
            "Epoch: 56 Train loss: 0.0064968 Validation loss: 0.021482\n",
            "Epoch: 57 Train loss: 0.0064865 Validation loss: 0.021406\n",
            "Epoch: 58 Train loss: 0.0064763 Validation loss: 0.021455\n",
            "Epoch: 59 Train loss: 0.0064662 Validation loss: 0.021383\n",
            "Epoch: 60 Train loss: 0.0064562 Validation loss: 0.021429\n",
            "Epoch: 61 Train loss: 0.0064464 Validation loss: 0.021362\n",
            "Epoch: 62 Train loss: 0.0064366 Validation loss: 0.021406\n",
            "Epoch: 63 Train loss: 0.0064269 Validation loss: 0.021342\n",
            "Epoch: 64 Train loss: 0.0064174 Validation loss: 0.021384\n",
            "Epoch: 65 Train loss: 0.0064079 Validation loss: 0.021325\n",
            "Epoch: 66 Train loss: 0.0063985 Validation loss: 0.021365\n",
            "Epoch: 67 Train loss: 0.0063892 Validation loss: 0.021309\n",
            "Epoch: 68 Train loss: 0.00638 Validation loss: 0.021346\n",
            "Epoch: 69 Train loss: 0.0063708 Validation loss: 0.021294\n",
            "Epoch: 70 Train loss: 0.0063617 Validation loss: 0.02133\n",
            "Epoch: 71 Train loss: 0.0063527 Validation loss: 0.021282\n",
            "Epoch: 72 Train loss: 0.0063438 Validation loss: 0.021315\n",
            "Epoch: 73 Train loss: 0.0063349 Validation loss: 0.02127\n",
            "Epoch: 74 Train loss: 0.0063261 Validation loss: 0.021302\n",
            "Epoch: 75 Train loss: 0.0063173 Validation loss: 0.02126\n",
            "Epoch: 76 Train loss: 0.0063087 Validation loss: 0.02129\n",
            "Epoch: 77 Train loss: 0.0063 Validation loss: 0.021251\n",
            "Epoch: 78 Train loss: 0.0062915 Validation loss: 0.021279\n",
            "Epoch: 79 Train loss: 0.006283 Validation loss: 0.021244\n",
            "Epoch: 80 Train loss: 0.0062745 Validation loss: 0.02127\n",
            "Epoch: 81 Train loss: 0.0062661 Validation loss: 0.021238\n",
            "Epoch: 82 Train loss: 0.0062578 Validation loss: 0.021262\n",
            "Epoch: 83 Train loss: 0.0062496 Validation loss: 0.021233\n",
            "Epoch: 84 Train loss: 0.0062413 Validation loss: 0.021256\n",
            "Epoch: 85 Train loss: 0.0062331 Validation loss: 0.021229\n",
            "Epoch: 86 Train loss: 0.006225 Validation loss: 0.02125\n",
            "Epoch: 87 Train loss: 0.0062169 Validation loss: 0.021226\n",
            "Epoch: 88 Train loss: 0.0062089 Validation loss: 0.021246\n",
            "Epoch: 89 Train loss: 0.0062009 Validation loss: 0.021224\n",
            "Epoch: 90 Train loss: 0.006193 Validation loss: 0.021243\n",
            "Epoch: 91 Train loss: 0.0061851 Validation loss: 0.021224\n",
            "Epoch: 92 Train loss: 0.0061773 Validation loss: 0.021241\n",
            "Epoch: 93 Train loss: 0.0061695 Validation loss: 0.021224\n",
            "Epoch: 94 Train loss: 0.0061618 Validation loss: 0.021241\n",
            "Epoch: 95 Train loss: 0.0061541 Validation loss: 0.021226\n",
            "Epoch: 96 Train loss: 0.0061464 Validation loss: 0.021241\n",
            "Epoch: 97 Train loss: 0.0061389 Validation loss: 0.021228\n",
            "Epoch: 98 Train loss: 0.0061314 Validation loss: 0.021243\n",
            "Epoch: 99 Train loss: 0.0061238 Validation loss: 0.021231\n",
            "Epoch: 100 Train loss: 0.0061164 Validation loss: 0.021245\n",
            "Epoch: 101 Train loss: 0.006109 Validation loss: 0.021235\n",
            "Epoch: 102 Train loss: 0.0061017 Validation loss: 0.021248\n",
            "Epoch: 103 Train loss: 0.0060943 Validation loss: 0.02124\n",
            "Epoch: 104 Train loss: 0.006087 Validation loss: 0.021253\n",
            "Epoch: 105 Train loss: 0.0060798 Validation loss: 0.021246\n",
            "Epoch: 106 Train loss: 0.0060726 Validation loss: 0.021258\n",
            "Epoch: 107 Train loss: 0.0060655 Validation loss: 0.021253\n",
            "Epoch: 108 Train loss: 0.0060583 Validation loss: 0.021265\n",
            "Epoch: 109 Train loss: 0.0060513 Validation loss: 0.021261\n",
            "Epoch: 110 Train loss: 0.0060442 Validation loss: 0.021272\n",
            "Epoch: 111 Train loss: 0.0060372 Validation loss: 0.021269\n",
            "Epoch: 112 Train loss: 0.0060303 Validation loss: 0.02128\n",
            "Epoch: 113 Train loss: 0.0060235 Validation loss: 0.021279\n",
            "Epoch: 114 Train loss: 0.0060166 Validation loss: 0.021289\n",
            "Epoch: 115 Train loss: 0.0060098 Validation loss: 0.021289\n",
            "Epoch: 116 Train loss: 0.006003 Validation loss: 0.021299\n",
            "Epoch: 117 Train loss: 0.0059962 Validation loss: 0.0213\n",
            "Epoch: 118 Train loss: 0.0059895 Validation loss: 0.02131\n",
            "Epoch: 119 Train loss: 0.0059829 Validation loss: 0.021311\n",
            "Epoch: 120 Train loss: 0.0059763 Validation loss: 0.021321\n",
            "Epoch: 121 Train loss: 0.0059697 Validation loss: 0.021324\n",
            "Epoch: 122 Train loss: 0.0059632 Validation loss: 0.021334\n",
            "Epoch: 123 Train loss: 0.0059567 Validation loss: 0.021337\n",
            "Epoch: 124 Train loss: 0.0059502 Validation loss: 0.021347\n",
            "Epoch: 125 Train loss: 0.0059438 Validation loss: 0.021351\n",
            "Epoch: 126 Train loss: 0.0059375 Validation loss: 0.021361\n",
            "Epoch: 127 Train loss: 0.0059311 Validation loss: 0.021365\n",
            "Epoch: 128 Train loss: 0.0059248 Validation loss: 0.021375\n",
            "Epoch: 129 Train loss: 0.0059185 Validation loss: 0.021381\n",
            "Epoch: 130 Train loss: 0.0059123 Validation loss: 0.021391\n",
            "Epoch: 131 Train loss: 0.0059061 Validation loss: 0.021397\n",
            "Epoch: 132 Train loss: 0.0058999 Validation loss: 0.021407\n",
            "Epoch: 133 Train loss: 0.0058939 Validation loss: 0.021413\n",
            "Epoch: 134 Train loss: 0.0058878 Validation loss: 0.021423\n",
            "Epoch: 135 Train loss: 0.0058817 Validation loss: 0.02143\n",
            "Epoch: 136 Train loss: 0.0058757 Validation loss: 0.021441\n",
            "Epoch: 137 Train loss: 0.0058697 Validation loss: 0.021448\n",
            "Epoch: 138 Train loss: 0.0058638 Validation loss: 0.021459\n",
            "Epoch: 139 Train loss: 0.0058579 Validation loss: 0.021466\n",
            "Epoch: 140 Train loss: 0.0058521 Validation loss: 0.021477\n",
            "Epoch: 141 Train loss: 0.0058462 Validation loss: 0.021485\n",
            "Epoch: 142 Train loss: 0.0058405 Validation loss: 0.021496\n",
            "Epoch: 143 Train loss: 0.0058347 Validation loss: 0.021505\n",
            "Epoch: 144 Train loss: 0.005829 Validation loss: 0.021516\n",
            "Epoch: 145 Train loss: 0.0058233 Validation loss: 0.021525\n",
            "Epoch: 146 Train loss: 0.0058176 Validation loss: 0.021537\n",
            "Epoch: 147 Train loss: 0.005812 Validation loss: 0.021546\n",
            "Epoch: 148 Train loss: 0.0058064 Validation loss: 0.021557\n",
            "Epoch: 149 Train loss: 0.0058009 Validation loss: 0.021568\n",
            "Epoch: 150 Train loss: 0.0057953 Validation loss: 0.021579\n",
            "Epoch: 151 Train loss: 0.0057899 Validation loss: 0.021589\n",
            "Epoch: 152 Train loss: 0.0057844 Validation loss: 0.021601\n",
            "Epoch: 153 Train loss: 0.005779 Validation loss: 0.021612\n",
            "Epoch: 154 Train loss: 0.0057736 Validation loss: 0.021624\n",
            "Epoch: 155 Train loss: 0.0057683 Validation loss: 0.021635\n",
            "Epoch: 156 Train loss: 0.0057629 Validation loss: 0.021647\n",
            "Epoch: 157 Train loss: 0.0057576 Validation loss: 0.021658\n",
            "Epoch: 158 Train loss: 0.0057524 Validation loss: 0.02167\n",
            "Epoch: 159 Train loss: 0.0057471 Validation loss: 0.021682\n",
            "Epoch: 160 Train loss: 0.005742 Validation loss: 0.021694\n",
            "Epoch: 161 Train loss: 0.0057368 Validation loss: 0.021706\n",
            "Epoch: 162 Train loss: 0.0057317 Validation loss: 0.021719\n",
            "Epoch: 163 Train loss: 0.0057266 Validation loss: 0.021731\n",
            "Epoch: 164 Train loss: 0.0057215 Validation loss: 0.021744\n",
            "Epoch: 165 Train loss: 0.0057165 Validation loss: 0.021756\n",
            "Epoch: 166 Train loss: 0.0057115 Validation loss: 0.021769\n",
            "Epoch: 167 Train loss: 0.0057065 Validation loss: 0.021782\n",
            "Epoch: 168 Train loss: 0.0057016 Validation loss: 0.021795\n",
            "Epoch: 169 Train loss: 0.0056967 Validation loss: 0.021808\n",
            "Epoch: 170 Train loss: 0.0056918 Validation loss: 0.021821\n",
            "Epoch: 171 Train loss: 0.0056869 Validation loss: 0.021835\n",
            "Epoch: 172 Train loss: 0.0056821 Validation loss: 0.021848\n",
            "Epoch: 173 Train loss: 0.0056773 Validation loss: 0.021862\n",
            "Epoch: 174 Train loss: 0.0056725 Validation loss: 0.021875\n",
            "Epoch: 175 Train loss: 0.0056678 Validation loss: 0.021889\n",
            "Epoch: 176 Train loss: 0.0056631 Validation loss: 0.021902\n",
            "Epoch: 177 Train loss: 0.0056584 Validation loss: 0.021916\n",
            "Epoch: 178 Train loss: 0.0056538 Validation loss: 0.02193\n",
            "Epoch: 179 Train loss: 0.0056492 Validation loss: 0.021945\n",
            "Epoch: 180 Train loss: 0.0056446 Validation loss: 0.021958\n",
            "Epoch: 181 Train loss: 0.00564 Validation loss: 0.021973\n",
            "Epoch: 182 Train loss: 0.0056354 Validation loss: 0.021987\n",
            "Epoch: 183 Train loss: 0.005631 Validation loss: 0.022001\n",
            "Epoch: 184 Train loss: 0.0056264 Validation loss: 0.022016\n",
            "Epoch: 185 Train loss: 0.005622 Validation loss: 0.02203\n",
            "Epoch: 186 Train loss: 0.0056176 Validation loss: 0.022045\n",
            "Epoch: 187 Train loss: 0.0056132 Validation loss: 0.02206\n",
            "Epoch: 188 Train loss: 0.0056088 Validation loss: 0.022074\n",
            "Epoch: 189 Train loss: 0.0056044 Validation loss: 0.022089\n",
            "Epoch: 190 Train loss: 0.0056002 Validation loss: 0.022104\n",
            "Epoch: 191 Train loss: 0.0055959 Validation loss: 0.022119\n",
            "Epoch: 192 Train loss: 0.0055916 Validation loss: 0.022134\n",
            "Epoch: 193 Train loss: 0.0055874 Validation loss: 0.022149\n",
            "Epoch: 194 Train loss: 0.0055831 Validation loss: 0.022164\n",
            "Epoch: 195 Train loss: 0.005579 Validation loss: 0.02218\n",
            "Epoch: 196 Train loss: 0.0055748 Validation loss: 0.022195\n",
            "Epoch: 197 Train loss: 0.0055706 Validation loss: 0.02221\n",
            "Epoch: 198 Train loss: 0.0055665 Validation loss: 0.022226\n",
            "Epoch: 199 Train loss: 0.0055624 Validation loss: 0.022241\n",
            "Epoch: 200 Train loss: 0.0055584 Validation loss: 0.022257\n",
            "Epoch: 201 Train loss: 0.0055543 Validation loss: 0.022272\n",
            "Epoch: 202 Train loss: 0.0055503 Validation loss: 0.022288\n",
            "Epoch: 203 Train loss: 0.0055463 Validation loss: 0.022304\n",
            "Epoch: 204 Train loss: 0.0055424 Validation loss: 0.02232\n",
            "Epoch: 205 Train loss: 0.0055384 Validation loss: 0.022335\n",
            "Epoch: 206 Train loss: 0.0055345 Validation loss: 0.022352\n",
            "Epoch: 207 Train loss: 0.0055306 Validation loss: 0.022367\n",
            "Epoch: 208 Train loss: 0.0055267 Validation loss: 0.022384\n",
            "Epoch: 209 Train loss: 0.0055229 Validation loss: 0.022399\n",
            "Epoch: 210 Train loss: 0.0055191 Validation loss: 0.022416\n",
            "Epoch: 211 Train loss: 0.0055153 Validation loss: 0.022432\n",
            "Epoch: 212 Train loss: 0.0055115 Validation loss: 0.022448\n",
            "Epoch: 213 Train loss: 0.0055077 Validation loss: 0.022464\n",
            "Epoch: 214 Train loss: 0.005504 Validation loss: 0.022481\n",
            "Epoch: 215 Train loss: 0.0055003 Validation loss: 0.022497\n",
            "Epoch: 216 Train loss: 0.0054966 Validation loss: 0.022513\n",
            "Epoch: 217 Train loss: 0.005493 Validation loss: 0.022529\n",
            "Epoch: 218 Train loss: 0.0054893 Validation loss: 0.022546\n",
            "Epoch: 219 Train loss: 0.0054857 Validation loss: 0.022562\n",
            "Epoch: 220 Train loss: 0.0054821 Validation loss: 0.022579\n",
            "Epoch: 221 Train loss: 0.0054785 Validation loss: 0.022595\n",
            "Epoch: 222 Train loss: 0.005475 Validation loss: 0.022612\n",
            "Epoch: 223 Train loss: 0.0054715 Validation loss: 0.022629\n",
            "Epoch: 224 Train loss: 0.0054679 Validation loss: 0.022645\n",
            "Epoch: 225 Train loss: 0.0054645 Validation loss: 0.022662\n",
            "Epoch: 226 Train loss: 0.005461 Validation loss: 0.022679\n",
            "Epoch: 227 Train loss: 0.0054576 Validation loss: 0.022695\n",
            "Epoch: 228 Train loss: 0.0054541 Validation loss: 0.022712\n",
            "Epoch: 229 Train loss: 0.0054507 Validation loss: 0.022729\n",
            "Epoch: 230 Train loss: 0.0054473 Validation loss: 0.022746\n",
            "Epoch: 231 Train loss: 0.005444 Validation loss: 0.022763\n",
            "Epoch: 232 Train loss: 0.0054406 Validation loss: 0.02278\n",
            "Epoch: 233 Train loss: 0.0054373 Validation loss: 0.022796\n",
            "Epoch: 234 Train loss: 0.005434 Validation loss: 0.022813\n",
            "Epoch: 235 Train loss: 0.0054307 Validation loss: 0.02283\n",
            "Epoch: 236 Train loss: 0.0054274 Validation loss: 0.022847\n",
            "Epoch: 237 Train loss: 0.0054242 Validation loss: 0.022864\n",
            "Epoch: 238 Train loss: 0.005421 Validation loss: 0.022881\n",
            "Epoch: 239 Train loss: 0.0054177 Validation loss: 0.022898\n",
            "Epoch: 240 Train loss: 0.0054146 Validation loss: 0.022915\n",
            "Epoch: 241 Train loss: 0.0054114 Validation loss: 0.022932\n",
            "Epoch: 242 Train loss: 0.0054082 Validation loss: 0.022949\n",
            "Epoch: 243 Train loss: 0.0054051 Validation loss: 0.022966\n",
            "Epoch: 244 Train loss: 0.005402 Validation loss: 0.022984\n",
            "Epoch: 245 Train loss: 0.0053989 Validation loss: 0.023001\n",
            "Epoch: 246 Train loss: 0.0053958 Validation loss: 0.023018\n",
            "Epoch: 247 Train loss: 0.0053928 Validation loss: 0.023035\n",
            "Epoch: 248 Train loss: 0.0053897 Validation loss: 0.023052\n",
            "Epoch: 249 Train loss: 0.0053867 Validation loss: 0.023069\n",
            "Epoch: 250 Train loss: 0.0053837 Validation loss: 0.023086\n",
            "Epoch: 251 Train loss: 0.0053808 Validation loss: 0.023104\n",
            "Epoch: 252 Train loss: 0.0053778 Validation loss: 0.023121\n",
            "Epoch: 253 Train loss: 0.0053748 Validation loss: 0.023138\n",
            "Epoch: 254 Train loss: 0.0053719 Validation loss: 0.023155\n",
            "Epoch: 255 Train loss: 0.005369 Validation loss: 0.023172\n",
            "Epoch: 256 Train loss: 0.0053661 Validation loss: 0.023189\n",
            "Epoch: 257 Train loss: 0.0053632 Validation loss: 0.023207\n",
            "Epoch: 258 Train loss: 0.0053604 Validation loss: 0.023224\n",
            "Epoch: 259 Train loss: 0.0053575 Validation loss: 0.023241\n",
            "Epoch: 260 Train loss: 0.0053547 Validation loss: 0.023258\n",
            "Epoch: 261 Train loss: 0.0053519 Validation loss: 0.023276\n",
            "Epoch: 262 Train loss: 0.005349 Validation loss: 0.023293\n",
            "Epoch: 263 Train loss: 0.0053463 Validation loss: 0.02331\n",
            "Epoch: 264 Train loss: 0.0053435 Validation loss: 0.023327\n",
            "Epoch: 265 Train loss: 0.0053408 Validation loss: 0.023344\n",
            "Epoch: 266 Train loss: 0.0053381 Validation loss: 0.023361\n",
            "Epoch: 267 Train loss: 0.0053354 Validation loss: 0.023379\n",
            "Epoch: 268 Train loss: 0.0053326 Validation loss: 0.023396\n",
            "Epoch: 269 Train loss: 0.0053299 Validation loss: 0.023413\n",
            "Epoch: 270 Train loss: 0.0053273 Validation loss: 0.02343\n",
            "Epoch: 271 Train loss: 0.0053246 Validation loss: 0.023447\n",
            "Epoch: 272 Train loss: 0.005322 Validation loss: 0.023465\n",
            "Epoch: 273 Train loss: 0.0053194 Validation loss: 0.023482\n",
            "Epoch: 274 Train loss: 0.0053168 Validation loss: 0.023499\n",
            "Epoch: 275 Train loss: 0.0053142 Validation loss: 0.023516\n",
            "Epoch: 276 Train loss: 0.0053116 Validation loss: 0.023533\n",
            "Epoch: 277 Train loss: 0.005309 Validation loss: 0.02355\n",
            "Epoch: 278 Train loss: 0.0053065 Validation loss: 0.023567\n",
            "Epoch: 279 Train loss: 0.0053039 Validation loss: 0.023584\n",
            "Epoch: 280 Train loss: 0.0053015 Validation loss: 0.023602\n",
            "Epoch: 281 Train loss: 0.0052989 Validation loss: 0.023619\n",
            "Epoch: 282 Train loss: 0.0052964 Validation loss: 0.023636\n",
            "Epoch: 283 Train loss: 0.005294 Validation loss: 0.023653\n",
            "Epoch: 284 Train loss: 0.0052915 Validation loss: 0.02367\n",
            "Epoch: 285 Train loss: 0.0052891 Validation loss: 0.023687\n",
            "Epoch: 286 Train loss: 0.0052867 Validation loss: 0.023704\n",
            "Epoch: 287 Train loss: 0.0052842 Validation loss: 0.023721\n",
            "Epoch: 288 Train loss: 0.0052818 Validation loss: 0.023738\n",
            "Epoch: 289 Train loss: 0.0052795 Validation loss: 0.023755\n",
            "Epoch: 290 Train loss: 0.0052771 Validation loss: 0.023772\n",
            "Epoch: 291 Train loss: 0.0052747 Validation loss: 0.023789\n",
            "Epoch: 292 Train loss: 0.0052724 Validation loss: 0.023806\n",
            "Epoch: 293 Train loss: 0.00527 Validation loss: 0.023823\n",
            "Epoch: 294 Train loss: 0.0052677 Validation loss: 0.02384\n",
            "Epoch: 295 Train loss: 0.0052654 Validation loss: 0.023856\n",
            "Epoch: 296 Train loss: 0.0052631 Validation loss: 0.023873\n",
            "Epoch: 297 Train loss: 0.0052608 Validation loss: 0.02389\n",
            "Epoch: 298 Train loss: 0.0052585 Validation loss: 0.023907\n",
            "Epoch: 299 Train loss: 0.0052563 Validation loss: 0.023924\n",
            "Epoch: 300 Train loss: 0.005254 Validation loss: 0.023941\n",
            "Epoch: 301 Train loss: 0.0052518 Validation loss: 0.023957\n",
            "Epoch: 302 Train loss: 0.0052496 Validation loss: 0.023974\n",
            "Epoch: 303 Train loss: 0.0052474 Validation loss: 0.023991\n",
            "Epoch: 304 Train loss: 0.0052452 Validation loss: 0.024008\n",
            "Epoch: 305 Train loss: 0.005243 Validation loss: 0.024024\n",
            "Epoch: 306 Train loss: 0.0052408 Validation loss: 0.024041\n",
            "Epoch: 307 Train loss: 0.0052387 Validation loss: 0.024057\n",
            "Epoch: 308 Train loss: 0.0052366 Validation loss: 0.024074\n",
            "Epoch: 309 Train loss: 0.0052344 Validation loss: 0.02409\n",
            "Epoch: 310 Train loss: 0.0052323 Validation loss: 0.024107\n",
            "Epoch: 311 Train loss: 0.0052302 Validation loss: 0.024124\n",
            "Epoch: 312 Train loss: 0.0052281 Validation loss: 0.02414\n",
            "Epoch: 313 Train loss: 0.005226 Validation loss: 0.024156\n",
            "Epoch: 314 Train loss: 0.0052239 Validation loss: 0.024173\n",
            "Epoch: 315 Train loss: 0.0052218 Validation loss: 0.024189\n",
            "Epoch: 316 Train loss: 0.0052198 Validation loss: 0.024206\n",
            "Epoch: 317 Train loss: 0.0052177 Validation loss: 0.024222\n",
            "Epoch: 318 Train loss: 0.0052157 Validation loss: 0.024239\n",
            "Epoch: 319 Train loss: 0.0052137 Validation loss: 0.024255\n",
            "Epoch: 320 Train loss: 0.0052117 Validation loss: 0.024271\n",
            "Epoch: 321 Train loss: 0.0052097 Validation loss: 0.024287\n",
            "Epoch: 322 Train loss: 0.0052077 Validation loss: 0.024304\n",
            "Epoch: 323 Train loss: 0.0052057 Validation loss: 0.02432\n",
            "Epoch: 324 Train loss: 0.0052038 Validation loss: 0.024336\n",
            "Epoch: 325 Train loss: 0.0052018 Validation loss: 0.024352\n",
            "Epoch: 326 Train loss: 0.0051999 Validation loss: 0.024369\n",
            "Epoch: 327 Train loss: 0.0051979 Validation loss: 0.024385\n",
            "Epoch: 328 Train loss: 0.005196 Validation loss: 0.024401\n",
            "Epoch: 329 Train loss: 0.0051941 Validation loss: 0.024417\n",
            "Epoch: 330 Train loss: 0.0051922 Validation loss: 0.024433\n",
            "Epoch: 331 Train loss: 0.0051903 Validation loss: 0.024449\n",
            "Epoch: 332 Train loss: 0.0051884 Validation loss: 0.024465\n",
            "Epoch: 333 Train loss: 0.0051866 Validation loss: 0.02448\n",
            "Epoch: 334 Train loss: 0.0051847 Validation loss: 0.024496\n",
            "Epoch: 335 Train loss: 0.0051828 Validation loss: 0.024512\n",
            "Epoch: 336 Train loss: 0.005181 Validation loss: 0.024528\n",
            "Epoch: 337 Train loss: 0.0051792 Validation loss: 0.024544\n",
            "Epoch: 338 Train loss: 0.0051773 Validation loss: 0.02456\n",
            "Epoch: 339 Train loss: 0.0051755 Validation loss: 0.024575\n",
            "Epoch: 340 Train loss: 0.0051737 Validation loss: 0.024591\n",
            "Epoch: 341 Train loss: 0.0051719 Validation loss: 0.024607\n",
            "Epoch: 342 Train loss: 0.0051702 Validation loss: 0.024622\n",
            "Epoch: 343 Train loss: 0.0051683 Validation loss: 0.024638\n",
            "Epoch: 344 Train loss: 0.0051666 Validation loss: 0.024653\n",
            "Epoch: 345 Train loss: 0.0051648 Validation loss: 0.024669\n",
            "Epoch: 346 Train loss: 0.0051631 Validation loss: 0.024684\n",
            "Epoch: 347 Train loss: 0.0051614 Validation loss: 0.0247\n",
            "Epoch: 348 Train loss: 0.0051596 Validation loss: 0.024715\n",
            "Epoch: 349 Train loss: 0.0051579 Validation loss: 0.024731\n",
            "Epoch: 350 Train loss: 0.0051562 Validation loss: 0.024746\n",
            "Epoch: 351 Train loss: 0.0051544 Validation loss: 0.024761\n",
            "Epoch: 352 Train loss: 0.0051528 Validation loss: 0.024777\n",
            "Epoch: 353 Train loss: 0.0051511 Validation loss: 0.024792\n",
            "Epoch: 354 Train loss: 0.0051494 Validation loss: 0.024807\n",
            "Epoch: 355 Train loss: 0.0051478 Validation loss: 0.024822\n",
            "Epoch: 356 Train loss: 0.0051461 Validation loss: 0.024837\n",
            "Epoch: 357 Train loss: 0.0051445 Validation loss: 0.024853\n",
            "Epoch: 358 Train loss: 0.0051428 Validation loss: 0.024868\n",
            "Epoch: 359 Train loss: 0.0051412 Validation loss: 0.024883\n",
            "Epoch: 360 Train loss: 0.0051396 Validation loss: 0.024898\n",
            "Epoch: 361 Train loss: 0.0051379 Validation loss: 0.024913\n",
            "Epoch: 362 Train loss: 0.0051363 Validation loss: 0.024928\n",
            "Epoch: 363 Train loss: 0.0051347 Validation loss: 0.024943\n",
            "Epoch: 364 Train loss: 0.0051331 Validation loss: 0.024957\n",
            "Epoch: 365 Train loss: 0.0051315 Validation loss: 0.024972\n",
            "Epoch: 366 Train loss: 0.0051299 Validation loss: 0.024987\n",
            "Epoch: 367 Train loss: 0.0051284 Validation loss: 0.025002\n",
            "Epoch: 368 Train loss: 0.0051268 Validation loss: 0.025016\n",
            "Epoch: 369 Train loss: 0.0051253 Validation loss: 0.025031\n",
            "Epoch: 370 Train loss: 0.0051237 Validation loss: 0.025046\n",
            "Epoch: 371 Train loss: 0.0051222 Validation loss: 0.02506\n",
            "Epoch: 372 Train loss: 0.0051206 Validation loss: 0.025075\n",
            "Epoch: 373 Train loss: 0.0051191 Validation loss: 0.025089\n",
            "Epoch: 374 Train loss: 0.0051176 Validation loss: 0.025104\n",
            "Epoch: 375 Train loss: 0.0051161 Validation loss: 0.025118\n",
            "Epoch: 376 Train loss: 0.0051146 Validation loss: 0.025133\n",
            "Epoch: 377 Train loss: 0.0051131 Validation loss: 0.025147\n",
            "Epoch: 378 Train loss: 0.0051116 Validation loss: 0.025161\n",
            "Epoch: 379 Train loss: 0.0051102 Validation loss: 0.025176\n",
            "Epoch: 380 Train loss: 0.0051087 Validation loss: 0.02519\n",
            "Epoch: 381 Train loss: 0.0051072 Validation loss: 0.025204\n",
            "Epoch: 382 Train loss: 0.0051058 Validation loss: 0.025218\n",
            "Epoch: 383 Train loss: 0.0051043 Validation loss: 0.025233\n",
            "Epoch: 384 Train loss: 0.0051028 Validation loss: 0.025247\n",
            "Epoch: 385 Train loss: 0.0051014 Validation loss: 0.025261\n",
            "Epoch: 386 Train loss: 0.0051 Validation loss: 0.025275\n",
            "Epoch: 387 Train loss: 0.0050985 Validation loss: 0.025289\n",
            "Epoch: 388 Train loss: 0.0050971 Validation loss: 0.025303\n",
            "Epoch: 389 Train loss: 0.0050957 Validation loss: 0.025317\n",
            "Epoch: 390 Train loss: 0.0050943 Validation loss: 0.02533\n",
            "Epoch: 391 Train loss: 0.0050929 Validation loss: 0.025344\n",
            "Epoch: 392 Train loss: 0.0050915 Validation loss: 0.025358\n",
            "Epoch: 393 Train loss: 0.0050902 Validation loss: 0.025372\n",
            "Epoch: 394 Train loss: 0.0050888 Validation loss: 0.025386\n",
            "Epoch: 395 Train loss: 0.0050874 Validation loss: 0.025399\n",
            "Epoch: 396 Train loss: 0.005086 Validation loss: 0.025413\n",
            "Epoch: 397 Train loss: 0.0050846 Validation loss: 0.025427\n",
            "Epoch: 398 Train loss: 0.0050833 Validation loss: 0.02544\n",
            "Epoch: 399 Train loss: 0.005082 Validation loss: 0.025454\n",
            "Epoch: 400 Train loss: 0.0050806 Validation loss: 0.025467\n",
            "Epoch: 401 Train loss: 0.0050793 Validation loss: 0.025481\n",
            "Epoch: 402 Train loss: 0.005078 Validation loss: 0.025494\n",
            "Epoch: 403 Train loss: 0.0050766 Validation loss: 0.025508\n",
            "Epoch: 404 Train loss: 0.0050753 Validation loss: 0.025521\n",
            "Epoch: 405 Train loss: 0.005074 Validation loss: 0.025534\n",
            "Epoch: 406 Train loss: 0.0050727 Validation loss: 0.025547\n",
            "Epoch: 407 Train loss: 0.0050714 Validation loss: 0.025561\n",
            "Epoch: 408 Train loss: 0.0050701 Validation loss: 0.025574\n",
            "Epoch: 409 Train loss: 0.0050688 Validation loss: 0.025587\n",
            "Epoch: 410 Train loss: 0.0050676 Validation loss: 0.0256\n",
            "Epoch: 411 Train loss: 0.0050663 Validation loss: 0.025613\n",
            "Epoch: 412 Train loss: 0.005065 Validation loss: 0.025626\n",
            "Epoch: 413 Train loss: 0.0050638 Validation loss: 0.025639\n",
            "Epoch: 414 Train loss: 0.0050625 Validation loss: 0.025652\n",
            "Epoch: 415 Train loss: 0.0050613 Validation loss: 0.025665\n",
            "Epoch: 416 Train loss: 0.00506 Validation loss: 0.025678\n",
            "Epoch: 417 Train loss: 0.0050588 Validation loss: 0.025691\n",
            "Epoch: 418 Train loss: 0.0050575 Validation loss: 0.025703\n",
            "Epoch: 419 Train loss: 0.0050563 Validation loss: 0.025716\n",
            "Epoch: 420 Train loss: 0.0050551 Validation loss: 0.025729\n",
            "Epoch: 421 Train loss: 0.0050539 Validation loss: 0.025742\n",
            "Epoch: 422 Train loss: 0.0050526 Validation loss: 0.025754\n",
            "Epoch: 423 Train loss: 0.0050514 Validation loss: 0.025767\n",
            "Epoch: 424 Train loss: 0.0050502 Validation loss: 0.025779\n",
            "Epoch: 425 Train loss: 0.005049 Validation loss: 0.025792\n",
            "Epoch: 426 Train loss: 0.0050478 Validation loss: 0.025804\n",
            "Epoch: 427 Train loss: 0.0050467 Validation loss: 0.025817\n",
            "Epoch: 428 Train loss: 0.0050454 Validation loss: 0.025829\n",
            "Epoch: 429 Train loss: 0.0050443 Validation loss: 0.025841\n",
            "Epoch: 430 Train loss: 0.0050431 Validation loss: 0.025854\n",
            "Epoch: 431 Train loss: 0.0050419 Validation loss: 0.025866\n",
            "Epoch: 432 Train loss: 0.0050408 Validation loss: 0.025878\n",
            "Epoch: 433 Train loss: 0.0050396 Validation loss: 0.02589\n",
            "Epoch: 434 Train loss: 0.0050385 Validation loss: 0.025903\n",
            "Epoch: 435 Train loss: 0.0050373 Validation loss: 0.025915\n",
            "Epoch: 436 Train loss: 0.0050362 Validation loss: 0.025927\n",
            "Epoch: 437 Train loss: 0.005035 Validation loss: 0.025939\n",
            "Epoch: 438 Train loss: 0.0050339 Validation loss: 0.025951\n",
            "Epoch: 439 Train loss: 0.0050327 Validation loss: 0.025963\n",
            "Epoch: 440 Train loss: 0.0050316 Validation loss: 0.025975\n",
            "Epoch: 441 Train loss: 0.0050305 Validation loss: 0.025987\n",
            "Epoch: 442 Train loss: 0.0050294 Validation loss: 0.025999\n",
            "Epoch: 443 Train loss: 0.0050283 Validation loss: 0.02601\n",
            "Epoch: 444 Train loss: 0.0050272 Validation loss: 0.026022\n",
            "Epoch: 445 Train loss: 0.0050261 Validation loss: 0.026034\n",
            "Epoch: 446 Train loss: 0.005025 Validation loss: 0.026046\n",
            "Epoch: 447 Train loss: 0.0050239 Validation loss: 0.026057\n",
            "Epoch: 448 Train loss: 0.0050228 Validation loss: 0.026069\n",
            "Epoch: 449 Train loss: 0.0050217 Validation loss: 0.02608\n",
            "Epoch: 450 Train loss: 0.0050206 Validation loss: 0.026092\n",
            "Epoch: 451 Train loss: 0.0050195 Validation loss: 0.026103\n",
            "Epoch: 452 Train loss: 0.0050185 Validation loss: 0.026115\n",
            "Epoch: 453 Train loss: 0.0050174 Validation loss: 0.026126\n",
            "Epoch: 454 Train loss: 0.0050164 Validation loss: 0.026138\n",
            "Epoch: 455 Train loss: 0.0050153 Validation loss: 0.026149\n",
            "Epoch: 456 Train loss: 0.0050142 Validation loss: 0.026161\n",
            "Epoch: 457 Train loss: 0.0050132 Validation loss: 0.026172\n",
            "Epoch: 458 Train loss: 0.0050121 Validation loss: 0.026183\n",
            "Epoch: 459 Train loss: 0.0050111 Validation loss: 0.026194\n",
            "Epoch: 460 Train loss: 0.00501 Validation loss: 0.026206\n",
            "Epoch: 461 Train loss: 0.005009 Validation loss: 0.026217\n",
            "Epoch: 462 Train loss: 0.005008 Validation loss: 0.026228\n",
            "Epoch: 463 Train loss: 0.0050069 Validation loss: 0.026239\n",
            "Epoch: 464 Train loss: 0.0050059 Validation loss: 0.02625\n",
            "Epoch: 465 Train loss: 0.0050049 Validation loss: 0.026261\n",
            "Epoch: 466 Train loss: 0.0050039 Validation loss: 0.026272\n",
            "Epoch: 467 Train loss: 0.0050029 Validation loss: 0.026282\n",
            "Epoch: 468 Train loss: 0.0050019 Validation loss: 0.026294\n",
            "Epoch: 469 Train loss: 0.0050009 Validation loss: 0.026304\n",
            "Epoch: 470 Train loss: 0.0049999 Validation loss: 0.026315\n",
            "Epoch: 471 Train loss: 0.0049989 Validation loss: 0.026326\n",
            "Epoch: 472 Train loss: 0.0049979 Validation loss: 0.026337\n",
            "Epoch: 473 Train loss: 0.0049969 Validation loss: 0.026347\n",
            "Epoch: 474 Train loss: 0.0049959 Validation loss: 0.026358\n",
            "Epoch: 475 Train loss: 0.0049949 Validation loss: 0.026369\n",
            "Epoch: 476 Train loss: 0.0049939 Validation loss: 0.026379\n",
            "Epoch: 477 Train loss: 0.004993 Validation loss: 0.02639\n",
            "Epoch: 478 Train loss: 0.004992 Validation loss: 0.0264\n",
            "Epoch: 479 Train loss: 0.004991 Validation loss: 0.026411\n",
            "Epoch: 480 Train loss: 0.0049901 Validation loss: 0.026421\n",
            "Epoch: 481 Train loss: 0.0049891 Validation loss: 0.026432\n",
            "Epoch: 482 Train loss: 0.0049881 Validation loss: 0.026442\n",
            "Epoch: 483 Train loss: 0.0049872 Validation loss: 0.026452\n",
            "Epoch: 484 Train loss: 0.0049862 Validation loss: 0.026463\n",
            "Epoch: 485 Train loss: 0.0049853 Validation loss: 0.026473\n",
            "Epoch: 486 Train loss: 0.0049844 Validation loss: 0.026483\n",
            "Epoch: 487 Train loss: 0.0049834 Validation loss: 0.026493\n",
            "Epoch: 488 Train loss: 0.0049825 Validation loss: 0.026504\n",
            "Epoch: 489 Train loss: 0.0049815 Validation loss: 0.026514\n",
            "Epoch: 490 Train loss: 0.0049806 Validation loss: 0.026524\n",
            "Epoch: 491 Train loss: 0.0049797 Validation loss: 0.026534\n",
            "Epoch: 492 Train loss: 0.0049788 Validation loss: 0.026544\n",
            "Epoch: 493 Train loss: 0.0049778 Validation loss: 0.026554\n",
            "Epoch: 494 Train loss: 0.0049769 Validation loss: 0.026564\n",
            "Epoch: 495 Train loss: 0.004976 Validation loss: 0.026574\n",
            "Epoch: 496 Train loss: 0.0049751 Validation loss: 0.026584\n",
            "Epoch: 497 Train loss: 0.0049742 Validation loss: 0.026593\n",
            "Epoch: 498 Train loss: 0.0049732 Validation loss: 0.026603\n",
            "Epoch: 499 Train loss: 0.0049724 Validation loss: 0.026613\n",
            "Epoch: 500 Train loss: 0.0049714 Validation loss: 0.026623\n",
            "Epoch: 501 Train loss: 0.0049705 Validation loss: 0.026632\n",
            "Epoch: 502 Train loss: 0.0049697 Validation loss: 0.026642\n",
            "Epoch: 503 Train loss: 0.0049688 Validation loss: 0.026651\n",
            "Epoch: 504 Train loss: 0.0049679 Validation loss: 0.026661\n",
            "Epoch: 505 Train loss: 0.004967 Validation loss: 0.026671\n",
            "Epoch: 506 Train loss: 0.0049661 Validation loss: 0.02668\n",
            "Epoch: 507 Train loss: 0.0049653 Validation loss: 0.02669\n",
            "Epoch: 508 Train loss: 0.0049643 Validation loss: 0.026699\n",
            "Epoch: 509 Train loss: 0.0049635 Validation loss: 0.026709\n",
            "Epoch: 510 Train loss: 0.0049626 Validation loss: 0.026718\n",
            "Epoch: 511 Train loss: 0.0049618 Validation loss: 0.026727\n",
            "Epoch: 512 Train loss: 0.0049609 Validation loss: 0.026737\n",
            "Epoch: 513 Train loss: 0.00496 Validation loss: 0.026746\n",
            "Epoch: 514 Train loss: 0.0049592 Validation loss: 0.026755\n",
            "Epoch: 515 Train loss: 0.0049583 Validation loss: 0.026765\n",
            "Epoch: 516 Train loss: 0.0049574 Validation loss: 0.026774\n",
            "Epoch: 517 Train loss: 0.0049566 Validation loss: 0.026783\n",
            "Epoch: 518 Train loss: 0.0049558 Validation loss: 0.026792\n",
            "Epoch: 519 Train loss: 0.0049549 Validation loss: 0.026801\n",
            "Epoch: 520 Train loss: 0.0049541 Validation loss: 0.02681\n",
            "Epoch: 521 Train loss: 0.0049532 Validation loss: 0.026819\n",
            "Epoch: 522 Train loss: 0.0049524 Validation loss: 0.026828\n",
            "Epoch: 523 Train loss: 0.0049516 Validation loss: 0.026837\n",
            "Epoch: 524 Train loss: 0.0049507 Validation loss: 0.026846\n",
            "Epoch: 525 Train loss: 0.0049499 Validation loss: 0.026855\n",
            "Epoch: 526 Train loss: 0.0049491 Validation loss: 0.026864\n",
            "Epoch: 527 Train loss: 0.0049482 Validation loss: 0.026873\n",
            "Epoch: 528 Train loss: 0.0049474 Validation loss: 0.026881\n",
            "Epoch: 529 Train loss: 0.0049466 Validation loss: 0.02689\n",
            "Epoch: 530 Train loss: 0.0049458 Validation loss: 0.026899\n",
            "Epoch: 531 Train loss: 0.004945 Validation loss: 0.026907\n",
            "Epoch: 532 Train loss: 0.0049442 Validation loss: 0.026916\n",
            "Epoch: 533 Train loss: 0.0049434 Validation loss: 0.026925\n",
            "Epoch: 534 Train loss: 0.0049425 Validation loss: 0.026933\n",
            "Epoch: 535 Train loss: 0.0049418 Validation loss: 0.026942\n",
            "Epoch: 536 Train loss: 0.0049409 Validation loss: 0.02695\n",
            "Epoch: 537 Train loss: 0.0049401 Validation loss: 0.026959\n",
            "Epoch: 538 Train loss: 0.0049393 Validation loss: 0.026967\n",
            "Epoch: 539 Train loss: 0.0049385 Validation loss: 0.026976\n",
            "Epoch: 540 Train loss: 0.0049377 Validation loss: 0.026984\n",
            "Epoch: 541 Train loss: 0.004937 Validation loss: 0.026993\n",
            "Epoch: 542 Train loss: 0.0049361 Validation loss: 0.027001\n",
            "Epoch: 543 Train loss: 0.0049354 Validation loss: 0.02701\n",
            "Epoch: 544 Train loss: 0.0049346 Validation loss: 0.027018\n",
            "Epoch: 545 Train loss: 0.0049338 Validation loss: 0.027026\n",
            "Epoch: 546 Train loss: 0.004933 Validation loss: 0.027034\n",
            "Epoch: 547 Train loss: 0.0049323 Validation loss: 0.027042\n",
            "Epoch: 548 Train loss: 0.0049315 Validation loss: 0.02705\n",
            "Epoch: 549 Train loss: 0.0049307 Validation loss: 0.027059\n",
            "Epoch: 550 Train loss: 0.0049299 Validation loss: 0.027067\n",
            "Epoch: 551 Train loss: 0.0049292 Validation loss: 0.027075\n",
            "Epoch: 552 Train loss: 0.0049284 Validation loss: 0.027083\n",
            "Epoch: 553 Train loss: 0.0049276 Validation loss: 0.027091\n",
            "Epoch: 554 Train loss: 0.0049268 Validation loss: 0.027099\n",
            "Epoch: 555 Train loss: 0.0049261 Validation loss: 0.027107\n",
            "Epoch: 556 Train loss: 0.0049254 Validation loss: 0.027115\n",
            "Epoch: 557 Train loss: 0.0049246 Validation loss: 0.027123\n",
            "Epoch: 558 Train loss: 0.0049238 Validation loss: 0.02713\n",
            "Epoch: 559 Train loss: 0.0049231 Validation loss: 0.027138\n",
            "Epoch: 560 Train loss: 0.0049224 Validation loss: 0.027146\n",
            "Epoch: 561 Train loss: 0.0049216 Validation loss: 0.027154\n",
            "Epoch: 562 Train loss: 0.0049209 Validation loss: 0.027162\n",
            "Epoch: 563 Train loss: 0.0049201 Validation loss: 0.027169\n",
            "Epoch: 564 Train loss: 0.0049194 Validation loss: 0.027177\n",
            "Epoch: 565 Train loss: 0.0049186 Validation loss: 0.027185\n",
            "Epoch: 566 Train loss: 0.0049179 Validation loss: 0.027192\n",
            "Epoch: 567 Train loss: 0.0049171 Validation loss: 0.0272\n",
            "Epoch: 568 Train loss: 0.0049164 Validation loss: 0.027207\n",
            "Epoch: 569 Train loss: 0.0049157 Validation loss: 0.027215\n",
            "Epoch: 570 Train loss: 0.0049149 Validation loss: 0.027222\n",
            "Epoch: 571 Train loss: 0.0049142 Validation loss: 0.02723\n",
            "Epoch: 572 Train loss: 0.0049135 Validation loss: 0.027237\n",
            "Epoch: 573 Train loss: 0.0049128 Validation loss: 0.027245\n",
            "Epoch: 574 Train loss: 0.004912 Validation loss: 0.027252\n",
            "Epoch: 575 Train loss: 0.0049113 Validation loss: 0.027259\n",
            "Epoch: 576 Train loss: 0.0049106 Validation loss: 0.027267\n",
            "Epoch: 577 Train loss: 0.0049099 Validation loss: 0.027274\n",
            "Epoch: 578 Train loss: 0.0049091 Validation loss: 0.027281\n",
            "Epoch: 579 Train loss: 0.0049084 Validation loss: 0.027288\n",
            "Epoch: 580 Train loss: 0.0049077 Validation loss: 0.027296\n",
            "Epoch: 581 Train loss: 0.004907 Validation loss: 0.027303\n",
            "Epoch: 582 Train loss: 0.0049063 Validation loss: 0.02731\n",
            "Epoch: 583 Train loss: 0.0049056 Validation loss: 0.027317\n",
            "Epoch: 584 Train loss: 0.0049049 Validation loss: 0.027325\n",
            "Epoch: 585 Train loss: 0.0049042 Validation loss: 0.027332\n",
            "Epoch: 586 Train loss: 0.0049035 Validation loss: 0.027339\n",
            "Epoch: 587 Train loss: 0.0049028 Validation loss: 0.027346\n",
            "Epoch: 588 Train loss: 0.0049021 Validation loss: 0.027353\n",
            "Epoch: 589 Train loss: 0.0049014 Validation loss: 0.02736\n",
            "Epoch: 590 Train loss: 0.0049007 Validation loss: 0.027367\n",
            "Epoch: 591 Train loss: 0.0049 Validation loss: 0.027374\n",
            "Epoch: 592 Train loss: 0.0048993 Validation loss: 0.027381\n",
            "Epoch: 593 Train loss: 0.0048986 Validation loss: 0.027387\n",
            "Epoch: 594 Train loss: 0.0048979 Validation loss: 0.027394\n",
            "Epoch: 595 Train loss: 0.0048972 Validation loss: 0.027401\n",
            "Epoch: 596 Train loss: 0.0048965 Validation loss: 0.027408\n",
            "Epoch: 597 Train loss: 0.0048959 Validation loss: 0.027415\n",
            "Epoch: 598 Train loss: 0.0048952 Validation loss: 0.027421\n",
            "Epoch: 599 Train loss: 0.0048945 Validation loss: 0.027428\n",
            "Epoch: 600 Train loss: 0.0048938 Validation loss: 0.027435\n",
            "Epoch: 601 Train loss: 0.0048931 Validation loss: 0.027441\n",
            "Epoch: 602 Train loss: 0.0048925 Validation loss: 0.027448\n",
            "Epoch: 603 Train loss: 0.0048918 Validation loss: 0.027455\n",
            "Epoch: 604 Train loss: 0.0048911 Validation loss: 0.027461\n",
            "Epoch: 605 Train loss: 0.0048904 Validation loss: 0.027468\n",
            "Epoch: 606 Train loss: 0.0048898 Validation loss: 0.027474\n",
            "Epoch: 607 Train loss: 0.0048891 Validation loss: 0.027481\n",
            "Epoch: 608 Train loss: 0.0048885 Validation loss: 0.027487\n",
            "Epoch: 609 Train loss: 0.0048878 Validation loss: 0.027494\n",
            "Epoch: 610 Train loss: 0.0048871 Validation loss: 0.0275\n",
            "Epoch: 611 Train loss: 0.0048864 Validation loss: 0.027507\n",
            "Epoch: 612 Train loss: 0.0048858 Validation loss: 0.027513\n",
            "Epoch: 613 Train loss: 0.0048851 Validation loss: 0.02752\n",
            "Epoch: 614 Train loss: 0.0048845 Validation loss: 0.027526\n",
            "Epoch: 615 Train loss: 0.0048838 Validation loss: 0.027532\n",
            "Epoch: 616 Train loss: 0.0048832 Validation loss: 0.027538\n",
            "Epoch: 617 Train loss: 0.0048825 Validation loss: 0.027545\n",
            "Epoch: 618 Train loss: 0.0048818 Validation loss: 0.027551\n",
            "Epoch: 619 Train loss: 0.0048812 Validation loss: 0.027557\n",
            "Epoch: 620 Train loss: 0.0048805 Validation loss: 0.027563\n",
            "Epoch: 621 Train loss: 0.0048799 Validation loss: 0.027569\n",
            "Epoch: 622 Train loss: 0.0048793 Validation loss: 0.027576\n",
            "Epoch: 623 Train loss: 0.0048786 Validation loss: 0.027582\n",
            "Epoch: 624 Train loss: 0.004878 Validation loss: 0.027588\n",
            "Epoch: 625 Train loss: 0.0048773 Validation loss: 0.027594\n",
            "Epoch: 626 Train loss: 0.0048767 Validation loss: 0.0276\n",
            "Epoch: 627 Train loss: 0.004876 Validation loss: 0.027606\n",
            "Epoch: 628 Train loss: 0.0048754 Validation loss: 0.027612\n",
            "Epoch: 629 Train loss: 0.0048747 Validation loss: 0.027618\n",
            "Epoch: 630 Train loss: 0.0048741 Validation loss: 0.027624\n",
            "Epoch: 631 Train loss: 0.0048735 Validation loss: 0.02763\n",
            "Epoch: 632 Train loss: 0.0048728 Validation loss: 0.027636\n",
            "Epoch: 633 Train loss: 0.0048722 Validation loss: 0.027641\n",
            "Epoch: 634 Train loss: 0.0048716 Validation loss: 0.027647\n",
            "Epoch: 635 Train loss: 0.004871 Validation loss: 0.027653\n",
            "Epoch: 636 Train loss: 0.0048703 Validation loss: 0.027659\n",
            "Epoch: 637 Train loss: 0.0048697 Validation loss: 0.027665\n",
            "Epoch: 638 Train loss: 0.004869 Validation loss: 0.02767\n",
            "Epoch: 639 Train loss: 0.0048684 Validation loss: 0.027676\n",
            "Epoch: 640 Train loss: 0.0048678 Validation loss: 0.027682\n",
            "Epoch: 641 Train loss: 0.0048671 Validation loss: 0.027688\n",
            "Epoch: 642 Train loss: 0.0048665 Validation loss: 0.027693\n",
            "Epoch: 643 Train loss: 0.0048659 Validation loss: 0.027699\n",
            "Epoch: 644 Train loss: 0.0048653 Validation loss: 0.027704\n",
            "Epoch: 645 Train loss: 0.0048647 Validation loss: 0.02771\n",
            "Epoch: 646 Train loss: 0.0048641 Validation loss: 0.027716\n",
            "Epoch: 647 Train loss: 0.0048635 Validation loss: 0.027721\n",
            "Epoch: 648 Train loss: 0.0048628 Validation loss: 0.027727\n",
            "Epoch: 649 Train loss: 0.0048622 Validation loss: 0.027732\n",
            "Epoch: 650 Train loss: 0.0048616 Validation loss: 0.027738\n",
            "Epoch: 651 Train loss: 0.004861 Validation loss: 0.027743\n",
            "Epoch: 652 Train loss: 0.0048604 Validation loss: 0.027748\n",
            "Epoch: 653 Train loss: 0.0048598 Validation loss: 0.027754\n",
            "Epoch: 654 Train loss: 0.0048592 Validation loss: 0.027759\n",
            "Epoch: 655 Train loss: 0.0048585 Validation loss: 0.027765\n",
            "Epoch: 656 Train loss: 0.0048579 Validation loss: 0.02777\n",
            "Epoch: 657 Train loss: 0.0048574 Validation loss: 0.027775\n",
            "Epoch: 658 Train loss: 0.0048567 Validation loss: 0.027781\n",
            "Epoch: 659 Train loss: 0.0048561 Validation loss: 0.027786\n",
            "Epoch: 660 Train loss: 0.0048555 Validation loss: 0.027791\n",
            "Epoch: 661 Train loss: 0.0048549 Validation loss: 0.027796\n",
            "Epoch: 662 Train loss: 0.0048543 Validation loss: 0.027802\n",
            "Epoch: 663 Train loss: 0.0048537 Validation loss: 0.027807\n",
            "Epoch: 664 Train loss: 0.0048531 Validation loss: 0.027812\n",
            "Epoch: 665 Train loss: 0.0048525 Validation loss: 0.027817\n",
            "Epoch: 666 Train loss: 0.0048519 Validation loss: 0.027822\n",
            "Epoch: 667 Train loss: 0.0048513 Validation loss: 0.027827\n",
            "Epoch: 668 Train loss: 0.0048507 Validation loss: 0.027832\n",
            "Epoch: 669 Train loss: 0.0048501 Validation loss: 0.027838\n",
            "Epoch: 670 Train loss: 0.0048495 Validation loss: 0.027843\n",
            "Epoch: 671 Train loss: 0.004849 Validation loss: 0.027848\n",
            "Epoch: 672 Train loss: 0.0048484 Validation loss: 0.027853\n",
            "Epoch: 673 Train loss: 0.0048478 Validation loss: 0.027858\n",
            "Epoch: 674 Train loss: 0.0048472 Validation loss: 0.027863\n",
            "Epoch: 675 Train loss: 0.0048466 Validation loss: 0.027868\n",
            "Epoch: 676 Train loss: 0.004846 Validation loss: 0.027872\n",
            "Epoch: 677 Train loss: 0.0048455 Validation loss: 0.027877\n",
            "Epoch: 678 Train loss: 0.0048449 Validation loss: 0.027882\n",
            "Epoch: 679 Train loss: 0.0048443 Validation loss: 0.027887\n",
            "Epoch: 680 Train loss: 0.0048437 Validation loss: 0.027892\n",
            "Epoch: 681 Train loss: 0.0048431 Validation loss: 0.027897\n",
            "Epoch: 682 Train loss: 0.0048425 Validation loss: 0.027901\n",
            "Epoch: 683 Train loss: 0.004842 Validation loss: 0.027906\n",
            "Epoch: 684 Train loss: 0.0048414 Validation loss: 0.027911\n",
            "Epoch: 685 Train loss: 0.0048408 Validation loss: 0.027916\n",
            "Epoch: 686 Train loss: 0.0048402 Validation loss: 0.027921\n",
            "Epoch: 687 Train loss: 0.0048396 Validation loss: 0.027925\n",
            "Epoch: 688 Train loss: 0.004839 Validation loss: 0.02793\n",
            "Epoch: 689 Train loss: 0.0048385 Validation loss: 0.027934\n",
            "Epoch: 690 Train loss: 0.0048379 Validation loss: 0.027939\n",
            "Epoch: 691 Train loss: 0.0048374 Validation loss: 0.027944\n",
            "Epoch: 692 Train loss: 0.0048368 Validation loss: 0.027948\n",
            "Epoch: 693 Train loss: 0.0048362 Validation loss: 0.027953\n",
            "Epoch: 694 Train loss: 0.0048356 Validation loss: 0.027958\n",
            "Epoch: 695 Train loss: 0.0048351 Validation loss: 0.027962\n",
            "Epoch: 696 Train loss: 0.0048345 Validation loss: 0.027967\n",
            "Epoch: 697 Train loss: 0.0048339 Validation loss: 0.027971\n",
            "Epoch: 698 Train loss: 0.0048334 Validation loss: 0.027976\n",
            "Epoch: 699 Train loss: 0.0048328 Validation loss: 0.02798\n",
            "Epoch: 700 Train loss: 0.0048322 Validation loss: 0.027985\n",
            "Epoch: 701 Train loss: 0.0048317 Validation loss: 0.027989\n",
            "Epoch: 702 Train loss: 0.0048311 Validation loss: 0.027994\n",
            "Epoch: 703 Train loss: 0.0048306 Validation loss: 0.027998\n",
            "Epoch: 704 Train loss: 0.00483 Validation loss: 0.028002\n",
            "Epoch: 705 Train loss: 0.0048294 Validation loss: 0.028007\n",
            "Epoch: 706 Train loss: 0.0048289 Validation loss: 0.028011\n",
            "Epoch: 707 Train loss: 0.0048283 Validation loss: 0.028016\n",
            "Epoch: 708 Train loss: 0.0048278 Validation loss: 0.028019\n",
            "Epoch: 709 Train loss: 0.0048272 Validation loss: 0.028024\n",
            "Epoch: 710 Train loss: 0.0048266 Validation loss: 0.028028\n",
            "Epoch: 711 Train loss: 0.0048261 Validation loss: 0.028033\n",
            "Epoch: 712 Train loss: 0.0048255 Validation loss: 0.028037\n",
            "Epoch: 713 Train loss: 0.004825 Validation loss: 0.028041\n",
            "Epoch: 714 Train loss: 0.0048244 Validation loss: 0.028045\n",
            "Epoch: 715 Train loss: 0.0048239 Validation loss: 0.028049\n",
            "Epoch: 716 Train loss: 0.0048233 Validation loss: 0.028054\n",
            "Epoch: 717 Train loss: 0.0048228 Validation loss: 0.028058\n",
            "Epoch: 718 Train loss: 0.0048222 Validation loss: 0.028062\n",
            "Epoch: 719 Train loss: 0.0048217 Validation loss: 0.028066\n",
            "Epoch: 720 Train loss: 0.0048211 Validation loss: 0.02807\n",
            "Epoch: 721 Train loss: 0.0048205 Validation loss: 0.028074\n",
            "Epoch: 722 Train loss: 0.00482 Validation loss: 0.028078\n",
            "Epoch: 723 Train loss: 0.0048195 Validation loss: 0.028083\n",
            "Epoch: 724 Train loss: 0.004819 Validation loss: 0.028087\n",
            "Epoch: 725 Train loss: 0.0048184 Validation loss: 0.028091\n",
            "Epoch: 726 Train loss: 0.0048178 Validation loss: 0.028095\n",
            "Epoch: 727 Train loss: 0.0048173 Validation loss: 0.028099\n",
            "Epoch: 728 Train loss: 0.0048167 Validation loss: 0.028103\n",
            "Epoch: 729 Train loss: 0.0048162 Validation loss: 0.028107\n",
            "Epoch: 730 Train loss: 0.0048157 Validation loss: 0.028111\n",
            "Epoch: 731 Train loss: 0.0048151 Validation loss: 0.028114\n",
            "Epoch: 732 Train loss: 0.0048146 Validation loss: 0.028118\n",
            "Epoch: 733 Train loss: 0.004814 Validation loss: 0.028122\n",
            "Epoch: 734 Train loss: 0.0048135 Validation loss: 0.028126\n",
            "Epoch: 735 Train loss: 0.004813 Validation loss: 0.02813\n",
            "Epoch: 736 Train loss: 0.0048124 Validation loss: 0.028134\n",
            "Epoch: 737 Train loss: 0.0048119 Validation loss: 0.028137\n",
            "Epoch: 738 Train loss: 0.0048114 Validation loss: 0.028141\n",
            "Epoch: 739 Train loss: 0.0048108 Validation loss: 0.028145\n",
            "Epoch: 740 Train loss: 0.0048103 Validation loss: 0.028149\n",
            "Epoch: 741 Train loss: 0.0048098 Validation loss: 0.028152\n",
            "Epoch: 742 Train loss: 0.0048092 Validation loss: 0.028156\n",
            "Epoch: 743 Train loss: 0.0048087 Validation loss: 0.02816\n",
            "Epoch: 744 Train loss: 0.0048082 Validation loss: 0.028164\n",
            "Epoch: 745 Train loss: 0.0048076 Validation loss: 0.028167\n",
            "Epoch: 746 Train loss: 0.0048071 Validation loss: 0.028171\n",
            "Epoch: 747 Train loss: 0.0048066 Validation loss: 0.028175\n",
            "Epoch: 748 Train loss: 0.0048061 Validation loss: 0.028178\n",
            "Epoch: 749 Train loss: 0.0048056 Validation loss: 0.028182\n",
            "Epoch: 750 Train loss: 0.004805 Validation loss: 0.028185\n",
            "Epoch: 751 Train loss: 0.0048045 Validation loss: 0.028189\n",
            "Epoch: 752 Train loss: 0.004804 Validation loss: 0.028193\n",
            "Epoch: 753 Train loss: 0.0048034 Validation loss: 0.028196\n",
            "Epoch: 754 Train loss: 0.0048029 Validation loss: 0.0282\n",
            "Epoch: 755 Train loss: 0.0048024 Validation loss: 0.028203\n",
            "Epoch: 756 Train loss: 0.0048019 Validation loss: 0.028207\n",
            "Epoch: 757 Train loss: 0.0048013 Validation loss: 0.02821\n",
            "Epoch: 758 Train loss: 0.0048008 Validation loss: 0.028214\n",
            "Epoch: 759 Train loss: 0.0048003 Validation loss: 0.028217\n",
            "Epoch: 760 Train loss: 0.0047998 Validation loss: 0.028221\n",
            "Epoch: 761 Train loss: 0.0047992 Validation loss: 0.028224\n",
            "Epoch: 762 Train loss: 0.0047988 Validation loss: 0.028227\n",
            "Epoch: 763 Train loss: 0.0047982 Validation loss: 0.028231\n",
            "Epoch: 764 Train loss: 0.0047977 Validation loss: 0.028234\n",
            "Epoch: 765 Train loss: 0.0047972 Validation loss: 0.028238\n",
            "Epoch: 766 Train loss: 0.0047967 Validation loss: 0.028241\n",
            "Epoch: 767 Train loss: 0.0047962 Validation loss: 0.028244\n",
            "Epoch: 768 Train loss: 0.0047956 Validation loss: 0.028248\n",
            "Epoch: 769 Train loss: 0.0047951 Validation loss: 0.028251\n",
            "Epoch: 770 Train loss: 0.0047946 Validation loss: 0.028254\n",
            "Epoch: 771 Train loss: 0.0047941 Validation loss: 0.028258\n",
            "Epoch: 772 Train loss: 0.0047936 Validation loss: 0.028261\n",
            "Epoch: 773 Train loss: 0.0047931 Validation loss: 0.028264\n",
            "Epoch: 774 Train loss: 0.0047926 Validation loss: 0.028267\n",
            "Epoch: 775 Train loss: 0.004792 Validation loss: 0.028271\n",
            "Epoch: 776 Train loss: 0.0047916 Validation loss: 0.028274\n",
            "Epoch: 777 Train loss: 0.004791 Validation loss: 0.028277\n",
            "Epoch: 778 Train loss: 0.0047905 Validation loss: 0.02828\n",
            "Epoch: 779 Train loss: 0.00479 Validation loss: 0.028283\n",
            "Epoch: 780 Train loss: 0.0047895 Validation loss: 0.028286\n",
            "Epoch: 781 Train loss: 0.004789 Validation loss: 0.02829\n",
            "Epoch: 782 Train loss: 0.0047885 Validation loss: 0.028293\n",
            "Epoch: 783 Train loss: 0.004788 Validation loss: 0.028296\n",
            "Epoch: 784 Train loss: 0.0047875 Validation loss: 0.028299\n",
            "Epoch: 785 Train loss: 0.0047869 Validation loss: 0.028302\n",
            "Epoch: 786 Train loss: 0.0047865 Validation loss: 0.028305\n",
            "Epoch: 787 Train loss: 0.0047859 Validation loss: 0.028308\n",
            "Epoch: 788 Train loss: 0.0047854 Validation loss: 0.028311\n",
            "Epoch: 789 Train loss: 0.0047849 Validation loss: 0.028314\n",
            "Epoch: 790 Train loss: 0.0047844 Validation loss: 0.028317\n",
            "Epoch: 791 Train loss: 0.004784 Validation loss: 0.02832\n",
            "Epoch: 792 Train loss: 0.0047834 Validation loss: 0.028323\n",
            "Epoch: 793 Train loss: 0.0047829 Validation loss: 0.028326\n",
            "Epoch: 794 Train loss: 0.0047824 Validation loss: 0.028329\n",
            "Epoch: 795 Train loss: 0.0047819 Validation loss: 0.028332\n",
            "Epoch: 796 Train loss: 0.0047814 Validation loss: 0.028335\n",
            "Epoch: 797 Train loss: 0.0047809 Validation loss: 0.028338\n",
            "Epoch: 798 Train loss: 0.0047804 Validation loss: 0.028341\n",
            "Epoch: 799 Train loss: 0.0047799 Validation loss: 0.028344\n",
            "Epoch: 800 Train loss: 0.0047794 Validation loss: 0.028347\n",
            "Epoch: 801 Train loss: 0.0047789 Validation loss: 0.02835\n",
            "Epoch: 802 Train loss: 0.0047784 Validation loss: 0.028353\n",
            "Epoch: 803 Train loss: 0.0047779 Validation loss: 0.028355\n",
            "Epoch: 804 Train loss: 0.0047774 Validation loss: 0.028358\n",
            "Epoch: 805 Train loss: 0.0047769 Validation loss: 0.028361\n",
            "Epoch: 806 Train loss: 0.0047765 Validation loss: 0.028364\n",
            "Epoch: 807 Train loss: 0.0047759 Validation loss: 0.028367\n",
            "Epoch: 808 Train loss: 0.0047755 Validation loss: 0.028369\n",
            "Epoch: 809 Train loss: 0.004775 Validation loss: 0.028372\n",
            "Epoch: 810 Train loss: 0.0047745 Validation loss: 0.028375\n",
            "Epoch: 811 Train loss: 0.004774 Validation loss: 0.028377\n",
            "Epoch: 812 Train loss: 0.0047735 Validation loss: 0.02838\n",
            "Epoch: 813 Train loss: 0.004773 Validation loss: 0.028383\n",
            "Epoch: 814 Train loss: 0.0047725 Validation loss: 0.028386\n",
            "Epoch: 815 Train loss: 0.004772 Validation loss: 0.028388\n",
            "Epoch: 816 Train loss: 0.0047715 Validation loss: 0.028391\n",
            "Epoch: 817 Train loss: 0.004771 Validation loss: 0.028394\n",
            "Epoch: 818 Train loss: 0.0047706 Validation loss: 0.028396\n",
            "Epoch: 819 Train loss: 0.0047701 Validation loss: 0.028399\n",
            "Epoch: 820 Train loss: 0.0047696 Validation loss: 0.028401\n",
            "Epoch: 821 Train loss: 0.0047691 Validation loss: 0.028404\n",
            "Epoch: 822 Train loss: 0.0047686 Validation loss: 0.028407\n",
            "Epoch: 823 Train loss: 0.0047681 Validation loss: 0.028409\n",
            "Epoch: 824 Train loss: 0.0047676 Validation loss: 0.028412\n",
            "Epoch: 825 Train loss: 0.0047671 Validation loss: 0.028415\n",
            "Epoch: 826 Train loss: 0.0047667 Validation loss: 0.028417\n",
            "Epoch: 827 Train loss: 0.0047662 Validation loss: 0.02842\n",
            "Epoch: 828 Train loss: 0.0047657 Validation loss: 0.028422\n",
            "Epoch: 829 Train loss: 0.0047652 Validation loss: 0.028425\n",
            "Epoch: 830 Train loss: 0.0047647 Validation loss: 0.028427\n",
            "Epoch: 831 Train loss: 0.0047642 Validation loss: 0.02843\n",
            "Epoch: 832 Train loss: 0.0047637 Validation loss: 0.028432\n",
            "Epoch: 833 Train loss: 0.0047633 Validation loss: 0.028435\n",
            "Epoch: 834 Train loss: 0.0047628 Validation loss: 0.028437\n",
            "Epoch: 835 Train loss: 0.0047623 Validation loss: 0.02844\n",
            "Epoch: 836 Train loss: 0.0047618 Validation loss: 0.028442\n",
            "Epoch: 837 Train loss: 0.0047613 Validation loss: 0.028445\n",
            "Epoch: 838 Train loss: 0.0047609 Validation loss: 0.028447\n",
            "Epoch: 839 Train loss: 0.0047604 Validation loss: 0.028449\n",
            "Epoch: 840 Train loss: 0.0047599 Validation loss: 0.028452\n",
            "Epoch: 841 Train loss: 0.0047594 Validation loss: 0.028454\n",
            "Epoch: 842 Train loss: 0.004759 Validation loss: 0.028456\n",
            "Epoch: 843 Train loss: 0.0047585 Validation loss: 0.028459\n",
            "Epoch: 844 Train loss: 0.004758 Validation loss: 0.028461\n",
            "Epoch: 845 Train loss: 0.0047575 Validation loss: 0.028464\n",
            "Epoch: 846 Train loss: 0.004757 Validation loss: 0.028466\n",
            "Epoch: 847 Train loss: 0.0047565 Validation loss: 0.028468\n",
            "Epoch: 848 Train loss: 0.0047561 Validation loss: 0.028471\n",
            "Epoch: 849 Train loss: 0.0047556 Validation loss: 0.028473\n",
            "Epoch: 850 Train loss: 0.0047551 Validation loss: 0.028475\n",
            "Epoch: 851 Train loss: 0.0047546 Validation loss: 0.028478\n",
            "Epoch: 852 Train loss: 0.0047542 Validation loss: 0.02848\n",
            "Epoch: 853 Train loss: 0.0047537 Validation loss: 0.028482\n",
            "Epoch: 854 Train loss: 0.0047532 Validation loss: 0.028484\n",
            "Epoch: 855 Train loss: 0.0047527 Validation loss: 0.028486\n",
            "Epoch: 856 Train loss: 0.0047523 Validation loss: 0.028489\n",
            "Epoch: 857 Train loss: 0.0047518 Validation loss: 0.028491\n",
            "Epoch: 858 Train loss: 0.0047513 Validation loss: 0.028493\n",
            "Epoch: 859 Train loss: 0.0047509 Validation loss: 0.028495\n",
            "Epoch: 860 Train loss: 0.0047504 Validation loss: 0.028497\n",
            "Epoch: 861 Train loss: 0.0047499 Validation loss: 0.0285\n",
            "Epoch: 862 Train loss: 0.0047495 Validation loss: 0.028502\n",
            "Epoch: 863 Train loss: 0.004749 Validation loss: 0.028504\n",
            "Epoch: 864 Train loss: 0.0047485 Validation loss: 0.028506\n",
            "Epoch: 865 Train loss: 0.004748 Validation loss: 0.028508\n",
            "Epoch: 866 Train loss: 0.0047476 Validation loss: 0.02851\n",
            "Epoch: 867 Train loss: 0.0047471 Validation loss: 0.028513\n",
            "Epoch: 868 Train loss: 0.0047466 Validation loss: 0.028515\n",
            "Epoch: 869 Train loss: 0.0047462 Validation loss: 0.028517\n",
            "Epoch: 870 Train loss: 0.0047457 Validation loss: 0.028519\n",
            "Epoch: 871 Train loss: 0.0047453 Validation loss: 0.028521\n",
            "Epoch: 872 Train loss: 0.0047448 Validation loss: 0.028523\n",
            "Epoch: 873 Train loss: 0.0047443 Validation loss: 0.028525\n",
            "Epoch: 874 Train loss: 0.0047438 Validation loss: 0.028527\n",
            "Epoch: 875 Train loss: 0.0047434 Validation loss: 0.028529\n",
            "Epoch: 876 Train loss: 0.0047429 Validation loss: 0.028531\n",
            "Epoch: 877 Train loss: 0.0047425 Validation loss: 0.028533\n",
            "Epoch: 878 Train loss: 0.004742 Validation loss: 0.028535\n",
            "Epoch: 879 Train loss: 0.0047415 Validation loss: 0.028537\n",
            "Epoch: 880 Train loss: 0.004741 Validation loss: 0.028539\n",
            "Epoch: 881 Train loss: 0.0047406 Validation loss: 0.028541\n",
            "Epoch: 882 Train loss: 0.0047401 Validation loss: 0.028543\n",
            "Epoch: 883 Train loss: 0.0047397 Validation loss: 0.028545\n",
            "Epoch: 884 Train loss: 0.0047392 Validation loss: 0.028547\n",
            "Epoch: 885 Train loss: 0.0047387 Validation loss: 0.028549\n",
            "Epoch: 886 Train loss: 0.0047383 Validation loss: 0.028551\n",
            "Epoch: 887 Train loss: 0.0047378 Validation loss: 0.028553\n",
            "Epoch: 888 Train loss: 0.0047374 Validation loss: 0.028555\n",
            "Epoch: 889 Train loss: 0.0047369 Validation loss: 0.028557\n",
            "Epoch: 890 Train loss: 0.0047365 Validation loss: 0.028558\n",
            "Epoch: 891 Train loss: 0.004736 Validation loss: 0.02856\n",
            "Epoch: 892 Train loss: 0.0047355 Validation loss: 0.028562\n",
            "Epoch: 893 Train loss: 0.004735 Validation loss: 0.028564\n",
            "Epoch: 894 Train loss: 0.0047346 Validation loss: 0.028566\n",
            "Epoch: 895 Train loss: 0.0047341 Validation loss: 0.028568\n",
            "Epoch: 896 Train loss: 0.0047337 Validation loss: 0.028569\n",
            "Epoch: 897 Train loss: 0.0047332 Validation loss: 0.028571\n",
            "Epoch: 898 Train loss: 0.0047328 Validation loss: 0.028573\n",
            "Epoch: 899 Train loss: 0.0047323 Validation loss: 0.028575\n",
            "Epoch: 900 Train loss: 0.0047319 Validation loss: 0.028576\n",
            "Epoch: 901 Train loss: 0.0047314 Validation loss: 0.028578\n",
            "Epoch: 902 Train loss: 0.004731 Validation loss: 0.02858\n",
            "Epoch: 903 Train loss: 0.0047305 Validation loss: 0.028582\n",
            "Epoch: 904 Train loss: 0.00473 Validation loss: 0.028583\n",
            "Epoch: 905 Train loss: 0.0047296 Validation loss: 0.028585\n",
            "Epoch: 906 Train loss: 0.0047292 Validation loss: 0.028587\n",
            "Epoch: 907 Train loss: 0.0047287 Validation loss: 0.028589\n",
            "Epoch: 908 Train loss: 0.0047282 Validation loss: 0.02859\n",
            "Epoch: 909 Train loss: 0.0047278 Validation loss: 0.028592\n",
            "Epoch: 910 Train loss: 0.0047273 Validation loss: 0.028594\n",
            "Epoch: 911 Train loss: 0.0047269 Validation loss: 0.028595\n",
            "Epoch: 912 Train loss: 0.0047264 Validation loss: 0.028597\n",
            "Epoch: 913 Train loss: 0.004726 Validation loss: 0.028599\n",
            "Epoch: 914 Train loss: 0.0047255 Validation loss: 0.0286\n",
            "Epoch: 915 Train loss: 0.004725 Validation loss: 0.028602\n",
            "Epoch: 916 Train loss: 0.0047246 Validation loss: 0.028603\n",
            "Epoch: 917 Train loss: 0.0047242 Validation loss: 0.028605\n",
            "Epoch: 918 Train loss: 0.0047237 Validation loss: 0.028607\n",
            "Epoch: 919 Train loss: 0.0047232 Validation loss: 0.028609\n",
            "Epoch: 920 Train loss: 0.0047228 Validation loss: 0.02861\n",
            "Epoch: 921 Train loss: 0.0047223 Validation loss: 0.028612\n",
            "Epoch: 922 Train loss: 0.0047219 Validation loss: 0.028613\n",
            "Epoch: 923 Train loss: 0.0047214 Validation loss: 0.028615\n",
            "Epoch: 924 Train loss: 0.004721 Validation loss: 0.028616\n",
            "Epoch: 925 Train loss: 0.0047205 Validation loss: 0.028618\n",
            "Epoch: 926 Train loss: 0.0047201 Validation loss: 0.02862\n",
            "Epoch: 927 Train loss: 0.0047197 Validation loss: 0.028621\n",
            "Epoch: 928 Train loss: 0.0047192 Validation loss: 0.028623\n",
            "Epoch: 929 Train loss: 0.0047188 Validation loss: 0.028624\n",
            "Epoch: 930 Train loss: 0.0047183 Validation loss: 0.028626\n",
            "Epoch: 931 Train loss: 0.0047178 Validation loss: 0.028627\n",
            "Epoch: 932 Train loss: 0.0047174 Validation loss: 0.028629\n",
            "Epoch: 933 Train loss: 0.004717 Validation loss: 0.02863\n",
            "Epoch: 934 Train loss: 0.0047166 Validation loss: 0.028632\n",
            "Epoch: 935 Train loss: 0.0047161 Validation loss: 0.028633\n",
            "Epoch: 936 Train loss: 0.0047157 Validation loss: 0.028635\n",
            "Epoch: 937 Train loss: 0.0047152 Validation loss: 0.028636\n",
            "Epoch: 938 Train loss: 0.0047148 Validation loss: 0.028638\n",
            "Epoch: 939 Train loss: 0.0047143 Validation loss: 0.028639\n",
            "Epoch: 940 Train loss: 0.0047139 Validation loss: 0.028641\n",
            "Epoch: 941 Train loss: 0.0047134 Validation loss: 0.028642\n",
            "Epoch: 942 Train loss: 0.004713 Validation loss: 0.028644\n",
            "Epoch: 943 Train loss: 0.0047125 Validation loss: 0.028645\n",
            "Epoch: 944 Train loss: 0.0047121 Validation loss: 0.028646\n",
            "Epoch: 945 Train loss: 0.0047116 Validation loss: 0.028648\n",
            "Epoch: 946 Train loss: 0.0047112 Validation loss: 0.028649\n",
            "Epoch: 947 Train loss: 0.0047108 Validation loss: 0.028651\n",
            "Epoch: 948 Train loss: 0.0047103 Validation loss: 0.028652\n",
            "Epoch: 949 Train loss: 0.0047099 Validation loss: 0.028653\n",
            "Epoch: 950 Train loss: 0.0047094 Validation loss: 0.028655\n",
            "Epoch: 951 Train loss: 0.004709 Validation loss: 0.028656\n",
            "Epoch: 952 Train loss: 0.0047086 Validation loss: 0.028657\n",
            "Epoch: 953 Train loss: 0.0047081 Validation loss: 0.028659\n",
            "Epoch: 954 Train loss: 0.0047077 Validation loss: 0.02866\n",
            "Epoch: 955 Train loss: 0.0047072 Validation loss: 0.028661\n",
            "Epoch: 956 Train loss: 0.0047068 Validation loss: 0.028663\n",
            "Epoch: 957 Train loss: 0.0047064 Validation loss: 0.028664\n",
            "Epoch: 958 Train loss: 0.0047059 Validation loss: 0.028665\n",
            "Epoch: 959 Train loss: 0.0047055 Validation loss: 0.028667\n",
            "Epoch: 960 Train loss: 0.0047051 Validation loss: 0.028668\n",
            "Epoch: 961 Train loss: 0.0047046 Validation loss: 0.028669\n",
            "Epoch: 962 Train loss: 0.0047042 Validation loss: 0.02867\n",
            "Epoch: 963 Train loss: 0.0047037 Validation loss: 0.028672\n",
            "Epoch: 964 Train loss: 0.0047033 Validation loss: 0.028673\n",
            "Epoch: 965 Train loss: 0.0047029 Validation loss: 0.028674\n",
            "Epoch: 966 Train loss: 0.0047024 Validation loss: 0.028675\n",
            "Epoch: 967 Train loss: 0.004702 Validation loss: 0.028677\n",
            "Epoch: 968 Train loss: 0.0047016 Validation loss: 0.028678\n",
            "Epoch: 969 Train loss: 0.0047011 Validation loss: 0.028679\n",
            "Epoch: 970 Train loss: 0.0047007 Validation loss: 0.02868\n",
            "Epoch: 971 Train loss: 0.0047003 Validation loss: 0.028681\n",
            "Epoch: 972 Train loss: 0.0046998 Validation loss: 0.028683\n",
            "Epoch: 973 Train loss: 0.0046994 Validation loss: 0.028684\n",
            "Epoch: 974 Train loss: 0.0046989 Validation loss: 0.028685\n",
            "Epoch: 975 Train loss: 0.0046985 Validation loss: 0.028686\n",
            "Epoch: 976 Train loss: 0.0046981 Validation loss: 0.028687\n",
            "Epoch: 977 Train loss: 0.0046976 Validation loss: 0.028688\n",
            "Epoch: 978 Train loss: 0.0046972 Validation loss: 0.02869\n",
            "Epoch: 979 Train loss: 0.0046968 Validation loss: 0.028691\n",
            "Epoch: 980 Train loss: 0.0046963 Validation loss: 0.028692\n",
            "Epoch: 981 Train loss: 0.0046959 Validation loss: 0.028693\n",
            "Epoch: 982 Train loss: 0.0046955 Validation loss: 0.028694\n",
            "Epoch: 983 Train loss: 0.0046951 Validation loss: 0.028695\n",
            "Epoch: 984 Train loss: 0.0046946 Validation loss: 0.028696\n",
            "Epoch: 985 Train loss: 0.0046942 Validation loss: 0.028697\n",
            "Epoch: 986 Train loss: 0.0046937 Validation loss: 0.028699\n",
            "Epoch: 987 Train loss: 0.0046933 Validation loss: 0.0287\n",
            "Epoch: 988 Train loss: 0.0046929 Validation loss: 0.028701\n",
            "Epoch: 989 Train loss: 0.0046924 Validation loss: 0.028702\n",
            "Epoch: 990 Train loss: 0.004692 Validation loss: 0.028703\n",
            "Epoch: 991 Train loss: 0.0046916 Validation loss: 0.028704\n",
            "Epoch: 992 Train loss: 0.0046912 Validation loss: 0.028705\n",
            "Epoch: 993 Train loss: 0.0046908 Validation loss: 0.028706\n",
            "Epoch: 994 Train loss: 0.0046903 Validation loss: 0.028707\n",
            "Epoch: 995 Train loss: 0.0046899 Validation loss: 0.028708\n",
            "Epoch: 996 Train loss: 0.0046895 Validation loss: 0.028709\n",
            "Epoch: 997 Train loss: 0.004689 Validation loss: 0.02871\n",
            "Epoch: 998 Train loss: 0.0046886 Validation loss: 0.028711\n",
            "Epoch: 999 Train loss: 0.0046882 Validation loss: 0.028712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gkaUDmA8Ps6w"
      },
      "source": [
        "Predicting with this model shows overfitting. For recognizing overfitting a comparison of the validation and training loss is very useful. If the training loss decreases during training while the validation loss consistently increases, the model you are training is probably overfitting. Plotting the models prediction and the target also shows that there is a significant discrepancy between the target and the prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Sq-9xhWPxI4",
        "outputId": "29d48265-6340-4fac-b63d-0b632ac62400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_pred = big_mdl(x) # Predict on x with \"big_mdl\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Target\", \"Prediction\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZ36J2EN85b9"
      },
      "source": [
        "In order to implement a regularization we need to modify the loss function. Since the loss function in this exercise is computed during the training step, we define a new training step with a regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLbcWwlt9Jwl",
        "colab": {}
      },
      "source": [
        "\"\"\" In order to avoid overfitting we implement a training step that also includes a regularization on the weights of our big model. For this we use the Frobenius/squared l2-norm of each weight matrix/vector. \n",
        "Hint: Use the tf.reduce_sum() function on a list of individual regularization terms for each matrix/vector of the network.\"\"\"\n",
        "\n",
        "def regularized_train_step(model, optimizer, x, y, lmbd):\n",
        "    y = tf.reshape(y, [-1,1])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.square(y_pred - y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "        regul_val = lmbd * tf.reduce_sum(tf.square(model.trainable_variables[0])) + lmbd * tf.reduce_sum(tf.square(model.trainable_variables[2])) + lmbd * tf.reduce_sum(tf.math.square(model.trainable_variables[4])) # Compute the regularization based on the list \"model.trainable_variables\"\n",
        "        total_loss = loss_val + regul_val # Add the loss with a the regularization term weighted by \"lmbd\"\n",
        "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExK4FIw89s0M"
      },
      "source": [
        "We can now set the strength of the regularization and retrain the big model with a regularization. We create another instance of the big model in order to compare the big model with and without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PUUBGi496Vt",
        "outputId": "6777072b-0110-4974-cfac-9ec69377a81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model with the regularized_train_step function. Note: We are plotting the MSE loss without the regularization in order to compare it with the unregularized model. \"\"\"\n",
        "\n",
        "lmbd = 0.005\n",
        "\n",
        "big_reg_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += regularized_train_step(big_reg_mdl, big_opt, x_t, y_t, lmbd) # Perform a regularized training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\" with the regularization parameter being \"lmbd\"\n",
        "    train_iters += 1\n",
        "    if train_iters == int(N_train_samples_overfit/batch_size): # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_reg_mdl(x_v) # Compute a prediction with \"big_reg_mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        train_reg = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 25.748 Validation loss: 109.08\n",
            "Epoch: 1 Train loss: 108.4 Validation loss: 20.185\n",
            "Epoch: 2 Train loss: 20.332 Validation loss: 3.8128\n",
            "Epoch: 3 Train loss: 4.1565 Validation loss: 0.7818\n",
            "Epoch: 4 Train loss: 0.88265 Validation loss: 0.61623\n",
            "Epoch: 5 Train loss: 0.43545 Validation loss: 0.50848\n",
            "Epoch: 6 Train loss: 0.33242 Validation loss: 0.46917\n",
            "Epoch: 7 Train loss: 0.26738 Validation loss: 0.41501\n",
            "Epoch: 8 Train loss: 0.22068 Validation loss: 0.37798\n",
            "Epoch: 9 Train loss: 0.1861 Validation loss: 0.34491\n",
            "Epoch: 10 Train loss: 0.16043 Validation loss: 0.31945\n",
            "Epoch: 11 Train loss: 0.14161 Validation loss: 0.29903\n",
            "Epoch: 12 Train loss: 0.128 Validation loss: 0.28304\n",
            "Epoch: 13 Train loss: 0.11818 Validation loss: 0.27006\n",
            "Epoch: 14 Train loss: 0.111 Validation loss: 0.2592\n",
            "Epoch: 15 Train loss: 0.10559 Validation loss: 0.24978\n",
            "Epoch: 16 Train loss: 0.10137 Validation loss: 0.24139\n",
            "Epoch: 17 Train loss: 0.097924 Validation loss: 0.23374\n",
            "Epoch: 18 Train loss: 0.095013 Validation loss: 0.22671\n",
            "Epoch: 19 Train loss: 0.092473 Validation loss: 0.22018\n",
            "Epoch: 20 Train loss: 0.090202 Validation loss: 0.21409\n",
            "Epoch: 21 Train loss: 0.088135 Validation loss: 0.20839\n",
            "Epoch: 22 Train loss: 0.086227 Validation loss: 0.20306\n",
            "Epoch: 23 Train loss: 0.084447 Validation loss: 0.19804\n",
            "Epoch: 24 Train loss: 0.082771 Validation loss: 0.19333\n",
            "Epoch: 25 Train loss: 0.081184 Validation loss: 0.18888\n",
            "Epoch: 26 Train loss: 0.079672 Validation loss: 0.18468\n",
            "Epoch: 27 Train loss: 0.078223 Validation loss: 0.1807\n",
            "Epoch: 28 Train loss: 0.076831 Validation loss: 0.17692\n",
            "Epoch: 29 Train loss: 0.075487 Validation loss: 0.17333\n",
            "Epoch: 30 Train loss: 0.074187 Validation loss: 0.16991\n",
            "Epoch: 31 Train loss: 0.072924 Validation loss: 0.16664\n",
            "Epoch: 32 Train loss: 0.071696 Validation loss: 0.16352\n",
            "Epoch: 33 Train loss: 0.070499 Validation loss: 0.16052\n",
            "Epoch: 34 Train loss: 0.069331 Validation loss: 0.15765\n",
            "Epoch: 35 Train loss: 0.068189 Validation loss: 0.15488\n",
            "Epoch: 36 Train loss: 0.067071 Validation loss: 0.15222\n",
            "Epoch: 37 Train loss: 0.065976 Validation loss: 0.14965\n",
            "Epoch: 38 Train loss: 0.064903 Validation loss: 0.14717\n",
            "Epoch: 39 Train loss: 0.06385 Validation loss: 0.14478\n",
            "Epoch: 40 Train loss: 0.062818 Validation loss: 0.14246\n",
            "Epoch: 41 Train loss: 0.061804 Validation loss: 0.14021\n",
            "Epoch: 42 Train loss: 0.06081 Validation loss: 0.13803\n",
            "Epoch: 43 Train loss: 0.059835 Validation loss: 0.13592\n",
            "Epoch: 44 Train loss: 0.058878 Validation loss: 0.13387\n",
            "Epoch: 45 Train loss: 0.057939 Validation loss: 0.13188\n",
            "Epoch: 46 Train loss: 0.05702 Validation loss: 0.12994\n",
            "Epoch: 47 Train loss: 0.056118 Validation loss: 0.12806\n",
            "Epoch: 48 Train loss: 0.055236 Validation loss: 0.12623\n",
            "Epoch: 49 Train loss: 0.054372 Validation loss: 0.12445\n",
            "Epoch: 50 Train loss: 0.053527 Validation loss: 0.12272\n",
            "Epoch: 51 Train loss: 0.052702 Validation loss: 0.12103\n",
            "Epoch: 52 Train loss: 0.051895 Validation loss: 0.11939\n",
            "Epoch: 53 Train loss: 0.051108 Validation loss: 0.1178\n",
            "Epoch: 54 Train loss: 0.05034 Validation loss: 0.11624\n",
            "Epoch: 55 Train loss: 0.049591 Validation loss: 0.11473\n",
            "Epoch: 56 Train loss: 0.048861 Validation loss: 0.11325\n",
            "Epoch: 57 Train loss: 0.04815 Validation loss: 0.11181\n",
            "Epoch: 58 Train loss: 0.047459 Validation loss: 0.11041\n",
            "Epoch: 59 Train loss: 0.046786 Validation loss: 0.10904\n",
            "Epoch: 60 Train loss: 0.046131 Validation loss: 0.10771\n",
            "Epoch: 61 Train loss: 0.045495 Validation loss: 0.10641\n",
            "Epoch: 62 Train loss: 0.044877 Validation loss: 0.10514\n",
            "Epoch: 63 Train loss: 0.044276 Validation loss: 0.10391\n",
            "Epoch: 64 Train loss: 0.043693 Validation loss: 0.1027\n",
            "Epoch: 65 Train loss: 0.043127 Validation loss: 0.10152\n",
            "Epoch: 66 Train loss: 0.042577 Validation loss: 0.10037\n",
            "Epoch: 67 Train loss: 0.042042 Validation loss: 0.099249\n",
            "Epoch: 68 Train loss: 0.041524 Validation loss: 0.098152\n",
            "Epoch: 69 Train loss: 0.04102 Validation loss: 0.097079\n",
            "Epoch: 70 Train loss: 0.040531 Validation loss: 0.09603\n",
            "Epoch: 71 Train loss: 0.040057 Validation loss: 0.095005\n",
            "Epoch: 72 Train loss: 0.039595 Validation loss: 0.094002\n",
            "Epoch: 73 Train loss: 0.039148 Validation loss: 0.093021\n",
            "Epoch: 74 Train loss: 0.038712 Validation loss: 0.09206\n",
            "Epoch: 75 Train loss: 0.038289 Validation loss: 0.09112\n",
            "Epoch: 76 Train loss: 0.037878 Validation loss: 0.090199\n",
            "Epoch: 77 Train loss: 0.037479 Validation loss: 0.089297\n",
            "Epoch: 78 Train loss: 0.03709 Validation loss: 0.088413\n",
            "Epoch: 79 Train loss: 0.036712 Validation loss: 0.087546\n",
            "Epoch: 80 Train loss: 0.036344 Validation loss: 0.086697\n",
            "Epoch: 81 Train loss: 0.035985 Validation loss: 0.085863\n",
            "Epoch: 82 Train loss: 0.035636 Validation loss: 0.085046\n",
            "Epoch: 83 Train loss: 0.035297 Validation loss: 0.084243\n",
            "Epoch: 84 Train loss: 0.034965 Validation loss: 0.083456\n",
            "Epoch: 85 Train loss: 0.034642 Validation loss: 0.082682\n",
            "Epoch: 86 Train loss: 0.034327 Validation loss: 0.081923\n",
            "Epoch: 87 Train loss: 0.03402 Validation loss: 0.081177\n",
            "Epoch: 88 Train loss: 0.03372 Validation loss: 0.080444\n",
            "Epoch: 89 Train loss: 0.033426 Validation loss: 0.079723\n",
            "Epoch: 90 Train loss: 0.03314 Validation loss: 0.079015\n",
            "Epoch: 91 Train loss: 0.03286 Validation loss: 0.078318\n",
            "Epoch: 92 Train loss: 0.032587 Validation loss: 0.077633\n",
            "Epoch: 93 Train loss: 0.032319 Validation loss: 0.076959\n",
            "Epoch: 94 Train loss: 0.032057 Validation loss: 0.076296\n",
            "Epoch: 95 Train loss: 0.031801 Validation loss: 0.075643\n",
            "Epoch: 96 Train loss: 0.03155 Validation loss: 0.075001\n",
            "Epoch: 97 Train loss: 0.031304 Validation loss: 0.074368\n",
            "Epoch: 98 Train loss: 0.031063 Validation loss: 0.073745\n",
            "Epoch: 99 Train loss: 0.030827 Validation loss: 0.073132\n",
            "Epoch: 100 Train loss: 0.030596 Validation loss: 0.072527\n",
            "Epoch: 101 Train loss: 0.030368 Validation loss: 0.071932\n",
            "Epoch: 102 Train loss: 0.030145 Validation loss: 0.071345\n",
            "Epoch: 103 Train loss: 0.029926 Validation loss: 0.070767\n",
            "Epoch: 104 Train loss: 0.029711 Validation loss: 0.070197\n",
            "Epoch: 105 Train loss: 0.029499 Validation loss: 0.069635\n",
            "Epoch: 106 Train loss: 0.029292 Validation loss: 0.069081\n",
            "Epoch: 107 Train loss: 0.029087 Validation loss: 0.068535\n",
            "Epoch: 108 Train loss: 0.028886 Validation loss: 0.067996\n",
            "Epoch: 109 Train loss: 0.028689 Validation loss: 0.067465\n",
            "Epoch: 110 Train loss: 0.028494 Validation loss: 0.066941\n",
            "Epoch: 111 Train loss: 0.028303 Validation loss: 0.066424\n",
            "Epoch: 112 Train loss: 0.028114 Validation loss: 0.065913\n",
            "Epoch: 113 Train loss: 0.027929 Validation loss: 0.06541\n",
            "Epoch: 114 Train loss: 0.027746 Validation loss: 0.064913\n",
            "Epoch: 115 Train loss: 0.027565 Validation loss: 0.064423\n",
            "Epoch: 116 Train loss: 0.027388 Validation loss: 0.063939\n",
            "Epoch: 117 Train loss: 0.027212 Validation loss: 0.063462\n",
            "Epoch: 118 Train loss: 0.02704 Validation loss: 0.06299\n",
            "Epoch: 119 Train loss: 0.026869 Validation loss: 0.062524\n",
            "Epoch: 120 Train loss: 0.026701 Validation loss: 0.062065\n",
            "Epoch: 121 Train loss: 0.026535 Validation loss: 0.061611\n",
            "Epoch: 122 Train loss: 0.026371 Validation loss: 0.061163\n",
            "Epoch: 123 Train loss: 0.026209 Validation loss: 0.060721\n",
            "Epoch: 124 Train loss: 0.026049 Validation loss: 0.060284\n",
            "Epoch: 125 Train loss: 0.025891 Validation loss: 0.059852\n",
            "Epoch: 126 Train loss: 0.025735 Validation loss: 0.059426\n",
            "Epoch: 127 Train loss: 0.025581 Validation loss: 0.059006\n",
            "Epoch: 128 Train loss: 0.025429 Validation loss: 0.05859\n",
            "Epoch: 129 Train loss: 0.025278 Validation loss: 0.058179\n",
            "Epoch: 130 Train loss: 0.025129 Validation loss: 0.057774\n",
            "Epoch: 131 Train loss: 0.024982 Validation loss: 0.057374\n",
            "Epoch: 132 Train loss: 0.024836 Validation loss: 0.056978\n",
            "Epoch: 133 Train loss: 0.024692 Validation loss: 0.056588\n",
            "Epoch: 134 Train loss: 0.024549 Validation loss: 0.056202\n",
            "Epoch: 135 Train loss: 0.024408 Validation loss: 0.055821\n",
            "Epoch: 136 Train loss: 0.024268 Validation loss: 0.055444\n",
            "Epoch: 137 Train loss: 0.02413 Validation loss: 0.055073\n",
            "Epoch: 138 Train loss: 0.023993 Validation loss: 0.054705\n",
            "Epoch: 139 Train loss: 0.023857 Validation loss: 0.054342\n",
            "Epoch: 140 Train loss: 0.023723 Validation loss: 0.053984\n",
            "Epoch: 141 Train loss: 0.02359 Validation loss: 0.05363\n",
            "Epoch: 142 Train loss: 0.023458 Validation loss: 0.053281\n",
            "Epoch: 143 Train loss: 0.023327 Validation loss: 0.052936\n",
            "Epoch: 144 Train loss: 0.023198 Validation loss: 0.052595\n",
            "Epoch: 145 Train loss: 0.023069 Validation loss: 0.052258\n",
            "Epoch: 146 Train loss: 0.022942 Validation loss: 0.051925\n",
            "Epoch: 147 Train loss: 0.022816 Validation loss: 0.051597\n",
            "Epoch: 148 Train loss: 0.022691 Validation loss: 0.051273\n",
            "Epoch: 149 Train loss: 0.022567 Validation loss: 0.050952\n",
            "Epoch: 150 Train loss: 0.022444 Validation loss: 0.050636\n",
            "Epoch: 151 Train loss: 0.022322 Validation loss: 0.050324\n",
            "Epoch: 152 Train loss: 0.022201 Validation loss: 0.050016\n",
            "Epoch: 153 Train loss: 0.022081 Validation loss: 0.049712\n",
            "Epoch: 154 Train loss: 0.021962 Validation loss: 0.049411\n",
            "Epoch: 155 Train loss: 0.021844 Validation loss: 0.049115\n",
            "Epoch: 156 Train loss: 0.021727 Validation loss: 0.048822\n",
            "Epoch: 157 Train loss: 0.02161 Validation loss: 0.048533\n",
            "Epoch: 158 Train loss: 0.021495 Validation loss: 0.048248\n",
            "Epoch: 159 Train loss: 0.02138 Validation loss: 0.047966\n",
            "Epoch: 160 Train loss: 0.021266 Validation loss: 0.047688\n",
            "Epoch: 161 Train loss: 0.021153 Validation loss: 0.047414\n",
            "Epoch: 162 Train loss: 0.021041 Validation loss: 0.047144\n",
            "Epoch: 163 Train loss: 0.02093 Validation loss: 0.046877\n",
            "Epoch: 164 Train loss: 0.020819 Validation loss: 0.046614\n",
            "Epoch: 165 Train loss: 0.020709 Validation loss: 0.046354\n",
            "Epoch: 166 Train loss: 0.0206 Validation loss: 0.046098\n",
            "Epoch: 167 Train loss: 0.020491 Validation loss: 0.045845\n",
            "Epoch: 168 Train loss: 0.020383 Validation loss: 0.045596\n",
            "Epoch: 169 Train loss: 0.020276 Validation loss: 0.04535\n",
            "Epoch: 170 Train loss: 0.02017 Validation loss: 0.045108\n",
            "Epoch: 171 Train loss: 0.020064 Validation loss: 0.044869\n",
            "Epoch: 172 Train loss: 0.019959 Validation loss: 0.044633\n",
            "Epoch: 173 Train loss: 0.019854 Validation loss: 0.044401\n",
            "Epoch: 174 Train loss: 0.019751 Validation loss: 0.044172\n",
            "Epoch: 175 Train loss: 0.019647 Validation loss: 0.043946\n",
            "Epoch: 176 Train loss: 0.019545 Validation loss: 0.043723\n",
            "Epoch: 177 Train loss: 0.019443 Validation loss: 0.043504\n",
            "Epoch: 178 Train loss: 0.019341 Validation loss: 0.043288\n",
            "Epoch: 179 Train loss: 0.019241 Validation loss: 0.043075\n",
            "Epoch: 180 Train loss: 0.01914 Validation loss: 0.042865\n",
            "Epoch: 181 Train loss: 0.019041 Validation loss: 0.042659\n",
            "Epoch: 182 Train loss: 0.018941 Validation loss: 0.042455\n",
            "Epoch: 183 Train loss: 0.018843 Validation loss: 0.042255\n",
            "Epoch: 184 Train loss: 0.018745 Validation loss: 0.042057\n",
            "Epoch: 185 Train loss: 0.018647 Validation loss: 0.041862\n",
            "Epoch: 186 Train loss: 0.01855 Validation loss: 0.04167\n",
            "Epoch: 187 Train loss: 0.018454 Validation loss: 0.041482\n",
            "Epoch: 188 Train loss: 0.018358 Validation loss: 0.041296\n",
            "Epoch: 189 Train loss: 0.018263 Validation loss: 0.041112\n",
            "Epoch: 190 Train loss: 0.018168 Validation loss: 0.040932\n",
            "Epoch: 191 Train loss: 0.018074 Validation loss: 0.040754\n",
            "Epoch: 192 Train loss: 0.01798 Validation loss: 0.040579\n",
            "Epoch: 193 Train loss: 0.017886 Validation loss: 0.040407\n",
            "Epoch: 194 Train loss: 0.017794 Validation loss: 0.040237\n",
            "Epoch: 195 Train loss: 0.017701 Validation loss: 0.04007\n",
            "Epoch: 196 Train loss: 0.01761 Validation loss: 0.039905\n",
            "Epoch: 197 Train loss: 0.017518 Validation loss: 0.039743\n",
            "Epoch: 198 Train loss: 0.017428 Validation loss: 0.039583\n",
            "Epoch: 199 Train loss: 0.017338 Validation loss: 0.039426\n",
            "Epoch: 200 Train loss: 0.017248 Validation loss: 0.039271\n",
            "Epoch: 201 Train loss: 0.017159 Validation loss: 0.039118\n",
            "Epoch: 202 Train loss: 0.01707 Validation loss: 0.038967\n",
            "Epoch: 203 Train loss: 0.016982 Validation loss: 0.038819\n",
            "Epoch: 204 Train loss: 0.016894 Validation loss: 0.038673\n",
            "Epoch: 205 Train loss: 0.016807 Validation loss: 0.038528\n",
            "Epoch: 206 Train loss: 0.016721 Validation loss: 0.038386\n",
            "Epoch: 207 Train loss: 0.016635 Validation loss: 0.038246\n",
            "Epoch: 208 Train loss: 0.016549 Validation loss: 0.038108\n",
            "Epoch: 209 Train loss: 0.016464 Validation loss: 0.037971\n",
            "Epoch: 210 Train loss: 0.01638 Validation loss: 0.037837\n",
            "Epoch: 211 Train loss: 0.016296 Validation loss: 0.037704\n",
            "Epoch: 212 Train loss: 0.016213 Validation loss: 0.037572\n",
            "Epoch: 213 Train loss: 0.01613 Validation loss: 0.037443\n",
            "Epoch: 214 Train loss: 0.016048 Validation loss: 0.037315\n",
            "Epoch: 215 Train loss: 0.015966 Validation loss: 0.037188\n",
            "Epoch: 216 Train loss: 0.015885 Validation loss: 0.037063\n",
            "Epoch: 217 Train loss: 0.015805 Validation loss: 0.03694\n",
            "Epoch: 218 Train loss: 0.015725 Validation loss: 0.036818\n",
            "Epoch: 219 Train loss: 0.015646 Validation loss: 0.036697\n",
            "Epoch: 220 Train loss: 0.015567 Validation loss: 0.036577\n",
            "Epoch: 221 Train loss: 0.015489 Validation loss: 0.036458\n",
            "Epoch: 222 Train loss: 0.015412 Validation loss: 0.036341\n",
            "Epoch: 223 Train loss: 0.015335 Validation loss: 0.036225\n",
            "Epoch: 224 Train loss: 0.015259 Validation loss: 0.036109\n",
            "Epoch: 225 Train loss: 0.015183 Validation loss: 0.035995\n",
            "Epoch: 226 Train loss: 0.015109 Validation loss: 0.035882\n",
            "Epoch: 227 Train loss: 0.015034 Validation loss: 0.035769\n",
            "Epoch: 228 Train loss: 0.014961 Validation loss: 0.035657\n",
            "Epoch: 229 Train loss: 0.014888 Validation loss: 0.035547\n",
            "Epoch: 230 Train loss: 0.014815 Validation loss: 0.035436\n",
            "Epoch: 231 Train loss: 0.014743 Validation loss: 0.035327\n",
            "Epoch: 232 Train loss: 0.014672 Validation loss: 0.035218\n",
            "Epoch: 233 Train loss: 0.014602 Validation loss: 0.03511\n",
            "Epoch: 234 Train loss: 0.014532 Validation loss: 0.035003\n",
            "Epoch: 235 Train loss: 0.014463 Validation loss: 0.034895\n",
            "Epoch: 236 Train loss: 0.014395 Validation loss: 0.034789\n",
            "Epoch: 237 Train loss: 0.014327 Validation loss: 0.034683\n",
            "Epoch: 238 Train loss: 0.01426 Validation loss: 0.034577\n",
            "Epoch: 239 Train loss: 0.014193 Validation loss: 0.034472\n",
            "Epoch: 240 Train loss: 0.014127 Validation loss: 0.034367\n",
            "Epoch: 241 Train loss: 0.014062 Validation loss: 0.034262\n",
            "Epoch: 242 Train loss: 0.013998 Validation loss: 0.034157\n",
            "Epoch: 243 Train loss: 0.013934 Validation loss: 0.034053\n",
            "Epoch: 244 Train loss: 0.013871 Validation loss: 0.033949\n",
            "Epoch: 245 Train loss: 0.013808 Validation loss: 0.033846\n",
            "Epoch: 246 Train loss: 0.013746 Validation loss: 0.033742\n",
            "Epoch: 247 Train loss: 0.013685 Validation loss: 0.033639\n",
            "Epoch: 248 Train loss: 0.013625 Validation loss: 0.033536\n",
            "Epoch: 249 Train loss: 0.013565 Validation loss: 0.033433\n",
            "Epoch: 250 Train loss: 0.013505 Validation loss: 0.03333\n",
            "Epoch: 251 Train loss: 0.013447 Validation loss: 0.033227\n",
            "Epoch: 252 Train loss: 0.013389 Validation loss: 0.033124\n",
            "Epoch: 253 Train loss: 0.013331 Validation loss: 0.033022\n",
            "Epoch: 254 Train loss: 0.013274 Validation loss: 0.032919\n",
            "Epoch: 255 Train loss: 0.013218 Validation loss: 0.032817\n",
            "Epoch: 256 Train loss: 0.013163 Validation loss: 0.032714\n",
            "Epoch: 257 Train loss: 0.013108 Validation loss: 0.032612\n",
            "Epoch: 258 Train loss: 0.013054 Validation loss: 0.032509\n",
            "Epoch: 259 Train loss: 0.013 Validation loss: 0.032407\n",
            "Epoch: 260 Train loss: 0.012947 Validation loss: 0.032305\n",
            "Epoch: 261 Train loss: 0.012894 Validation loss: 0.032203\n",
            "Epoch: 262 Train loss: 0.012842 Validation loss: 0.0321\n",
            "Epoch: 263 Train loss: 0.012791 Validation loss: 0.031998\n",
            "Epoch: 264 Train loss: 0.01274 Validation loss: 0.031896\n",
            "Epoch: 265 Train loss: 0.01269 Validation loss: 0.031794\n",
            "Epoch: 266 Train loss: 0.01264 Validation loss: 0.031691\n",
            "Epoch: 267 Train loss: 0.012591 Validation loss: 0.031589\n",
            "Epoch: 268 Train loss: 0.012542 Validation loss: 0.031487\n",
            "Epoch: 269 Train loss: 0.012494 Validation loss: 0.031385\n",
            "Epoch: 270 Train loss: 0.012446 Validation loss: 0.031283\n",
            "Epoch: 271 Train loss: 0.012399 Validation loss: 0.031181\n",
            "Epoch: 272 Train loss: 0.012353 Validation loss: 0.031079\n",
            "Epoch: 273 Train loss: 0.012307 Validation loss: 0.030977\n",
            "Epoch: 274 Train loss: 0.012261 Validation loss: 0.030875\n",
            "Epoch: 275 Train loss: 0.012216 Validation loss: 0.030774\n",
            "Epoch: 276 Train loss: 0.012171 Validation loss: 0.030672\n",
            "Epoch: 277 Train loss: 0.012127 Validation loss: 0.03057\n",
            "Epoch: 278 Train loss: 0.012084 Validation loss: 0.030469\n",
            "Epoch: 279 Train loss: 0.01204 Validation loss: 0.030367\n",
            "Epoch: 280 Train loss: 0.011998 Validation loss: 0.030266\n",
            "Epoch: 281 Train loss: 0.011955 Validation loss: 0.030165\n",
            "Epoch: 282 Train loss: 0.011914 Validation loss: 0.030063\n",
            "Epoch: 283 Train loss: 0.011872 Validation loss: 0.029962\n",
            "Epoch: 284 Train loss: 0.011831 Validation loss: 0.029862\n",
            "Epoch: 285 Train loss: 0.011791 Validation loss: 0.029761\n",
            "Epoch: 286 Train loss: 0.011751 Validation loss: 0.02966\n",
            "Epoch: 287 Train loss: 0.011711 Validation loss: 0.02956\n",
            "Epoch: 288 Train loss: 0.011671 Validation loss: 0.029459\n",
            "Epoch: 289 Train loss: 0.011632 Validation loss: 0.029359\n",
            "Epoch: 290 Train loss: 0.011594 Validation loss: 0.029259\n",
            "Epoch: 291 Train loss: 0.011556 Validation loss: 0.02916\n",
            "Epoch: 292 Train loss: 0.011518 Validation loss: 0.02906\n",
            "Epoch: 293 Train loss: 0.011481 Validation loss: 0.028961\n",
            "Epoch: 294 Train loss: 0.011443 Validation loss: 0.028861\n",
            "Epoch: 295 Train loss: 0.011407 Validation loss: 0.028762\n",
            "Epoch: 296 Train loss: 0.01137 Validation loss: 0.028664\n",
            "Epoch: 297 Train loss: 0.011334 Validation loss: 0.028565\n",
            "Epoch: 298 Train loss: 0.011299 Validation loss: 0.028467\n",
            "Epoch: 299 Train loss: 0.011263 Validation loss: 0.028369\n",
            "Epoch: 300 Train loss: 0.011228 Validation loss: 0.028271\n",
            "Epoch: 301 Train loss: 0.011194 Validation loss: 0.028174\n",
            "Epoch: 302 Train loss: 0.011159 Validation loss: 0.028077\n",
            "Epoch: 303 Train loss: 0.011125 Validation loss: 0.02798\n",
            "Epoch: 304 Train loss: 0.011092 Validation loss: 0.027883\n",
            "Epoch: 305 Train loss: 0.011058 Validation loss: 0.027787\n",
            "Epoch: 306 Train loss: 0.011025 Validation loss: 0.027691\n",
            "Epoch: 307 Train loss: 0.010992 Validation loss: 0.027595\n",
            "Epoch: 308 Train loss: 0.01096 Validation loss: 0.0275\n",
            "Epoch: 309 Train loss: 0.010928 Validation loss: 0.027404\n",
            "Epoch: 310 Train loss: 0.010896 Validation loss: 0.02731\n",
            "Epoch: 311 Train loss: 0.010864 Validation loss: 0.027215\n",
            "Epoch: 312 Train loss: 0.010833 Validation loss: 0.027121\n",
            "Epoch: 313 Train loss: 0.010802 Validation loss: 0.027027\n",
            "Epoch: 314 Train loss: 0.010771 Validation loss: 0.026934\n",
            "Epoch: 315 Train loss: 0.01074 Validation loss: 0.026841\n",
            "Epoch: 316 Train loss: 0.01071 Validation loss: 0.026748\n",
            "Epoch: 317 Train loss: 0.01068 Validation loss: 0.026656\n",
            "Epoch: 318 Train loss: 0.01065 Validation loss: 0.026564\n",
            "Epoch: 319 Train loss: 0.010621 Validation loss: 0.026472\n",
            "Epoch: 320 Train loss: 0.010591 Validation loss: 0.026381\n",
            "Epoch: 321 Train loss: 0.010562 Validation loss: 0.02629\n",
            "Epoch: 322 Train loss: 0.010534 Validation loss: 0.0262\n",
            "Epoch: 323 Train loss: 0.010505 Validation loss: 0.02611\n",
            "Epoch: 324 Train loss: 0.010477 Validation loss: 0.02602\n",
            "Epoch: 325 Train loss: 0.010449 Validation loss: 0.025931\n",
            "Epoch: 326 Train loss: 0.010421 Validation loss: 0.025842\n",
            "Epoch: 327 Train loss: 0.010393 Validation loss: 0.025753\n",
            "Epoch: 328 Train loss: 0.010366 Validation loss: 0.025665\n",
            "Epoch: 329 Train loss: 0.010339 Validation loss: 0.025577\n",
            "Epoch: 330 Train loss: 0.010312 Validation loss: 0.02549\n",
            "Epoch: 331 Train loss: 0.010285 Validation loss: 0.025403\n",
            "Epoch: 332 Train loss: 0.010258 Validation loss: 0.025317\n",
            "Epoch: 333 Train loss: 0.010232 Validation loss: 0.025231\n",
            "Epoch: 334 Train loss: 0.010206 Validation loss: 0.025145\n",
            "Epoch: 335 Train loss: 0.01018 Validation loss: 0.02506\n",
            "Epoch: 336 Train loss: 0.010154 Validation loss: 0.024975\n",
            "Epoch: 337 Train loss: 0.010129 Validation loss: 0.024891\n",
            "Epoch: 338 Train loss: 0.010103 Validation loss: 0.024807\n",
            "Epoch: 339 Train loss: 0.010078 Validation loss: 0.024723\n",
            "Epoch: 340 Train loss: 0.010053 Validation loss: 0.02464\n",
            "Epoch: 341 Train loss: 0.010029 Validation loss: 0.024558\n",
            "Epoch: 342 Train loss: 0.010004 Validation loss: 0.024476\n",
            "Epoch: 343 Train loss: 0.0099797 Validation loss: 0.024394\n",
            "Epoch: 344 Train loss: 0.0099555 Validation loss: 0.024313\n",
            "Epoch: 345 Train loss: 0.0099316 Validation loss: 0.024232\n",
            "Epoch: 346 Train loss: 0.0099078 Validation loss: 0.024151\n",
            "Epoch: 347 Train loss: 0.0098841 Validation loss: 0.024072\n",
            "Epoch: 348 Train loss: 0.0098607 Validation loss: 0.023992\n",
            "Epoch: 349 Train loss: 0.0098374 Validation loss: 0.023913\n",
            "Epoch: 350 Train loss: 0.0098143 Validation loss: 0.023834\n",
            "Epoch: 351 Train loss: 0.0097914 Validation loss: 0.023756\n",
            "Epoch: 352 Train loss: 0.0097687 Validation loss: 0.023678\n",
            "Epoch: 353 Train loss: 0.0097461 Validation loss: 0.023601\n",
            "Epoch: 354 Train loss: 0.0097237 Validation loss: 0.023524\n",
            "Epoch: 355 Train loss: 0.0097015 Validation loss: 0.023448\n",
            "Epoch: 356 Train loss: 0.0096794 Validation loss: 0.023372\n",
            "Epoch: 357 Train loss: 0.0096575 Validation loss: 0.023297\n",
            "Epoch: 358 Train loss: 0.0096357 Validation loss: 0.023221\n",
            "Epoch: 359 Train loss: 0.0096141 Validation loss: 0.023147\n",
            "Epoch: 360 Train loss: 0.0095927 Validation loss: 0.023073\n",
            "Epoch: 361 Train loss: 0.0095714 Validation loss: 0.022999\n",
            "Epoch: 362 Train loss: 0.0095503 Validation loss: 0.022926\n",
            "Epoch: 363 Train loss: 0.0095294 Validation loss: 0.022853\n",
            "Epoch: 364 Train loss: 0.0095086 Validation loss: 0.022781\n",
            "Epoch: 365 Train loss: 0.0094879 Validation loss: 0.022709\n",
            "Epoch: 366 Train loss: 0.0094674 Validation loss: 0.022637\n",
            "Epoch: 367 Train loss: 0.009447 Validation loss: 0.022566\n",
            "Epoch: 368 Train loss: 0.0094268 Validation loss: 0.022496\n",
            "Epoch: 369 Train loss: 0.0094068 Validation loss: 0.022426\n",
            "Epoch: 370 Train loss: 0.0093868 Validation loss: 0.022356\n",
            "Epoch: 371 Train loss: 0.0093671 Validation loss: 0.022287\n",
            "Epoch: 372 Train loss: 0.0093474 Validation loss: 0.022218\n",
            "Epoch: 373 Train loss: 0.0093279 Validation loss: 0.02215\n",
            "Epoch: 374 Train loss: 0.0093085 Validation loss: 0.022082\n",
            "Epoch: 375 Train loss: 0.0092894 Validation loss: 0.022014\n",
            "Epoch: 376 Train loss: 0.0092703 Validation loss: 0.021947\n",
            "Epoch: 377 Train loss: 0.0092514 Validation loss: 0.021881\n",
            "Epoch: 378 Train loss: 0.0092326 Validation loss: 0.021815\n",
            "Epoch: 379 Train loss: 0.0092139 Validation loss: 0.021749\n",
            "Epoch: 380 Train loss: 0.0091954 Validation loss: 0.021684\n",
            "Epoch: 381 Train loss: 0.009177 Validation loss: 0.021619\n",
            "Epoch: 382 Train loss: 0.0091588 Validation loss: 0.021554\n",
            "Epoch: 383 Train loss: 0.0091406 Validation loss: 0.02149\n",
            "Epoch: 384 Train loss: 0.0091226 Validation loss: 0.021427\n",
            "Epoch: 385 Train loss: 0.0091047 Validation loss: 0.021364\n",
            "Epoch: 386 Train loss: 0.009087 Validation loss: 0.021301\n",
            "Epoch: 387 Train loss: 0.0090694 Validation loss: 0.021239\n",
            "Epoch: 388 Train loss: 0.0090519 Validation loss: 0.021177\n",
            "Epoch: 389 Train loss: 0.0090345 Validation loss: 0.021115\n",
            "Epoch: 390 Train loss: 0.0090173 Validation loss: 0.021054\n",
            "Epoch: 391 Train loss: 0.0090002 Validation loss: 0.020994\n",
            "Epoch: 392 Train loss: 0.0089831 Validation loss: 0.020934\n",
            "Epoch: 393 Train loss: 0.0089663 Validation loss: 0.020874\n",
            "Epoch: 394 Train loss: 0.0089495 Validation loss: 0.020815\n",
            "Epoch: 395 Train loss: 0.0089329 Validation loss: 0.020756\n",
            "Epoch: 396 Train loss: 0.0089163 Validation loss: 0.020697\n",
            "Epoch: 397 Train loss: 0.0088999 Validation loss: 0.020639\n",
            "Epoch: 398 Train loss: 0.0088836 Validation loss: 0.020582\n",
            "Epoch: 399 Train loss: 0.0088675 Validation loss: 0.020524\n",
            "Epoch: 400 Train loss: 0.0088515 Validation loss: 0.020468\n",
            "Epoch: 401 Train loss: 0.0088355 Validation loss: 0.020411\n",
            "Epoch: 402 Train loss: 0.0088196 Validation loss: 0.020355\n",
            "Epoch: 403 Train loss: 0.0088039 Validation loss: 0.020299\n",
            "Epoch: 404 Train loss: 0.0087884 Validation loss: 0.020244\n",
            "Epoch: 405 Train loss: 0.0087729 Validation loss: 0.020189\n",
            "Epoch: 406 Train loss: 0.0087575 Validation loss: 0.020135\n",
            "Epoch: 407 Train loss: 0.0087422 Validation loss: 0.020081\n",
            "Epoch: 408 Train loss: 0.008727 Validation loss: 0.020027\n",
            "Epoch: 409 Train loss: 0.008712 Validation loss: 0.019974\n",
            "Epoch: 410 Train loss: 0.008697 Validation loss: 0.019921\n",
            "Epoch: 411 Train loss: 0.0086822 Validation loss: 0.019869\n",
            "Epoch: 412 Train loss: 0.0086674 Validation loss: 0.019816\n",
            "Epoch: 413 Train loss: 0.0086528 Validation loss: 0.019765\n",
            "Epoch: 414 Train loss: 0.0086383 Validation loss: 0.019713\n",
            "Epoch: 415 Train loss: 0.0086238 Validation loss: 0.019662\n",
            "Epoch: 416 Train loss: 0.0086095 Validation loss: 0.019612\n",
            "Epoch: 417 Train loss: 0.0085953 Validation loss: 0.019562\n",
            "Epoch: 418 Train loss: 0.0085812 Validation loss: 0.019512\n",
            "Epoch: 419 Train loss: 0.0085672 Validation loss: 0.019462\n",
            "Epoch: 420 Train loss: 0.0085532 Validation loss: 0.019413\n",
            "Epoch: 421 Train loss: 0.0085394 Validation loss: 0.019365\n",
            "Epoch: 422 Train loss: 0.0085257 Validation loss: 0.019316\n",
            "Epoch: 423 Train loss: 0.0085121 Validation loss: 0.019268\n",
            "Epoch: 424 Train loss: 0.0084985 Validation loss: 0.019221\n",
            "Epoch: 425 Train loss: 0.0084851 Validation loss: 0.019173\n",
            "Epoch: 426 Train loss: 0.0084717 Validation loss: 0.019126\n",
            "Epoch: 427 Train loss: 0.0084585 Validation loss: 0.01908\n",
            "Epoch: 428 Train loss: 0.0084453 Validation loss: 0.019034\n",
            "Epoch: 429 Train loss: 0.0084323 Validation loss: 0.018988\n",
            "Epoch: 430 Train loss: 0.0084193 Validation loss: 0.018942\n",
            "Epoch: 431 Train loss: 0.0084065 Validation loss: 0.018897\n",
            "Epoch: 432 Train loss: 0.0083937 Validation loss: 0.018853\n",
            "Epoch: 433 Train loss: 0.008381 Validation loss: 0.018808\n",
            "Epoch: 434 Train loss: 0.0083684 Validation loss: 0.018764\n",
            "Epoch: 435 Train loss: 0.0083559 Validation loss: 0.01872\n",
            "Epoch: 436 Train loss: 0.0083435 Validation loss: 0.018677\n",
            "Epoch: 437 Train loss: 0.0083312 Validation loss: 0.018634\n",
            "Epoch: 438 Train loss: 0.0083189 Validation loss: 0.018591\n",
            "Epoch: 439 Train loss: 0.0083068 Validation loss: 0.018549\n",
            "Epoch: 440 Train loss: 0.0082946 Validation loss: 0.018507\n",
            "Epoch: 441 Train loss: 0.0082827 Validation loss: 0.018465\n",
            "Epoch: 442 Train loss: 0.0082708 Validation loss: 0.018424\n",
            "Epoch: 443 Train loss: 0.008259 Validation loss: 0.018382\n",
            "Epoch: 444 Train loss: 0.0082473 Validation loss: 0.018342\n",
            "Epoch: 445 Train loss: 0.0082356 Validation loss: 0.018301\n",
            "Epoch: 446 Train loss: 0.008224 Validation loss: 0.018261\n",
            "Epoch: 447 Train loss: 0.0082126 Validation loss: 0.018221\n",
            "Epoch: 448 Train loss: 0.0082012 Validation loss: 0.018182\n",
            "Epoch: 449 Train loss: 0.0081898 Validation loss: 0.018143\n",
            "Epoch: 450 Train loss: 0.0081786 Validation loss: 0.018104\n",
            "Epoch: 451 Train loss: 0.0081675 Validation loss: 0.018066\n",
            "Epoch: 452 Train loss: 0.0081564 Validation loss: 0.018027\n",
            "Epoch: 453 Train loss: 0.0081454 Validation loss: 0.017989\n",
            "Epoch: 454 Train loss: 0.0081344 Validation loss: 0.017952\n",
            "Epoch: 455 Train loss: 0.0081236 Validation loss: 0.017915\n",
            "Epoch: 456 Train loss: 0.0081129 Validation loss: 0.017878\n",
            "Epoch: 457 Train loss: 0.0081022 Validation loss: 0.017841\n",
            "Epoch: 458 Train loss: 0.0080916 Validation loss: 0.017804\n",
            "Epoch: 459 Train loss: 0.008081 Validation loss: 0.017768\n",
            "Epoch: 460 Train loss: 0.0080706 Validation loss: 0.017733\n",
            "Epoch: 461 Train loss: 0.0080602 Validation loss: 0.017697\n",
            "Epoch: 462 Train loss: 0.0080499 Validation loss: 0.017662\n",
            "Epoch: 463 Train loss: 0.0080397 Validation loss: 0.017627\n",
            "Epoch: 464 Train loss: 0.0080295 Validation loss: 0.017592\n",
            "Epoch: 465 Train loss: 0.0080194 Validation loss: 0.017558\n",
            "Epoch: 466 Train loss: 0.0080094 Validation loss: 0.017524\n",
            "Epoch: 467 Train loss: 0.0079995 Validation loss: 0.01749\n",
            "Epoch: 468 Train loss: 0.0079896 Validation loss: 0.017457\n",
            "Epoch: 469 Train loss: 0.0079798 Validation loss: 0.017424\n",
            "Epoch: 470 Train loss: 0.0079701 Validation loss: 0.017391\n",
            "Epoch: 471 Train loss: 0.0079604 Validation loss: 0.017358\n",
            "Epoch: 472 Train loss: 0.0079508 Validation loss: 0.017326\n",
            "Epoch: 473 Train loss: 0.0079413 Validation loss: 0.017293\n",
            "Epoch: 474 Train loss: 0.0079319 Validation loss: 0.017262\n",
            "Epoch: 475 Train loss: 0.0079225 Validation loss: 0.01723\n",
            "Epoch: 476 Train loss: 0.0079132 Validation loss: 0.017199\n",
            "Epoch: 477 Train loss: 0.0079039 Validation loss: 0.017168\n",
            "Epoch: 478 Train loss: 0.0078947 Validation loss: 0.017137\n",
            "Epoch: 479 Train loss: 0.0078856 Validation loss: 0.017106\n",
            "Epoch: 480 Train loss: 0.0078766 Validation loss: 0.017076\n",
            "Epoch: 481 Train loss: 0.0078676 Validation loss: 0.017046\n",
            "Epoch: 482 Train loss: 0.0078587 Validation loss: 0.017016\n",
            "Epoch: 483 Train loss: 0.0078498 Validation loss: 0.016987\n",
            "Epoch: 484 Train loss: 0.007841 Validation loss: 0.016958\n",
            "Epoch: 485 Train loss: 0.0078323 Validation loss: 0.016929\n",
            "Epoch: 486 Train loss: 0.0078237 Validation loss: 0.0169\n",
            "Epoch: 487 Train loss: 0.0078151 Validation loss: 0.016871\n",
            "Epoch: 488 Train loss: 0.0078065 Validation loss: 0.016843\n",
            "Epoch: 489 Train loss: 0.0077981 Validation loss: 0.016815\n",
            "Epoch: 490 Train loss: 0.0077896 Validation loss: 0.016787\n",
            "Epoch: 491 Train loss: 0.0077813 Validation loss: 0.01676\n",
            "Epoch: 492 Train loss: 0.007773 Validation loss: 0.016733\n",
            "Epoch: 493 Train loss: 0.0077648 Validation loss: 0.016706\n",
            "Epoch: 494 Train loss: 0.0077566 Validation loss: 0.016679\n",
            "Epoch: 495 Train loss: 0.0077485 Validation loss: 0.016652\n",
            "Epoch: 496 Train loss: 0.0077404 Validation loss: 0.016626\n",
            "Epoch: 497 Train loss: 0.0077324 Validation loss: 0.0166\n",
            "Epoch: 498 Train loss: 0.0077245 Validation loss: 0.016574\n",
            "Epoch: 499 Train loss: 0.0077167 Validation loss: 0.016548\n",
            "Epoch: 500 Train loss: 0.0077088 Validation loss: 0.016523\n",
            "Epoch: 501 Train loss: 0.007701 Validation loss: 0.016498\n",
            "Epoch: 502 Train loss: 0.0076934 Validation loss: 0.016473\n",
            "Epoch: 503 Train loss: 0.0076857 Validation loss: 0.016448\n",
            "Epoch: 504 Train loss: 0.0076781 Validation loss: 0.016423\n",
            "Epoch: 505 Train loss: 0.0076706 Validation loss: 0.016399\n",
            "Epoch: 506 Train loss: 0.0076631 Validation loss: 0.016375\n",
            "Epoch: 507 Train loss: 0.0076557 Validation loss: 0.016351\n",
            "Epoch: 508 Train loss: 0.0076483 Validation loss: 0.016328\n",
            "Epoch: 509 Train loss: 0.007641 Validation loss: 0.016304\n",
            "Epoch: 510 Train loss: 0.0076338 Validation loss: 0.016281\n",
            "Epoch: 511 Train loss: 0.0076266 Validation loss: 0.016258\n",
            "Epoch: 512 Train loss: 0.0076194 Validation loss: 0.016235\n",
            "Epoch: 513 Train loss: 0.0076123 Validation loss: 0.016212\n",
            "Epoch: 514 Train loss: 0.0076053 Validation loss: 0.01619\n",
            "Epoch: 515 Train loss: 0.0075983 Validation loss: 0.016168\n",
            "Epoch: 516 Train loss: 0.0075913 Validation loss: 0.016146\n",
            "Epoch: 517 Train loss: 0.0075844 Validation loss: 0.016124\n",
            "Epoch: 518 Train loss: 0.0075776 Validation loss: 0.016102\n",
            "Epoch: 519 Train loss: 0.0075708 Validation loss: 0.016081\n",
            "Epoch: 520 Train loss: 0.007564 Validation loss: 0.01606\n",
            "Epoch: 521 Train loss: 0.0075574 Validation loss: 0.016039\n",
            "Epoch: 522 Train loss: 0.0075507 Validation loss: 0.016018\n",
            "Epoch: 523 Train loss: 0.0075442 Validation loss: 0.015997\n",
            "Epoch: 524 Train loss: 0.0075376 Validation loss: 0.015977\n",
            "Epoch: 525 Train loss: 0.0075311 Validation loss: 0.015956\n",
            "Epoch: 526 Train loss: 0.0075246 Validation loss: 0.015936\n",
            "Epoch: 527 Train loss: 0.0075182 Validation loss: 0.015916\n",
            "Epoch: 528 Train loss: 0.0075119 Validation loss: 0.015897\n",
            "Epoch: 529 Train loss: 0.0075056 Validation loss: 0.015877\n",
            "Epoch: 530 Train loss: 0.0074993 Validation loss: 0.015858\n",
            "Epoch: 531 Train loss: 0.0074931 Validation loss: 0.015839\n",
            "Epoch: 532 Train loss: 0.007487 Validation loss: 0.01582\n",
            "Epoch: 533 Train loss: 0.0074809 Validation loss: 0.015801\n",
            "Epoch: 534 Train loss: 0.0074748 Validation loss: 0.015782\n",
            "Epoch: 535 Train loss: 0.0074688 Validation loss: 0.015764\n",
            "Epoch: 536 Train loss: 0.0074628 Validation loss: 0.015745\n",
            "Epoch: 537 Train loss: 0.0074568 Validation loss: 0.015727\n",
            "Epoch: 538 Train loss: 0.007451 Validation loss: 0.015709\n",
            "Epoch: 539 Train loss: 0.0074451 Validation loss: 0.015691\n",
            "Epoch: 540 Train loss: 0.0074393 Validation loss: 0.015674\n",
            "Epoch: 541 Train loss: 0.0074335 Validation loss: 0.015656\n",
            "Epoch: 542 Train loss: 0.0074278 Validation loss: 0.015639\n",
            "Epoch: 543 Train loss: 0.0074222 Validation loss: 0.015622\n",
            "Epoch: 544 Train loss: 0.0074165 Validation loss: 0.015605\n",
            "Epoch: 545 Train loss: 0.007411 Validation loss: 0.015588\n",
            "Epoch: 546 Train loss: 0.0074054 Validation loss: 0.015572\n",
            "Epoch: 547 Train loss: 0.0073999 Validation loss: 0.015555\n",
            "Epoch: 548 Train loss: 0.0073945 Validation loss: 0.015539\n",
            "Epoch: 549 Train loss: 0.0073891 Validation loss: 0.015523\n",
            "Epoch: 550 Train loss: 0.0073837 Validation loss: 0.015506\n",
            "Epoch: 551 Train loss: 0.0073784 Validation loss: 0.015491\n",
            "Epoch: 552 Train loss: 0.007373 Validation loss: 0.015475\n",
            "Epoch: 553 Train loss: 0.0073678 Validation loss: 0.015459\n",
            "Epoch: 554 Train loss: 0.0073626 Validation loss: 0.015444\n",
            "Epoch: 555 Train loss: 0.0073575 Validation loss: 0.015429\n",
            "Epoch: 556 Train loss: 0.0073523 Validation loss: 0.015413\n",
            "Epoch: 557 Train loss: 0.0073472 Validation loss: 0.015398\n",
            "Epoch: 558 Train loss: 0.0073422 Validation loss: 0.015384\n",
            "Epoch: 559 Train loss: 0.0073371 Validation loss: 0.015369\n",
            "Epoch: 560 Train loss: 0.0073321 Validation loss: 0.015354\n",
            "Epoch: 561 Train loss: 0.0073272 Validation loss: 0.01534\n",
            "Epoch: 562 Train loss: 0.0073223 Validation loss: 0.015326\n",
            "Epoch: 563 Train loss: 0.0073175 Validation loss: 0.015312\n",
            "Epoch: 564 Train loss: 0.0073126 Validation loss: 0.015298\n",
            "Epoch: 565 Train loss: 0.0073078 Validation loss: 0.015284\n",
            "Epoch: 566 Train loss: 0.0073031 Validation loss: 0.01527\n",
            "Epoch: 567 Train loss: 0.0072984 Validation loss: 0.015256\n",
            "Epoch: 568 Train loss: 0.0072937 Validation loss: 0.015243\n",
            "Epoch: 569 Train loss: 0.0072891 Validation loss: 0.015229\n",
            "Epoch: 570 Train loss: 0.0072845 Validation loss: 0.015216\n",
            "Epoch: 571 Train loss: 0.0072799 Validation loss: 0.015203\n",
            "Epoch: 572 Train loss: 0.0072754 Validation loss: 0.01519\n",
            "Epoch: 573 Train loss: 0.0072709 Validation loss: 0.015177\n",
            "Epoch: 574 Train loss: 0.0072664 Validation loss: 0.015165\n",
            "Epoch: 575 Train loss: 0.007262 Validation loss: 0.015152\n",
            "Epoch: 576 Train loss: 0.0072576 Validation loss: 0.01514\n",
            "Epoch: 577 Train loss: 0.0072533 Validation loss: 0.015127\n",
            "Epoch: 578 Train loss: 0.007249 Validation loss: 0.015115\n",
            "Epoch: 579 Train loss: 0.0072446 Validation loss: 0.015103\n",
            "Epoch: 580 Train loss: 0.0072404 Validation loss: 0.015091\n",
            "Epoch: 581 Train loss: 0.0072362 Validation loss: 0.015079\n",
            "Epoch: 582 Train loss: 0.007232 Validation loss: 0.015067\n",
            "Epoch: 583 Train loss: 0.0072279 Validation loss: 0.015056\n",
            "Epoch: 584 Train loss: 0.0072237 Validation loss: 0.015044\n",
            "Epoch: 585 Train loss: 0.0072197 Validation loss: 0.015033\n",
            "Epoch: 586 Train loss: 0.0072156 Validation loss: 0.015022\n",
            "Epoch: 587 Train loss: 0.0072116 Validation loss: 0.01501\n",
            "Epoch: 588 Train loss: 0.0072076 Validation loss: 0.014999\n",
            "Epoch: 589 Train loss: 0.0072037 Validation loss: 0.014988\n",
            "Epoch: 590 Train loss: 0.0071997 Validation loss: 0.014977\n",
            "Epoch: 591 Train loss: 0.0071958 Validation loss: 0.014967\n",
            "Epoch: 592 Train loss: 0.007192 Validation loss: 0.014956\n",
            "Epoch: 593 Train loss: 0.0071881 Validation loss: 0.014946\n",
            "Epoch: 594 Train loss: 0.0071844 Validation loss: 0.014935\n",
            "Epoch: 595 Train loss: 0.0071806 Validation loss: 0.014925\n",
            "Epoch: 596 Train loss: 0.0071768 Validation loss: 0.014915\n",
            "Epoch: 597 Train loss: 0.0071731 Validation loss: 0.014904\n",
            "Epoch: 598 Train loss: 0.0071694 Validation loss: 0.014894\n",
            "Epoch: 599 Train loss: 0.0071658 Validation loss: 0.014884\n",
            "Epoch: 600 Train loss: 0.0071622 Validation loss: 0.014875\n",
            "Epoch: 601 Train loss: 0.0071586 Validation loss: 0.014865\n",
            "Epoch: 602 Train loss: 0.007155 Validation loss: 0.014855\n",
            "Epoch: 603 Train loss: 0.0071515 Validation loss: 0.014846\n",
            "Epoch: 604 Train loss: 0.007148 Validation loss: 0.014836\n",
            "Epoch: 605 Train loss: 0.0071445 Validation loss: 0.014827\n",
            "Epoch: 606 Train loss: 0.0071411 Validation loss: 0.014818\n",
            "Epoch: 607 Train loss: 0.0071377 Validation loss: 0.014808\n",
            "Epoch: 608 Train loss: 0.0071343 Validation loss: 0.014799\n",
            "Epoch: 609 Train loss: 0.0071309 Validation loss: 0.01479\n",
            "Epoch: 610 Train loss: 0.0071276 Validation loss: 0.014781\n",
            "Epoch: 611 Train loss: 0.0071243 Validation loss: 0.014772\n",
            "Epoch: 612 Train loss: 0.007121 Validation loss: 0.014764\n",
            "Epoch: 613 Train loss: 0.0071177 Validation loss: 0.014755\n",
            "Epoch: 614 Train loss: 0.0071145 Validation loss: 0.014747\n",
            "Epoch: 615 Train loss: 0.0071113 Validation loss: 0.014738\n",
            "Epoch: 616 Train loss: 0.0071082 Validation loss: 0.01473\n",
            "Epoch: 617 Train loss: 0.007105 Validation loss: 0.014721\n",
            "Epoch: 618 Train loss: 0.0071019 Validation loss: 0.014713\n",
            "Epoch: 619 Train loss: 0.0070988 Validation loss: 0.014705\n",
            "Epoch: 620 Train loss: 0.0070957 Validation loss: 0.014697\n",
            "Epoch: 621 Train loss: 0.0070927 Validation loss: 0.014689\n",
            "Epoch: 622 Train loss: 0.0070897 Validation loss: 0.014681\n",
            "Epoch: 623 Train loss: 0.0070867 Validation loss: 0.014673\n",
            "Epoch: 624 Train loss: 0.0070837 Validation loss: 0.014665\n",
            "Epoch: 625 Train loss: 0.0070808 Validation loss: 0.014658\n",
            "Epoch: 626 Train loss: 0.0070779 Validation loss: 0.01465\n",
            "Epoch: 627 Train loss: 0.007075 Validation loss: 0.014642\n",
            "Epoch: 628 Train loss: 0.0070721 Validation loss: 0.014635\n",
            "Epoch: 629 Train loss: 0.0070693 Validation loss: 0.014628\n",
            "Epoch: 630 Train loss: 0.0070665 Validation loss: 0.01462\n",
            "Epoch: 631 Train loss: 0.0070637 Validation loss: 0.014613\n",
            "Epoch: 632 Train loss: 0.0070609 Validation loss: 0.014606\n",
            "Epoch: 633 Train loss: 0.0070582 Validation loss: 0.014599\n",
            "Epoch: 634 Train loss: 0.0070554 Validation loss: 0.014592\n",
            "Epoch: 635 Train loss: 0.0070528 Validation loss: 0.014585\n",
            "Epoch: 636 Train loss: 0.0070501 Validation loss: 0.014578\n",
            "Epoch: 637 Train loss: 0.0070475 Validation loss: 0.014571\n",
            "Epoch: 638 Train loss: 0.0070448 Validation loss: 0.014564\n",
            "Epoch: 639 Train loss: 0.0070422 Validation loss: 0.014557\n",
            "Epoch: 640 Train loss: 0.0070396 Validation loss: 0.014551\n",
            "Epoch: 641 Train loss: 0.0070371 Validation loss: 0.014544\n",
            "Epoch: 642 Train loss: 0.0070346 Validation loss: 0.014538\n",
            "Epoch: 643 Train loss: 0.007032 Validation loss: 0.014531\n",
            "Epoch: 644 Train loss: 0.0070296 Validation loss: 0.014525\n",
            "Epoch: 645 Train loss: 0.0070271 Validation loss: 0.014518\n",
            "Epoch: 646 Train loss: 0.0070247 Validation loss: 0.014512\n",
            "Epoch: 647 Train loss: 0.0070222 Validation loss: 0.014506\n",
            "Epoch: 648 Train loss: 0.0070198 Validation loss: 0.0145\n",
            "Epoch: 649 Train loss: 0.0070174 Validation loss: 0.014494\n",
            "Epoch: 650 Train loss: 0.0070151 Validation loss: 0.014488\n",
            "Epoch: 651 Train loss: 0.0070128 Validation loss: 0.014482\n",
            "Epoch: 652 Train loss: 0.0070104 Validation loss: 0.014476\n",
            "Epoch: 653 Train loss: 0.0070081 Validation loss: 0.01447\n",
            "Epoch: 654 Train loss: 0.0070058 Validation loss: 0.014464\n",
            "Epoch: 655 Train loss: 0.0070036 Validation loss: 0.014458\n",
            "Epoch: 656 Train loss: 0.0070014 Validation loss: 0.014453\n",
            "Epoch: 657 Train loss: 0.0069991 Validation loss: 0.014447\n",
            "Epoch: 658 Train loss: 0.006997 Validation loss: 0.014441\n",
            "Epoch: 659 Train loss: 0.0069948 Validation loss: 0.014436\n",
            "Epoch: 660 Train loss: 0.0069926 Validation loss: 0.01443\n",
            "Epoch: 661 Train loss: 0.0069905 Validation loss: 0.014425\n",
            "Epoch: 662 Train loss: 0.0069884 Validation loss: 0.014419\n",
            "Epoch: 663 Train loss: 0.0069863 Validation loss: 0.014414\n",
            "Epoch: 664 Train loss: 0.0069842 Validation loss: 0.014409\n",
            "Epoch: 665 Train loss: 0.0069822 Validation loss: 0.014403\n",
            "Epoch: 666 Train loss: 0.0069801 Validation loss: 0.014398\n",
            "Epoch: 667 Train loss: 0.0069781 Validation loss: 0.014393\n",
            "Epoch: 668 Train loss: 0.0069761 Validation loss: 0.014388\n",
            "Epoch: 669 Train loss: 0.0069741 Validation loss: 0.014383\n",
            "Epoch: 670 Train loss: 0.0069722 Validation loss: 0.014378\n",
            "Epoch: 671 Train loss: 0.0069702 Validation loss: 0.014373\n",
            "Epoch: 672 Train loss: 0.0069683 Validation loss: 0.014368\n",
            "Epoch: 673 Train loss: 0.0069664 Validation loss: 0.014363\n",
            "Epoch: 674 Train loss: 0.0069645 Validation loss: 0.014358\n",
            "Epoch: 675 Train loss: 0.0069626 Validation loss: 0.014353\n",
            "Epoch: 676 Train loss: 0.0069608 Validation loss: 0.014348\n",
            "Epoch: 677 Train loss: 0.0069589 Validation loss: 0.014344\n",
            "Epoch: 678 Train loss: 0.0069571 Validation loss: 0.014339\n",
            "Epoch: 679 Train loss: 0.0069553 Validation loss: 0.014334\n",
            "Epoch: 680 Train loss: 0.0069536 Validation loss: 0.01433\n",
            "Epoch: 681 Train loss: 0.0069518 Validation loss: 0.014325\n",
            "Epoch: 682 Train loss: 0.00695 Validation loss: 0.014321\n",
            "Epoch: 683 Train loss: 0.0069483 Validation loss: 0.014316\n",
            "Epoch: 684 Train loss: 0.0069466 Validation loss: 0.014312\n",
            "Epoch: 685 Train loss: 0.0069449 Validation loss: 0.014307\n",
            "Epoch: 686 Train loss: 0.0069432 Validation loss: 0.014303\n",
            "Epoch: 687 Train loss: 0.0069416 Validation loss: 0.014298\n",
            "Epoch: 688 Train loss: 0.0069399 Validation loss: 0.014294\n",
            "Epoch: 689 Train loss: 0.0069382 Validation loss: 0.01429\n",
            "Epoch: 690 Train loss: 0.0069367 Validation loss: 0.014286\n",
            "Epoch: 691 Train loss: 0.0069351 Validation loss: 0.014281\n",
            "Epoch: 692 Train loss: 0.0069335 Validation loss: 0.014277\n",
            "Epoch: 693 Train loss: 0.0069319 Validation loss: 0.014273\n",
            "Epoch: 694 Train loss: 0.0069303 Validation loss: 0.014269\n",
            "Epoch: 695 Train loss: 0.0069288 Validation loss: 0.014265\n",
            "Epoch: 696 Train loss: 0.0069273 Validation loss: 0.014261\n",
            "Epoch: 697 Train loss: 0.0069258 Validation loss: 0.014257\n",
            "Epoch: 698 Train loss: 0.0069243 Validation loss: 0.014253\n",
            "Epoch: 699 Train loss: 0.0069228 Validation loss: 0.014249\n",
            "Epoch: 700 Train loss: 0.0069214 Validation loss: 0.014245\n",
            "Epoch: 701 Train loss: 0.0069199 Validation loss: 0.014241\n",
            "Epoch: 702 Train loss: 0.0069185 Validation loss: 0.014237\n",
            "Epoch: 703 Train loss: 0.0069171 Validation loss: 0.014233\n",
            "Epoch: 704 Train loss: 0.0069156 Validation loss: 0.01423\n",
            "Epoch: 705 Train loss: 0.0069143 Validation loss: 0.014226\n",
            "Epoch: 706 Train loss: 0.0069129 Validation loss: 0.014222\n",
            "Epoch: 707 Train loss: 0.0069116 Validation loss: 0.014218\n",
            "Epoch: 708 Train loss: 0.0069102 Validation loss: 0.014215\n",
            "Epoch: 709 Train loss: 0.0069089 Validation loss: 0.014211\n",
            "Epoch: 710 Train loss: 0.0069076 Validation loss: 0.014207\n",
            "Epoch: 711 Train loss: 0.0069063 Validation loss: 0.014204\n",
            "Epoch: 712 Train loss: 0.006905 Validation loss: 0.0142\n",
            "Epoch: 713 Train loss: 0.0069038 Validation loss: 0.014197\n",
            "Epoch: 714 Train loss: 0.0069025 Validation loss: 0.014193\n",
            "Epoch: 715 Train loss: 0.0069012 Validation loss: 0.014189\n",
            "Epoch: 716 Train loss: 0.0069 Validation loss: 0.014186\n",
            "Epoch: 717 Train loss: 0.0068988 Validation loss: 0.014182\n",
            "Epoch: 718 Train loss: 0.0068976 Validation loss: 0.014179\n",
            "Epoch: 719 Train loss: 0.0068964 Validation loss: 0.014176\n",
            "Epoch: 720 Train loss: 0.0068952 Validation loss: 0.014172\n",
            "Epoch: 721 Train loss: 0.0068941 Validation loss: 0.014169\n",
            "Epoch: 722 Train loss: 0.0068929 Validation loss: 0.014165\n",
            "Epoch: 723 Train loss: 0.0068918 Validation loss: 0.014162\n",
            "Epoch: 724 Train loss: 0.0068907 Validation loss: 0.014159\n",
            "Epoch: 725 Train loss: 0.0068896 Validation loss: 0.014156\n",
            "Epoch: 726 Train loss: 0.0068885 Validation loss: 0.014152\n",
            "Epoch: 727 Train loss: 0.0068874 Validation loss: 0.014149\n",
            "Epoch: 728 Train loss: 0.0068863 Validation loss: 0.014146\n",
            "Epoch: 729 Train loss: 0.0068852 Validation loss: 0.014143\n",
            "Epoch: 730 Train loss: 0.0068842 Validation loss: 0.014139\n",
            "Epoch: 731 Train loss: 0.0068832 Validation loss: 0.014136\n",
            "Epoch: 732 Train loss: 0.0068821 Validation loss: 0.014133\n",
            "Epoch: 733 Train loss: 0.0068812 Validation loss: 0.01413\n",
            "Epoch: 734 Train loss: 0.0068801 Validation loss: 0.014127\n",
            "Epoch: 735 Train loss: 0.0068791 Validation loss: 0.014124\n",
            "Epoch: 736 Train loss: 0.0068782 Validation loss: 0.014121\n",
            "Epoch: 737 Train loss: 0.0068772 Validation loss: 0.014118\n",
            "Epoch: 738 Train loss: 0.0068763 Validation loss: 0.014115\n",
            "Epoch: 739 Train loss: 0.0068753 Validation loss: 0.014112\n",
            "Epoch: 740 Train loss: 0.0068744 Validation loss: 0.014109\n",
            "Epoch: 741 Train loss: 0.0068735 Validation loss: 0.014106\n",
            "Epoch: 742 Train loss: 0.0068726 Validation loss: 0.014103\n",
            "Epoch: 743 Train loss: 0.0068717 Validation loss: 0.0141\n",
            "Epoch: 744 Train loss: 0.0068708 Validation loss: 0.014097\n",
            "Epoch: 745 Train loss: 0.00687 Validation loss: 0.014094\n",
            "Epoch: 746 Train loss: 0.0068691 Validation loss: 0.014091\n",
            "Epoch: 747 Train loss: 0.0068683 Validation loss: 0.014088\n",
            "Epoch: 748 Train loss: 0.0068674 Validation loss: 0.014085\n",
            "Epoch: 749 Train loss: 0.0068666 Validation loss: 0.014082\n",
            "Epoch: 750 Train loss: 0.0068658 Validation loss: 0.014079\n",
            "Epoch: 751 Train loss: 0.0068649 Validation loss: 0.014076\n",
            "Epoch: 752 Train loss: 0.0068642 Validation loss: 0.014074\n",
            "Epoch: 753 Train loss: 0.0068634 Validation loss: 0.014071\n",
            "Epoch: 754 Train loss: 0.0068626 Validation loss: 0.014068\n",
            "Epoch: 755 Train loss: 0.0068619 Validation loss: 0.014065\n",
            "Epoch: 756 Train loss: 0.0068611 Validation loss: 0.014062\n",
            "Epoch: 757 Train loss: 0.0068604 Validation loss: 0.01406\n",
            "Epoch: 758 Train loss: 0.0068597 Validation loss: 0.014057\n",
            "Epoch: 759 Train loss: 0.0068589 Validation loss: 0.014054\n",
            "Epoch: 760 Train loss: 0.0068582 Validation loss: 0.014051\n",
            "Epoch: 761 Train loss: 0.0068575 Validation loss: 0.014049\n",
            "Epoch: 762 Train loss: 0.0068568 Validation loss: 0.014046\n",
            "Epoch: 763 Train loss: 0.0068561 Validation loss: 0.014043\n",
            "Epoch: 764 Train loss: 0.0068554 Validation loss: 0.014041\n",
            "Epoch: 765 Train loss: 0.0068548 Validation loss: 0.014038\n",
            "Epoch: 766 Train loss: 0.0068541 Validation loss: 0.014035\n",
            "Epoch: 767 Train loss: 0.0068535 Validation loss: 0.014033\n",
            "Epoch: 768 Train loss: 0.0068529 Validation loss: 0.01403\n",
            "Epoch: 769 Train loss: 0.0068523 Validation loss: 0.014027\n",
            "Epoch: 770 Train loss: 0.0068517 Validation loss: 0.014025\n",
            "Epoch: 771 Train loss: 0.0068511 Validation loss: 0.014022\n",
            "Epoch: 772 Train loss: 0.0068505 Validation loss: 0.01402\n",
            "Epoch: 773 Train loss: 0.0068499 Validation loss: 0.014017\n",
            "Epoch: 774 Train loss: 0.0068493 Validation loss: 0.014014\n",
            "Epoch: 775 Train loss: 0.0068488 Validation loss: 0.014012\n",
            "Epoch: 776 Train loss: 0.0068482 Validation loss: 0.014009\n",
            "Epoch: 777 Train loss: 0.0068477 Validation loss: 0.014007\n",
            "Epoch: 778 Train loss: 0.0068471 Validation loss: 0.014004\n",
            "Epoch: 779 Train loss: 0.0068466 Validation loss: 0.014002\n",
            "Epoch: 780 Train loss: 0.0068461 Validation loss: 0.013999\n",
            "Epoch: 781 Train loss: 0.0068456 Validation loss: 0.013997\n",
            "Epoch: 782 Train loss: 0.006845 Validation loss: 0.013994\n",
            "Epoch: 783 Train loss: 0.0068445 Validation loss: 0.013992\n",
            "Epoch: 784 Train loss: 0.0068441 Validation loss: 0.013989\n",
            "Epoch: 785 Train loss: 0.0068436 Validation loss: 0.013987\n",
            "Epoch: 786 Train loss: 0.0068431 Validation loss: 0.013984\n",
            "Epoch: 787 Train loss: 0.0068427 Validation loss: 0.013982\n",
            "Epoch: 788 Train loss: 0.0068422 Validation loss: 0.013979\n",
            "Epoch: 789 Train loss: 0.0068418 Validation loss: 0.013977\n",
            "Epoch: 790 Train loss: 0.0068413 Validation loss: 0.013974\n",
            "Epoch: 791 Train loss: 0.0068409 Validation loss: 0.013972\n",
            "Epoch: 792 Train loss: 0.0068405 Validation loss: 0.013969\n",
            "Epoch: 793 Train loss: 0.0068401 Validation loss: 0.013967\n",
            "Epoch: 794 Train loss: 0.0068397 Validation loss: 0.013965\n",
            "Epoch: 795 Train loss: 0.0068393 Validation loss: 0.013962\n",
            "Epoch: 796 Train loss: 0.0068389 Validation loss: 0.01396\n",
            "Epoch: 797 Train loss: 0.0068385 Validation loss: 0.013957\n",
            "Epoch: 798 Train loss: 0.0068382 Validation loss: 0.013955\n",
            "Epoch: 799 Train loss: 0.0068378 Validation loss: 0.013952\n",
            "Epoch: 800 Train loss: 0.0068375 Validation loss: 0.01395\n",
            "Epoch: 801 Train loss: 0.0068371 Validation loss: 0.013948\n",
            "Epoch: 802 Train loss: 0.0068368 Validation loss: 0.013945\n",
            "Epoch: 803 Train loss: 0.0068365 Validation loss: 0.013943\n",
            "Epoch: 804 Train loss: 0.0068361 Validation loss: 0.013941\n",
            "Epoch: 805 Train loss: 0.0068358 Validation loss: 0.013938\n",
            "Epoch: 806 Train loss: 0.0068355 Validation loss: 0.013936\n",
            "Epoch: 807 Train loss: 0.0068352 Validation loss: 0.013933\n",
            "Epoch: 808 Train loss: 0.0068349 Validation loss: 0.013931\n",
            "Epoch: 809 Train loss: 0.0068346 Validation loss: 0.013929\n",
            "Epoch: 810 Train loss: 0.0068343 Validation loss: 0.013926\n",
            "Epoch: 811 Train loss: 0.0068341 Validation loss: 0.013924\n",
            "Epoch: 812 Train loss: 0.0068338 Validation loss: 0.013922\n",
            "Epoch: 813 Train loss: 0.0068336 Validation loss: 0.013919\n",
            "Epoch: 814 Train loss: 0.0068333 Validation loss: 0.013917\n",
            "Epoch: 815 Train loss: 0.0068331 Validation loss: 0.013915\n",
            "Epoch: 816 Train loss: 0.0068328 Validation loss: 0.013912\n",
            "Epoch: 817 Train loss: 0.0068326 Validation loss: 0.01391\n",
            "Epoch: 818 Train loss: 0.0068324 Validation loss: 0.013908\n",
            "Epoch: 819 Train loss: 0.0068322 Validation loss: 0.013906\n",
            "Epoch: 820 Train loss: 0.0068319 Validation loss: 0.013903\n",
            "Epoch: 821 Train loss: 0.0068317 Validation loss: 0.013901\n",
            "Epoch: 822 Train loss: 0.0068316 Validation loss: 0.013899\n",
            "Epoch: 823 Train loss: 0.0068314 Validation loss: 0.013896\n",
            "Epoch: 824 Train loss: 0.0068312 Validation loss: 0.013894\n",
            "Epoch: 825 Train loss: 0.006831 Validation loss: 0.013892\n",
            "Epoch: 826 Train loss: 0.0068309 Validation loss: 0.013889\n",
            "Epoch: 827 Train loss: 0.0068307 Validation loss: 0.013887\n",
            "Epoch: 828 Train loss: 0.0068305 Validation loss: 0.013885\n",
            "Epoch: 829 Train loss: 0.0068304 Validation loss: 0.013883\n",
            "Epoch: 830 Train loss: 0.0068303 Validation loss: 0.01388\n",
            "Epoch: 831 Train loss: 0.0068301 Validation loss: 0.013878\n",
            "Epoch: 832 Train loss: 0.00683 Validation loss: 0.013876\n",
            "Epoch: 833 Train loss: 0.0068299 Validation loss: 0.013873\n",
            "Epoch: 834 Train loss: 0.0068298 Validation loss: 0.013871\n",
            "Epoch: 835 Train loss: 0.0068297 Validation loss: 0.013869\n",
            "Epoch: 836 Train loss: 0.0068296 Validation loss: 0.013867\n",
            "Epoch: 837 Train loss: 0.0068295 Validation loss: 0.013864\n",
            "Epoch: 838 Train loss: 0.0068294 Validation loss: 0.013862\n",
            "Epoch: 839 Train loss: 0.0068293 Validation loss: 0.01386\n",
            "Epoch: 840 Train loss: 0.0068292 Validation loss: 0.013858\n",
            "Epoch: 841 Train loss: 0.0068292 Validation loss: 0.013855\n",
            "Epoch: 842 Train loss: 0.0068291 Validation loss: 0.013853\n",
            "Epoch: 843 Train loss: 0.006829 Validation loss: 0.013851\n",
            "Epoch: 844 Train loss: 0.006829 Validation loss: 0.013849\n",
            "Epoch: 845 Train loss: 0.006829 Validation loss: 0.013846\n",
            "Epoch: 846 Train loss: 0.0068289 Validation loss: 0.013844\n",
            "Epoch: 847 Train loss: 0.0068288 Validation loss: 0.013842\n",
            "Epoch: 848 Train loss: 0.0068288 Validation loss: 0.01384\n",
            "Epoch: 849 Train loss: 0.0068288 Validation loss: 0.013837\n",
            "Epoch: 850 Train loss: 0.0068287 Validation loss: 0.013835\n",
            "Epoch: 851 Train loss: 0.0068287 Validation loss: 0.013833\n",
            "Epoch: 852 Train loss: 0.0068287 Validation loss: 0.013831\n",
            "Epoch: 853 Train loss: 0.0068287 Validation loss: 0.013828\n",
            "Epoch: 854 Train loss: 0.0068287 Validation loss: 0.013826\n",
            "Epoch: 855 Train loss: 0.0068288 Validation loss: 0.013824\n",
            "Epoch: 856 Train loss: 0.0068287 Validation loss: 0.013822\n",
            "Epoch: 857 Train loss: 0.0068288 Validation loss: 0.013819\n",
            "Epoch: 858 Train loss: 0.0068288 Validation loss: 0.013817\n",
            "Epoch: 859 Train loss: 0.0068288 Validation loss: 0.013815\n",
            "Epoch: 860 Train loss: 0.0068289 Validation loss: 0.013813\n",
            "Epoch: 861 Train loss: 0.006829 Validation loss: 0.013811\n",
            "Epoch: 862 Train loss: 0.006829 Validation loss: 0.013808\n",
            "Epoch: 863 Train loss: 0.006829 Validation loss: 0.013806\n",
            "Epoch: 864 Train loss: 0.0068291 Validation loss: 0.013804\n",
            "Epoch: 865 Train loss: 0.0068291 Validation loss: 0.013802\n",
            "Epoch: 866 Train loss: 0.0068292 Validation loss: 0.013799\n",
            "Epoch: 867 Train loss: 0.0068293 Validation loss: 0.013797\n",
            "Epoch: 868 Train loss: 0.0068293 Validation loss: 0.013795\n",
            "Epoch: 869 Train loss: 0.0068294 Validation loss: 0.013793\n",
            "Epoch: 870 Train loss: 0.0068295 Validation loss: 0.013791\n",
            "Epoch: 871 Train loss: 0.0068296 Validation loss: 0.013788\n",
            "Epoch: 872 Train loss: 0.0068297 Validation loss: 0.013786\n",
            "Epoch: 873 Train loss: 0.0068298 Validation loss: 0.013784\n",
            "Epoch: 874 Train loss: 0.0068299 Validation loss: 0.013782\n",
            "Epoch: 875 Train loss: 0.00683 Validation loss: 0.013779\n",
            "Epoch: 876 Train loss: 0.0068301 Validation loss: 0.013777\n",
            "Epoch: 877 Train loss: 0.0068302 Validation loss: 0.013775\n",
            "Epoch: 878 Train loss: 0.0068304 Validation loss: 0.013773\n",
            "Epoch: 879 Train loss: 0.0068305 Validation loss: 0.01377\n",
            "Epoch: 880 Train loss: 0.0068307 Validation loss: 0.013768\n",
            "Epoch: 881 Train loss: 0.0068308 Validation loss: 0.013766\n",
            "Epoch: 882 Train loss: 0.0068309 Validation loss: 0.013764\n",
            "Epoch: 883 Train loss: 0.0068311 Validation loss: 0.013762\n",
            "Epoch: 884 Train loss: 0.0068312 Validation loss: 0.013759\n",
            "Epoch: 885 Train loss: 0.0068314 Validation loss: 0.013757\n",
            "Epoch: 886 Train loss: 0.0068316 Validation loss: 0.013755\n",
            "Epoch: 887 Train loss: 0.0068317 Validation loss: 0.013753\n",
            "Epoch: 888 Train loss: 0.0068319 Validation loss: 0.01375\n",
            "Epoch: 889 Train loss: 0.0068321 Validation loss: 0.013748\n",
            "Epoch: 890 Train loss: 0.0068323 Validation loss: 0.013746\n",
            "Epoch: 891 Train loss: 0.0068324 Validation loss: 0.013744\n",
            "Epoch: 892 Train loss: 0.0068326 Validation loss: 0.013742\n",
            "Epoch: 893 Train loss: 0.0068328 Validation loss: 0.013739\n",
            "Epoch: 894 Train loss: 0.006833 Validation loss: 0.013737\n",
            "Epoch: 895 Train loss: 0.0068332 Validation loss: 0.013735\n",
            "Epoch: 896 Train loss: 0.0068334 Validation loss: 0.013733\n",
            "Epoch: 897 Train loss: 0.0068336 Validation loss: 0.01373\n",
            "Epoch: 898 Train loss: 0.0068339 Validation loss: 0.013728\n",
            "Epoch: 899 Train loss: 0.0068341 Validation loss: 0.013726\n",
            "Epoch: 900 Train loss: 0.0068344 Validation loss: 0.013724\n",
            "Epoch: 901 Train loss: 0.0068345 Validation loss: 0.013721\n",
            "Epoch: 902 Train loss: 0.0068348 Validation loss: 0.013719\n",
            "Epoch: 903 Train loss: 0.006835 Validation loss: 0.013717\n",
            "Epoch: 904 Train loss: 0.0068352 Validation loss: 0.013715\n",
            "Epoch: 905 Train loss: 0.0068354 Validation loss: 0.013712\n",
            "Epoch: 906 Train loss: 0.0068357 Validation loss: 0.01371\n",
            "Epoch: 907 Train loss: 0.006836 Validation loss: 0.013708\n",
            "Epoch: 908 Train loss: 0.0068362 Validation loss: 0.013706\n",
            "Epoch: 909 Train loss: 0.0068365 Validation loss: 0.013704\n",
            "Epoch: 910 Train loss: 0.0068368 Validation loss: 0.013701\n",
            "Epoch: 911 Train loss: 0.006837 Validation loss: 0.013699\n",
            "Epoch: 912 Train loss: 0.0068373 Validation loss: 0.013697\n",
            "Epoch: 913 Train loss: 0.0068375 Validation loss: 0.013695\n",
            "Epoch: 914 Train loss: 0.0068378 Validation loss: 0.013692\n",
            "Epoch: 915 Train loss: 0.0068381 Validation loss: 0.01369\n",
            "Epoch: 916 Train loss: 0.0068384 Validation loss: 0.013688\n",
            "Epoch: 917 Train loss: 0.0068387 Validation loss: 0.013686\n",
            "Epoch: 918 Train loss: 0.006839 Validation loss: 0.013683\n",
            "Epoch: 919 Train loss: 0.0068393 Validation loss: 0.013681\n",
            "Epoch: 920 Train loss: 0.0068396 Validation loss: 0.013679\n",
            "Epoch: 921 Train loss: 0.0068399 Validation loss: 0.013677\n",
            "Epoch: 922 Train loss: 0.0068402 Validation loss: 0.013674\n",
            "Epoch: 923 Train loss: 0.0068405 Validation loss: 0.013672\n",
            "Epoch: 924 Train loss: 0.0068408 Validation loss: 0.01367\n",
            "Epoch: 925 Train loss: 0.0068412 Validation loss: 0.013668\n",
            "Epoch: 926 Train loss: 0.0068415 Validation loss: 0.013665\n",
            "Epoch: 927 Train loss: 0.0068418 Validation loss: 0.013663\n",
            "Epoch: 928 Train loss: 0.0068421 Validation loss: 0.013661\n",
            "Epoch: 929 Train loss: 0.0068425 Validation loss: 0.013659\n",
            "Epoch: 930 Train loss: 0.0068428 Validation loss: 0.013656\n",
            "Epoch: 931 Train loss: 0.0068432 Validation loss: 0.013654\n",
            "Epoch: 932 Train loss: 0.0068435 Validation loss: 0.013652\n",
            "Epoch: 933 Train loss: 0.0068438 Validation loss: 0.01365\n",
            "Epoch: 934 Train loss: 0.0068442 Validation loss: 0.013647\n",
            "Epoch: 935 Train loss: 0.0068445 Validation loss: 0.013645\n",
            "Epoch: 936 Train loss: 0.0068449 Validation loss: 0.013643\n",
            "Epoch: 937 Train loss: 0.0068452 Validation loss: 0.013641\n",
            "Epoch: 938 Train loss: 0.0068456 Validation loss: 0.013638\n",
            "Epoch: 939 Train loss: 0.006846 Validation loss: 0.013636\n",
            "Epoch: 940 Train loss: 0.0068464 Validation loss: 0.013634\n",
            "Epoch: 941 Train loss: 0.0068467 Validation loss: 0.013631\n",
            "Epoch: 942 Train loss: 0.0068471 Validation loss: 0.013629\n",
            "Epoch: 943 Train loss: 0.0068475 Validation loss: 0.013627\n",
            "Epoch: 944 Train loss: 0.0068479 Validation loss: 0.013625\n",
            "Epoch: 945 Train loss: 0.0068483 Validation loss: 0.013622\n",
            "Epoch: 946 Train loss: 0.0068486 Validation loss: 0.01362\n",
            "Epoch: 947 Train loss: 0.0068491 Validation loss: 0.013618\n",
            "Epoch: 948 Train loss: 0.0068494 Validation loss: 0.013616\n",
            "Epoch: 949 Train loss: 0.0068498 Validation loss: 0.013613\n",
            "Epoch: 950 Train loss: 0.0068502 Validation loss: 0.013611\n",
            "Epoch: 951 Train loss: 0.0068506 Validation loss: 0.013609\n",
            "Epoch: 952 Train loss: 0.006851 Validation loss: 0.013607\n",
            "Epoch: 953 Train loss: 0.0068514 Validation loss: 0.013604\n",
            "Epoch: 954 Train loss: 0.0068519 Validation loss: 0.013602\n",
            "Epoch: 955 Train loss: 0.0068523 Validation loss: 0.0136\n",
            "Epoch: 956 Train loss: 0.0068527 Validation loss: 0.013597\n",
            "Epoch: 957 Train loss: 0.0068531 Validation loss: 0.013595\n",
            "Epoch: 958 Train loss: 0.0068536 Validation loss: 0.013593\n",
            "Epoch: 959 Train loss: 0.006854 Validation loss: 0.013591\n",
            "Epoch: 960 Train loss: 0.0068544 Validation loss: 0.013588\n",
            "Epoch: 961 Train loss: 0.0068548 Validation loss: 0.013586\n",
            "Epoch: 962 Train loss: 0.0068553 Validation loss: 0.013584\n",
            "Epoch: 963 Train loss: 0.0068557 Validation loss: 0.013581\n",
            "Epoch: 964 Train loss: 0.0068561 Validation loss: 0.013579\n",
            "Epoch: 965 Train loss: 0.0068566 Validation loss: 0.013577\n",
            "Epoch: 966 Train loss: 0.0068571 Validation loss: 0.013575\n",
            "Epoch: 967 Train loss: 0.0068575 Validation loss: 0.013572\n",
            "Epoch: 968 Train loss: 0.006858 Validation loss: 0.01357\n",
            "Epoch: 969 Train loss: 0.0068584 Validation loss: 0.013568\n",
            "Epoch: 970 Train loss: 0.0068589 Validation loss: 0.013565\n",
            "Epoch: 971 Train loss: 0.0068593 Validation loss: 0.013563\n",
            "Epoch: 972 Train loss: 0.0068598 Validation loss: 0.013561\n",
            "Epoch: 973 Train loss: 0.0068602 Validation loss: 0.013559\n",
            "Epoch: 974 Train loss: 0.0068607 Validation loss: 0.013556\n",
            "Epoch: 975 Train loss: 0.0068612 Validation loss: 0.013554\n",
            "Epoch: 976 Train loss: 0.0068617 Validation loss: 0.013552\n",
            "Epoch: 977 Train loss: 0.0068622 Validation loss: 0.013549\n",
            "Epoch: 978 Train loss: 0.0068627 Validation loss: 0.013547\n",
            "Epoch: 979 Train loss: 0.0068631 Validation loss: 0.013545\n",
            "Epoch: 980 Train loss: 0.0068637 Validation loss: 0.013542\n",
            "Epoch: 981 Train loss: 0.0068641 Validation loss: 0.01354\n",
            "Epoch: 982 Train loss: 0.0068646 Validation loss: 0.013538\n",
            "Epoch: 983 Train loss: 0.0068651 Validation loss: 0.013536\n",
            "Epoch: 984 Train loss: 0.0068656 Validation loss: 0.013533\n",
            "Epoch: 985 Train loss: 0.0068661 Validation loss: 0.013531\n",
            "Epoch: 986 Train loss: 0.0068666 Validation loss: 0.013529\n",
            "Epoch: 987 Train loss: 0.0068671 Validation loss: 0.013526\n",
            "Epoch: 988 Train loss: 0.0068676 Validation loss: 0.013524\n",
            "Epoch: 989 Train loss: 0.0068681 Validation loss: 0.013522\n",
            "Epoch: 990 Train loss: 0.0068686 Validation loss: 0.013519\n",
            "Epoch: 991 Train loss: 0.0068691 Validation loss: 0.013517\n",
            "Epoch: 992 Train loss: 0.0068696 Validation loss: 0.013515\n",
            "Epoch: 993 Train loss: 0.0068701 Validation loss: 0.013513\n",
            "Epoch: 994 Train loss: 0.0068707 Validation loss: 0.01351\n",
            "Epoch: 995 Train loss: 0.0068712 Validation loss: 0.013508\n",
            "Epoch: 996 Train loss: 0.0068718 Validation loss: 0.013506\n",
            "Epoch: 997 Train loss: 0.0068723 Validation loss: 0.013503\n",
            "Epoch: 998 Train loss: 0.0068727 Validation loss: 0.013501\n",
            "Epoch: 999 Train loss: 0.0068733 Validation loss: 0.013499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylr1C2ovWXbO"
      },
      "source": [
        "During the training of the regularized model we can already notice, that, although there is still a difference between training and validation loss, the validation loss decreases as the training loss dreases. The effect of the regularization becomes even more evident if we plot the predictions of the regularized model and the overfitting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdMRV0vAWLmm",
        "outputId": "f3139354-8f3c-4379-d3f4-bb6e84c495a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We now want to plot the prediction of the regularized and unregularized big model. \"\"\"\n",
        "\n",
        "y_pred = big_reg_mdl(x) # Predict with \"big_reg_mdl\" on \"x\"\n",
        "y_pred_overfit = big_mdl(x) # Predict with \"big_mdl\" on \"x\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.plot(x, y_pred_overfit.numpy())\n",
        "plt.legend([\"Target\", \"Regularization\", \"No regularization\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sePQBaGqZzT6"
      },
      "source": [
        "The model with regularization seems to follow the overall trend of the data, while the model without any regularization very precisely fits the training samples. This is espacilly evident in the interval $\\left[0,0.5\\right]$, where the prediction of the unregularized model shows an oscillating behavior. Such oscillations are however not present in the ground truth and therefore undesirable. The regularized model on the other hand is not as flexible as the unregularized model and therefore does not fit the target function well in the interval $\\left[2.25, 3.0\\right]$.\n",
        "\n",
        "## Conclusion\n",
        "In this exercise we revisited the mathematical background for a simple regression task and covered it's practical implementation in Tensorflow 2. We also explored the phenomenon of overfitting and derived different regularizations from a probabilistic perspective. This exercise covers a very simple task with a very basic neural architecture and is intended as a primer for the second part of the regression exercise, which is dealing with a bigger and more realistic problem. In this second part we will consider the problem of estimating the age of a person from a potrait picture."
      ]
    }
  ]
}