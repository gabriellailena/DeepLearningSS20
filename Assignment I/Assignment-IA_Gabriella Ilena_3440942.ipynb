{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_regression_task_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjlEFdXpMgvw"
      },
      "source": [
        "# Deep learning programming I-A: Regression\n",
        "Felix Wiewel, Institute of Signal Processing and System Theory, University of Stuttgart, 24.04.2020\n",
        "\n",
        "## Introduction\n",
        "This programming exercise is the first of a series of exercises, which are intended as a supplement to the theoretical part of the Deep Learning course offered by the ISS. The goal is to introduce you to basic tasks and applications of methods you have encountered in the lecture. After completing the exercise you should be familiar with the basic ideas and one, possibly simple, way of solving the respective task. It is worth mentioning that most of the tasks can be solved in many different, not necessarily deep learning based, ways and the solution presented here is just one of them.\n",
        "\n",
        "## Regression\n",
        "\n",
        "In this exercise we consider the problem of regression, where we are interested in modeling a functional dependence between different variables with, possibly noisy, observations of input-output pairs. Mathematically such a dependence can be formulated as\n",
        "\n",
        "$\\mathbf{y}=f(\\mathbf{x})+\\boldsymbol{\\epsilon}$,\n",
        "\n",
        "where $\\mathbf{y}\\in\\mathbb{R}^{M}$ and $\\mathbf{x}\\in\\mathbb{R}^{N}$ are the input and output observations, $f:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ is the function mapping inputs to outputs and $\\boldsymbol{\\epsilon}\\in\\mathbb{R}^{M}$ is a random vector, which models noise in our observations. Note that this assumes additive noise that only acts on the output and not on the input variable, which might not be true in all practical applications but is a reasonable approximation. For regression we are now interested in estimating the functional relationship $f$ between the inputs and outputs. This can be done in many different ways, not just with neural networks, but for this exercise we focus on approximating this relationship with a neural network $g_{\\boldsymbol{\\theta}}:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ with parameter vector $\\boldsymbol{\\theta}$. The task is now to choose the parameters of the neural network in a way that results in a \"good\" approximation of $f$ with $g_{\\boldsymbol{\\theta}}$.\n",
        "\n",
        "In order to quantify how \"good\" our neural network can approximate $f$, we adopt a probabilistic view. For this we make the assumption that the noise $\\boldsymbol{\\epsilon}$ is a random vector drawn from a known dustribution, which enables us to derive a suitable cost function for training our neural network and also for quantifying a \"good\" approximation.\n",
        "\n",
        "### Mathematical formulation\n",
        "If we assume that the noise $\\boldsymbol{\\epsilon}$ is drawn from a gaussian distribution, e.g. $\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$, we can use\n",
        "\n",
        "$\\mathbf{y}=g_{\\boldsymbol{\\theta}}(\\mathbf{x})+\\boldsymbol{\\epsilon}\\Rightarrow \\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})=\\boldsymbol{\\epsilon}$\n",
        "\n",
        "to derive a log likelihood. Since the probability density function (pdf) of a multivariate normal distribution is given by\n",
        "\n",
        "$p(\\mathbf{x})=\\dfrac{1}{\\sqrt{(2\\pi)^{D}\\vert\\mathbf{C}\\vert}}\\mathrm{e}^{-\\dfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})\\mathbf{C}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})^{T}}$,\n",
        "\n",
        "we get\n",
        "\n",
        "$\\ln{p(\\boldsymbol{\\epsilon})}=\\ln{\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}}}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$.\n",
        "\n",
        "Replacing $\\boldsymbol{\\epsilon}$ by $\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})$ yields the log likelihood for one particular input-output pair:\n",
        "\n",
        "$\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})=\\ln {p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$\n",
        "\n",
        "This log likelihood measures how likely the input-output pair is and we can use it to train our neural network. For this we maximize the expected log likelihood over all input-output pairs under the assumption that the noise is idependent and identically distributed (i.i.d.) over all input-output pairs. This corresponds to finding the parameters $\\boldsymbol{\\theta}^{\\star}$ of our neural network, which maximize the the expected probability for observing the corresponding input-output pairs. Mathematically the optimal parameters for our neural network are given by\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[-\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}\\right]\\approx\\arg\\min_{\\boldsymbol{\\theta}}\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where all terms, which are independent of $\\boldsymbol{\\theta}$, are ignored and the expectation operator is approximated by the mean over all $N_{D}$ input-output pairs. In other words we are maximizing the log likelihood by minimizing the mean squared error loss over all input-output pairs in our dataset, hence this approach is called Maximum Likelihood (ML) estimation. For solving this optimization problem and obtaining the optimal network parameters, stochastic gradient descent (SGD) or one of it's many variants is typically used.\n",
        "\n",
        "It is worth noting, that choosing different distributions for the noise $\\boldsymbol{\\epsilon}$ leads to different log likelihoods and therefore different cost functions for training the neural network. Another commonly used distribution for modelling the noise in regression tasks is the laplace distribution. Deriving the log likelihood and the corresponding costfunction leads to the mean absolute error, which is given by the $l_{1}$-norm of the difference between observations predictions of the neural network. This cost function is considered more robust against outliers since these have less influence on the averall loss compared to the mean squared error.\n",
        "\n",
        "###  Implementation\n",
        "\n",
        "In the following we consider a simple regression task, implement a neural network and train it based on the mathematical fomrulation above. For this we first need to create a set of input-output pairs, which then needs to be partitioned into a training, validation and test set. We also define some constants to be used for partitioning the data and the hyperparameters for our neural network.\n",
        "\n",
        "But before we can start, we need to import the necessary packages tensorflow, numpy and matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPuVp2lyNK2J",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J84v9uucMgv5"
      },
      "source": [
        "Next we define our constants and set the random seeds of tensorflow and numpy in order to get reproducable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwC-1OnHMgv7",
        "colab": {}
      },
      "source": [
        "N_train_samples = 600\n",
        "N_validation_samples = 100\n",
        "N_test_samples = 100\n",
        "N_samples = N_train_samples + N_validation_samples + N_test_samples\n",
        "noise_sig = 0.1\n",
        "N_epochs = 150\n",
        "batch_size = 8\n",
        "learning_rate = 0.01\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngFFSyG-MgwA"
      },
      "source": [
        "We create $600$ training samples, $100$ validation samples to optimize our hyperparameters and $100$ test samples, which are used to check if our model can generalize to unseen data. Furthermore we set the level of noise added to the observations. For training the model we plan to train it for $150$ epochs with a batch size of $8$ and a learning rate of $0.01$. Next we create the actual input-output pairs $\\mathbf{x},\\mathbf{y}$ for which we want to learn the regression model and plot them. In this simple example we choose scalar inputs as well as output but in general $\\mathbf{x}$ and $\\mathbf{y}$ can be vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4s8AtsdQMgwB",
        "outputId": "048b50c5-9083-465e-9860-50e861d6aa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = np.linspace(0.0, 3.0, N_samples, dtype=np.float32)\n",
        "y = np.expand_dims(np.sin(1.0+x*x) + noise_sig*np.random.randn(N_samples).astype(np.float32), axis=-1)\n",
        "y_true = np.sin(1.0+x*x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.legend([\"Observation\", \"Ground truth\"])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3wx8vJlMgwI"
      },
      "source": [
        "With the input-output pairs created, your first task is now to partition the data in the training, validation and test sets. Keep in mind that we have created the data in a structured way, i.e. the input-output pairs are ordered. This means you need to shuffle the data before partitioning it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDIMUZs0MgwK",
        "colab": {}
      },
      "source": [
        "\"\"\" Shuffle and partition the data set accordingly. you can use the predefined constants \"N_train_samples\", \"N_validation_samples\" and \"N_test_samples\". Use the variable names that are already in the below code \n",
        "to store the final shuffled and partitioned data. Hint: Shuffle the data and the labels in such a way that the pairing between an image and it's label is preserved.\"\"\"\n",
        "# Shuffle the data\n",
        "c = np.column_stack((x, y))\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(c)\n",
        "\n",
        "# Partition the data\n",
        "x_train = c[:N_train_samples, 0]\n",
        "y_train = c[:N_train_samples, 1]\n",
        "x_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 0]\n",
        "y_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 1]\n",
        "x_test = c[(N_train_samples + N_validation_samples):N_samples, 0]\n",
        "y_test = c[(N_train_samples + N_validation_samples):N_samples, 1]\n",
        "\n",
        "# Cell testing\n",
        "assert np.array_equal(c[:,0], np.concatenate((x_train, x_validation, x_test))), \"Column 0 of c (x) does not have the same shape and/or elements as its splits.\"\n",
        "assert np.array_equal(c[:,1], np.concatenate((y_train, y_validation, y_test))), \"Column 1 of c (y) does not have the same shape and/or elements as its splits.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ucvKRhOMgwN"
      },
      "source": [
        "In order to feed the data to our model, we will use the Dataset class provided by Tensorflow. This class is simple to use and provides all the functionality we need for shuffling, batching and feeding the data to our model. It is also tightly integrated into the Tensorflow framework, which makes it very performant. Performance is not an aspect we need to worry about in this exercise, but it is important in more demanding applications.\n",
        "\n",
        "In this exercise we instantiate a separate Dataset object for the training, validation and test data sets, where we shuffle and repeat just the training data set. Shuffling the validation and test data sets is not necessary, since we only evaluate the loss on those data sets and do not perform SGD on it. Please fill in the missing part of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HifQ63iPMgwP",
        "colab": {}
      },
      "source": [
        "\"\"\" Create three tensorflow Dataset objects that can be used to feed the training test and validation data to a neural network. Hint: For the training data set use shuffling, batching with the size according to\n",
        "the predefined constant \"batch_size\" and repeat the data set indefinetly. For the validation and test data sets no shuffling or batching is needed.\"\"\"\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(N_train_samples).batch(batch_size).repeat()\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \n",
        "\n",
        "# print(list(validation_ds.as_numpy_iterator()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Crr6fIkMgwT"
      },
      "source": [
        "In this exercise we will create a a simple neural network with two hidden layers containing $10$ neurons. For creating a model and keeping track of its weights a class called MyModel is used. When initializing an instance of this class the necessary variables are created and stored in a list called \"trainable_variables\". This makes it easy to get all trainable variables of the model. We also override the \\__call__ method of this class in order to implement the forward pass of the neural network. This method should accept the inputs to the neural network and should return the result of the forward pass as an output. Please fill in the missing part of the code and select suitable activation functions for the different layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nq8ri416MgwX",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a neural network with two hidden dense layers containing 10 neurons each. As an activation function use the tangens hyperbolicus (tf.nn.tanh()). Since we are not using Keras, we need to create and \n",
        "manage all the variables that we need ourselves. The varaibles are created in the constructor of our model class. Since we want to be able to just call the class with some inputs in order to make a prediction, \n",
        "we implement a __call__ method which computes the forward pass and returns the output of the network.\"\"\"\n",
        "\n",
        "class MyModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,10]), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.random.truncated_normal([10]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([10,10]), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.random.truncated_normal([10]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([10,1]), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.random.truncated_normal([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uf6m8zXoMgwb"
      },
      "source": [
        "Now after the model class is defined we can instantiate a MyModel object by running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSfI8wjLMgwb",
        "colab": {}
      },
      "source": [
        "mdl = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KraeH6MsMgwh"
      },
      "source": [
        "We can now use the model to make predictions by calling it. In the following we predict on the inputs an plot the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1at5RObMgwi",
        "outputId": "8999cbd7-c86d-4d44-c1df-6a6545d8ab9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We want to plot a prediction on the complete data set with a model before training. For this make a prediction on the variable \"x\". \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "utFkv4F3NULQ"
      },
      "source": [
        "Since we have initialized the variables of the neural network randomly, it's prediction is also random. In order to fit the model we need to minimize the expected mean squared error over all input-ouput pairs in our training data set. For this we need to create a function, that performs a training step when provided with the model, an optimizer and a batch of input-ouput pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4zFN0-kOdu7",
        "colab": {}
      },
      "source": [
        "\"\"\" For training we need to implement a function that executes one training step. Fill in the missing code pieces for this function.\"\"\"\n",
        "\n",
        "def train_step(model, optimizer, x, y):\n",
        "    y = tf.reshape(y, [-1, 1]) # Reshaping to ensure y.shape = y_pred.shape to prevent wrong broadcasting\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.square(y_pred - y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "    grads = tape.gradient(loss_val, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ax-Kfd-tOm7I"
      },
      "source": [
        "This function uses the GradientTape to record the operations for which gradients have to be calculated. In our case this is the forward pass through our model and the computation of the loss function. After these operations are recoded we can get their gradients and apply these through the use of an optimizer. Finally we return the loss value in order to print it.\n",
        "\n",
        "With the training step function defined we now need to choose a suitable optimizer. Tensorflow offers a wide variety of optimizers but in this exercise we will use the RMSprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PahsqMscPcKD",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.RMSprop(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8_WjHrAwQB9e"
      },
      "source": [
        "We now have everything we need to start training the model. For this we repeatedly sample a batch of input-output pairs from our training data set and use the train_step function to minimize the loss function over this batch. We repeat this until we have iterated over the complete training data set once. After this we compute the loss on the validation data set, print it and repeat with another epoch until we have reached $N\\_epochs$ epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3LqS3d_QrX6",
        "outputId": "49e4b272-3632-4d45-b1f2-b79ce6d0f360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" We can now use the train_step function to perform the training. Fill in the missing code parts.\"\"\"\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_ds:\n",
        "    train_loss += train_step(mdl, opt, x_t, y_t) # Perform a training step with the model \"mdl\" and the optimizer \"opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples // batch_size) == 0: # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = mdl(x_v) # Compute a prediction with \"mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0.27207 Validation loss: 0.09653\n",
            "Epoch: 1 Train loss: 0.15441 Validation loss: 0.10493\n",
            "Epoch: 2 Train loss: 0.12611 Validation loss: 0.080325\n",
            "Epoch: 3 Train loss: 0.12021 Validation loss: 0.083434\n",
            "Epoch: 4 Train loss: 0.10796 Validation loss: 0.052595\n",
            "Epoch: 5 Train loss: 0.094702 Validation loss: 0.061393\n",
            "Epoch: 6 Train loss: 0.090064 Validation loss: 0.09087\n",
            "Epoch: 7 Train loss: 0.084773 Validation loss: 0.037398\n",
            "Epoch: 8 Train loss: 0.080517 Validation loss: 0.039037\n",
            "Epoch: 9 Train loss: 0.077089 Validation loss: 0.041347\n",
            "Epoch: 10 Train loss: 0.073165 Validation loss: 0.051984\n",
            "Epoch: 11 Train loss: 0.072477 Validation loss: 0.033797\n",
            "Epoch: 12 Train loss: 0.067822 Validation loss: 0.028401\n",
            "Epoch: 13 Train loss: 0.0609 Validation loss: 0.032525\n",
            "Epoch: 14 Train loss: 0.055267 Validation loss: 0.043709\n",
            "Epoch: 15 Train loss: 0.05094 Validation loss: 0.032858\n",
            "Epoch: 16 Train loss: 0.046363 Validation loss: 0.072367\n",
            "Epoch: 17 Train loss: 0.04384 Validation loss: 0.027105\n",
            "Epoch: 18 Train loss: 0.039645 Validation loss: 0.045709\n",
            "Epoch: 19 Train loss: 0.043087 Validation loss: 0.02851\n",
            "Epoch: 20 Train loss: 0.034861 Validation loss: 0.025124\n",
            "Epoch: 21 Train loss: 0.036588 Validation loss: 0.019646\n",
            "Epoch: 22 Train loss: 0.033858 Validation loss: 0.027236\n",
            "Epoch: 23 Train loss: 0.030269 Validation loss: 0.018398\n",
            "Epoch: 24 Train loss: 0.031991 Validation loss: 0.025142\n",
            "Epoch: 25 Train loss: 0.029639 Validation loss: 0.022344\n",
            "Epoch: 26 Train loss: 0.029887 Validation loss: 0.022664\n",
            "Epoch: 27 Train loss: 0.028146 Validation loss: 0.054689\n",
            "Epoch: 28 Train loss: 0.031945 Validation loss: 0.038204\n",
            "Epoch: 29 Train loss: 0.030051 Validation loss: 0.012966\n",
            "Epoch: 30 Train loss: 0.032652 Validation loss: 0.014797\n",
            "Epoch: 31 Train loss: 0.025874 Validation loss: 0.029876\n",
            "Epoch: 32 Train loss: 0.027712 Validation loss: 0.012913\n",
            "Epoch: 33 Train loss: 0.028383 Validation loss: 0.012113\n",
            "Epoch: 34 Train loss: 0.026973 Validation loss: 0.015297\n",
            "Epoch: 35 Train loss: 0.024138 Validation loss: 0.016338\n",
            "Epoch: 36 Train loss: 0.027422 Validation loss: 0.033774\n",
            "Epoch: 37 Train loss: 0.027172 Validation loss: 0.027166\n",
            "Epoch: 38 Train loss: 0.027622 Validation loss: 0.019115\n",
            "Epoch: 39 Train loss: 0.025325 Validation loss: 0.013365\n",
            "Epoch: 40 Train loss: 0.028532 Validation loss: 0.018868\n",
            "Epoch: 41 Train loss: 0.025945 Validation loss: 0.025063\n",
            "Epoch: 42 Train loss: 0.02514 Validation loss: 0.016437\n",
            "Epoch: 43 Train loss: 0.026375 Validation loss: 0.014926\n",
            "Epoch: 44 Train loss: 0.028304 Validation loss: 0.014003\n",
            "Epoch: 45 Train loss: 0.02555 Validation loss: 0.026948\n",
            "Epoch: 46 Train loss: 0.026016 Validation loss: 0.014548\n",
            "Epoch: 47 Train loss: 0.022318 Validation loss: 0.021047\n",
            "Epoch: 48 Train loss: 0.022207 Validation loss: 0.02068\n",
            "Epoch: 49 Train loss: 0.025291 Validation loss: 0.018568\n",
            "Epoch: 50 Train loss: 0.021015 Validation loss: 0.045548\n",
            "Epoch: 51 Train loss: 0.024217 Validation loss: 0.028948\n",
            "Epoch: 52 Train loss: 0.023529 Validation loss: 0.017045\n",
            "Epoch: 53 Train loss: 0.023698 Validation loss: 0.023658\n",
            "Epoch: 54 Train loss: 0.023397 Validation loss: 0.014656\n",
            "Epoch: 55 Train loss: 0.02201 Validation loss: 0.022616\n",
            "Epoch: 56 Train loss: 0.022292 Validation loss: 0.014625\n",
            "Epoch: 57 Train loss: 0.02375 Validation loss: 0.012014\n",
            "Epoch: 58 Train loss: 0.022745 Validation loss: 0.011481\n",
            "Epoch: 59 Train loss: 0.022972 Validation loss: 0.011241\n",
            "Epoch: 60 Train loss: 0.022155 Validation loss: 0.019895\n",
            "Epoch: 61 Train loss: 0.022557 Validation loss: 0.014357\n",
            "Epoch: 62 Train loss: 0.023009 Validation loss: 0.01692\n",
            "Epoch: 63 Train loss: 0.02312 Validation loss: 0.041525\n",
            "Epoch: 64 Train loss: 0.024974 Validation loss: 0.020235\n",
            "Epoch: 65 Train loss: 0.021023 Validation loss: 0.017744\n",
            "Epoch: 66 Train loss: 0.019244 Validation loss: 0.055348\n",
            "Epoch: 67 Train loss: 0.022697 Validation loss: 0.011261\n",
            "Epoch: 68 Train loss: 0.022071 Validation loss: 0.031023\n",
            "Epoch: 69 Train loss: 0.022217 Validation loss: 0.01261\n",
            "Epoch: 70 Train loss: 0.020932 Validation loss: 0.012519\n",
            "Epoch: 71 Train loss: 0.022334 Validation loss: 0.015274\n",
            "Epoch: 72 Train loss: 0.022555 Validation loss: 0.023642\n",
            "Epoch: 73 Train loss: 0.020829 Validation loss: 0.013089\n",
            "Epoch: 74 Train loss: 0.022326 Validation loss: 0.03667\n",
            "Epoch: 75 Train loss: 0.021358 Validation loss: 0.025554\n",
            "Epoch: 76 Train loss: 0.020753 Validation loss: 0.014665\n",
            "Epoch: 77 Train loss: 0.020283 Validation loss: 0.021248\n",
            "Epoch: 78 Train loss: 0.022274 Validation loss: 0.018501\n",
            "Epoch: 79 Train loss: 0.021606 Validation loss: 0.013458\n",
            "Epoch: 80 Train loss: 0.020166 Validation loss: 0.019503\n",
            "Epoch: 81 Train loss: 0.021168 Validation loss: 0.013651\n",
            "Epoch: 82 Train loss: 0.020234 Validation loss: 0.032462\n",
            "Epoch: 83 Train loss: 0.021809 Validation loss: 0.018832\n",
            "Epoch: 84 Train loss: 0.019539 Validation loss: 0.018271\n",
            "Epoch: 85 Train loss: 0.0222 Validation loss: 0.011644\n",
            "Epoch: 86 Train loss: 0.021803 Validation loss: 0.016195\n",
            "Epoch: 87 Train loss: 0.019862 Validation loss: 0.01482\n",
            "Epoch: 88 Train loss: 0.021004 Validation loss: 0.016522\n",
            "Epoch: 89 Train loss: 0.021642 Validation loss: 0.017903\n",
            "Epoch: 90 Train loss: 0.021389 Validation loss: 0.019457\n",
            "Epoch: 91 Train loss: 0.020636 Validation loss: 0.015443\n",
            "Epoch: 92 Train loss: 0.020519 Validation loss: 0.019337\n",
            "Epoch: 93 Train loss: 0.018701 Validation loss: 0.018007\n",
            "Epoch: 94 Train loss: 0.020037 Validation loss: 0.058429\n",
            "Epoch: 95 Train loss: 0.022748 Validation loss: 0.014526\n",
            "Epoch: 96 Train loss: 0.01917 Validation loss: 0.020824\n",
            "Epoch: 97 Train loss: 0.020034 Validation loss: 0.032517\n",
            "Epoch: 98 Train loss: 0.019867 Validation loss: 0.018762\n",
            "Epoch: 99 Train loss: 0.020109 Validation loss: 0.014835\n",
            "Epoch: 100 Train loss: 0.020131 Validation loss: 0.020127\n",
            "Epoch: 101 Train loss: 0.020549 Validation loss: 0.023704\n",
            "Epoch: 102 Train loss: 0.02138 Validation loss: 0.012023\n",
            "Epoch: 103 Train loss: 0.019636 Validation loss: 0.020517\n",
            "Epoch: 104 Train loss: 0.020585 Validation loss: 0.016057\n",
            "Epoch: 105 Train loss: 0.018836 Validation loss: 0.014797\n",
            "Epoch: 106 Train loss: 0.021786 Validation loss: 0.017887\n",
            "Epoch: 107 Train loss: 0.022298 Validation loss: 0.011244\n",
            "Epoch: 108 Train loss: 0.018785 Validation loss: 0.020423\n",
            "Epoch: 109 Train loss: 0.01953 Validation loss: 0.020125\n",
            "Epoch: 110 Train loss: 0.019447 Validation loss: 0.013664\n",
            "Epoch: 111 Train loss: 0.018489 Validation loss: 0.017688\n",
            "Epoch: 112 Train loss: 0.018996 Validation loss: 0.015285\n",
            "Epoch: 113 Train loss: 0.019779 Validation loss: 0.02284\n",
            "Epoch: 114 Train loss: 0.020613 Validation loss: 0.01203\n",
            "Epoch: 115 Train loss: 0.020459 Validation loss: 0.018805\n",
            "Epoch: 116 Train loss: 0.02031 Validation loss: 0.012156\n",
            "Epoch: 117 Train loss: 0.019411 Validation loss: 0.035371\n",
            "Epoch: 118 Train loss: 0.019604 Validation loss: 0.012425\n",
            "Epoch: 119 Train loss: 0.018723 Validation loss: 0.024662\n",
            "Epoch: 120 Train loss: 0.018066 Validation loss: 0.01121\n",
            "Epoch: 121 Train loss: 0.01988 Validation loss: 0.012307\n",
            "Epoch: 122 Train loss: 0.020607 Validation loss: 0.01136\n",
            "Epoch: 123 Train loss: 0.019676 Validation loss: 0.014014\n",
            "Epoch: 124 Train loss: 0.018725 Validation loss: 0.025527\n",
            "Epoch: 125 Train loss: 0.017048 Validation loss: 0.020196\n",
            "Epoch: 126 Train loss: 0.022139 Validation loss: 0.012927\n",
            "Epoch: 127 Train loss: 0.01817 Validation loss: 0.017531\n",
            "Epoch: 128 Train loss: 0.020626 Validation loss: 0.015227\n",
            "Epoch: 129 Train loss: 0.019373 Validation loss: 0.013684\n",
            "Epoch: 130 Train loss: 0.019482 Validation loss: 0.025106\n",
            "Epoch: 131 Train loss: 0.018573 Validation loss: 0.025932\n",
            "Epoch: 132 Train loss: 0.020406 Validation loss: 0.014734\n",
            "Epoch: 133 Train loss: 0.018876 Validation loss: 0.012715\n",
            "Epoch: 134 Train loss: 0.018346 Validation loss: 0.026565\n",
            "Epoch: 135 Train loss: 0.018596 Validation loss: 0.016018\n",
            "Epoch: 136 Train loss: 0.019219 Validation loss: 0.016488\n",
            "Epoch: 137 Train loss: 0.018617 Validation loss: 0.016393\n",
            "Epoch: 138 Train loss: 0.019847 Validation loss: 0.021195\n",
            "Epoch: 139 Train loss: 0.019607 Validation loss: 0.011906\n",
            "Epoch: 140 Train loss: 0.019229 Validation loss: 0.016503\n",
            "Epoch: 141 Train loss: 0.018987 Validation loss: 0.027648\n",
            "Epoch: 142 Train loss: 0.01908 Validation loss: 0.027801\n",
            "Epoch: 143 Train loss: 0.018038 Validation loss: 0.024684\n",
            "Epoch: 144 Train loss: 0.019035 Validation loss: 0.016173\n",
            "Epoch: 145 Train loss: 0.019399 Validation loss: 0.012815\n",
            "Epoch: 146 Train loss: 0.018797 Validation loss: 0.011864\n",
            "Epoch: 147 Train loss: 0.018808 Validation loss: 0.012265\n",
            "Epoch: 148 Train loss: 0.019803 Validation loss: 0.015393\n",
            "Epoch: 149 Train loss: 0.01952 Validation loss: 0.01153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DduaR_pCQ0k-"
      },
      "source": [
        "After completion of the training process we use the test data set to test the models generalization to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ofClNnHRAUy",
        "outputId": "17ad63fa-d59b-4004-e6b9-896323039986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss = 0.0\n",
        "for x_t, y_t in test_ds:\n",
        "    y_pred = mdl(x_t) # Compute a prediction with \"mdl\" on the input \"x_t\"\n",
        "    test_loss += float(tf.square(y_pred - y_t)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_t\"\n",
        "print(\"Test loss: {:.5}\".format(test_loss/N_test_samples))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.010748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzJ7wOZmRbez"
      },
      "source": [
        "After we have verified that our model achieves a similar loss on the test as on the validation and training data set, we can conclude that our model is not overfitting or underfitting and generalizes to unseen data. We can now predict on the inputs again and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyvFN03bR8ez",
        "outputId": "1ed47720-bf56-4b4c-e8a2-d7724e7ac779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" Now we want to plot the prediction after training. Predict on the variable \"x\" again. \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WKmuAAmLSmiR"
      },
      "source": [
        "Now our model has learned to approximate the function mapping from the input to the output. The capability of neural networks to learn from input-ouput pairs alone and approximate an arbitrary function, see universal approximation theorem, can be very useful if the mapping between the input and output is too complex to be captured with model based approaches. But learning from input-ouput pairs alone implies that the model will only be able to make accurate predictions over input ranges it has seen during training. In order to demonstrate this we will predict on an interval that exeeds the $\\left[0,3\\right]$ interval the model was trained on, i.e. we will predict on the interval $\\left[-2,5\\right]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRF8hAmmVFcH",
        "outputId": "acdc6a70-8655-47f2-b78b-346e5316f0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x_generalize = np.linspace(-2.0, 5.0, N_samples, dtype=np.float32)\n",
        "y_generalize = np.sin(1.0+x_generalize*x_generalize) + noise_sig*np.random.randn(N_samples).astype(np.float32)\n",
        "y_truey_generalize = np.sin(1.0+x_generalize*x_generalize)\n",
        "y_pred = mdl(x_generalize)\n",
        "plt.plot(x_generalize, y_generalize)\n",
        "plt.plot(x_generalize, y_truey_generalize)\n",
        "plt.plot(x_generalize, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J2yr-0UCVIli"
      },
      "source": [
        "As expected, the model is able to make farely accurate predictions on the interval it was trained on but makes unreliable predictions outside this interval.\n",
        "\n",
        "### Regularization\n",
        "In this section we will explore the concept of regularization. As there is no theorem that can be used to determine the required size and structure of a neural network given a certain task, one has to find a suitable neural architecture by trial and error. This can result in choosing a architecture with a capacity that is higher than required for solving the given task and hence overfitting might occur. A common way to prevent large neural networks networks from overfitting is to employ some sort of regularization, e.g. weight norm penalty, dropout, early stopping and data augmentation. In this section we will focus on weight norm penalty as a regularization and derive a probabilistic interpretation for some of those.\n",
        "\n",
        "We start by restating the conditional probability of the output $\\mathbf{y}$ given the input $\\mathbf{x}$ and the networks parameters $\\boldsymbol{\\theta}$\n",
        "\n",
        "$p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})=\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}}$,\n",
        "\n",
        "which we used to derive the log likelihood. If we have some prior knowledge about the parameters of the neural network, which is given by a pdf $p(\\boldsymbol{\\theta})$ over the weights, we can use Bayes theorem to derive a posterior distribution\n",
        "\n",
        "$p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})=\\dfrac{p(\\boldsymbol{\\theta},\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})}=\\dfrac{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p(\\mathbf{y})}$\n",
        "\n",
        "where $p(\\boldsymbol{\\theta})$ is the  prior over the networks parameters. Similar to the derivation at the beginning of the exercise, we can use this posterior distribution to derive a cost function for training the neural network. In this case, however, we are not maximizing the log likelihood but the posterior distribution over the weights, hence this approach is called Maximum A Posteori (MAP) estimation of the parameters. Mathematically we can formulate this as\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\ln{p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})}\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\ln{p(\\boldsymbol{\\theta})}+\\mathbb{E}\\left[\\ln{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}\\right]$,\n",
        "\n",
        "where we used the fact that applying a strictly increasing function, e.g. $\\ln{}$, does not change the position of the maximum of a cost function, ignored $p(\\mathbf{y})$, since it is independent of the network parameters and dropped the expectation operator for $\\ln{p(\\boldsymbol{\\theta})}$, since it is not depending on the random variable $\\mathbf{x}$. Comparing the MAP estimate of the parameters with the ML estimate we derived above, shows that the only difference is the addition of $\\ln{p(\\boldsymbol{\\theta})}$. This term is the regularization, i.e. the weight norm penalty. Depending on the distribution over $\\boldsymbol{\\theta}$ it can have different forms. If we choose a standard normal distribution, i.e. $\\boldsymbol{\\theta\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})}$,  we get\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{2}^{2}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where we have made the same simplifications as for the ML estimation and also introduced the parameter $\\lambda=\\sigma^{2}$, which is used to control the strength of the regularization. This form of regularization is commonly known as $l_{2}$-norm or weight decay regularization. Choosing a prior where the weights follow an i.i.d laplacian distribution, i.e. $p(\\boldsymbol{\\theta})=\\prod_{j}\\dfrac{1}{2}\\mathrm{e}^{\\vert\\theta_{j}\\vert}$, leads to\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{1}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where the strength of the regularization is again controlled by $\\lambda=\\sigma^{2}$. This type of regularization is known as  $l_{1}$-norm and it has the property to induce sparsity in the parameters of the network.\n",
        "\n",
        "With this theoretical background on regularization we can now implement it and observe it's effects on the regression problem covered in this exercise. For this we will define a model with a high capacity and train it for a extended time to provoke overfitting. For this, we will increase the number of hidden neurons in both hidden layers to $100$ and $50$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2Fv2J-VK_vw",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a bigger model with again two hidden layers containing 100 and 50 neurons. As an activation use the tangens hyperbolicus function where it is appropiate. \"\"\"\n",
        "\n",
        "class MyBigModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,100]), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.random.truncated_normal([100]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([100,50]), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.random.truncated_normal([50]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([50,1]), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.random.truncated_normal([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y1XpaZTNLV-p"
      },
      "source": [
        "After creating one instance of this class we can again train it on our data set. We will also create a new optimizer for training this bigger model, since some optimizers adapt the learning rates for individual parameters during a training process and we do not want to train our bigger model with learning rates adopted from an earlier training run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7Yq-a1FLi0X",
        "colab": {}
      },
      "source": [
        "big_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dBrf0I68MnMy"
      },
      "source": [
        "Now we are ready to train this bigger model using the same training step and training loop. In order to provoke overfitting we also reduce the number of samples in the training data set a lot, increase the batch size and train for a more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nz_lXM8LMwXo",
        "outputId": "022c7dc8-2243-46e2-eb6a-a30471a4d5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model similar to the training of the small model before. \"\"\"\n",
        "\n",
        "N_train_samples_overfit = 30\n",
        "N_epochs = 1000\n",
        "batch_size = 30\n",
        "\n",
        "sel_idx = np.arange(0, N_train_samples)\n",
        "sel_idx = np.random.choice(sel_idx, N_train_samples_overfit)\n",
        "x_train_overfit = x_train[sel_idx]\n",
        "y_train_overfit = y_train[sel_idx]\n",
        "\n",
        "train_overfit_ds = tf.data.Dataset.from_tensor_slices((x_train_overfit, y_train_overfit)).shuffle(N_train_samples_overfit).batch(batch_size).repeat()\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += train_step(big_mdl, big_opt, x_t, y_t) # Perform a training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples_overfit//batch_size) == 0: # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_mdl(x_v) # Compute a prediction with \"big_mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 26.697 Validation loss: 98.711\n",
            "Epoch: 1 Train loss: 93.855 Validation loss: 5.0487\n",
            "Epoch: 2 Train loss: 5.1751 Validation loss: 1.641\n",
            "Epoch: 3 Train loss: 2.0091 Validation loss: 0.92767\n",
            "Epoch: 4 Train loss: 1.1337 Validation loss: 0.64748\n",
            "Epoch: 5 Train loss: 0.73411 Validation loss: 0.52969\n",
            "Epoch: 6 Train loss: 0.54359 Validation loss: 0.47117\n",
            "Epoch: 7 Train loss: 0.44832 Validation loss: 0.43524\n",
            "Epoch: 8 Train loss: 0.39679 Validation loss: 0.40962\n",
            "Epoch: 9 Train loss: 0.36647 Validation loss: 0.38989\n",
            "Epoch: 10 Train loss: 0.34719 Validation loss: 0.37401\n",
            "Epoch: 11 Train loss: 0.33393 Validation loss: 0.36075\n",
            "Epoch: 12 Train loss: 0.32404 Validation loss: 0.34932\n",
            "Epoch: 13 Train loss: 0.31608 Validation loss: 0.33919\n",
            "Epoch: 14 Train loss: 0.30928 Validation loss: 0.33001\n",
            "Epoch: 15 Train loss: 0.3032 Validation loss: 0.32156\n",
            "Epoch: 16 Train loss: 0.29762 Validation loss: 0.31371\n",
            "Epoch: 17 Train loss: 0.2924 Validation loss: 0.30633\n",
            "Epoch: 18 Train loss: 0.28745 Validation loss: 0.29937\n",
            "Epoch: 19 Train loss: 0.28272 Validation loss: 0.29275\n",
            "Epoch: 20 Train loss: 0.27817 Validation loss: 0.28645\n",
            "Epoch: 21 Train loss: 0.27378 Validation loss: 0.28042\n",
            "Epoch: 22 Train loss: 0.26951 Validation loss: 0.27463\n",
            "Epoch: 23 Train loss: 0.26536 Validation loss: 0.26905\n",
            "Epoch: 24 Train loss: 0.2613 Validation loss: 0.26367\n",
            "Epoch: 25 Train loss: 0.25732 Validation loss: 0.25845\n",
            "Epoch: 26 Train loss: 0.25341 Validation loss: 0.2534\n",
            "Epoch: 27 Train loss: 0.24955 Validation loss: 0.24849\n",
            "Epoch: 28 Train loss: 0.24573 Validation loss: 0.2437\n",
            "Epoch: 29 Train loss: 0.24195 Validation loss: 0.23904\n",
            "Epoch: 30 Train loss: 0.23818 Validation loss: 0.23449\n",
            "Epoch: 31 Train loss: 0.23444 Validation loss: 0.23004\n",
            "Epoch: 32 Train loss: 0.23069 Validation loss: 0.22569\n",
            "Epoch: 33 Train loss: 0.22696 Validation loss: 0.22143\n",
            "Epoch: 34 Train loss: 0.22321 Validation loss: 0.21728\n",
            "Epoch: 35 Train loss: 0.21947 Validation loss: 0.21321\n",
            "Epoch: 36 Train loss: 0.21572 Validation loss: 0.20924\n",
            "Epoch: 37 Train loss: 0.21198 Validation loss: 0.20538\n",
            "Epoch: 38 Train loss: 0.20825 Validation loss: 0.20162\n",
            "Epoch: 39 Train loss: 0.20453 Validation loss: 0.19797\n",
            "Epoch: 40 Train loss: 0.20085 Validation loss: 0.19443\n",
            "Epoch: 41 Train loss: 0.19722 Validation loss: 0.19102\n",
            "Epoch: 42 Train loss: 0.19366 Validation loss: 0.18772\n",
            "Epoch: 43 Train loss: 0.19018 Validation loss: 0.18455\n",
            "Epoch: 44 Train loss: 0.18679 Validation loss: 0.1815\n",
            "Epoch: 45 Train loss: 0.1835 Validation loss: 0.17857\n",
            "Epoch: 46 Train loss: 0.18033 Validation loss: 0.17574\n",
            "Epoch: 47 Train loss: 0.17728 Validation loss: 0.17302\n",
            "Epoch: 48 Train loss: 0.17435 Validation loss: 0.1704\n",
            "Epoch: 49 Train loss: 0.17154 Validation loss: 0.16787\n",
            "Epoch: 50 Train loss: 0.16884 Validation loss: 0.16543\n",
            "Epoch: 51 Train loss: 0.16625 Validation loss: 0.16307\n",
            "Epoch: 52 Train loss: 0.16377 Validation loss: 0.16079\n",
            "Epoch: 53 Train loss: 0.16138 Validation loss: 0.15858\n",
            "Epoch: 54 Train loss: 0.15909 Validation loss: 0.15643\n",
            "Epoch: 55 Train loss: 0.15687 Validation loss: 0.15435\n",
            "Epoch: 56 Train loss: 0.15474 Validation loss: 0.15233\n",
            "Epoch: 57 Train loss: 0.15268 Validation loss: 0.15036\n",
            "Epoch: 58 Train loss: 0.15068 Validation loss: 0.14844\n",
            "Epoch: 59 Train loss: 0.14874 Validation loss: 0.14657\n",
            "Epoch: 60 Train loss: 0.14685 Validation loss: 0.14475\n",
            "Epoch: 61 Train loss: 0.14502 Validation loss: 0.14296\n",
            "Epoch: 62 Train loss: 0.14323 Validation loss: 0.14122\n",
            "Epoch: 63 Train loss: 0.14148 Validation loss: 0.13951\n",
            "Epoch: 64 Train loss: 0.13977 Validation loss: 0.13784\n",
            "Epoch: 65 Train loss: 0.1381 Validation loss: 0.1362\n",
            "Epoch: 66 Train loss: 0.13646 Validation loss: 0.13459\n",
            "Epoch: 67 Train loss: 0.13484 Validation loss: 0.13301\n",
            "Epoch: 68 Train loss: 0.13326 Validation loss: 0.13146\n",
            "Epoch: 69 Train loss: 0.1317 Validation loss: 0.12993\n",
            "Epoch: 70 Train loss: 0.13017 Validation loss: 0.12843\n",
            "Epoch: 71 Train loss: 0.12865 Validation loss: 0.12695\n",
            "Epoch: 72 Train loss: 0.12716 Validation loss: 0.1255\n",
            "Epoch: 73 Train loss: 0.12569 Validation loss: 0.12407\n",
            "Epoch: 74 Train loss: 0.12424 Validation loss: 0.12266\n",
            "Epoch: 75 Train loss: 0.1228 Validation loss: 0.12127\n",
            "Epoch: 76 Train loss: 0.12138 Validation loss: 0.1199\n",
            "Epoch: 77 Train loss: 0.11997 Validation loss: 0.11854\n",
            "Epoch: 78 Train loss: 0.11857 Validation loss: 0.11721\n",
            "Epoch: 79 Train loss: 0.11719 Validation loss: 0.1159\n",
            "Epoch: 80 Train loss: 0.11582 Validation loss: 0.1146\n",
            "Epoch: 81 Train loss: 0.11446 Validation loss: 0.11332\n",
            "Epoch: 82 Train loss: 0.11311 Validation loss: 0.11205\n",
            "Epoch: 83 Train loss: 0.11177 Validation loss: 0.11081\n",
            "Epoch: 84 Train loss: 0.11044 Validation loss: 0.10957\n",
            "Epoch: 85 Train loss: 0.10912 Validation loss: 0.10836\n",
            "Epoch: 86 Train loss: 0.1078 Validation loss: 0.10716\n",
            "Epoch: 87 Train loss: 0.10649 Validation loss: 0.10597\n",
            "Epoch: 88 Train loss: 0.10518 Validation loss: 0.1048\n",
            "Epoch: 89 Train loss: 0.10387 Validation loss: 0.10364\n",
            "Epoch: 90 Train loss: 0.10257 Validation loss: 0.1025\n",
            "Epoch: 91 Train loss: 0.10127 Validation loss: 0.10137\n",
            "Epoch: 92 Train loss: 0.099961 Validation loss: 0.10025\n",
            "Epoch: 93 Train loss: 0.098654 Validation loss: 0.099154\n",
            "Epoch: 94 Train loss: 0.097343 Validation loss: 0.098068\n",
            "Epoch: 95 Train loss: 0.096026 Validation loss: 0.096997\n",
            "Epoch: 96 Train loss: 0.094701 Validation loss: 0.09594\n",
            "Epoch: 97 Train loss: 0.093366 Validation loss: 0.0949\n",
            "Epoch: 98 Train loss: 0.092018 Validation loss: 0.093876\n",
            "Epoch: 99 Train loss: 0.090655 Validation loss: 0.092871\n",
            "Epoch: 100 Train loss: 0.089274 Validation loss: 0.091886\n",
            "Epoch: 101 Train loss: 0.087872 Validation loss: 0.090924\n",
            "Epoch: 102 Train loss: 0.086446 Validation loss: 0.089989\n",
            "Epoch: 103 Train loss: 0.084994 Validation loss: 0.089085\n",
            "Epoch: 104 Train loss: 0.083513 Validation loss: 0.088217\n",
            "Epoch: 105 Train loss: 0.082002 Validation loss: 0.087394\n",
            "Epoch: 106 Train loss: 0.080457 Validation loss: 0.086623\n",
            "Epoch: 107 Train loss: 0.078882 Validation loss: 0.085916\n",
            "Epoch: 108 Train loss: 0.077276 Validation loss: 0.085282\n",
            "Epoch: 109 Train loss: 0.075645 Validation loss: 0.084735\n",
            "Epoch: 110 Train loss: 0.073997 Validation loss: 0.084284\n",
            "Epoch: 111 Train loss: 0.072342 Validation loss: 0.08394\n",
            "Epoch: 112 Train loss: 0.070695 Validation loss: 0.083704\n",
            "Epoch: 113 Train loss: 0.069073 Validation loss: 0.083576\n",
            "Epoch: 114 Train loss: 0.067495 Validation loss: 0.083543\n",
            "Epoch: 115 Train loss: 0.065977 Validation loss: 0.083589\n",
            "Epoch: 116 Train loss: 0.064536 Validation loss: 0.08369\n",
            "Epoch: 117 Train loss: 0.063182 Validation loss: 0.083823\n",
            "Epoch: 118 Train loss: 0.061921 Validation loss: 0.083964\n",
            "Epoch: 119 Train loss: 0.060755 Validation loss: 0.084097\n",
            "Epoch: 120 Train loss: 0.059681 Validation loss: 0.084209\n",
            "Epoch: 121 Train loss: 0.058694 Validation loss: 0.084294\n",
            "Epoch: 122 Train loss: 0.057785 Validation loss: 0.084347\n",
            "Epoch: 123 Train loss: 0.056948 Validation loss: 0.084368\n",
            "Epoch: 124 Train loss: 0.056174 Validation loss: 0.084357\n",
            "Epoch: 125 Train loss: 0.055456 Validation loss: 0.084316\n",
            "Epoch: 126 Train loss: 0.054786 Validation loss: 0.084248\n",
            "Epoch: 127 Train loss: 0.05416 Validation loss: 0.084153\n",
            "Epoch: 128 Train loss: 0.053572 Validation loss: 0.084034\n",
            "Epoch: 129 Train loss: 0.053016 Validation loss: 0.083894\n",
            "Epoch: 130 Train loss: 0.052489 Validation loss: 0.083734\n",
            "Epoch: 131 Train loss: 0.051988 Validation loss: 0.083557\n",
            "Epoch: 132 Train loss: 0.05151 Validation loss: 0.083364\n",
            "Epoch: 133 Train loss: 0.051051 Validation loss: 0.083158\n",
            "Epoch: 134 Train loss: 0.050611 Validation loss: 0.08294\n",
            "Epoch: 135 Train loss: 0.050186 Validation loss: 0.082712\n",
            "Epoch: 136 Train loss: 0.049777 Validation loss: 0.082475\n",
            "Epoch: 137 Train loss: 0.04938 Validation loss: 0.082231\n",
            "Epoch: 138 Train loss: 0.048996 Validation loss: 0.081982\n",
            "Epoch: 139 Train loss: 0.048623 Validation loss: 0.081728\n",
            "Epoch: 140 Train loss: 0.048261 Validation loss: 0.08147\n",
            "Epoch: 141 Train loss: 0.047908 Validation loss: 0.08121\n",
            "Epoch: 142 Train loss: 0.047565 Validation loss: 0.080948\n",
            "Epoch: 143 Train loss: 0.047229 Validation loss: 0.080686\n",
            "Epoch: 144 Train loss: 0.046902 Validation loss: 0.080423\n",
            "Epoch: 145 Train loss: 0.046583 Validation loss: 0.080161\n",
            "Epoch: 146 Train loss: 0.04627 Validation loss: 0.0799\n",
            "Epoch: 147 Train loss: 0.045965 Validation loss: 0.07964\n",
            "Epoch: 148 Train loss: 0.045666 Validation loss: 0.079382\n",
            "Epoch: 149 Train loss: 0.045374 Validation loss: 0.079127\n",
            "Epoch: 150 Train loss: 0.045087 Validation loss: 0.078875\n",
            "Epoch: 151 Train loss: 0.044806 Validation loss: 0.078625\n",
            "Epoch: 152 Train loss: 0.044531 Validation loss: 0.078378\n",
            "Epoch: 153 Train loss: 0.044261 Validation loss: 0.078135\n",
            "Epoch: 154 Train loss: 0.043997 Validation loss: 0.077896\n",
            "Epoch: 155 Train loss: 0.043737 Validation loss: 0.07766\n",
            "Epoch: 156 Train loss: 0.043482 Validation loss: 0.077427\n",
            "Epoch: 157 Train loss: 0.043232 Validation loss: 0.077199\n",
            "Epoch: 158 Train loss: 0.042987 Validation loss: 0.076974\n",
            "Epoch: 159 Train loss: 0.042746 Validation loss: 0.076754\n",
            "Epoch: 160 Train loss: 0.042509 Validation loss: 0.076537\n",
            "Epoch: 161 Train loss: 0.042277 Validation loss: 0.076324\n",
            "Epoch: 162 Train loss: 0.042049 Validation loss: 0.076115\n",
            "Epoch: 163 Train loss: 0.041824 Validation loss: 0.07591\n",
            "Epoch: 164 Train loss: 0.041604 Validation loss: 0.075709\n",
            "Epoch: 165 Train loss: 0.041387 Validation loss: 0.075512\n",
            "Epoch: 166 Train loss: 0.041174 Validation loss: 0.075318\n",
            "Epoch: 167 Train loss: 0.040965 Validation loss: 0.075129\n",
            "Epoch: 168 Train loss: 0.040759 Validation loss: 0.074942\n",
            "Epoch: 169 Train loss: 0.040556 Validation loss: 0.07476\n",
            "Epoch: 170 Train loss: 0.040357 Validation loss: 0.074581\n",
            "Epoch: 171 Train loss: 0.040161 Validation loss: 0.074406\n",
            "Epoch: 172 Train loss: 0.039968 Validation loss: 0.074234\n",
            "Epoch: 173 Train loss: 0.039778 Validation loss: 0.074065\n",
            "Epoch: 174 Train loss: 0.039591 Validation loss: 0.0739\n",
            "Epoch: 175 Train loss: 0.039408 Validation loss: 0.073737\n",
            "Epoch: 176 Train loss: 0.039227 Validation loss: 0.073578\n",
            "Epoch: 177 Train loss: 0.039048 Validation loss: 0.073422\n",
            "Epoch: 178 Train loss: 0.038873 Validation loss: 0.073269\n",
            "Epoch: 179 Train loss: 0.0387 Validation loss: 0.073119\n",
            "Epoch: 180 Train loss: 0.03853 Validation loss: 0.072971\n",
            "Epoch: 181 Train loss: 0.038363 Validation loss: 0.072827\n",
            "Epoch: 182 Train loss: 0.038198 Validation loss: 0.072685\n",
            "Epoch: 183 Train loss: 0.038035 Validation loss: 0.072545\n",
            "Epoch: 184 Train loss: 0.037875 Validation loss: 0.072408\n",
            "Epoch: 185 Train loss: 0.037717 Validation loss: 0.072274\n",
            "Epoch: 186 Train loss: 0.037561 Validation loss: 0.072142\n",
            "Epoch: 187 Train loss: 0.037408 Validation loss: 0.072012\n",
            "Epoch: 188 Train loss: 0.037257 Validation loss: 0.071884\n",
            "Epoch: 189 Train loss: 0.037108 Validation loss: 0.071759\n",
            "Epoch: 190 Train loss: 0.036961 Validation loss: 0.071636\n",
            "Epoch: 191 Train loss: 0.036816 Validation loss: 0.071515\n",
            "Epoch: 192 Train loss: 0.036673 Validation loss: 0.071395\n",
            "Epoch: 193 Train loss: 0.036532 Validation loss: 0.071278\n",
            "Epoch: 194 Train loss: 0.036393 Validation loss: 0.071163\n",
            "Epoch: 195 Train loss: 0.036256 Validation loss: 0.071049\n",
            "Epoch: 196 Train loss: 0.036121 Validation loss: 0.070938\n",
            "Epoch: 197 Train loss: 0.035987 Validation loss: 0.070828\n",
            "Epoch: 198 Train loss: 0.035856 Validation loss: 0.07072\n",
            "Epoch: 199 Train loss: 0.035726 Validation loss: 0.070613\n",
            "Epoch: 200 Train loss: 0.035598 Validation loss: 0.070508\n",
            "Epoch: 201 Train loss: 0.035471 Validation loss: 0.070405\n",
            "Epoch: 202 Train loss: 0.035346 Validation loss: 0.070303\n",
            "Epoch: 203 Train loss: 0.035223 Validation loss: 0.070202\n",
            "Epoch: 204 Train loss: 0.035101 Validation loss: 0.070103\n",
            "Epoch: 205 Train loss: 0.034981 Validation loss: 0.070006\n",
            "Epoch: 206 Train loss: 0.034863 Validation loss: 0.069909\n",
            "Epoch: 207 Train loss: 0.034746 Validation loss: 0.069815\n",
            "Epoch: 208 Train loss: 0.03463 Validation loss: 0.069721\n",
            "Epoch: 209 Train loss: 0.034516 Validation loss: 0.069628\n",
            "Epoch: 210 Train loss: 0.034403 Validation loss: 0.069537\n",
            "Epoch: 211 Train loss: 0.034292 Validation loss: 0.069447\n",
            "Epoch: 212 Train loss: 0.034182 Validation loss: 0.069358\n",
            "Epoch: 213 Train loss: 0.034073 Validation loss: 0.06927\n",
            "Epoch: 214 Train loss: 0.033966 Validation loss: 0.069184\n",
            "Epoch: 215 Train loss: 0.033859 Validation loss: 0.069098\n",
            "Epoch: 216 Train loss: 0.033755 Validation loss: 0.069014\n",
            "Epoch: 217 Train loss: 0.033651 Validation loss: 0.06893\n",
            "Epoch: 218 Train loss: 0.033549 Validation loss: 0.068848\n",
            "Epoch: 219 Train loss: 0.033447 Validation loss: 0.068766\n",
            "Epoch: 220 Train loss: 0.033347 Validation loss: 0.068685\n",
            "Epoch: 221 Train loss: 0.033248 Validation loss: 0.068606\n",
            "Epoch: 222 Train loss: 0.033151 Validation loss: 0.068527\n",
            "Epoch: 223 Train loss: 0.033054 Validation loss: 0.068449\n",
            "Epoch: 224 Train loss: 0.032959 Validation loss: 0.068372\n",
            "Epoch: 225 Train loss: 0.032864 Validation loss: 0.068295\n",
            "Epoch: 226 Train loss: 0.032771 Validation loss: 0.06822\n",
            "Epoch: 227 Train loss: 0.032678 Validation loss: 0.068145\n",
            "Epoch: 228 Train loss: 0.032587 Validation loss: 0.068072\n",
            "Epoch: 229 Train loss: 0.032497 Validation loss: 0.067998\n",
            "Epoch: 230 Train loss: 0.032407 Validation loss: 0.067926\n",
            "Epoch: 231 Train loss: 0.032319 Validation loss: 0.067854\n",
            "Epoch: 232 Train loss: 0.032231 Validation loss: 0.067783\n",
            "Epoch: 233 Train loss: 0.032145 Validation loss: 0.067713\n",
            "Epoch: 234 Train loss: 0.032059 Validation loss: 0.067644\n",
            "Epoch: 235 Train loss: 0.031975 Validation loss: 0.067575\n",
            "Epoch: 236 Train loss: 0.031891 Validation loss: 0.067506\n",
            "Epoch: 237 Train loss: 0.031808 Validation loss: 0.067439\n",
            "Epoch: 238 Train loss: 0.031726 Validation loss: 0.067372\n",
            "Epoch: 239 Train loss: 0.031644 Validation loss: 0.067305\n",
            "Epoch: 240 Train loss: 0.031564 Validation loss: 0.06724\n",
            "Epoch: 241 Train loss: 0.031485 Validation loss: 0.067174\n",
            "Epoch: 242 Train loss: 0.031406 Validation loss: 0.06711\n",
            "Epoch: 243 Train loss: 0.031328 Validation loss: 0.067046\n",
            "Epoch: 244 Train loss: 0.03125 Validation loss: 0.066982\n",
            "Epoch: 245 Train loss: 0.031174 Validation loss: 0.066919\n",
            "Epoch: 246 Train loss: 0.031098 Validation loss: 0.066857\n",
            "Epoch: 247 Train loss: 0.031023 Validation loss: 0.066795\n",
            "Epoch: 248 Train loss: 0.030949 Validation loss: 0.066734\n",
            "Epoch: 249 Train loss: 0.030875 Validation loss: 0.066673\n",
            "Epoch: 250 Train loss: 0.030803 Validation loss: 0.066612\n",
            "Epoch: 251 Train loss: 0.03073 Validation loss: 0.066552\n",
            "Epoch: 252 Train loss: 0.030659 Validation loss: 0.066493\n",
            "Epoch: 253 Train loss: 0.030588 Validation loss: 0.066434\n",
            "Epoch: 254 Train loss: 0.030518 Validation loss: 0.066376\n",
            "Epoch: 255 Train loss: 0.030449 Validation loss: 0.066317\n",
            "Epoch: 256 Train loss: 0.03038 Validation loss: 0.06626\n",
            "Epoch: 257 Train loss: 0.030311 Validation loss: 0.066203\n",
            "Epoch: 258 Train loss: 0.030244 Validation loss: 0.066146\n",
            "Epoch: 259 Train loss: 0.030177 Validation loss: 0.06609\n",
            "Epoch: 260 Train loss: 0.03011 Validation loss: 0.066034\n",
            "Epoch: 261 Train loss: 0.030045 Validation loss: 0.065978\n",
            "Epoch: 262 Train loss: 0.029979 Validation loss: 0.065923\n",
            "Epoch: 263 Train loss: 0.029915 Validation loss: 0.065868\n",
            "Epoch: 264 Train loss: 0.02985 Validation loss: 0.065814\n",
            "Epoch: 265 Train loss: 0.029787 Validation loss: 0.06576\n",
            "Epoch: 266 Train loss: 0.029724 Validation loss: 0.065707\n",
            "Epoch: 267 Train loss: 0.029661 Validation loss: 0.065653\n",
            "Epoch: 268 Train loss: 0.029599 Validation loss: 0.065601\n",
            "Epoch: 269 Train loss: 0.029538 Validation loss: 0.065548\n",
            "Epoch: 270 Train loss: 0.029477 Validation loss: 0.065496\n",
            "Epoch: 271 Train loss: 0.029417 Validation loss: 0.065444\n",
            "Epoch: 272 Train loss: 0.029357 Validation loss: 0.065393\n",
            "Epoch: 273 Train loss: 0.029297 Validation loss: 0.065342\n",
            "Epoch: 274 Train loss: 0.029238 Validation loss: 0.065291\n",
            "Epoch: 275 Train loss: 0.02918 Validation loss: 0.06524\n",
            "Epoch: 276 Train loss: 0.029122 Validation loss: 0.06519\n",
            "Epoch: 277 Train loss: 0.029064 Validation loss: 0.06514\n",
            "Epoch: 278 Train loss: 0.029007 Validation loss: 0.065091\n",
            "Epoch: 279 Train loss: 0.02895 Validation loss: 0.065041\n",
            "Epoch: 280 Train loss: 0.028894 Validation loss: 0.064993\n",
            "Epoch: 281 Train loss: 0.028838 Validation loss: 0.064944\n",
            "Epoch: 282 Train loss: 0.028783 Validation loss: 0.064896\n",
            "Epoch: 283 Train loss: 0.028728 Validation loss: 0.064847\n",
            "Epoch: 284 Train loss: 0.028673 Validation loss: 0.0648\n",
            "Epoch: 285 Train loss: 0.028619 Validation loss: 0.064752\n",
            "Epoch: 286 Train loss: 0.028565 Validation loss: 0.064705\n",
            "Epoch: 287 Train loss: 0.028512 Validation loss: 0.064658\n",
            "Epoch: 288 Train loss: 0.028459 Validation loss: 0.064611\n",
            "Epoch: 289 Train loss: 0.028407 Validation loss: 0.064565\n",
            "Epoch: 290 Train loss: 0.028354 Validation loss: 0.064518\n",
            "Epoch: 291 Train loss: 0.028303 Validation loss: 0.064472\n",
            "Epoch: 292 Train loss: 0.028251 Validation loss: 0.064427\n",
            "Epoch: 293 Train loss: 0.0282 Validation loss: 0.064381\n",
            "Epoch: 294 Train loss: 0.028149 Validation loss: 0.064336\n",
            "Epoch: 295 Train loss: 0.028099 Validation loss: 0.064291\n",
            "Epoch: 296 Train loss: 0.028049 Validation loss: 0.064246\n",
            "Epoch: 297 Train loss: 0.027999 Validation loss: 0.064202\n",
            "Epoch: 298 Train loss: 0.02795 Validation loss: 0.064157\n",
            "Epoch: 299 Train loss: 0.027901 Validation loss: 0.064113\n",
            "Epoch: 300 Train loss: 0.027852 Validation loss: 0.06407\n",
            "Epoch: 301 Train loss: 0.027804 Validation loss: 0.064026\n",
            "Epoch: 302 Train loss: 0.027756 Validation loss: 0.063982\n",
            "Epoch: 303 Train loss: 0.027708 Validation loss: 0.063939\n",
            "Epoch: 304 Train loss: 0.027661 Validation loss: 0.063896\n",
            "Epoch: 305 Train loss: 0.027614 Validation loss: 0.063854\n",
            "Epoch: 306 Train loss: 0.027567 Validation loss: 0.063811\n",
            "Epoch: 307 Train loss: 0.02752 Validation loss: 0.063769\n",
            "Epoch: 308 Train loss: 0.027474 Validation loss: 0.063726\n",
            "Epoch: 309 Train loss: 0.027428 Validation loss: 0.063684\n",
            "Epoch: 310 Train loss: 0.027383 Validation loss: 0.063642\n",
            "Epoch: 311 Train loss: 0.027337 Validation loss: 0.063601\n",
            "Epoch: 312 Train loss: 0.027292 Validation loss: 0.063559\n",
            "Epoch: 313 Train loss: 0.027247 Validation loss: 0.063518\n",
            "Epoch: 314 Train loss: 0.027203 Validation loss: 0.063477\n",
            "Epoch: 315 Train loss: 0.027159 Validation loss: 0.063436\n",
            "Epoch: 316 Train loss: 0.027115 Validation loss: 0.063395\n",
            "Epoch: 317 Train loss: 0.027071 Validation loss: 0.063355\n",
            "Epoch: 318 Train loss: 0.027028 Validation loss: 0.063315\n",
            "Epoch: 319 Train loss: 0.026984 Validation loss: 0.063275\n",
            "Epoch: 320 Train loss: 0.026941 Validation loss: 0.063234\n",
            "Epoch: 321 Train loss: 0.026899 Validation loss: 0.063195\n",
            "Epoch: 322 Train loss: 0.026856 Validation loss: 0.063155\n",
            "Epoch: 323 Train loss: 0.026814 Validation loss: 0.063116\n",
            "Epoch: 324 Train loss: 0.026772 Validation loss: 0.063076\n",
            "Epoch: 325 Train loss: 0.02673 Validation loss: 0.063037\n",
            "Epoch: 326 Train loss: 0.026689 Validation loss: 0.062998\n",
            "Epoch: 327 Train loss: 0.026648 Validation loss: 0.062959\n",
            "Epoch: 328 Train loss: 0.026607 Validation loss: 0.06292\n",
            "Epoch: 329 Train loss: 0.026566 Validation loss: 0.062882\n",
            "Epoch: 330 Train loss: 0.026525 Validation loss: 0.062843\n",
            "Epoch: 331 Train loss: 0.026485 Validation loss: 0.062805\n",
            "Epoch: 332 Train loss: 0.026445 Validation loss: 0.062767\n",
            "Epoch: 333 Train loss: 0.026405 Validation loss: 0.062729\n",
            "Epoch: 334 Train loss: 0.026365 Validation loss: 0.062691\n",
            "Epoch: 335 Train loss: 0.026325 Validation loss: 0.062654\n",
            "Epoch: 336 Train loss: 0.026286 Validation loss: 0.062616\n",
            "Epoch: 337 Train loss: 0.026247 Validation loss: 0.062578\n",
            "Epoch: 338 Train loss: 0.026208 Validation loss: 0.062541\n",
            "Epoch: 339 Train loss: 0.026169 Validation loss: 0.062504\n",
            "Epoch: 340 Train loss: 0.026131 Validation loss: 0.062467\n",
            "Epoch: 341 Train loss: 0.026093 Validation loss: 0.06243\n",
            "Epoch: 342 Train loss: 0.026054 Validation loss: 0.062393\n",
            "Epoch: 343 Train loss: 0.026016 Validation loss: 0.062357\n",
            "Epoch: 344 Train loss: 0.025979 Validation loss: 0.06232\n",
            "Epoch: 345 Train loss: 0.025941 Validation loss: 0.062284\n",
            "Epoch: 346 Train loss: 0.025904 Validation loss: 0.062247\n",
            "Epoch: 347 Train loss: 0.025867 Validation loss: 0.062212\n",
            "Epoch: 348 Train loss: 0.02583 Validation loss: 0.062175\n",
            "Epoch: 349 Train loss: 0.025793 Validation loss: 0.06214\n",
            "Epoch: 350 Train loss: 0.025756 Validation loss: 0.062104\n",
            "Epoch: 351 Train loss: 0.02572 Validation loss: 0.062068\n",
            "Epoch: 352 Train loss: 0.025683 Validation loss: 0.062032\n",
            "Epoch: 353 Train loss: 0.025647 Validation loss: 0.061997\n",
            "Epoch: 354 Train loss: 0.025611 Validation loss: 0.061962\n",
            "Epoch: 355 Train loss: 0.025575 Validation loss: 0.061926\n",
            "Epoch: 356 Train loss: 0.02554 Validation loss: 0.061891\n",
            "Epoch: 357 Train loss: 0.025504 Validation loss: 0.061856\n",
            "Epoch: 358 Train loss: 0.025469 Validation loss: 0.061822\n",
            "Epoch: 359 Train loss: 0.025434 Validation loss: 0.061787\n",
            "Epoch: 360 Train loss: 0.025399 Validation loss: 0.061752\n",
            "Epoch: 361 Train loss: 0.025364 Validation loss: 0.061718\n",
            "Epoch: 362 Train loss: 0.025329 Validation loss: 0.061683\n",
            "Epoch: 363 Train loss: 0.025294 Validation loss: 0.061649\n",
            "Epoch: 364 Train loss: 0.02526 Validation loss: 0.061614\n",
            "Epoch: 365 Train loss: 0.025226 Validation loss: 0.061581\n",
            "Epoch: 366 Train loss: 0.025192 Validation loss: 0.061546\n",
            "Epoch: 367 Train loss: 0.025158 Validation loss: 0.061513\n",
            "Epoch: 368 Train loss: 0.025124 Validation loss: 0.061478\n",
            "Epoch: 369 Train loss: 0.02509 Validation loss: 0.061445\n",
            "Epoch: 370 Train loss: 0.025057 Validation loss: 0.061411\n",
            "Epoch: 371 Train loss: 0.025023 Validation loss: 0.061378\n",
            "Epoch: 372 Train loss: 0.02499 Validation loss: 0.061344\n",
            "Epoch: 373 Train loss: 0.024957 Validation loss: 0.061311\n",
            "Epoch: 374 Train loss: 0.024924 Validation loss: 0.061277\n",
            "Epoch: 375 Train loss: 0.024891 Validation loss: 0.061245\n",
            "Epoch: 376 Train loss: 0.024858 Validation loss: 0.061211\n",
            "Epoch: 377 Train loss: 0.024826 Validation loss: 0.061179\n",
            "Epoch: 378 Train loss: 0.024793 Validation loss: 0.061145\n",
            "Epoch: 379 Train loss: 0.024761 Validation loss: 0.061113\n",
            "Epoch: 380 Train loss: 0.024729 Validation loss: 0.061079\n",
            "Epoch: 381 Train loss: 0.024696 Validation loss: 0.061048\n",
            "Epoch: 382 Train loss: 0.024664 Validation loss: 0.061014\n",
            "Epoch: 383 Train loss: 0.024633 Validation loss: 0.060983\n",
            "Epoch: 384 Train loss: 0.024601 Validation loss: 0.060949\n",
            "Epoch: 385 Train loss: 0.024569 Validation loss: 0.060918\n",
            "Epoch: 386 Train loss: 0.024538 Validation loss: 0.060884\n",
            "Epoch: 387 Train loss: 0.024506 Validation loss: 0.060854\n",
            "Epoch: 388 Train loss: 0.024475 Validation loss: 0.06082\n",
            "Epoch: 389 Train loss: 0.024444 Validation loss: 0.060791\n",
            "Epoch: 390 Train loss: 0.024413 Validation loss: 0.060756\n",
            "Epoch: 391 Train loss: 0.024382 Validation loss: 0.060727\n",
            "Epoch: 392 Train loss: 0.024351 Validation loss: 0.060692\n",
            "Epoch: 393 Train loss: 0.024321 Validation loss: 0.060664\n",
            "Epoch: 394 Train loss: 0.02429 Validation loss: 0.060628\n",
            "Epoch: 395 Train loss: 0.024259 Validation loss: 0.060602\n",
            "Epoch: 396 Train loss: 0.024229 Validation loss: 0.060565\n",
            "Epoch: 397 Train loss: 0.024199 Validation loss: 0.06054\n",
            "Epoch: 398 Train loss: 0.024169 Validation loss: 0.060501\n",
            "Epoch: 399 Train loss: 0.024139 Validation loss: 0.060478\n",
            "Epoch: 400 Train loss: 0.024109 Validation loss: 0.060438\n",
            "Epoch: 401 Train loss: 0.024079 Validation loss: 0.060417\n",
            "Epoch: 402 Train loss: 0.024049 Validation loss: 0.060375\n",
            "Epoch: 403 Train loss: 0.024019 Validation loss: 0.060356\n",
            "Epoch: 404 Train loss: 0.02399 Validation loss: 0.060312\n",
            "Epoch: 405 Train loss: 0.02396 Validation loss: 0.060296\n",
            "Epoch: 406 Train loss: 0.023931 Validation loss: 0.060249\n",
            "Epoch: 407 Train loss: 0.023902 Validation loss: 0.060237\n",
            "Epoch: 408 Train loss: 0.023873 Validation loss: 0.060185\n",
            "Epoch: 409 Train loss: 0.023844 Validation loss: 0.060179\n",
            "Epoch: 410 Train loss: 0.023815 Validation loss: 0.060121\n",
            "Epoch: 411 Train loss: 0.023786 Validation loss: 0.060122\n",
            "Epoch: 412 Train loss: 0.023757 Validation loss: 0.060056\n",
            "Epoch: 413 Train loss: 0.023728 Validation loss: 0.060067\n",
            "Epoch: 414 Train loss: 0.0237 Validation loss: 0.05999\n",
            "Epoch: 415 Train loss: 0.023671 Validation loss: 0.060013\n",
            "Epoch: 416 Train loss: 0.023643 Validation loss: 0.059922\n",
            "Epoch: 417 Train loss: 0.023614 Validation loss: 0.059962\n",
            "Epoch: 418 Train loss: 0.023586 Validation loss: 0.059852\n",
            "Epoch: 419 Train loss: 0.023558 Validation loss: 0.059915\n",
            "Epoch: 420 Train loss: 0.02353 Validation loss: 0.059778\n",
            "Epoch: 421 Train loss: 0.023502 Validation loss: 0.059873\n",
            "Epoch: 422 Train loss: 0.023474 Validation loss: 0.059698\n",
            "Epoch: 423 Train loss: 0.023446 Validation loss: 0.059839\n",
            "Epoch: 424 Train loss: 0.023419 Validation loss: 0.059611\n",
            "Epoch: 425 Train loss: 0.023391 Validation loss: 0.059814\n",
            "Epoch: 426 Train loss: 0.023364 Validation loss: 0.059512\n",
            "Epoch: 427 Train loss: 0.023336 Validation loss: 0.059803\n",
            "Epoch: 428 Train loss: 0.023309 Validation loss: 0.059398\n",
            "Epoch: 429 Train loss: 0.023282 Validation loss: 0.059813\n",
            "Epoch: 430 Train loss: 0.023256 Validation loss: 0.05926\n",
            "Epoch: 431 Train loss: 0.02323 Validation loss: 0.059854\n",
            "Epoch: 432 Train loss: 0.023204 Validation loss: 0.059087\n",
            "Epoch: 433 Train loss: 0.023179 Validation loss: 0.059941\n",
            "Epoch: 434 Train loss: 0.023154 Validation loss: 0.058865\n",
            "Epoch: 435 Train loss: 0.023131 Validation loss: 0.060097\n",
            "Epoch: 436 Train loss: 0.02311 Validation loss: 0.05857\n",
            "Epoch: 437 Train loss: 0.023092 Validation loss: 0.060358\n",
            "Epoch: 438 Train loss: 0.023076 Validation loss: 0.05817\n",
            "Epoch: 439 Train loss: 0.023068 Validation loss: 0.060782\n",
            "Epoch: 440 Train loss: 0.023066 Validation loss: 0.057621\n",
            "Epoch: 441 Train loss: 0.023079 Validation loss: 0.061466\n",
            "Epoch: 442 Train loss: 0.023104 Validation loss: 0.056869\n",
            "Epoch: 443 Train loss: 0.023167 Validation loss: 0.062568\n",
            "Epoch: 444 Train loss: 0.023251 Validation loss: 0.055862\n",
            "Epoch: 445 Train loss: 0.023429 Validation loss: 0.064352\n",
            "Epoch: 446 Train loss: 0.023635 Validation loss: 0.054594\n",
            "Epoch: 447 Train loss: 0.02408 Validation loss: 0.06724\n",
            "Epoch: 448 Train loss: 0.024516 Validation loss: 0.053227\n",
            "Epoch: 449 Train loss: 0.025571 Validation loss: 0.071789\n",
            "Epoch: 450 Train loss: 0.026354 Validation loss: 0.052296\n",
            "Epoch: 451 Train loss: 0.028688 Validation loss: 0.078269\n",
            "Epoch: 452 Train loss: 0.029635 Validation loss: 0.052687\n",
            "Epoch: 453 Train loss: 0.034114 Validation loss: 0.085292\n",
            "Epoch: 454 Train loss: 0.03392 Validation loss: 0.054379\n",
            "Epoch: 455 Train loss: 0.040398 Validation loss: 0.08891\n",
            "Epoch: 456 Train loss: 0.03677 Validation loss: 0.054995\n",
            "Epoch: 457 Train loss: 0.042794 Validation loss: 0.086759\n",
            "Epoch: 458 Train loss: 0.036161 Validation loss: 0.053425\n",
            "Epoch: 459 Train loss: 0.039679 Validation loss: 0.081587\n",
            "Epoch: 460 Train loss: 0.033433 Validation loss: 0.051706\n",
            "Epoch: 461 Train loss: 0.03503 Validation loss: 0.07669\n",
            "Epoch: 462 Train loss: 0.030686 Validation loss: 0.050886\n",
            "Epoch: 463 Train loss: 0.031442 Validation loss: 0.07312\n",
            "Epoch: 464 Train loss: 0.028666 Validation loss: 0.050727\n",
            "Epoch: 465 Train loss: 0.029116 Validation loss: 0.070752\n",
            "Epoch: 466 Train loss: 0.027317 Validation loss: 0.050865\n",
            "Epoch: 467 Train loss: 0.027664 Validation loss: 0.069253\n",
            "Epoch: 468 Train loss: 0.026438 Validation loss: 0.05109\n",
            "Epoch: 469 Train loss: 0.026759 Validation loss: 0.068354\n",
            "Epoch: 470 Train loss: 0.025873 Validation loss: 0.051305\n",
            "Epoch: 471 Train loss: 0.026201 Validation loss: 0.067872\n",
            "Epoch: 472 Train loss: 0.025521 Validation loss: 0.051472\n",
            "Epoch: 473 Train loss: 0.025872 Validation loss: 0.067684\n",
            "Epoch: 474 Train loss: 0.025317 Validation loss: 0.05158\n",
            "Epoch: 475 Train loss: 0.025704 Validation loss: 0.06771\n",
            "Epoch: 476 Train loss: 0.025222 Validation loss: 0.051632\n",
            "Epoch: 477 Train loss: 0.025653 Validation loss: 0.06789\n",
            "Epoch: 478 Train loss: 0.02521 Validation loss: 0.051636\n",
            "Epoch: 479 Train loss: 0.02569 Validation loss: 0.068176\n",
            "Epoch: 480 Train loss: 0.02526 Validation loss: 0.051606\n",
            "Epoch: 481 Train loss: 0.025795 Validation loss: 0.068528\n",
            "Epoch: 482 Train loss: 0.025354 Validation loss: 0.051551\n",
            "Epoch: 483 Train loss: 0.025944 Validation loss: 0.068904\n",
            "Epoch: 484 Train loss: 0.025474 Validation loss: 0.051485\n",
            "Epoch: 485 Train loss: 0.026116 Validation loss: 0.069264\n",
            "Epoch: 486 Train loss: 0.025602 Validation loss: 0.051415\n",
            "Epoch: 487 Train loss: 0.026287 Validation loss: 0.069571\n",
            "Epoch: 488 Train loss: 0.025718 Validation loss: 0.051348\n",
            "Epoch: 489 Train loss: 0.026433 Validation loss: 0.069793\n",
            "Epoch: 490 Train loss: 0.025805 Validation loss: 0.051288\n",
            "Epoch: 491 Train loss: 0.026533 Validation loss: 0.069911\n",
            "Epoch: 492 Train loss: 0.025849 Validation loss: 0.051237\n",
            "Epoch: 493 Train loss: 0.026572 Validation loss: 0.069917\n",
            "Epoch: 494 Train loss: 0.025844 Validation loss: 0.051196\n",
            "Epoch: 495 Train loss: 0.026547 Validation loss: 0.069818\n",
            "Epoch: 496 Train loss: 0.02579 Validation loss: 0.051167\n",
            "Epoch: 497 Train loss: 0.026461 Validation loss: 0.069631\n",
            "Epoch: 498 Train loss: 0.025692 Validation loss: 0.051149\n",
            "Epoch: 499 Train loss: 0.026325 Validation loss: 0.06938\n",
            "Epoch: 500 Train loss: 0.025562 Validation loss: 0.051143\n",
            "Epoch: 501 Train loss: 0.026153 Validation loss: 0.069089\n",
            "Epoch: 502 Train loss: 0.02541 Validation loss: 0.051148\n",
            "Epoch: 503 Train loss: 0.025961 Validation loss: 0.068782\n",
            "Epoch: 504 Train loss: 0.025247 Validation loss: 0.051161\n",
            "Epoch: 505 Train loss: 0.025762 Validation loss: 0.068477\n",
            "Epoch: 506 Train loss: 0.025083 Validation loss: 0.05118\n",
            "Epoch: 507 Train loss: 0.025566 Validation loss: 0.068188\n",
            "Epoch: 508 Train loss: 0.024923 Validation loss: 0.051203\n",
            "Epoch: 509 Train loss: 0.025381 Validation loss: 0.067923\n",
            "Epoch: 510 Train loss: 0.024774 Validation loss: 0.051226\n",
            "Epoch: 511 Train loss: 0.025211 Validation loss: 0.067689\n",
            "Epoch: 512 Train loss: 0.024638 Validation loss: 0.051247\n",
            "Epoch: 513 Train loss: 0.025059 Validation loss: 0.067485\n",
            "Epoch: 514 Train loss: 0.024515 Validation loss: 0.051264\n",
            "Epoch: 515 Train loss: 0.024924 Validation loss: 0.067312\n",
            "Epoch: 516 Train loss: 0.024407 Validation loss: 0.051277\n",
            "Epoch: 517 Train loss: 0.024806 Validation loss: 0.067168\n",
            "Epoch: 518 Train loss: 0.024311 Validation loss: 0.051284\n",
            "Epoch: 519 Train loss: 0.024704 Validation loss: 0.067049\n",
            "Epoch: 520 Train loss: 0.024227 Validation loss: 0.051286\n",
            "Epoch: 521 Train loss: 0.024617 Validation loss: 0.066951\n",
            "Epoch: 522 Train loss: 0.024154 Validation loss: 0.051282\n",
            "Epoch: 523 Train loss: 0.024541 Validation loss: 0.066871\n",
            "Epoch: 524 Train loss: 0.024089 Validation loss: 0.051273\n",
            "Epoch: 525 Train loss: 0.024475 Validation loss: 0.066804\n",
            "Epoch: 526 Train loss: 0.024031 Validation loss: 0.05126\n",
            "Epoch: 527 Train loss: 0.024416 Validation loss: 0.066747\n",
            "Epoch: 528 Train loss: 0.023979 Validation loss: 0.051244\n",
            "Epoch: 529 Train loss: 0.024364 Validation loss: 0.066697\n",
            "Epoch: 530 Train loss: 0.023931 Validation loss: 0.051225\n",
            "Epoch: 531 Train loss: 0.024315 Validation loss: 0.066649\n",
            "Epoch: 532 Train loss: 0.023884 Validation loss: 0.051204\n",
            "Epoch: 533 Train loss: 0.024268 Validation loss: 0.066601\n",
            "Epoch: 534 Train loss: 0.023839 Validation loss: 0.051182\n",
            "Epoch: 535 Train loss: 0.024221 Validation loss: 0.066552\n",
            "Epoch: 536 Train loss: 0.023794 Validation loss: 0.051159\n",
            "Epoch: 537 Train loss: 0.024175 Validation loss: 0.066499\n",
            "Epoch: 538 Train loss: 0.023749 Validation loss: 0.051137\n",
            "Epoch: 539 Train loss: 0.024127 Validation loss: 0.066443\n",
            "Epoch: 540 Train loss: 0.023702 Validation loss: 0.051115\n",
            "Epoch: 541 Train loss: 0.024077 Validation loss: 0.066381\n",
            "Epoch: 542 Train loss: 0.023653 Validation loss: 0.051094\n",
            "Epoch: 543 Train loss: 0.024025 Validation loss: 0.066315\n",
            "Epoch: 544 Train loss: 0.023603 Validation loss: 0.051074\n",
            "Epoch: 545 Train loss: 0.023971 Validation loss: 0.066244\n",
            "Epoch: 546 Train loss: 0.023551 Validation loss: 0.051054\n",
            "Epoch: 547 Train loss: 0.023914 Validation loss: 0.066169\n",
            "Epoch: 548 Train loss: 0.023497 Validation loss: 0.051036\n",
            "Epoch: 549 Train loss: 0.023856 Validation loss: 0.06609\n",
            "Epoch: 550 Train loss: 0.023442 Validation loss: 0.051019\n",
            "Epoch: 551 Train loss: 0.023797 Validation loss: 0.06601\n",
            "Epoch: 552 Train loss: 0.023386 Validation loss: 0.051002\n",
            "Epoch: 553 Train loss: 0.023736 Validation loss: 0.065928\n",
            "Epoch: 554 Train loss: 0.023329 Validation loss: 0.050986\n",
            "Epoch: 555 Train loss: 0.023675 Validation loss: 0.065846\n",
            "Epoch: 556 Train loss: 0.023273 Validation loss: 0.050971\n",
            "Epoch: 557 Train loss: 0.023613 Validation loss: 0.065763\n",
            "Epoch: 558 Train loss: 0.023216 Validation loss: 0.050955\n",
            "Epoch: 559 Train loss: 0.023552 Validation loss: 0.065682\n",
            "Epoch: 560 Train loss: 0.023159 Validation loss: 0.05094\n",
            "Epoch: 561 Train loss: 0.023492 Validation loss: 0.065603\n",
            "Epoch: 562 Train loss: 0.023104 Validation loss: 0.050925\n",
            "Epoch: 563 Train loss: 0.023432 Validation loss: 0.065525\n",
            "Epoch: 564 Train loss: 0.023049 Validation loss: 0.050909\n",
            "Epoch: 565 Train loss: 0.023374 Validation loss: 0.06545\n",
            "Epoch: 566 Train loss: 0.022995 Validation loss: 0.050893\n",
            "Epoch: 567 Train loss: 0.023317 Validation loss: 0.065378\n",
            "Epoch: 568 Train loss: 0.022942 Validation loss: 0.050877\n",
            "Epoch: 569 Train loss: 0.023262 Validation loss: 0.065308\n",
            "Epoch: 570 Train loss: 0.022891 Validation loss: 0.05086\n",
            "Epoch: 571 Train loss: 0.023208 Validation loss: 0.065242\n",
            "Epoch: 572 Train loss: 0.022841 Validation loss: 0.050842\n",
            "Epoch: 573 Train loss: 0.023156 Validation loss: 0.065177\n",
            "Epoch: 574 Train loss: 0.022792 Validation loss: 0.050824\n",
            "Epoch: 575 Train loss: 0.023105 Validation loss: 0.065115\n",
            "Epoch: 576 Train loss: 0.022744 Validation loss: 0.050805\n",
            "Epoch: 577 Train loss: 0.023055 Validation loss: 0.065055\n",
            "Epoch: 578 Train loss: 0.022697 Validation loss: 0.050786\n",
            "Epoch: 579 Train loss: 0.023006 Validation loss: 0.064997\n",
            "Epoch: 580 Train loss: 0.022652 Validation loss: 0.050766\n",
            "Epoch: 581 Train loss: 0.022959 Validation loss: 0.06494\n",
            "Epoch: 582 Train loss: 0.022607 Validation loss: 0.050746\n",
            "Epoch: 583 Train loss: 0.022912 Validation loss: 0.064885\n",
            "Epoch: 584 Train loss: 0.022562 Validation loss: 0.050726\n",
            "Epoch: 585 Train loss: 0.022866 Validation loss: 0.06483\n",
            "Epoch: 586 Train loss: 0.022518 Validation loss: 0.050705\n",
            "Epoch: 587 Train loss: 0.022821 Validation loss: 0.064777\n",
            "Epoch: 588 Train loss: 0.022475 Validation loss: 0.050684\n",
            "Epoch: 589 Train loss: 0.022776 Validation loss: 0.064724\n",
            "Epoch: 590 Train loss: 0.022432 Validation loss: 0.050663\n",
            "Epoch: 591 Train loss: 0.022732 Validation loss: 0.064671\n",
            "Epoch: 592 Train loss: 0.02239 Validation loss: 0.050642\n",
            "Epoch: 593 Train loss: 0.022688 Validation loss: 0.064619\n",
            "Epoch: 594 Train loss: 0.022347 Validation loss: 0.050621\n",
            "Epoch: 595 Train loss: 0.022644 Validation loss: 0.064567\n",
            "Epoch: 596 Train loss: 0.022305 Validation loss: 0.0506\n",
            "Epoch: 597 Train loss: 0.022601 Validation loss: 0.064515\n",
            "Epoch: 598 Train loss: 0.022263 Validation loss: 0.050579\n",
            "Epoch: 599 Train loss: 0.022557 Validation loss: 0.064463\n",
            "Epoch: 600 Train loss: 0.022221 Validation loss: 0.050558\n",
            "Epoch: 601 Train loss: 0.022514 Validation loss: 0.064411\n",
            "Epoch: 602 Train loss: 0.02218 Validation loss: 0.050538\n",
            "Epoch: 603 Train loss: 0.022471 Validation loss: 0.064359\n",
            "Epoch: 604 Train loss: 0.022138 Validation loss: 0.050517\n",
            "Epoch: 605 Train loss: 0.022428 Validation loss: 0.064308\n",
            "Epoch: 606 Train loss: 0.022096 Validation loss: 0.050496\n",
            "Epoch: 607 Train loss: 0.022385 Validation loss: 0.064256\n",
            "Epoch: 608 Train loss: 0.022055 Validation loss: 0.050476\n",
            "Epoch: 609 Train loss: 0.022342 Validation loss: 0.064204\n",
            "Epoch: 610 Train loss: 0.022014 Validation loss: 0.050455\n",
            "Epoch: 611 Train loss: 0.022299 Validation loss: 0.064153\n",
            "Epoch: 612 Train loss: 0.021972 Validation loss: 0.050435\n",
            "Epoch: 613 Train loss: 0.022256 Validation loss: 0.064103\n",
            "Epoch: 614 Train loss: 0.021931 Validation loss: 0.050415\n",
            "Epoch: 615 Train loss: 0.022214 Validation loss: 0.064052\n",
            "Epoch: 616 Train loss: 0.021891 Validation loss: 0.050395\n",
            "Epoch: 617 Train loss: 0.022172 Validation loss: 0.064002\n",
            "Epoch: 618 Train loss: 0.02185 Validation loss: 0.050374\n",
            "Epoch: 619 Train loss: 0.02213 Validation loss: 0.063953\n",
            "Epoch: 620 Train loss: 0.02181 Validation loss: 0.050354\n",
            "Epoch: 621 Train loss: 0.022088 Validation loss: 0.063903\n",
            "Epoch: 622 Train loss: 0.02177 Validation loss: 0.050334\n",
            "Epoch: 623 Train loss: 0.022047 Validation loss: 0.063855\n",
            "Epoch: 624 Train loss: 0.02173 Validation loss: 0.050314\n",
            "Epoch: 625 Train loss: 0.022006 Validation loss: 0.063806\n",
            "Epoch: 626 Train loss: 0.02169 Validation loss: 0.050294\n",
            "Epoch: 627 Train loss: 0.021965 Validation loss: 0.063759\n",
            "Epoch: 628 Train loss: 0.021651 Validation loss: 0.050274\n",
            "Epoch: 629 Train loss: 0.021925 Validation loss: 0.063712\n",
            "Epoch: 630 Train loss: 0.021612 Validation loss: 0.050254\n",
            "Epoch: 631 Train loss: 0.021885 Validation loss: 0.063665\n",
            "Epoch: 632 Train loss: 0.021573 Validation loss: 0.050234\n",
            "Epoch: 633 Train loss: 0.021845 Validation loss: 0.063619\n",
            "Epoch: 634 Train loss: 0.021534 Validation loss: 0.050214\n",
            "Epoch: 635 Train loss: 0.021805 Validation loss: 0.063573\n",
            "Epoch: 636 Train loss: 0.021496 Validation loss: 0.050194\n",
            "Epoch: 637 Train loss: 0.021766 Validation loss: 0.063528\n",
            "Epoch: 638 Train loss: 0.021458 Validation loss: 0.050174\n",
            "Epoch: 639 Train loss: 0.021727 Validation loss: 0.063483\n",
            "Epoch: 640 Train loss: 0.02142 Validation loss: 0.050154\n",
            "Epoch: 641 Train loss: 0.021689 Validation loss: 0.063439\n",
            "Epoch: 642 Train loss: 0.021383 Validation loss: 0.050134\n",
            "Epoch: 643 Train loss: 0.02165 Validation loss: 0.063395\n",
            "Epoch: 644 Train loss: 0.021346 Validation loss: 0.050114\n",
            "Epoch: 645 Train loss: 0.021612 Validation loss: 0.063352\n",
            "Epoch: 646 Train loss: 0.021308 Validation loss: 0.050094\n",
            "Epoch: 647 Train loss: 0.021574 Validation loss: 0.063309\n",
            "Epoch: 648 Train loss: 0.021272 Validation loss: 0.050074\n",
            "Epoch: 649 Train loss: 0.021536 Validation loss: 0.063266\n",
            "Epoch: 650 Train loss: 0.021235 Validation loss: 0.050055\n",
            "Epoch: 651 Train loss: 0.021499 Validation loss: 0.063223\n",
            "Epoch: 652 Train loss: 0.021198 Validation loss: 0.050035\n",
            "Epoch: 653 Train loss: 0.021461 Validation loss: 0.063181\n",
            "Epoch: 654 Train loss: 0.021162 Validation loss: 0.050015\n",
            "Epoch: 655 Train loss: 0.021424 Validation loss: 0.063139\n",
            "Epoch: 656 Train loss: 0.021125 Validation loss: 0.049996\n",
            "Epoch: 657 Train loss: 0.021387 Validation loss: 0.063097\n",
            "Epoch: 658 Train loss: 0.021089 Validation loss: 0.049976\n",
            "Epoch: 659 Train loss: 0.02135 Validation loss: 0.063055\n",
            "Epoch: 660 Train loss: 0.021053 Validation loss: 0.049957\n",
            "Epoch: 661 Train loss: 0.021313 Validation loss: 0.063014\n",
            "Epoch: 662 Train loss: 0.021017 Validation loss: 0.049938\n",
            "Epoch: 663 Train loss: 0.021277 Validation loss: 0.062973\n",
            "Epoch: 664 Train loss: 0.020982 Validation loss: 0.049918\n",
            "Epoch: 665 Train loss: 0.02124 Validation loss: 0.062932\n",
            "Epoch: 666 Train loss: 0.020946 Validation loss: 0.049899\n",
            "Epoch: 667 Train loss: 0.021204 Validation loss: 0.062891\n",
            "Epoch: 668 Train loss: 0.020911 Validation loss: 0.04988\n",
            "Epoch: 669 Train loss: 0.021168 Validation loss: 0.062851\n",
            "Epoch: 670 Train loss: 0.020875 Validation loss: 0.049861\n",
            "Epoch: 671 Train loss: 0.021132 Validation loss: 0.062811\n",
            "Epoch: 672 Train loss: 0.02084 Validation loss: 0.049842\n",
            "Epoch: 673 Train loss: 0.021096 Validation loss: 0.062771\n",
            "Epoch: 674 Train loss: 0.020805 Validation loss: 0.049824\n",
            "Epoch: 675 Train loss: 0.02106 Validation loss: 0.062731\n",
            "Epoch: 676 Train loss: 0.02077 Validation loss: 0.049805\n",
            "Epoch: 677 Train loss: 0.021024 Validation loss: 0.062691\n",
            "Epoch: 678 Train loss: 0.020735 Validation loss: 0.049787\n",
            "Epoch: 679 Train loss: 0.020989 Validation loss: 0.062652\n",
            "Epoch: 680 Train loss: 0.020701 Validation loss: 0.049768\n",
            "Epoch: 681 Train loss: 0.020953 Validation loss: 0.062613\n",
            "Epoch: 682 Train loss: 0.020666 Validation loss: 0.04975\n",
            "Epoch: 683 Train loss: 0.020918 Validation loss: 0.062574\n",
            "Epoch: 684 Train loss: 0.020632 Validation loss: 0.049732\n",
            "Epoch: 685 Train loss: 0.020883 Validation loss: 0.062536\n",
            "Epoch: 686 Train loss: 0.020598 Validation loss: 0.049714\n",
            "Epoch: 687 Train loss: 0.020848 Validation loss: 0.062497\n",
            "Epoch: 688 Train loss: 0.020563 Validation loss: 0.049696\n",
            "Epoch: 689 Train loss: 0.020813 Validation loss: 0.062459\n",
            "Epoch: 690 Train loss: 0.020529 Validation loss: 0.049678\n",
            "Epoch: 691 Train loss: 0.020779 Validation loss: 0.062421\n",
            "Epoch: 692 Train loss: 0.020496 Validation loss: 0.04966\n",
            "Epoch: 693 Train loss: 0.020744 Validation loss: 0.062384\n",
            "Epoch: 694 Train loss: 0.020462 Validation loss: 0.049642\n",
            "Epoch: 695 Train loss: 0.02071 Validation loss: 0.062347\n",
            "Epoch: 696 Train loss: 0.020429 Validation loss: 0.049624\n",
            "Epoch: 697 Train loss: 0.020676 Validation loss: 0.06231\n",
            "Epoch: 698 Train loss: 0.020395 Validation loss: 0.049607\n",
            "Epoch: 699 Train loss: 0.020642 Validation loss: 0.062273\n",
            "Epoch: 700 Train loss: 0.020362 Validation loss: 0.049589\n",
            "Epoch: 701 Train loss: 0.020608 Validation loss: 0.062237\n",
            "Epoch: 702 Train loss: 0.020329 Validation loss: 0.049572\n",
            "Epoch: 703 Train loss: 0.020574 Validation loss: 0.0622\n",
            "Epoch: 704 Train loss: 0.020296 Validation loss: 0.049554\n",
            "Epoch: 705 Train loss: 0.020541 Validation loss: 0.062164\n",
            "Epoch: 706 Train loss: 0.020263 Validation loss: 0.049537\n",
            "Epoch: 707 Train loss: 0.020507 Validation loss: 0.062129\n",
            "Epoch: 708 Train loss: 0.02023 Validation loss: 0.04952\n",
            "Epoch: 709 Train loss: 0.020474 Validation loss: 0.062093\n",
            "Epoch: 710 Train loss: 0.020197 Validation loss: 0.049503\n",
            "Epoch: 711 Train loss: 0.020441 Validation loss: 0.062057\n",
            "Epoch: 712 Train loss: 0.020165 Validation loss: 0.049486\n",
            "Epoch: 713 Train loss: 0.020408 Validation loss: 0.062022\n",
            "Epoch: 714 Train loss: 0.020132 Validation loss: 0.04947\n",
            "Epoch: 715 Train loss: 0.020375 Validation loss: 0.061987\n",
            "Epoch: 716 Train loss: 0.0201 Validation loss: 0.049453\n",
            "Epoch: 717 Train loss: 0.020342 Validation loss: 0.061952\n",
            "Epoch: 718 Train loss: 0.020068 Validation loss: 0.049436\n",
            "Epoch: 719 Train loss: 0.020309 Validation loss: 0.061917\n",
            "Epoch: 720 Train loss: 0.020036 Validation loss: 0.04942\n",
            "Epoch: 721 Train loss: 0.020276 Validation loss: 0.061883\n",
            "Epoch: 722 Train loss: 0.020004 Validation loss: 0.049404\n",
            "Epoch: 723 Train loss: 0.020244 Validation loss: 0.061848\n",
            "Epoch: 724 Train loss: 0.019972 Validation loss: 0.049387\n",
            "Epoch: 725 Train loss: 0.020211 Validation loss: 0.061814\n",
            "Epoch: 726 Train loss: 0.01994 Validation loss: 0.049371\n",
            "Epoch: 727 Train loss: 0.020179 Validation loss: 0.06178\n",
            "Epoch: 728 Train loss: 0.019908 Validation loss: 0.049355\n",
            "Epoch: 729 Train loss: 0.020146 Validation loss: 0.061746\n",
            "Epoch: 730 Train loss: 0.019876 Validation loss: 0.049339\n",
            "Epoch: 731 Train loss: 0.020114 Validation loss: 0.061712\n",
            "Epoch: 732 Train loss: 0.019845 Validation loss: 0.049324\n",
            "Epoch: 733 Train loss: 0.020082 Validation loss: 0.061679\n",
            "Epoch: 734 Train loss: 0.019813 Validation loss: 0.049308\n",
            "Epoch: 735 Train loss: 0.02005 Validation loss: 0.061646\n",
            "Epoch: 736 Train loss: 0.019782 Validation loss: 0.049293\n",
            "Epoch: 737 Train loss: 0.020018 Validation loss: 0.061613\n",
            "Epoch: 738 Train loss: 0.019751 Validation loss: 0.049277\n",
            "Epoch: 739 Train loss: 0.019987 Validation loss: 0.06158\n",
            "Epoch: 740 Train loss: 0.01972 Validation loss: 0.049262\n",
            "Epoch: 741 Train loss: 0.019955 Validation loss: 0.061547\n",
            "Epoch: 742 Train loss: 0.019689 Validation loss: 0.049247\n",
            "Epoch: 743 Train loss: 0.019923 Validation loss: 0.061514\n",
            "Epoch: 744 Train loss: 0.019658 Validation loss: 0.049231\n",
            "Epoch: 745 Train loss: 0.019892 Validation loss: 0.061482\n",
            "Epoch: 746 Train loss: 0.019627 Validation loss: 0.049216\n",
            "Epoch: 747 Train loss: 0.019861 Validation loss: 0.06145\n",
            "Epoch: 748 Train loss: 0.019596 Validation loss: 0.049201\n",
            "Epoch: 749 Train loss: 0.01983 Validation loss: 0.061418\n",
            "Epoch: 750 Train loss: 0.019566 Validation loss: 0.049187\n",
            "Epoch: 751 Train loss: 0.019799 Validation loss: 0.061386\n",
            "Epoch: 752 Train loss: 0.019535 Validation loss: 0.049172\n",
            "Epoch: 753 Train loss: 0.019768 Validation loss: 0.061355\n",
            "Epoch: 754 Train loss: 0.019505 Validation loss: 0.049157\n",
            "Epoch: 755 Train loss: 0.019737 Validation loss: 0.061323\n",
            "Epoch: 756 Train loss: 0.019475 Validation loss: 0.049143\n",
            "Epoch: 757 Train loss: 0.019706 Validation loss: 0.061292\n",
            "Epoch: 758 Train loss: 0.019444 Validation loss: 0.049129\n",
            "Epoch: 759 Train loss: 0.019675 Validation loss: 0.06126\n",
            "Epoch: 760 Train loss: 0.019414 Validation loss: 0.049115\n",
            "Epoch: 761 Train loss: 0.019644 Validation loss: 0.061229\n",
            "Epoch: 762 Train loss: 0.019384 Validation loss: 0.0491\n",
            "Epoch: 763 Train loss: 0.019614 Validation loss: 0.061198\n",
            "Epoch: 764 Train loss: 0.019354 Validation loss: 0.049086\n",
            "Epoch: 765 Train loss: 0.019583 Validation loss: 0.061167\n",
            "Epoch: 766 Train loss: 0.019324 Validation loss: 0.049073\n",
            "Epoch: 767 Train loss: 0.019553 Validation loss: 0.061137\n",
            "Epoch: 768 Train loss: 0.019294 Validation loss: 0.049059\n",
            "Epoch: 769 Train loss: 0.019523 Validation loss: 0.061106\n",
            "Epoch: 770 Train loss: 0.019264 Validation loss: 0.049045\n",
            "Epoch: 771 Train loss: 0.019492 Validation loss: 0.061076\n",
            "Epoch: 772 Train loss: 0.019235 Validation loss: 0.049032\n",
            "Epoch: 773 Train loss: 0.019462 Validation loss: 0.061046\n",
            "Epoch: 774 Train loss: 0.019205 Validation loss: 0.049018\n",
            "Epoch: 775 Train loss: 0.019432 Validation loss: 0.061016\n",
            "Epoch: 776 Train loss: 0.019176 Validation loss: 0.049005\n",
            "Epoch: 777 Train loss: 0.019402 Validation loss: 0.060986\n",
            "Epoch: 778 Train loss: 0.019146 Validation loss: 0.048992\n",
            "Epoch: 779 Train loss: 0.019372 Validation loss: 0.060956\n",
            "Epoch: 780 Train loss: 0.019117 Validation loss: 0.048979\n",
            "Epoch: 781 Train loss: 0.019343 Validation loss: 0.060927\n",
            "Epoch: 782 Train loss: 0.019088 Validation loss: 0.048966\n",
            "Epoch: 783 Train loss: 0.019313 Validation loss: 0.060897\n",
            "Epoch: 784 Train loss: 0.019059 Validation loss: 0.048953\n",
            "Epoch: 785 Train loss: 0.019283 Validation loss: 0.060868\n",
            "Epoch: 786 Train loss: 0.01903 Validation loss: 0.04894\n",
            "Epoch: 787 Train loss: 0.019254 Validation loss: 0.060839\n",
            "Epoch: 788 Train loss: 0.019001 Validation loss: 0.048927\n",
            "Epoch: 789 Train loss: 0.019225 Validation loss: 0.06081\n",
            "Epoch: 790 Train loss: 0.018972 Validation loss: 0.048915\n",
            "Epoch: 791 Train loss: 0.019195 Validation loss: 0.060781\n",
            "Epoch: 792 Train loss: 0.018943 Validation loss: 0.048902\n",
            "Epoch: 793 Train loss: 0.019166 Validation loss: 0.060753\n",
            "Epoch: 794 Train loss: 0.018914 Validation loss: 0.04889\n",
            "Epoch: 795 Train loss: 0.019136 Validation loss: 0.060724\n",
            "Epoch: 796 Train loss: 0.018886 Validation loss: 0.048878\n",
            "Epoch: 797 Train loss: 0.019107 Validation loss: 0.060696\n",
            "Epoch: 798 Train loss: 0.018857 Validation loss: 0.048866\n",
            "Epoch: 799 Train loss: 0.019078 Validation loss: 0.060667\n",
            "Epoch: 800 Train loss: 0.018829 Validation loss: 0.048854\n",
            "Epoch: 801 Train loss: 0.019049 Validation loss: 0.060639\n",
            "Epoch: 802 Train loss: 0.0188 Validation loss: 0.048842\n",
            "Epoch: 803 Train loss: 0.01902 Validation loss: 0.060611\n",
            "Epoch: 804 Train loss: 0.018772 Validation loss: 0.04883\n",
            "Epoch: 805 Train loss: 0.018992 Validation loss: 0.060583\n",
            "Epoch: 806 Train loss: 0.018743 Validation loss: 0.048818\n",
            "Epoch: 807 Train loss: 0.018963 Validation loss: 0.060556\n",
            "Epoch: 808 Train loss: 0.018715 Validation loss: 0.048807\n",
            "Epoch: 809 Train loss: 0.018934 Validation loss: 0.060528\n",
            "Epoch: 810 Train loss: 0.018687 Validation loss: 0.048795\n",
            "Epoch: 811 Train loss: 0.018906 Validation loss: 0.060501\n",
            "Epoch: 812 Train loss: 0.018659 Validation loss: 0.048784\n",
            "Epoch: 813 Train loss: 0.018877 Validation loss: 0.060473\n",
            "Epoch: 814 Train loss: 0.018631 Validation loss: 0.048772\n",
            "Epoch: 815 Train loss: 0.018849 Validation loss: 0.060446\n",
            "Epoch: 816 Train loss: 0.018603 Validation loss: 0.048761\n",
            "Epoch: 817 Train loss: 0.018821 Validation loss: 0.060419\n",
            "Epoch: 818 Train loss: 0.018576 Validation loss: 0.04875\n",
            "Epoch: 819 Train loss: 0.018792 Validation loss: 0.060392\n",
            "Epoch: 820 Train loss: 0.018548 Validation loss: 0.048739\n",
            "Epoch: 821 Train loss: 0.018764 Validation loss: 0.060365\n",
            "Epoch: 822 Train loss: 0.01852 Validation loss: 0.048728\n",
            "Epoch: 823 Train loss: 0.018736 Validation loss: 0.060339\n",
            "Epoch: 824 Train loss: 0.018493 Validation loss: 0.048717\n",
            "Epoch: 825 Train loss: 0.018708 Validation loss: 0.060312\n",
            "Epoch: 826 Train loss: 0.018465 Validation loss: 0.048706\n",
            "Epoch: 827 Train loss: 0.01868 Validation loss: 0.060286\n",
            "Epoch: 828 Train loss: 0.018438 Validation loss: 0.048696\n",
            "Epoch: 829 Train loss: 0.018653 Validation loss: 0.06026\n",
            "Epoch: 830 Train loss: 0.018411 Validation loss: 0.048685\n",
            "Epoch: 831 Train loss: 0.018625 Validation loss: 0.060234\n",
            "Epoch: 832 Train loss: 0.018383 Validation loss: 0.048675\n",
            "Epoch: 833 Train loss: 0.018597 Validation loss: 0.060208\n",
            "Epoch: 834 Train loss: 0.018356 Validation loss: 0.048665\n",
            "Epoch: 835 Train loss: 0.018569 Validation loss: 0.060182\n",
            "Epoch: 836 Train loss: 0.018329 Validation loss: 0.048654\n",
            "Epoch: 837 Train loss: 0.018542 Validation loss: 0.060157\n",
            "Epoch: 838 Train loss: 0.018302 Validation loss: 0.048644\n",
            "Epoch: 839 Train loss: 0.018514 Validation loss: 0.060131\n",
            "Epoch: 840 Train loss: 0.018275 Validation loss: 0.048634\n",
            "Epoch: 841 Train loss: 0.018487 Validation loss: 0.060106\n",
            "Epoch: 842 Train loss: 0.018248 Validation loss: 0.048624\n",
            "Epoch: 843 Train loss: 0.01846 Validation loss: 0.06008\n",
            "Epoch: 844 Train loss: 0.018222 Validation loss: 0.048614\n",
            "Epoch: 845 Train loss: 0.018432 Validation loss: 0.060055\n",
            "Epoch: 846 Train loss: 0.018195 Validation loss: 0.048605\n",
            "Epoch: 847 Train loss: 0.018405 Validation loss: 0.06003\n",
            "Epoch: 848 Train loss: 0.018168 Validation loss: 0.048595\n",
            "Epoch: 849 Train loss: 0.018378 Validation loss: 0.060005\n",
            "Epoch: 850 Train loss: 0.018142 Validation loss: 0.048585\n",
            "Epoch: 851 Train loss: 0.018351 Validation loss: 0.05998\n",
            "Epoch: 852 Train loss: 0.018115 Validation loss: 0.048576\n",
            "Epoch: 853 Train loss: 0.018324 Validation loss: 0.059955\n",
            "Epoch: 854 Train loss: 0.018089 Validation loss: 0.048566\n",
            "Epoch: 855 Train loss: 0.018297 Validation loss: 0.05993\n",
            "Epoch: 856 Train loss: 0.018062 Validation loss: 0.048557\n",
            "Epoch: 857 Train loss: 0.01827 Validation loss: 0.059905\n",
            "Epoch: 858 Train loss: 0.018036 Validation loss: 0.048548\n",
            "Epoch: 859 Train loss: 0.018244 Validation loss: 0.059881\n",
            "Epoch: 860 Train loss: 0.018009 Validation loss: 0.048538\n",
            "Epoch: 861 Train loss: 0.018217 Validation loss: 0.059856\n",
            "Epoch: 862 Train loss: 0.017983 Validation loss: 0.048529\n",
            "Epoch: 863 Train loss: 0.01819 Validation loss: 0.059832\n",
            "Epoch: 864 Train loss: 0.017957 Validation loss: 0.04852\n",
            "Epoch: 865 Train loss: 0.018164 Validation loss: 0.059808\n",
            "Epoch: 866 Train loss: 0.017931 Validation loss: 0.048511\n",
            "Epoch: 867 Train loss: 0.018137 Validation loss: 0.059784\n",
            "Epoch: 868 Train loss: 0.017905 Validation loss: 0.048502\n",
            "Epoch: 869 Train loss: 0.018111 Validation loss: 0.05976\n",
            "Epoch: 870 Train loss: 0.017879 Validation loss: 0.048494\n",
            "Epoch: 871 Train loss: 0.018085 Validation loss: 0.059737\n",
            "Epoch: 872 Train loss: 0.017854 Validation loss: 0.048485\n",
            "Epoch: 873 Train loss: 0.018058 Validation loss: 0.059713\n",
            "Epoch: 874 Train loss: 0.017828 Validation loss: 0.048476\n",
            "Epoch: 875 Train loss: 0.018032 Validation loss: 0.05969\n",
            "Epoch: 876 Train loss: 0.017802 Validation loss: 0.048468\n",
            "Epoch: 877 Train loss: 0.018006 Validation loss: 0.059666\n",
            "Epoch: 878 Train loss: 0.017777 Validation loss: 0.048459\n",
            "Epoch: 879 Train loss: 0.01798 Validation loss: 0.059643\n",
            "Epoch: 880 Train loss: 0.017751 Validation loss: 0.048451\n",
            "Epoch: 881 Train loss: 0.017954 Validation loss: 0.05962\n",
            "Epoch: 882 Train loss: 0.017726 Validation loss: 0.048442\n",
            "Epoch: 883 Train loss: 0.017929 Validation loss: 0.059597\n",
            "Epoch: 884 Train loss: 0.017701 Validation loss: 0.048434\n",
            "Epoch: 885 Train loss: 0.017903 Validation loss: 0.059574\n",
            "Epoch: 886 Train loss: 0.017676 Validation loss: 0.048425\n",
            "Epoch: 887 Train loss: 0.017877 Validation loss: 0.059552\n",
            "Epoch: 888 Train loss: 0.01765 Validation loss: 0.048417\n",
            "Epoch: 889 Train loss: 0.017852 Validation loss: 0.059529\n",
            "Epoch: 890 Train loss: 0.017625 Validation loss: 0.048409\n",
            "Epoch: 891 Train loss: 0.017826 Validation loss: 0.059506\n",
            "Epoch: 892 Train loss: 0.0176 Validation loss: 0.048401\n",
            "Epoch: 893 Train loss: 0.017801 Validation loss: 0.059484\n",
            "Epoch: 894 Train loss: 0.017575 Validation loss: 0.048393\n",
            "Epoch: 895 Train loss: 0.017776 Validation loss: 0.059462\n",
            "Epoch: 896 Train loss: 0.01755 Validation loss: 0.048385\n",
            "Epoch: 897 Train loss: 0.01775 Validation loss: 0.05944\n",
            "Epoch: 898 Train loss: 0.017526 Validation loss: 0.048377\n",
            "Epoch: 899 Train loss: 0.017725 Validation loss: 0.059417\n",
            "Epoch: 900 Train loss: 0.017501 Validation loss: 0.048369\n",
            "Epoch: 901 Train loss: 0.0177 Validation loss: 0.059395\n",
            "Epoch: 902 Train loss: 0.017476 Validation loss: 0.048361\n",
            "Epoch: 903 Train loss: 0.017675 Validation loss: 0.059373\n",
            "Epoch: 904 Train loss: 0.017452 Validation loss: 0.048354\n",
            "Epoch: 905 Train loss: 0.01765 Validation loss: 0.059352\n",
            "Epoch: 906 Train loss: 0.017427 Validation loss: 0.048346\n",
            "Epoch: 907 Train loss: 0.017625 Validation loss: 0.05933\n",
            "Epoch: 908 Train loss: 0.017403 Validation loss: 0.048338\n",
            "Epoch: 909 Train loss: 0.0176 Validation loss: 0.059308\n",
            "Epoch: 910 Train loss: 0.017378 Validation loss: 0.048331\n",
            "Epoch: 911 Train loss: 0.017575 Validation loss: 0.059287\n",
            "Epoch: 912 Train loss: 0.017354 Validation loss: 0.048323\n",
            "Epoch: 913 Train loss: 0.017551 Validation loss: 0.059265\n",
            "Epoch: 914 Train loss: 0.01733 Validation loss: 0.048316\n",
            "Epoch: 915 Train loss: 0.017526 Validation loss: 0.059244\n",
            "Epoch: 916 Train loss: 0.017305 Validation loss: 0.048308\n",
            "Epoch: 917 Train loss: 0.017501 Validation loss: 0.059223\n",
            "Epoch: 918 Train loss: 0.017281 Validation loss: 0.048301\n",
            "Epoch: 919 Train loss: 0.017477 Validation loss: 0.059202\n",
            "Epoch: 920 Train loss: 0.017257 Validation loss: 0.048294\n",
            "Epoch: 921 Train loss: 0.017452 Validation loss: 0.059181\n",
            "Epoch: 922 Train loss: 0.017233 Validation loss: 0.048286\n",
            "Epoch: 923 Train loss: 0.017428 Validation loss: 0.05916\n",
            "Epoch: 924 Train loss: 0.01721 Validation loss: 0.048279\n",
            "Epoch: 925 Train loss: 0.017404 Validation loss: 0.059139\n",
            "Epoch: 926 Train loss: 0.017186 Validation loss: 0.048272\n",
            "Epoch: 927 Train loss: 0.01738 Validation loss: 0.059119\n",
            "Epoch: 928 Train loss: 0.017162 Validation loss: 0.048265\n",
            "Epoch: 929 Train loss: 0.017356 Validation loss: 0.059098\n",
            "Epoch: 930 Train loss: 0.017138 Validation loss: 0.048257\n",
            "Epoch: 931 Train loss: 0.017332 Validation loss: 0.059078\n",
            "Epoch: 932 Train loss: 0.017115 Validation loss: 0.04825\n",
            "Epoch: 933 Train loss: 0.017308 Validation loss: 0.059057\n",
            "Epoch: 934 Train loss: 0.017091 Validation loss: 0.048243\n",
            "Epoch: 935 Train loss: 0.017284 Validation loss: 0.059037\n",
            "Epoch: 936 Train loss: 0.017068 Validation loss: 0.048236\n",
            "Epoch: 937 Train loss: 0.01726 Validation loss: 0.059016\n",
            "Epoch: 938 Train loss: 0.017044 Validation loss: 0.048229\n",
            "Epoch: 939 Train loss: 0.017236 Validation loss: 0.058996\n",
            "Epoch: 940 Train loss: 0.017021 Validation loss: 0.048222\n",
            "Epoch: 941 Train loss: 0.017213 Validation loss: 0.058976\n",
            "Epoch: 942 Train loss: 0.016998 Validation loss: 0.048215\n",
            "Epoch: 943 Train loss: 0.017189 Validation loss: 0.058956\n",
            "Epoch: 944 Train loss: 0.016975 Validation loss: 0.048208\n",
            "Epoch: 945 Train loss: 0.017166 Validation loss: 0.058937\n",
            "Epoch: 946 Train loss: 0.016952 Validation loss: 0.048202\n",
            "Epoch: 947 Train loss: 0.017142 Validation loss: 0.058917\n",
            "Epoch: 948 Train loss: 0.016929 Validation loss: 0.048195\n",
            "Epoch: 949 Train loss: 0.017119 Validation loss: 0.058897\n",
            "Epoch: 950 Train loss: 0.016906 Validation loss: 0.048188\n",
            "Epoch: 951 Train loss: 0.017096 Validation loss: 0.058878\n",
            "Epoch: 952 Train loss: 0.016883 Validation loss: 0.048181\n",
            "Epoch: 953 Train loss: 0.017072 Validation loss: 0.058858\n",
            "Epoch: 954 Train loss: 0.01686 Validation loss: 0.048174\n",
            "Epoch: 955 Train loss: 0.017049 Validation loss: 0.058839\n",
            "Epoch: 956 Train loss: 0.016838 Validation loss: 0.048167\n",
            "Epoch: 957 Train loss: 0.017026 Validation loss: 0.05882\n",
            "Epoch: 958 Train loss: 0.016815 Validation loss: 0.048161\n",
            "Epoch: 959 Train loss: 0.017004 Validation loss: 0.058801\n",
            "Epoch: 960 Train loss: 0.016793 Validation loss: 0.048154\n",
            "Epoch: 961 Train loss: 0.016981 Validation loss: 0.058782\n",
            "Epoch: 962 Train loss: 0.01677 Validation loss: 0.048147\n",
            "Epoch: 963 Train loss: 0.016958 Validation loss: 0.058763\n",
            "Epoch: 964 Train loss: 0.016748 Validation loss: 0.048141\n",
            "Epoch: 965 Train loss: 0.016935 Validation loss: 0.058745\n",
            "Epoch: 966 Train loss: 0.016725 Validation loss: 0.048134\n",
            "Epoch: 967 Train loss: 0.016913 Validation loss: 0.058726\n",
            "Epoch: 968 Train loss: 0.016703 Validation loss: 0.048127\n",
            "Epoch: 969 Train loss: 0.01689 Validation loss: 0.058707\n",
            "Epoch: 970 Train loss: 0.016681 Validation loss: 0.048121\n",
            "Epoch: 971 Train loss: 0.016868 Validation loss: 0.058689\n",
            "Epoch: 972 Train loss: 0.016659 Validation loss: 0.048114\n",
            "Epoch: 973 Train loss: 0.016845 Validation loss: 0.05867\n",
            "Epoch: 974 Train loss: 0.016637 Validation loss: 0.048107\n",
            "Epoch: 975 Train loss: 0.016823 Validation loss: 0.058652\n",
            "Epoch: 976 Train loss: 0.016615 Validation loss: 0.048101\n",
            "Epoch: 977 Train loss: 0.016801 Validation loss: 0.058634\n",
            "Epoch: 978 Train loss: 0.016593 Validation loss: 0.048094\n",
            "Epoch: 979 Train loss: 0.016779 Validation loss: 0.058615\n",
            "Epoch: 980 Train loss: 0.016571 Validation loss: 0.048087\n",
            "Epoch: 981 Train loss: 0.016757 Validation loss: 0.058597\n",
            "Epoch: 982 Train loss: 0.01655 Validation loss: 0.048081\n",
            "Epoch: 983 Train loss: 0.016734 Validation loss: 0.058579\n",
            "Epoch: 984 Train loss: 0.016528 Validation loss: 0.048074\n",
            "Epoch: 985 Train loss: 0.016712 Validation loss: 0.058561\n",
            "Epoch: 986 Train loss: 0.016506 Validation loss: 0.048068\n",
            "Epoch: 987 Train loss: 0.016691 Validation loss: 0.058543\n",
            "Epoch: 988 Train loss: 0.016485 Validation loss: 0.048061\n",
            "Epoch: 989 Train loss: 0.016669 Validation loss: 0.058525\n",
            "Epoch: 990 Train loss: 0.016463 Validation loss: 0.048055\n",
            "Epoch: 991 Train loss: 0.016647 Validation loss: 0.058508\n",
            "Epoch: 992 Train loss: 0.016442 Validation loss: 0.048048\n",
            "Epoch: 993 Train loss: 0.016625 Validation loss: 0.05849\n",
            "Epoch: 994 Train loss: 0.016421 Validation loss: 0.048042\n",
            "Epoch: 995 Train loss: 0.016604 Validation loss: 0.058472\n",
            "Epoch: 996 Train loss: 0.016399 Validation loss: 0.048035\n",
            "Epoch: 997 Train loss: 0.016582 Validation loss: 0.058455\n",
            "Epoch: 998 Train loss: 0.016378 Validation loss: 0.048028\n",
            "Epoch: 999 Train loss: 0.016561 Validation loss: 0.058437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gkaUDmA8Ps6w"
      },
      "source": [
        "Predicting with this model shows overfitting. For recognizing overfitting a comparison of the validation and training loss is very useful. If the training loss decreases during training while the validation loss consistently increases, the model you are training is probably overfitting. Plotting the models prediction and the target also shows that there is a significant discrepancy between the target and the prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Sq-9xhWPxI4",
        "outputId": "b782d350-6d2e-4437-81b1-f14a116e03d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_pred = big_mdl(x) # Predict on x with \"big_mdl\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Target\", \"Prediction\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZ36J2EN85b9"
      },
      "source": [
        "In order to implement a regularization we need to modify the loss function. Since the loss function in this exercise is computed during the training step, we define a new training step with a regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLbcWwlt9Jwl",
        "colab": {}
      },
      "source": [
        "\"\"\" In order to avoid overfitting we implement a training step that also includes a regularization on the weights of our big model. For this we use the Frobenius/squared l2-norm of each weight matrix/vector. \n",
        "Hint: Use the tf.reduce_sum() function on a list of individual regularization terms for each matrix/vector of the network.\"\"\"\n",
        "\n",
        "def regularized_train_step(model, optimizer, x, y, lmbd):\n",
        "    y = tf.reshape(y, [-1,1])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.square(y_pred - y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "        regul_val = lmbd * tf.reduce_sum(tf.square(model.trainable_variables[0])) + lmbd * tf.reduce_sum(tf.square(model.trainable_variables[2])) + lmbd * tf.reduce_sum(tf.math.square(model.trainable_variables[4])) # Compute the regularization based on the list \"model.trainable_variables\"\n",
        "        total_loss = loss_val + regul_val # Add the loss with a the regularization term weighted by \"lmbd\"\n",
        "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExK4FIw89s0M"
      },
      "source": [
        "We can now set the strength of the regularization and retrain the big model with a regularization. We create another instance of the big model in order to compare the big model with and without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PUUBGi496Vt",
        "outputId": "e9af9573-8e5d-478d-89d3-80b2d2e97c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model with the regularized_train_step function. Note: We are plotting the MSE loss without the regularization in order to compare it with the unregularized model. \"\"\"\n",
        "\n",
        "lmbd = 0.005\n",
        "\n",
        "big_reg_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += regularized_train_step(big_reg_mdl, big_opt, x_t, y_t, lmbd) # Perform a regularized training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\" with the regularization parameter being \"lmbd\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples_overfit//batch_size) == 0: # An epoch is completed\n",
        "        validation_loss = 0.0\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_reg_mdl(x_v) # Compute a prediction with \"big_reg_mdl\" on the input \"x_v\"\n",
        "            validation_loss += float(tf.square(y_pred - y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss/N_validation_samples))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        train_reg = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 2.8413 Validation loss: 1.4069\n",
            "Epoch: 1 Train loss: 1.2579 Validation loss: 1.2236\n",
            "Epoch: 2 Train loss: 1.1076 Validation loss: 1.3396\n",
            "Epoch: 3 Train loss: 1.2323 Validation loss: 2.7873\n",
            "Epoch: 4 Train loss: 2.9699 Validation loss: 5.4673\n",
            "Epoch: 5 Train loss: 5.5176 Validation loss: 6.75\n",
            "Epoch: 6 Train loss: 6.2063 Validation loss: 2.6387\n",
            "Epoch: 7 Train loss: 2.1657 Validation loss: 1.2169\n",
            "Epoch: 8 Train loss: 1.3374 Validation loss: 1.1603\n",
            "Epoch: 9 Train loss: 1.1113 Validation loss: 1.0226\n",
            "Epoch: 10 Train loss: 0.96105 Validation loss: 0.95757\n",
            "Epoch: 11 Train loss: 0.84054 Validation loss: 0.8648\n",
            "Epoch: 12 Train loss: 0.75893 Validation loss: 0.79588\n",
            "Epoch: 13 Train loss: 0.70419 Validation loss: 0.72411\n",
            "Epoch: 14 Train loss: 0.66052 Validation loss: 0.666\n",
            "Epoch: 15 Train loss: 0.62181 Validation loss: 0.60222\n",
            "Epoch: 16 Train loss: 0.58594 Validation loss: 0.55203\n",
            "Epoch: 17 Train loss: 0.55239 Validation loss: 0.49384\n",
            "Epoch: 18 Train loss: 0.52157 Validation loss: 0.45566\n",
            "Epoch: 19 Train loss: 0.49536 Validation loss: 0.41447\n",
            "Epoch: 20 Train loss: 0.48371 Validation loss: 0.43118\n",
            "Epoch: 21 Train loss: 0.51061 Validation loss: 0.54423\n",
            "Epoch: 22 Train loss: 0.68363 Validation loss: 0.84242\n",
            "Epoch: 23 Train loss: 0.98729 Validation loss: 1.4334\n",
            "Epoch: 24 Train loss: 1.6467 Validation loss: 0.90753\n",
            "Epoch: 25 Train loss: 0.83187 Validation loss: 0.67279\n",
            "Epoch: 26 Train loss: 0.81967 Validation loss: 0.47431\n",
            "Epoch: 27 Train loss: 0.37308 Validation loss: 0.26164\n",
            "Epoch: 28 Train loss: 0.29345 Validation loss: 0.30849\n",
            "Epoch: 29 Train loss: 0.23145 Validation loss: 0.21004\n",
            "Epoch: 30 Train loss: 0.20733 Validation loss: 0.24759\n",
            "Epoch: 31 Train loss: 0.18625 Validation loss: 0.18098\n",
            "Epoch: 32 Train loss: 0.17813 Validation loss: 0.22128\n",
            "Epoch: 33 Train loss: 0.16986 Validation loss: 0.16904\n",
            "Epoch: 34 Train loss: 0.17625 Validation loss: 0.22775\n",
            "Epoch: 35 Train loss: 0.18171 Validation loss: 0.19425\n",
            "Epoch: 36 Train loss: 0.22105 Validation loss: 0.29142\n",
            "Epoch: 37 Train loss: 0.24867 Validation loss: 0.30452\n",
            "Epoch: 38 Train loss: 0.36335 Validation loss: 0.41664\n",
            "Epoch: 39 Train loss: 0.36622 Validation loss: 0.44478\n",
            "Epoch: 40 Train loss: 0.52379 Validation loss: 0.44658\n",
            "Epoch: 41 Train loss: 0.36245 Validation loss: 0.34148\n",
            "Epoch: 42 Train loss: 0.41032 Validation loss: 0.3426\n",
            "Epoch: 43 Train loss: 0.25822 Validation loss: 0.20797\n",
            "Epoch: 44 Train loss: 0.25295 Validation loss: 0.2582\n",
            "Epoch: 45 Train loss: 0.1927 Validation loss: 0.1635\n",
            "Epoch: 46 Train loss: 0.19143 Validation loss: 0.22025\n",
            "Epoch: 47 Train loss: 0.16744 Validation loss: 0.1525\n",
            "Epoch: 48 Train loss: 0.17486 Validation loss: 0.21057\n",
            "Epoch: 49 Train loss: 0.16455 Validation loss: 0.15964\n",
            "Epoch: 50 Train loss: 0.18401 Validation loss: 0.22416\n",
            "Epoch: 51 Train loss: 0.18133 Validation loss: 0.18921\n",
            "Epoch: 52 Train loss: 0.22082 Validation loss: 0.26166\n",
            "Epoch: 53 Train loss: 0.2191 Validation loss: 0.24277\n",
            "Epoch: 54 Train loss: 0.28379 Validation loss: 0.30826\n",
            "Epoch: 55 Train loss: 0.26104 Validation loss: 0.28626\n",
            "Epoch: 56 Train loss: 0.3322 Validation loss: 0.32329\n",
            "Epoch: 57 Train loss: 0.26735 Validation loss: 0.26879\n",
            "Epoch: 58 Train loss: 0.31185 Validation loss: 0.29263\n",
            "Epoch: 59 Train loss: 0.2342 Validation loss: 0.21718\n",
            "Epoch: 60 Train loss: 0.25251 Validation loss: 0.24977\n",
            "Epoch: 61 Train loss: 0.1968 Validation loss: 0.18006\n",
            "Epoch: 62 Train loss: 0.20718 Validation loss: 0.21966\n",
            "Epoch: 63 Train loss: 0.17348 Validation loss: 0.16379\n",
            "Epoch: 64 Train loss: 0.18532 Validation loss: 0.20554\n",
            "Epoch: 65 Train loss: 0.16442 Validation loss: 0.1625\n",
            "Epoch: 66 Train loss: 0.18141 Validation loss: 0.20496\n",
            "Epoch: 67 Train loss: 0.16695 Validation loss: 0.17313\n",
            "Epoch: 68 Train loss: 0.19154 Validation loss: 0.2153\n",
            "Epoch: 69 Train loss: 0.17875 Validation loss: 0.193\n",
            "Epoch: 70 Train loss: 0.21189 Validation loss: 0.23161\n",
            "Epoch: 71 Train loss: 0.19488 Validation loss: 0.21441\n",
            "Epoch: 72 Train loss: 0.23337 Validation loss: 0.24438\n",
            "Epoch: 73 Train loss: 0.20599 Validation loss: 0.22437\n",
            "Epoch: 74 Train loss: 0.24195 Validation loss: 0.2441\n",
            "Epoch: 75 Train loss: 0.20389 Validation loss: 0.21611\n",
            "Epoch: 76 Train loss: 0.23078 Validation loss: 0.23033\n",
            "Epoch: 77 Train loss: 0.18995 Validation loss: 0.19714\n",
            "Epoch: 78 Train loss: 0.20796 Validation loss: 0.21112\n",
            "Epoch: 79 Train loss: 0.17245 Validation loss: 0.17904\n",
            "Epoch: 80 Train loss: 0.18568 Validation loss: 0.19419\n",
            "Epoch: 81 Train loss: 0.15802 Validation loss: 0.16741\n",
            "Epoch: 82 Train loss: 0.1701 Validation loss: 0.18287\n",
            "Epoch: 83 Train loss: 0.14902 Validation loss: 0.16288\n",
            "Epoch: 84 Train loss: 0.16207 Validation loss: 0.17739\n",
            "Epoch: 85 Train loss: 0.14538 Validation loss: 0.16434\n",
            "Epoch: 86 Train loss: 0.16047 Validation loss: 0.17673\n",
            "Epoch: 87 Train loss: 0.14606 Validation loss: 0.17009\n",
            "Epoch: 88 Train loss: 0.16345 Validation loss: 0.17909\n",
            "Epoch: 89 Train loss: 0.14935 Validation loss: 0.17765\n",
            "Epoch: 90 Train loss: 0.16841 Validation loss: 0.18195\n",
            "Epoch: 91 Train loss: 0.15283 Validation loss: 0.18371\n",
            "Epoch: 92 Train loss: 0.17192 Validation loss: 0.1825\n",
            "Epoch: 93 Train loss: 0.15382 Validation loss: 0.18515\n",
            "Epoch: 94 Train loss: 0.17093 Validation loss: 0.17883\n",
            "Epoch: 95 Train loss: 0.15066 Validation loss: 0.18093\n",
            "Epoch: 96 Train loss: 0.16443 Validation loss: 0.17104\n",
            "Epoch: 97 Train loss: 0.14365 Validation loss: 0.17264\n",
            "Epoch: 98 Train loss: 0.15402 Validation loss: 0.16095\n",
            "Epoch: 99 Train loss: 0.13465 Validation loss: 0.1632\n",
            "Epoch: 100 Train loss: 0.14252 Validation loss: 0.15079\n",
            "Epoch: 101 Train loss: 0.12571 Validation loss: 0.15496\n",
            "Epoch: 102 Train loss: 0.13222 Validation loss: 0.14206\n",
            "Epoch: 103 Train loss: 0.11821 Validation loss: 0.14908\n",
            "Epoch: 104 Train loss: 0.12424 Validation loss: 0.13539\n",
            "Epoch: 105 Train loss: 0.11269 Validation loss: 0.14576\n",
            "Epoch: 106 Train loss: 0.11879 Validation loss: 0.13078\n",
            "Epoch: 107 Train loss: 0.10913 Validation loss: 0.14473\n",
            "Epoch: 108 Train loss: 0.1156 Validation loss: 0.12791\n",
            "Epoch: 109 Train loss: 0.10724 Validation loss: 0.14546\n",
            "Epoch: 110 Train loss: 0.11416 Validation loss: 0.12629\n",
            "Epoch: 111 Train loss: 0.10657 Validation loss: 0.14728\n",
            "Epoch: 112 Train loss: 0.11383 Validation loss: 0.12536\n",
            "Epoch: 113 Train loss: 0.10653 Validation loss: 0.14942\n",
            "Epoch: 114 Train loss: 0.11389 Validation loss: 0.1245\n",
            "Epoch: 115 Train loss: 0.10651 Validation loss: 0.15108\n",
            "Epoch: 116 Train loss: 0.11362 Validation loss: 0.12318\n",
            "Epoch: 117 Train loss: 0.10593 Validation loss: 0.15162\n",
            "Epoch: 118 Train loss: 0.11242 Validation loss: 0.12103\n",
            "Epoch: 119 Train loss: 0.10444 Validation loss: 0.15071\n",
            "Epoch: 120 Train loss: 0.11005 Validation loss: 0.11797\n",
            "Epoch: 121 Train loss: 0.10194 Validation loss: 0.14846\n",
            "Epoch: 122 Train loss: 0.10658 Validation loss: 0.1142\n",
            "Epoch: 123 Train loss: 0.09863 Validation loss: 0.1453\n",
            "Epoch: 124 Train loss: 0.10239 Validation loss: 0.11008\n",
            "Epoch: 125 Train loss: 0.094891 Validation loss: 0.14176\n",
            "Epoch: 126 Train loss: 0.097958 Validation loss: 0.10599\n",
            "Epoch: 127 Train loss: 0.091112 Validation loss: 0.13837\n",
            "Epoch: 128 Train loss: 0.093711 Validation loss: 0.10223\n",
            "Epoch: 129 Train loss: 0.087608 Validation loss: 0.13545\n",
            "Epoch: 130 Train loss: 0.089936 Validation loss: 0.098954\n",
            "Epoch: 131 Train loss: 0.084573 Validation loss: 0.1332\n",
            "Epoch: 132 Train loss: 0.086779 Validation loss: 0.096232\n",
            "Epoch: 133 Train loss: 0.082091 Validation loss: 0.13167\n",
            "Epoch: 134 Train loss: 0.084275 Validation loss: 0.094046\n",
            "Epoch: 135 Train loss: 0.080167 Validation loss: 0.13082\n",
            "Epoch: 136 Train loss: 0.082384 Validation loss: 0.092335\n",
            "Epoch: 137 Train loss: 0.078749 Validation loss: 0.13056\n",
            "Epoch: 138 Train loss: 0.081019 Validation loss: 0.091007\n",
            "Epoch: 139 Train loss: 0.077752 Validation loss: 0.13073\n",
            "Epoch: 140 Train loss: 0.080067 Validation loss: 0.089966\n",
            "Epoch: 141 Train loss: 0.07707 Validation loss: 0.13121\n",
            "Epoch: 142 Train loss: 0.079401 Validation loss: 0.089106\n",
            "Epoch: 143 Train loss: 0.076587 Validation loss: 0.13181\n",
            "Epoch: 144 Train loss: 0.078889 Validation loss: 0.088331\n",
            "Epoch: 145 Train loss: 0.076188 Validation loss: 0.13238\n",
            "Epoch: 146 Train loss: 0.078406 Validation loss: 0.087552\n",
            "Epoch: 147 Train loss: 0.075765 Validation loss: 0.13278\n",
            "Epoch: 148 Train loss: 0.077843 Validation loss: 0.086703\n",
            "Epoch: 149 Train loss: 0.075231 Validation loss: 0.13291\n",
            "Epoch: 150 Train loss: 0.077123 Validation loss: 0.085742\n",
            "Epoch: 151 Train loss: 0.074532 Validation loss: 0.13272\n",
            "Epoch: 152 Train loss: 0.076206 Validation loss: 0.084659\n",
            "Epoch: 153 Train loss: 0.073645 Validation loss: 0.13221\n",
            "Epoch: 154 Train loss: 0.07509 Validation loss: 0.083467\n",
            "Epoch: 155 Train loss: 0.072584 Validation loss: 0.13142\n",
            "Epoch: 156 Train loss: 0.073806 Validation loss: 0.0822\n",
            "Epoch: 157 Train loss: 0.071386 Validation loss: 0.13043\n",
            "Epoch: 158 Train loss: 0.07241 Validation loss: 0.080902\n",
            "Epoch: 159 Train loss: 0.070108 Validation loss: 0.12932\n",
            "Epoch: 160 Train loss: 0.070964 Validation loss: 0.07962\n",
            "Epoch: 161 Train loss: 0.068808 Validation loss: 0.12818\n",
            "Epoch: 162 Train loss: 0.069532 Validation loss: 0.078391\n",
            "Epoch: 163 Train loss: 0.06754 Validation loss: 0.1271\n",
            "Epoch: 164 Train loss: 0.068167 Validation loss: 0.077247\n",
            "Epoch: 165 Train loss: 0.066351 Validation loss: 0.12612\n",
            "Epoch: 166 Train loss: 0.066911 Validation loss: 0.076205\n",
            "Epoch: 167 Train loss: 0.065272 Validation loss: 0.12529\n",
            "Epoch: 168 Train loss: 0.065789 Validation loss: 0.075275\n",
            "Epoch: 169 Train loss: 0.064324 Validation loss: 0.12464\n",
            "Epoch: 170 Train loss: 0.064815 Validation loss: 0.074456\n",
            "Epoch: 171 Train loss: 0.063515 Validation loss: 0.12417\n",
            "Epoch: 172 Train loss: 0.063992 Validation loss: 0.073743\n",
            "Epoch: 173 Train loss: 0.062846 Validation loss: 0.12388\n",
            "Epoch: 174 Train loss: 0.063313 Validation loss: 0.073125\n",
            "Epoch: 175 Train loss: 0.062306 Validation loss: 0.12374\n",
            "Epoch: 176 Train loss: 0.062766 Validation loss: 0.072591\n",
            "Epoch: 177 Train loss: 0.061884 Validation loss: 0.12374\n",
            "Epoch: 178 Train loss: 0.062332 Validation loss: 0.072125\n",
            "Epoch: 179 Train loss: 0.06156 Validation loss: 0.12384\n",
            "Epoch: 180 Train loss: 0.061991 Validation loss: 0.071712\n",
            "Epoch: 181 Train loss: 0.061315 Validation loss: 0.12401\n",
            "Epoch: 182 Train loss: 0.061719 Validation loss: 0.071338\n",
            "Epoch: 183 Train loss: 0.061125 Validation loss: 0.12422\n",
            "Epoch: 184 Train loss: 0.061493 Validation loss: 0.070988\n",
            "Epoch: 185 Train loss: 0.060971 Validation loss: 0.12444\n",
            "Epoch: 186 Train loss: 0.061291 Validation loss: 0.07065\n",
            "Epoch: 187 Train loss: 0.060831 Validation loss: 0.12464\n",
            "Epoch: 188 Train loss: 0.061095 Validation loss: 0.070314\n",
            "Epoch: 189 Train loss: 0.060686 Validation loss: 0.12479\n",
            "Epoch: 190 Train loss: 0.060885 Validation loss: 0.06997\n",
            "Epoch: 191 Train loss: 0.060525 Validation loss: 0.12488\n",
            "Epoch: 192 Train loss: 0.060652 Validation loss: 0.069613\n",
            "Epoch: 193 Train loss: 0.060334 Validation loss: 0.12489\n",
            "Epoch: 194 Train loss: 0.060387 Validation loss: 0.069242\n",
            "Epoch: 195 Train loss: 0.060111 Validation loss: 0.12483\n",
            "Epoch: 196 Train loss: 0.060087 Validation loss: 0.068856\n",
            "Epoch: 197 Train loss: 0.059853 Validation loss: 0.1247\n",
            "Epoch: 198 Train loss: 0.059754 Validation loss: 0.068457\n",
            "Epoch: 199 Train loss: 0.059564 Validation loss: 0.1245\n",
            "Epoch: 200 Train loss: 0.059393 Validation loss: 0.06805\n",
            "Epoch: 201 Train loss: 0.059251 Validation loss: 0.12426\n",
            "Epoch: 202 Train loss: 0.059013 Validation loss: 0.06764\n",
            "Epoch: 203 Train loss: 0.058922 Validation loss: 0.12399\n",
            "Epoch: 204 Train loss: 0.058624 Validation loss: 0.067232\n",
            "Epoch: 205 Train loss: 0.058587 Validation loss: 0.12369\n",
            "Epoch: 206 Train loss: 0.058234 Validation loss: 0.066832\n",
            "Epoch: 207 Train loss: 0.058257 Validation loss: 0.1234\n",
            "Epoch: 208 Train loss: 0.057856 Validation loss: 0.066445\n",
            "Epoch: 209 Train loss: 0.05794 Validation loss: 0.12313\n",
            "Epoch: 210 Train loss: 0.057497 Validation loss: 0.066075\n",
            "Epoch: 211 Train loss: 0.057646 Validation loss: 0.12288\n",
            "Epoch: 212 Train loss: 0.057165 Validation loss: 0.065725\n",
            "Epoch: 213 Train loss: 0.05738 Validation loss: 0.12267\n",
            "Epoch: 214 Train loss: 0.056865 Validation loss: 0.065396\n",
            "Epoch: 215 Train loss: 0.057149 Validation loss: 0.1225\n",
            "Epoch: 216 Train loss: 0.0566 Validation loss: 0.065089\n",
            "Epoch: 217 Train loss: 0.056953 Validation loss: 0.12237\n",
            "Epoch: 218 Train loss: 0.056372 Validation loss: 0.064805\n",
            "Epoch: 219 Train loss: 0.056795 Validation loss: 0.1223\n",
            "Epoch: 220 Train loss: 0.056181 Validation loss: 0.064541\n",
            "Epoch: 221 Train loss: 0.056672 Validation loss: 0.12226\n",
            "Epoch: 222 Train loss: 0.056025 Validation loss: 0.064298\n",
            "Epoch: 223 Train loss: 0.056584 Validation loss: 0.12226\n",
            "Epoch: 224 Train loss: 0.0559 Validation loss: 0.064071\n",
            "Epoch: 225 Train loss: 0.056525 Validation loss: 0.12229\n",
            "Epoch: 226 Train loss: 0.055802 Validation loss: 0.06386\n",
            "Epoch: 227 Train loss: 0.056492 Validation loss: 0.12234\n",
            "Epoch: 228 Train loss: 0.055725 Validation loss: 0.06366\n",
            "Epoch: 229 Train loss: 0.056478 Validation loss: 0.12241\n",
            "Epoch: 230 Train loss: 0.055665 Validation loss: 0.063469\n",
            "Epoch: 231 Train loss: 0.056479 Validation loss: 0.12248\n",
            "Epoch: 232 Train loss: 0.055616 Validation loss: 0.063284\n",
            "Epoch: 233 Train loss: 0.056488 Validation loss: 0.12254\n",
            "Epoch: 234 Train loss: 0.055572 Validation loss: 0.063103\n",
            "Epoch: 235 Train loss: 0.0565 Validation loss: 0.1226\n",
            "Epoch: 236 Train loss: 0.055528 Validation loss: 0.062923\n",
            "Epoch: 237 Train loss: 0.05651 Validation loss: 0.12264\n",
            "Epoch: 238 Train loss: 0.055481 Validation loss: 0.062742\n",
            "Epoch: 239 Train loss: 0.056515 Validation loss: 0.12266\n",
            "Epoch: 240 Train loss: 0.055427 Validation loss: 0.062559\n",
            "Epoch: 241 Train loss: 0.056512 Validation loss: 0.12266\n",
            "Epoch: 242 Train loss: 0.055365 Validation loss: 0.062373\n",
            "Epoch: 243 Train loss: 0.0565 Validation loss: 0.12263\n",
            "Epoch: 244 Train loss: 0.055293 Validation loss: 0.062185\n",
            "Epoch: 245 Train loss: 0.056476 Validation loss: 0.12257\n",
            "Epoch: 246 Train loss: 0.055211 Validation loss: 0.061993\n",
            "Epoch: 247 Train loss: 0.056442 Validation loss: 0.1225\n",
            "Epoch: 248 Train loss: 0.055121 Validation loss: 0.061799\n",
            "Epoch: 249 Train loss: 0.056399 Validation loss: 0.1224\n",
            "Epoch: 250 Train loss: 0.055023 Validation loss: 0.061603\n",
            "Epoch: 251 Train loss: 0.056349 Validation loss: 0.12229\n",
            "Epoch: 252 Train loss: 0.05492 Validation loss: 0.061408\n",
            "Epoch: 253 Train loss: 0.056294 Validation loss: 0.12217\n",
            "Epoch: 254 Train loss: 0.054814 Validation loss: 0.061214\n",
            "Epoch: 255 Train loss: 0.056238 Validation loss: 0.12205\n",
            "Epoch: 256 Train loss: 0.054709 Validation loss: 0.061022\n",
            "Epoch: 257 Train loss: 0.056182 Validation loss: 0.12192\n",
            "Epoch: 258 Train loss: 0.054605 Validation loss: 0.060834\n",
            "Epoch: 259 Train loss: 0.056129 Validation loss: 0.12179\n",
            "Epoch: 260 Train loss: 0.054506 Validation loss: 0.060651\n",
            "Epoch: 261 Train loss: 0.056081 Validation loss: 0.12166\n",
            "Epoch: 262 Train loss: 0.054413 Validation loss: 0.060473\n",
            "Epoch: 263 Train loss: 0.05604 Validation loss: 0.12155\n",
            "Epoch: 264 Train loss: 0.054328 Validation loss: 0.060301\n",
            "Epoch: 265 Train loss: 0.056006 Validation loss: 0.12144\n",
            "Epoch: 266 Train loss: 0.05425 Validation loss: 0.060135\n",
            "Epoch: 267 Train loss: 0.055981 Validation loss: 0.12134\n",
            "Epoch: 268 Train loss: 0.054181 Validation loss: 0.059976\n",
            "Epoch: 269 Train loss: 0.055965 Validation loss: 0.12124\n",
            "Epoch: 270 Train loss: 0.05412 Validation loss: 0.059823\n",
            "Epoch: 271 Train loss: 0.055956 Validation loss: 0.12116\n",
            "Epoch: 272 Train loss: 0.054066 Validation loss: 0.059676\n",
            "Epoch: 273 Train loss: 0.055955 Validation loss: 0.12108\n",
            "Epoch: 274 Train loss: 0.054019 Validation loss: 0.059533\n",
            "Epoch: 275 Train loss: 0.055959 Validation loss: 0.121\n",
            "Epoch: 276 Train loss: 0.053977 Validation loss: 0.059395\n",
            "Epoch: 277 Train loss: 0.055968 Validation loss: 0.12093\n",
            "Epoch: 278 Train loss: 0.053938 Validation loss: 0.059261\n",
            "Epoch: 279 Train loss: 0.05598 Validation loss: 0.12086\n",
            "Epoch: 280 Train loss: 0.053902 Validation loss: 0.059129\n",
            "Epoch: 281 Train loss: 0.055993 Validation loss: 0.12078\n",
            "Epoch: 282 Train loss: 0.053867 Validation loss: 0.058999\n",
            "Epoch: 283 Train loss: 0.056006 Validation loss: 0.1207\n",
            "Epoch: 284 Train loss: 0.053831 Validation loss: 0.058871\n",
            "Epoch: 285 Train loss: 0.056016 Validation loss: 0.12061\n",
            "Epoch: 286 Train loss: 0.053793 Validation loss: 0.058743\n",
            "Epoch: 287 Train loss: 0.056024 Validation loss: 0.12052\n",
            "Epoch: 288 Train loss: 0.053753 Validation loss: 0.058614\n",
            "Epoch: 289 Train loss: 0.056027 Validation loss: 0.12041\n",
            "Epoch: 290 Train loss: 0.053709 Validation loss: 0.058486\n",
            "Epoch: 291 Train loss: 0.056026 Validation loss: 0.1203\n",
            "Epoch: 292 Train loss: 0.053661 Validation loss: 0.058357\n",
            "Epoch: 293 Train loss: 0.056019 Validation loss: 0.12018\n",
            "Epoch: 294 Train loss: 0.053609 Validation loss: 0.058228\n",
            "Epoch: 295 Train loss: 0.056007 Validation loss: 0.12005\n",
            "Epoch: 296 Train loss: 0.053553 Validation loss: 0.058098\n",
            "Epoch: 297 Train loss: 0.05599 Validation loss: 0.11991\n",
            "Epoch: 298 Train loss: 0.053493 Validation loss: 0.057968\n",
            "Epoch: 299 Train loss: 0.055968 Validation loss: 0.11977\n",
            "Epoch: 300 Train loss: 0.05343 Validation loss: 0.057837\n",
            "Epoch: 301 Train loss: 0.055942 Validation loss: 0.11962\n",
            "Epoch: 302 Train loss: 0.053363 Validation loss: 0.057707\n",
            "Epoch: 303 Train loss: 0.055912 Validation loss: 0.11946\n",
            "Epoch: 304 Train loss: 0.053295 Validation loss: 0.057577\n",
            "Epoch: 305 Train loss: 0.055879 Validation loss: 0.1193\n",
            "Epoch: 306 Train loss: 0.053225 Validation loss: 0.057447\n",
            "Epoch: 307 Train loss: 0.055844 Validation loss: 0.11914\n",
            "Epoch: 308 Train loss: 0.053153 Validation loss: 0.057319\n",
            "Epoch: 309 Train loss: 0.055806 Validation loss: 0.11897\n",
            "Epoch: 310 Train loss: 0.053081 Validation loss: 0.057192\n",
            "Epoch: 311 Train loss: 0.055768 Validation loss: 0.11881\n",
            "Epoch: 312 Train loss: 0.053009 Validation loss: 0.057066\n",
            "Epoch: 313 Train loss: 0.055729 Validation loss: 0.11864\n",
            "Epoch: 314 Train loss: 0.052937 Validation loss: 0.056943\n",
            "Epoch: 315 Train loss: 0.05569 Validation loss: 0.11847\n",
            "Epoch: 316 Train loss: 0.052866 Validation loss: 0.05682\n",
            "Epoch: 317 Train loss: 0.05565 Validation loss: 0.11831\n",
            "Epoch: 318 Train loss: 0.052795 Validation loss: 0.056699\n",
            "Epoch: 319 Train loss: 0.055609 Validation loss: 0.11814\n",
            "Epoch: 320 Train loss: 0.052724 Validation loss: 0.05658\n",
            "Epoch: 321 Train loss: 0.055568 Validation loss: 0.11797\n",
            "Epoch: 322 Train loss: 0.052653 Validation loss: 0.056462\n",
            "Epoch: 323 Train loss: 0.055526 Validation loss: 0.11781\n",
            "Epoch: 324 Train loss: 0.052582 Validation loss: 0.056345\n",
            "Epoch: 325 Train loss: 0.055484 Validation loss: 0.11764\n",
            "Epoch: 326 Train loss: 0.05251 Validation loss: 0.056229\n",
            "Epoch: 327 Train loss: 0.05544 Validation loss: 0.11747\n",
            "Epoch: 328 Train loss: 0.052438 Validation loss: 0.056114\n",
            "Epoch: 329 Train loss: 0.055394 Validation loss: 0.11729\n",
            "Epoch: 330 Train loss: 0.052365 Validation loss: 0.055999\n",
            "Epoch: 331 Train loss: 0.055345 Validation loss: 0.11712\n",
            "Epoch: 332 Train loss: 0.05229 Validation loss: 0.055884\n",
            "Epoch: 333 Train loss: 0.055295 Validation loss: 0.11694\n",
            "Epoch: 334 Train loss: 0.052214 Validation loss: 0.05577\n",
            "Epoch: 335 Train loss: 0.055242 Validation loss: 0.11676\n",
            "Epoch: 336 Train loss: 0.052137 Validation loss: 0.055656\n",
            "Epoch: 337 Train loss: 0.055186 Validation loss: 0.11658\n",
            "Epoch: 338 Train loss: 0.052058 Validation loss: 0.055541\n",
            "Epoch: 339 Train loss: 0.055128 Validation loss: 0.11639\n",
            "Epoch: 340 Train loss: 0.051977 Validation loss: 0.055427\n",
            "Epoch: 341 Train loss: 0.055067 Validation loss: 0.1162\n",
            "Epoch: 342 Train loss: 0.051894 Validation loss: 0.055313\n",
            "Epoch: 343 Train loss: 0.055003 Validation loss: 0.11601\n",
            "Epoch: 344 Train loss: 0.051809 Validation loss: 0.055198\n",
            "Epoch: 345 Train loss: 0.054936 Validation loss: 0.11582\n",
            "Epoch: 346 Train loss: 0.051723 Validation loss: 0.055084\n",
            "Epoch: 347 Train loss: 0.054867 Validation loss: 0.11562\n",
            "Epoch: 348 Train loss: 0.051636 Validation loss: 0.054969\n",
            "Epoch: 349 Train loss: 0.054796 Validation loss: 0.11542\n",
            "Epoch: 350 Train loss: 0.051547 Validation loss: 0.054855\n",
            "Epoch: 351 Train loss: 0.054723 Validation loss: 0.11522\n",
            "Epoch: 352 Train loss: 0.051457 Validation loss: 0.054741\n",
            "Epoch: 353 Train loss: 0.054647 Validation loss: 0.11502\n",
            "Epoch: 354 Train loss: 0.051366 Validation loss: 0.054627\n",
            "Epoch: 355 Train loss: 0.05457 Validation loss: 0.11482\n",
            "Epoch: 356 Train loss: 0.051275 Validation loss: 0.054513\n",
            "Epoch: 357 Train loss: 0.054491 Validation loss: 0.11461\n",
            "Epoch: 358 Train loss: 0.051182 Validation loss: 0.0544\n",
            "Epoch: 359 Train loss: 0.054411 Validation loss: 0.11441\n",
            "Epoch: 360 Train loss: 0.051089 Validation loss: 0.054287\n",
            "Epoch: 361 Train loss: 0.054331 Validation loss: 0.11421\n",
            "Epoch: 362 Train loss: 0.050996 Validation loss: 0.054175\n",
            "Epoch: 363 Train loss: 0.054249 Validation loss: 0.114\n",
            "Epoch: 364 Train loss: 0.050903 Validation loss: 0.054063\n",
            "Epoch: 365 Train loss: 0.054166 Validation loss: 0.1138\n",
            "Epoch: 366 Train loss: 0.050809 Validation loss: 0.053952\n",
            "Epoch: 367 Train loss: 0.054082 Validation loss: 0.11359\n",
            "Epoch: 368 Train loss: 0.050715 Validation loss: 0.053841\n",
            "Epoch: 369 Train loss: 0.053998 Validation loss: 0.11339\n",
            "Epoch: 370 Train loss: 0.050622 Validation loss: 0.053731\n",
            "Epoch: 371 Train loss: 0.053913 Validation loss: 0.11318\n",
            "Epoch: 372 Train loss: 0.050528 Validation loss: 0.053622\n",
            "Epoch: 373 Train loss: 0.053828 Validation loss: 0.11298\n",
            "Epoch: 374 Train loss: 0.050434 Validation loss: 0.053513\n",
            "Epoch: 375 Train loss: 0.053742 Validation loss: 0.11277\n",
            "Epoch: 376 Train loss: 0.05034 Validation loss: 0.053405\n",
            "Epoch: 377 Train loss: 0.053655 Validation loss: 0.11257\n",
            "Epoch: 378 Train loss: 0.050247 Validation loss: 0.053297\n",
            "Epoch: 379 Train loss: 0.053568 Validation loss: 0.11236\n",
            "Epoch: 380 Train loss: 0.050153 Validation loss: 0.05319\n",
            "Epoch: 381 Train loss: 0.05348 Validation loss: 0.11216\n",
            "Epoch: 382 Train loss: 0.050058 Validation loss: 0.053082\n",
            "Epoch: 383 Train loss: 0.053391 Validation loss: 0.11195\n",
            "Epoch: 384 Train loss: 0.049964 Validation loss: 0.052976\n",
            "Epoch: 385 Train loss: 0.053302 Validation loss: 0.11175\n",
            "Epoch: 386 Train loss: 0.04987 Validation loss: 0.052869\n",
            "Epoch: 387 Train loss: 0.053212 Validation loss: 0.11154\n",
            "Epoch: 388 Train loss: 0.049775 Validation loss: 0.052763\n",
            "Epoch: 389 Train loss: 0.053121 Validation loss: 0.11134\n",
            "Epoch: 390 Train loss: 0.04968 Validation loss: 0.052658\n",
            "Epoch: 391 Train loss: 0.053029 Validation loss: 0.11113\n",
            "Epoch: 392 Train loss: 0.049585 Validation loss: 0.052553\n",
            "Epoch: 393 Train loss: 0.052937 Validation loss: 0.11093\n",
            "Epoch: 394 Train loss: 0.04949 Validation loss: 0.052448\n",
            "Epoch: 395 Train loss: 0.052844 Validation loss: 0.11072\n",
            "Epoch: 396 Train loss: 0.049394 Validation loss: 0.052343\n",
            "Epoch: 397 Train loss: 0.052751 Validation loss: 0.11051\n",
            "Epoch: 398 Train loss: 0.049299 Validation loss: 0.052239\n",
            "Epoch: 399 Train loss: 0.052657 Validation loss: 0.11031\n",
            "Epoch: 400 Train loss: 0.049203 Validation loss: 0.052135\n",
            "Epoch: 401 Train loss: 0.052563 Validation loss: 0.1101\n",
            "Epoch: 402 Train loss: 0.049108 Validation loss: 0.052032\n",
            "Epoch: 403 Train loss: 0.052468 Validation loss: 0.1099\n",
            "Epoch: 404 Train loss: 0.049012 Validation loss: 0.051929\n",
            "Epoch: 405 Train loss: 0.052373 Validation loss: 0.10969\n",
            "Epoch: 406 Train loss: 0.048917 Validation loss: 0.051826\n",
            "Epoch: 407 Train loss: 0.052277 Validation loss: 0.10949\n",
            "Epoch: 408 Train loss: 0.048821 Validation loss: 0.051724\n",
            "Epoch: 409 Train loss: 0.052182 Validation loss: 0.10928\n",
            "Epoch: 410 Train loss: 0.048726 Validation loss: 0.051622\n",
            "Epoch: 411 Train loss: 0.052086 Validation loss: 0.10908\n",
            "Epoch: 412 Train loss: 0.048631 Validation loss: 0.051521\n",
            "Epoch: 413 Train loss: 0.05199 Validation loss: 0.10887\n",
            "Epoch: 414 Train loss: 0.048536 Validation loss: 0.051421\n",
            "Epoch: 415 Train loss: 0.051894 Validation loss: 0.10867\n",
            "Epoch: 416 Train loss: 0.048442 Validation loss: 0.05132\n",
            "Epoch: 417 Train loss: 0.051798 Validation loss: 0.10847\n",
            "Epoch: 418 Train loss: 0.048347 Validation loss: 0.051221\n",
            "Epoch: 419 Train loss: 0.051702 Validation loss: 0.10826\n",
            "Epoch: 420 Train loss: 0.048253 Validation loss: 0.051122\n",
            "Epoch: 421 Train loss: 0.051605 Validation loss: 0.10806\n",
            "Epoch: 422 Train loss: 0.048159 Validation loss: 0.051023\n",
            "Epoch: 423 Train loss: 0.051509 Validation loss: 0.10786\n",
            "Epoch: 424 Train loss: 0.048066 Validation loss: 0.050924\n",
            "Epoch: 425 Train loss: 0.051412 Validation loss: 0.10766\n",
            "Epoch: 426 Train loss: 0.047972 Validation loss: 0.050827\n",
            "Epoch: 427 Train loss: 0.051316 Validation loss: 0.10746\n",
            "Epoch: 428 Train loss: 0.047879 Validation loss: 0.050729\n",
            "Epoch: 429 Train loss: 0.051219 Validation loss: 0.10726\n",
            "Epoch: 430 Train loss: 0.047786 Validation loss: 0.050632\n",
            "Epoch: 431 Train loss: 0.051123 Validation loss: 0.10705\n",
            "Epoch: 432 Train loss: 0.047693 Validation loss: 0.050536\n",
            "Epoch: 433 Train loss: 0.051026 Validation loss: 0.10685\n",
            "Epoch: 434 Train loss: 0.0476 Validation loss: 0.050439\n",
            "Epoch: 435 Train loss: 0.050929 Validation loss: 0.10665\n",
            "Epoch: 436 Train loss: 0.047508 Validation loss: 0.050343\n",
            "Epoch: 437 Train loss: 0.050832 Validation loss: 0.10646\n",
            "Epoch: 438 Train loss: 0.047415 Validation loss: 0.050248\n",
            "Epoch: 439 Train loss: 0.050735 Validation loss: 0.10626\n",
            "Epoch: 440 Train loss: 0.047323 Validation loss: 0.050153\n",
            "Epoch: 441 Train loss: 0.050638 Validation loss: 0.10606\n",
            "Epoch: 442 Train loss: 0.047231 Validation loss: 0.050059\n",
            "Epoch: 443 Train loss: 0.050541 Validation loss: 0.10586\n",
            "Epoch: 444 Train loss: 0.04714 Validation loss: 0.049965\n",
            "Epoch: 445 Train loss: 0.050444 Validation loss: 0.10566\n",
            "Epoch: 446 Train loss: 0.047048 Validation loss: 0.049871\n",
            "Epoch: 447 Train loss: 0.050346 Validation loss: 0.10547\n",
            "Epoch: 448 Train loss: 0.046957 Validation loss: 0.049777\n",
            "Epoch: 449 Train loss: 0.050249 Validation loss: 0.10527\n",
            "Epoch: 450 Train loss: 0.046865 Validation loss: 0.049684\n",
            "Epoch: 451 Train loss: 0.050152 Validation loss: 0.10507\n",
            "Epoch: 452 Train loss: 0.046774 Validation loss: 0.049592\n",
            "Epoch: 453 Train loss: 0.050054 Validation loss: 0.10487\n",
            "Epoch: 454 Train loss: 0.046683 Validation loss: 0.049499\n",
            "Epoch: 455 Train loss: 0.049957 Validation loss: 0.10468\n",
            "Epoch: 456 Train loss: 0.046592 Validation loss: 0.049407\n",
            "Epoch: 457 Train loss: 0.04986 Validation loss: 0.10448\n",
            "Epoch: 458 Train loss: 0.046502 Validation loss: 0.049316\n",
            "Epoch: 459 Train loss: 0.049762 Validation loss: 0.10429\n",
            "Epoch: 460 Train loss: 0.046412 Validation loss: 0.049225\n",
            "Epoch: 461 Train loss: 0.049665 Validation loss: 0.10409\n",
            "Epoch: 462 Train loss: 0.046322 Validation loss: 0.049134\n",
            "Epoch: 463 Train loss: 0.049568 Validation loss: 0.1039\n",
            "Epoch: 464 Train loss: 0.046232 Validation loss: 0.049044\n",
            "Epoch: 465 Train loss: 0.049471 Validation loss: 0.10371\n",
            "Epoch: 466 Train loss: 0.046143 Validation loss: 0.048954\n",
            "Epoch: 467 Train loss: 0.049374 Validation loss: 0.10351\n",
            "Epoch: 468 Train loss: 0.046054 Validation loss: 0.048865\n",
            "Epoch: 469 Train loss: 0.049277 Validation loss: 0.10332\n",
            "Epoch: 470 Train loss: 0.045965 Validation loss: 0.048776\n",
            "Epoch: 471 Train loss: 0.04918 Validation loss: 0.10313\n",
            "Epoch: 472 Train loss: 0.045875 Validation loss: 0.048687\n",
            "Epoch: 473 Train loss: 0.049083 Validation loss: 0.10293\n",
            "Epoch: 474 Train loss: 0.045787 Validation loss: 0.048598\n",
            "Epoch: 475 Train loss: 0.048986 Validation loss: 0.10274\n",
            "Epoch: 476 Train loss: 0.045698 Validation loss: 0.04851\n",
            "Epoch: 477 Train loss: 0.048889 Validation loss: 0.10255\n",
            "Epoch: 478 Train loss: 0.04561 Validation loss: 0.048422\n",
            "Epoch: 479 Train loss: 0.048792 Validation loss: 0.10236\n",
            "Epoch: 480 Train loss: 0.045522 Validation loss: 0.048335\n",
            "Epoch: 481 Train loss: 0.048695 Validation loss: 0.10217\n",
            "Epoch: 482 Train loss: 0.045434 Validation loss: 0.048248\n",
            "Epoch: 483 Train loss: 0.048598 Validation loss: 0.10198\n",
            "Epoch: 484 Train loss: 0.045346 Validation loss: 0.048161\n",
            "Epoch: 485 Train loss: 0.048502 Validation loss: 0.10179\n",
            "Epoch: 486 Train loss: 0.045259 Validation loss: 0.048075\n",
            "Epoch: 487 Train loss: 0.048405 Validation loss: 0.1016\n",
            "Epoch: 488 Train loss: 0.045172 Validation loss: 0.047989\n",
            "Epoch: 489 Train loss: 0.048308 Validation loss: 0.10141\n",
            "Epoch: 490 Train loss: 0.045084 Validation loss: 0.047903\n",
            "Epoch: 491 Train loss: 0.048212 Validation loss: 0.10122\n",
            "Epoch: 492 Train loss: 0.044997 Validation loss: 0.047817\n",
            "Epoch: 493 Train loss: 0.048115 Validation loss: 0.10103\n",
            "Epoch: 494 Train loss: 0.044911 Validation loss: 0.047733\n",
            "Epoch: 495 Train loss: 0.048018 Validation loss: 0.10084\n",
            "Epoch: 496 Train loss: 0.044824 Validation loss: 0.047648\n",
            "Epoch: 497 Train loss: 0.047922 Validation loss: 0.10065\n",
            "Epoch: 498 Train loss: 0.044738 Validation loss: 0.047563\n",
            "Epoch: 499 Train loss: 0.047825 Validation loss: 0.10046\n",
            "Epoch: 500 Train loss: 0.044651 Validation loss: 0.047479\n",
            "Epoch: 501 Train loss: 0.047729 Validation loss: 0.10028\n",
            "Epoch: 502 Train loss: 0.044565 Validation loss: 0.047395\n",
            "Epoch: 503 Train loss: 0.047632 Validation loss: 0.10009\n",
            "Epoch: 504 Train loss: 0.044479 Validation loss: 0.047311\n",
            "Epoch: 505 Train loss: 0.047536 Validation loss: 0.099903\n",
            "Epoch: 506 Train loss: 0.044394 Validation loss: 0.047228\n",
            "Epoch: 507 Train loss: 0.04744 Validation loss: 0.099717\n",
            "Epoch: 508 Train loss: 0.044308 Validation loss: 0.047145\n",
            "Epoch: 509 Train loss: 0.047344 Validation loss: 0.09953\n",
            "Epoch: 510 Train loss: 0.044223 Validation loss: 0.047062\n",
            "Epoch: 511 Train loss: 0.047248 Validation loss: 0.099344\n",
            "Epoch: 512 Train loss: 0.044138 Validation loss: 0.04698\n",
            "Epoch: 513 Train loss: 0.047152 Validation loss: 0.099158\n",
            "Epoch: 514 Train loss: 0.044053 Validation loss: 0.046898\n",
            "Epoch: 515 Train loss: 0.047056 Validation loss: 0.098973\n",
            "Epoch: 516 Train loss: 0.043968 Validation loss: 0.046816\n",
            "Epoch: 517 Train loss: 0.04696 Validation loss: 0.098788\n",
            "Epoch: 518 Train loss: 0.043883 Validation loss: 0.046735\n",
            "Epoch: 519 Train loss: 0.046865 Validation loss: 0.098603\n",
            "Epoch: 520 Train loss: 0.043799 Validation loss: 0.046653\n",
            "Epoch: 521 Train loss: 0.046769 Validation loss: 0.098418\n",
            "Epoch: 522 Train loss: 0.043715 Validation loss: 0.046572\n",
            "Epoch: 523 Train loss: 0.046673 Validation loss: 0.098233\n",
            "Epoch: 524 Train loss: 0.04363 Validation loss: 0.046491\n",
            "Epoch: 525 Train loss: 0.046577 Validation loss: 0.098049\n",
            "Epoch: 526 Train loss: 0.043546 Validation loss: 0.04641\n",
            "Epoch: 527 Train loss: 0.046482 Validation loss: 0.097865\n",
            "Epoch: 528 Train loss: 0.043462 Validation loss: 0.04633\n",
            "Epoch: 529 Train loss: 0.046386 Validation loss: 0.097681\n",
            "Epoch: 530 Train loss: 0.043379 Validation loss: 0.04625\n",
            "Epoch: 531 Train loss: 0.046291 Validation loss: 0.097498\n",
            "Epoch: 532 Train loss: 0.043296 Validation loss: 0.046171\n",
            "Epoch: 533 Train loss: 0.046196 Validation loss: 0.097315\n",
            "Epoch: 534 Train loss: 0.043212 Validation loss: 0.046091\n",
            "Epoch: 535 Train loss: 0.046101 Validation loss: 0.097132\n",
            "Epoch: 536 Train loss: 0.043129 Validation loss: 0.046012\n",
            "Epoch: 537 Train loss: 0.046005 Validation loss: 0.09695\n",
            "Epoch: 538 Train loss: 0.043046 Validation loss: 0.045933\n",
            "Epoch: 539 Train loss: 0.04591 Validation loss: 0.096768\n",
            "Epoch: 540 Train loss: 0.042963 Validation loss: 0.045854\n",
            "Epoch: 541 Train loss: 0.045815 Validation loss: 0.096585\n",
            "Epoch: 542 Train loss: 0.042881 Validation loss: 0.045775\n",
            "Epoch: 543 Train loss: 0.04572 Validation loss: 0.096403\n",
            "Epoch: 544 Train loss: 0.042798 Validation loss: 0.045697\n",
            "Epoch: 545 Train loss: 0.045625 Validation loss: 0.096221\n",
            "Epoch: 546 Train loss: 0.042715 Validation loss: 0.045619\n",
            "Epoch: 547 Train loss: 0.04553 Validation loss: 0.096039\n",
            "Epoch: 548 Train loss: 0.042633 Validation loss: 0.04554\n",
            "Epoch: 549 Train loss: 0.045435 Validation loss: 0.095857\n",
            "Epoch: 550 Train loss: 0.04255 Validation loss: 0.045462\n",
            "Epoch: 551 Train loss: 0.04534 Validation loss: 0.095675\n",
            "Epoch: 552 Train loss: 0.042468 Validation loss: 0.045385\n",
            "Epoch: 553 Train loss: 0.045245 Validation loss: 0.095494\n",
            "Epoch: 554 Train loss: 0.042386 Validation loss: 0.045307\n",
            "Epoch: 555 Train loss: 0.04515 Validation loss: 0.095312\n",
            "Epoch: 556 Train loss: 0.042304 Validation loss: 0.045229\n",
            "Epoch: 557 Train loss: 0.045055 Validation loss: 0.095131\n",
            "Epoch: 558 Train loss: 0.042221 Validation loss: 0.045152\n",
            "Epoch: 559 Train loss: 0.044959 Validation loss: 0.094949\n",
            "Epoch: 560 Train loss: 0.042139 Validation loss: 0.045075\n",
            "Epoch: 561 Train loss: 0.044864 Validation loss: 0.094767\n",
            "Epoch: 562 Train loss: 0.042057 Validation loss: 0.044998\n",
            "Epoch: 563 Train loss: 0.044768 Validation loss: 0.094586\n",
            "Epoch: 564 Train loss: 0.041975 Validation loss: 0.044921\n",
            "Epoch: 565 Train loss: 0.044673 Validation loss: 0.094404\n",
            "Epoch: 566 Train loss: 0.041893 Validation loss: 0.044844\n",
            "Epoch: 567 Train loss: 0.044578 Validation loss: 0.094223\n",
            "Epoch: 568 Train loss: 0.041811 Validation loss: 0.044767\n",
            "Epoch: 569 Train loss: 0.044483 Validation loss: 0.094042\n",
            "Epoch: 570 Train loss: 0.041729 Validation loss: 0.044691\n",
            "Epoch: 571 Train loss: 0.044387 Validation loss: 0.093861\n",
            "Epoch: 572 Train loss: 0.041648 Validation loss: 0.044615\n",
            "Epoch: 573 Train loss: 0.044293 Validation loss: 0.09368\n",
            "Epoch: 574 Train loss: 0.041566 Validation loss: 0.044539\n",
            "Epoch: 575 Train loss: 0.044197 Validation loss: 0.0935\n",
            "Epoch: 576 Train loss: 0.041485 Validation loss: 0.044463\n",
            "Epoch: 577 Train loss: 0.044102 Validation loss: 0.093319\n",
            "Epoch: 578 Train loss: 0.041403 Validation loss: 0.044387\n",
            "Epoch: 579 Train loss: 0.044007 Validation loss: 0.093138\n",
            "Epoch: 580 Train loss: 0.041322 Validation loss: 0.044312\n",
            "Epoch: 581 Train loss: 0.043912 Validation loss: 0.092958\n",
            "Epoch: 582 Train loss: 0.041241 Validation loss: 0.044236\n",
            "Epoch: 583 Train loss: 0.043817 Validation loss: 0.092777\n",
            "Epoch: 584 Train loss: 0.041159 Validation loss: 0.044161\n",
            "Epoch: 585 Train loss: 0.043722 Validation loss: 0.092596\n",
            "Epoch: 586 Train loss: 0.041078 Validation loss: 0.044085\n",
            "Epoch: 587 Train loss: 0.043626 Validation loss: 0.092415\n",
            "Epoch: 588 Train loss: 0.040996 Validation loss: 0.04401\n",
            "Epoch: 589 Train loss: 0.043531 Validation loss: 0.092234\n",
            "Epoch: 590 Train loss: 0.040915 Validation loss: 0.043934\n",
            "Epoch: 591 Train loss: 0.043435 Validation loss: 0.092053\n",
            "Epoch: 592 Train loss: 0.040833 Validation loss: 0.043859\n",
            "Epoch: 593 Train loss: 0.04334 Validation loss: 0.091872\n",
            "Epoch: 594 Train loss: 0.040752 Validation loss: 0.043784\n",
            "Epoch: 595 Train loss: 0.043244 Validation loss: 0.09169\n",
            "Epoch: 596 Train loss: 0.04067 Validation loss: 0.043709\n",
            "Epoch: 597 Train loss: 0.043147 Validation loss: 0.091508\n",
            "Epoch: 598 Train loss: 0.040588 Validation loss: 0.043634\n",
            "Epoch: 599 Train loss: 0.043051 Validation loss: 0.091326\n",
            "Epoch: 600 Train loss: 0.040506 Validation loss: 0.043558\n",
            "Epoch: 601 Train loss: 0.042954 Validation loss: 0.091144\n",
            "Epoch: 602 Train loss: 0.040424 Validation loss: 0.043483\n",
            "Epoch: 603 Train loss: 0.042858 Validation loss: 0.090961\n",
            "Epoch: 604 Train loss: 0.040342 Validation loss: 0.043408\n",
            "Epoch: 605 Train loss: 0.042761 Validation loss: 0.090779\n",
            "Epoch: 606 Train loss: 0.04026 Validation loss: 0.043333\n",
            "Epoch: 607 Train loss: 0.042664 Validation loss: 0.090596\n",
            "Epoch: 608 Train loss: 0.040178 Validation loss: 0.043258\n",
            "Epoch: 609 Train loss: 0.042567 Validation loss: 0.090413\n",
            "Epoch: 610 Train loss: 0.040095 Validation loss: 0.043182\n",
            "Epoch: 611 Train loss: 0.04247 Validation loss: 0.09023\n",
            "Epoch: 612 Train loss: 0.040012 Validation loss: 0.043107\n",
            "Epoch: 613 Train loss: 0.042372 Validation loss: 0.090046\n",
            "Epoch: 614 Train loss: 0.03993 Validation loss: 0.043032\n",
            "Epoch: 615 Train loss: 0.042275 Validation loss: 0.089862\n",
            "Epoch: 616 Train loss: 0.039847 Validation loss: 0.042957\n",
            "Epoch: 617 Train loss: 0.042177 Validation loss: 0.089679\n",
            "Epoch: 618 Train loss: 0.039764 Validation loss: 0.042882\n",
            "Epoch: 619 Train loss: 0.042079 Validation loss: 0.089495\n",
            "Epoch: 620 Train loss: 0.039681 Validation loss: 0.042807\n",
            "Epoch: 621 Train loss: 0.041981 Validation loss: 0.08931\n",
            "Epoch: 622 Train loss: 0.039598 Validation loss: 0.042731\n",
            "Epoch: 623 Train loss: 0.041883 Validation loss: 0.089126\n",
            "Epoch: 624 Train loss: 0.039515 Validation loss: 0.042656\n",
            "Epoch: 625 Train loss: 0.041784 Validation loss: 0.088941\n",
            "Epoch: 626 Train loss: 0.039432 Validation loss: 0.042581\n",
            "Epoch: 627 Train loss: 0.041686 Validation loss: 0.088755\n",
            "Epoch: 628 Train loss: 0.039348 Validation loss: 0.042506\n",
            "Epoch: 629 Train loss: 0.041586 Validation loss: 0.088569\n",
            "Epoch: 630 Train loss: 0.039264 Validation loss: 0.04243\n",
            "Epoch: 631 Train loss: 0.041487 Validation loss: 0.088383\n",
            "Epoch: 632 Train loss: 0.03918 Validation loss: 0.042354\n",
            "Epoch: 633 Train loss: 0.041387 Validation loss: 0.088196\n",
            "Epoch: 634 Train loss: 0.039095 Validation loss: 0.042278\n",
            "Epoch: 635 Train loss: 0.041287 Validation loss: 0.088009\n",
            "Epoch: 636 Train loss: 0.03901 Validation loss: 0.042203\n",
            "Epoch: 637 Train loss: 0.041187 Validation loss: 0.087821\n",
            "Epoch: 638 Train loss: 0.038926 Validation loss: 0.042127\n",
            "Epoch: 639 Train loss: 0.041086 Validation loss: 0.087633\n",
            "Epoch: 640 Train loss: 0.03884 Validation loss: 0.042051\n",
            "Epoch: 641 Train loss: 0.040985 Validation loss: 0.087444\n",
            "Epoch: 642 Train loss: 0.038755 Validation loss: 0.041975\n",
            "Epoch: 643 Train loss: 0.040884 Validation loss: 0.087255\n",
            "Epoch: 644 Train loss: 0.038669 Validation loss: 0.041898\n",
            "Epoch: 645 Train loss: 0.040782 Validation loss: 0.087066\n",
            "Epoch: 646 Train loss: 0.038583 Validation loss: 0.041822\n",
            "Epoch: 647 Train loss: 0.04068 Validation loss: 0.086876\n",
            "Epoch: 648 Train loss: 0.038497 Validation loss: 0.041745\n",
            "Epoch: 649 Train loss: 0.040578 Validation loss: 0.086685\n",
            "Epoch: 650 Train loss: 0.03841 Validation loss: 0.041669\n",
            "Epoch: 651 Train loss: 0.040475 Validation loss: 0.086494\n",
            "Epoch: 652 Train loss: 0.038323 Validation loss: 0.041592\n",
            "Epoch: 653 Train loss: 0.040372 Validation loss: 0.086302\n",
            "Epoch: 654 Train loss: 0.038235 Validation loss: 0.041514\n",
            "Epoch: 655 Train loss: 0.040268 Validation loss: 0.086109\n",
            "Epoch: 656 Train loss: 0.038147 Validation loss: 0.041437\n",
            "Epoch: 657 Train loss: 0.040164 Validation loss: 0.085915\n",
            "Epoch: 658 Train loss: 0.038059 Validation loss: 0.041359\n",
            "Epoch: 659 Train loss: 0.040059 Validation loss: 0.085721\n",
            "Epoch: 660 Train loss: 0.03797 Validation loss: 0.041281\n",
            "Epoch: 661 Train loss: 0.039953 Validation loss: 0.085526\n",
            "Epoch: 662 Train loss: 0.03788 Validation loss: 0.041203\n",
            "Epoch: 663 Train loss: 0.039847 Validation loss: 0.08533\n",
            "Epoch: 664 Train loss: 0.037791 Validation loss: 0.041125\n",
            "Epoch: 665 Train loss: 0.039741 Validation loss: 0.085133\n",
            "Epoch: 666 Train loss: 0.0377 Validation loss: 0.041046\n",
            "Epoch: 667 Train loss: 0.039634 Validation loss: 0.084936\n",
            "Epoch: 668 Train loss: 0.037609 Validation loss: 0.040967\n",
            "Epoch: 669 Train loss: 0.039526 Validation loss: 0.084738\n",
            "Epoch: 670 Train loss: 0.037518 Validation loss: 0.040888\n",
            "Epoch: 671 Train loss: 0.039418 Validation loss: 0.084538\n",
            "Epoch: 672 Train loss: 0.037426 Validation loss: 0.040808\n",
            "Epoch: 673 Train loss: 0.039309 Validation loss: 0.084338\n",
            "Epoch: 674 Train loss: 0.037333 Validation loss: 0.040728\n",
            "Epoch: 675 Train loss: 0.0392 Validation loss: 0.084137\n",
            "Epoch: 676 Train loss: 0.03724 Validation loss: 0.040648\n",
            "Epoch: 677 Train loss: 0.03909 Validation loss: 0.083936\n",
            "Epoch: 678 Train loss: 0.037147 Validation loss: 0.040568\n",
            "Epoch: 679 Train loss: 0.03898 Validation loss: 0.083733\n",
            "Epoch: 680 Train loss: 0.037053 Validation loss: 0.040487\n",
            "Epoch: 681 Train loss: 0.038869 Validation loss: 0.08353\n",
            "Epoch: 682 Train loss: 0.036958 Validation loss: 0.040406\n",
            "Epoch: 683 Train loss: 0.038757 Validation loss: 0.083325\n",
            "Epoch: 684 Train loss: 0.036863 Validation loss: 0.040325\n",
            "Epoch: 685 Train loss: 0.038644 Validation loss: 0.08312\n",
            "Epoch: 686 Train loss: 0.036766 Validation loss: 0.040243\n",
            "Epoch: 687 Train loss: 0.038531 Validation loss: 0.082914\n",
            "Epoch: 688 Train loss: 0.03667 Validation loss: 0.040161\n",
            "Epoch: 689 Train loss: 0.038418 Validation loss: 0.082706\n",
            "Epoch: 690 Train loss: 0.036573 Validation loss: 0.040079\n",
            "Epoch: 691 Train loss: 0.038303 Validation loss: 0.082498\n",
            "Epoch: 692 Train loss: 0.036475 Validation loss: 0.039996\n",
            "Epoch: 693 Train loss: 0.038188 Validation loss: 0.082288\n",
            "Epoch: 694 Train loss: 0.036376 Validation loss: 0.039913\n",
            "Epoch: 695 Train loss: 0.038072 Validation loss: 0.082078\n",
            "Epoch: 696 Train loss: 0.036277 Validation loss: 0.039829\n",
            "Epoch: 697 Train loss: 0.037955 Validation loss: 0.081866\n",
            "Epoch: 698 Train loss: 0.036177 Validation loss: 0.039745\n",
            "Epoch: 699 Train loss: 0.037838 Validation loss: 0.081653\n",
            "Epoch: 700 Train loss: 0.036076 Validation loss: 0.039661\n",
            "Epoch: 701 Train loss: 0.037719 Validation loss: 0.081439\n",
            "Epoch: 702 Train loss: 0.035975 Validation loss: 0.039576\n",
            "Epoch: 703 Train loss: 0.037601 Validation loss: 0.081224\n",
            "Epoch: 704 Train loss: 0.035872 Validation loss: 0.039491\n",
            "Epoch: 705 Train loss: 0.037481 Validation loss: 0.081007\n",
            "Epoch: 706 Train loss: 0.035769 Validation loss: 0.039405\n",
            "Epoch: 707 Train loss: 0.03736 Validation loss: 0.08079\n",
            "Epoch: 708 Train loss: 0.035665 Validation loss: 0.039319\n",
            "Epoch: 709 Train loss: 0.037238 Validation loss: 0.08057\n",
            "Epoch: 710 Train loss: 0.03556 Validation loss: 0.039232\n",
            "Epoch: 711 Train loss: 0.037116 Validation loss: 0.08035\n",
            "Epoch: 712 Train loss: 0.035455 Validation loss: 0.039145\n",
            "Epoch: 713 Train loss: 0.036992 Validation loss: 0.080128\n",
            "Epoch: 714 Train loss: 0.035348 Validation loss: 0.039057\n",
            "Epoch: 715 Train loss: 0.036868 Validation loss: 0.079905\n",
            "Epoch: 716 Train loss: 0.035241 Validation loss: 0.038969\n",
            "Epoch: 717 Train loss: 0.036743 Validation loss: 0.079681\n",
            "Epoch: 718 Train loss: 0.035132 Validation loss: 0.03888\n",
            "Epoch: 719 Train loss: 0.036616 Validation loss: 0.079455\n",
            "Epoch: 720 Train loss: 0.035023 Validation loss: 0.038791\n",
            "Epoch: 721 Train loss: 0.036489 Validation loss: 0.079227\n",
            "Epoch: 722 Train loss: 0.034912 Validation loss: 0.038701\n",
            "Epoch: 723 Train loss: 0.03636 Validation loss: 0.078998\n",
            "Epoch: 724 Train loss: 0.0348 Validation loss: 0.038611\n",
            "Epoch: 725 Train loss: 0.036231 Validation loss: 0.078767\n",
            "Epoch: 726 Train loss: 0.034688 Validation loss: 0.03852\n",
            "Epoch: 727 Train loss: 0.0361 Validation loss: 0.078535\n",
            "Epoch: 728 Train loss: 0.034574 Validation loss: 0.038428\n",
            "Epoch: 729 Train loss: 0.035968 Validation loss: 0.078301\n",
            "Epoch: 730 Train loss: 0.034459 Validation loss: 0.038336\n",
            "Epoch: 731 Train loss: 0.035836 Validation loss: 0.078066\n",
            "Epoch: 732 Train loss: 0.034343 Validation loss: 0.038243\n",
            "Epoch: 733 Train loss: 0.035702 Validation loss: 0.077829\n",
            "Epoch: 734 Train loss: 0.034227 Validation loss: 0.03815\n",
            "Epoch: 735 Train loss: 0.035567 Validation loss: 0.07759\n",
            "Epoch: 736 Train loss: 0.034109 Validation loss: 0.038056\n",
            "Epoch: 737 Train loss: 0.035431 Validation loss: 0.07735\n",
            "Epoch: 738 Train loss: 0.03399 Validation loss: 0.037962\n",
            "Epoch: 739 Train loss: 0.035294 Validation loss: 0.077108\n",
            "Epoch: 740 Train loss: 0.03387 Validation loss: 0.037867\n",
            "Epoch: 741 Train loss: 0.035156 Validation loss: 0.076866\n",
            "Epoch: 742 Train loss: 0.033748 Validation loss: 0.037771\n",
            "Epoch: 743 Train loss: 0.035017 Validation loss: 0.076621\n",
            "Epoch: 744 Train loss: 0.033626 Validation loss: 0.037675\n",
            "Epoch: 745 Train loss: 0.034876 Validation loss: 0.076374\n",
            "Epoch: 746 Train loss: 0.033503 Validation loss: 0.037578\n",
            "Epoch: 747 Train loss: 0.034735 Validation loss: 0.076125\n",
            "Epoch: 748 Train loss: 0.033378 Validation loss: 0.03748\n",
            "Epoch: 749 Train loss: 0.034592 Validation loss: 0.075875\n",
            "Epoch: 750 Train loss: 0.033252 Validation loss: 0.037382\n",
            "Epoch: 751 Train loss: 0.034448 Validation loss: 0.075623\n",
            "Epoch: 752 Train loss: 0.033124 Validation loss: 0.037283\n",
            "Epoch: 753 Train loss: 0.034302 Validation loss: 0.075369\n",
            "Epoch: 754 Train loss: 0.032996 Validation loss: 0.037184\n",
            "Epoch: 755 Train loss: 0.034156 Validation loss: 0.075113\n",
            "Epoch: 756 Train loss: 0.032866 Validation loss: 0.037084\n",
            "Epoch: 757 Train loss: 0.034008 Validation loss: 0.074856\n",
            "Epoch: 758 Train loss: 0.032735 Validation loss: 0.036983\n",
            "Epoch: 759 Train loss: 0.033859 Validation loss: 0.074596\n",
            "Epoch: 760 Train loss: 0.032603 Validation loss: 0.036881\n",
            "Epoch: 761 Train loss: 0.033709 Validation loss: 0.074335\n",
            "Epoch: 762 Train loss: 0.032469 Validation loss: 0.036779\n",
            "Epoch: 763 Train loss: 0.033557 Validation loss: 0.074071\n",
            "Epoch: 764 Train loss: 0.032334 Validation loss: 0.036676\n",
            "Epoch: 765 Train loss: 0.033405 Validation loss: 0.073806\n",
            "Epoch: 766 Train loss: 0.032198 Validation loss: 0.036573\n",
            "Epoch: 767 Train loss: 0.03325 Validation loss: 0.073539\n",
            "Epoch: 768 Train loss: 0.03206 Validation loss: 0.036469\n",
            "Epoch: 769 Train loss: 0.033095 Validation loss: 0.073271\n",
            "Epoch: 770 Train loss: 0.031921 Validation loss: 0.036364\n",
            "Epoch: 771 Train loss: 0.032938 Validation loss: 0.073\n",
            "Epoch: 772 Train loss: 0.03178 Validation loss: 0.036258\n",
            "Epoch: 773 Train loss: 0.03278 Validation loss: 0.072727\n",
            "Epoch: 774 Train loss: 0.031639 Validation loss: 0.036152\n",
            "Epoch: 775 Train loss: 0.032621 Validation loss: 0.072452\n",
            "Epoch: 776 Train loss: 0.031496 Validation loss: 0.036045\n",
            "Epoch: 777 Train loss: 0.03246 Validation loss: 0.072176\n",
            "Epoch: 778 Train loss: 0.031351 Validation loss: 0.035938\n",
            "Epoch: 779 Train loss: 0.032298 Validation loss: 0.071897\n",
            "Epoch: 780 Train loss: 0.031205 Validation loss: 0.035829\n",
            "Epoch: 781 Train loss: 0.032135 Validation loss: 0.071616\n",
            "Epoch: 782 Train loss: 0.031058 Validation loss: 0.035721\n",
            "Epoch: 783 Train loss: 0.03197 Validation loss: 0.071333\n",
            "Epoch: 784 Train loss: 0.030909 Validation loss: 0.035611\n",
            "Epoch: 785 Train loss: 0.031804 Validation loss: 0.071048\n",
            "Epoch: 786 Train loss: 0.030759 Validation loss: 0.035501\n",
            "Epoch: 787 Train loss: 0.031636 Validation loss: 0.070761\n",
            "Epoch: 788 Train loss: 0.030607 Validation loss: 0.03539\n",
            "Epoch: 789 Train loss: 0.031467 Validation loss: 0.070473\n",
            "Epoch: 790 Train loss: 0.030454 Validation loss: 0.035278\n",
            "Epoch: 791 Train loss: 0.031297 Validation loss: 0.070182\n",
            "Epoch: 792 Train loss: 0.030299 Validation loss: 0.035166\n",
            "Epoch: 793 Train loss: 0.031125 Validation loss: 0.069889\n",
            "Epoch: 794 Train loss: 0.030143 Validation loss: 0.035053\n",
            "Epoch: 795 Train loss: 0.030952 Validation loss: 0.069594\n",
            "Epoch: 796 Train loss: 0.029986 Validation loss: 0.03494\n",
            "Epoch: 797 Train loss: 0.030778 Validation loss: 0.069297\n",
            "Epoch: 798 Train loss: 0.029827 Validation loss: 0.034826\n",
            "Epoch: 799 Train loss: 0.030602 Validation loss: 0.068998\n",
            "Epoch: 800 Train loss: 0.029667 Validation loss: 0.034711\n",
            "Epoch: 801 Train loss: 0.030425 Validation loss: 0.068697\n",
            "Epoch: 802 Train loss: 0.029505 Validation loss: 0.034596\n",
            "Epoch: 803 Train loss: 0.030247 Validation loss: 0.068394\n",
            "Epoch: 804 Train loss: 0.029342 Validation loss: 0.03448\n",
            "Epoch: 805 Train loss: 0.030068 Validation loss: 0.068089\n",
            "Epoch: 806 Train loss: 0.029177 Validation loss: 0.034364\n",
            "Epoch: 807 Train loss: 0.029887 Validation loss: 0.067782\n",
            "Epoch: 808 Train loss: 0.029011 Validation loss: 0.034247\n",
            "Epoch: 809 Train loss: 0.029705 Validation loss: 0.067474\n",
            "Epoch: 810 Train loss: 0.028844 Validation loss: 0.034129\n",
            "Epoch: 811 Train loss: 0.029522 Validation loss: 0.067164\n",
            "Epoch: 812 Train loss: 0.028676 Validation loss: 0.034011\n",
            "Epoch: 813 Train loss: 0.029337 Validation loss: 0.066851\n",
            "Epoch: 814 Train loss: 0.028506 Validation loss: 0.033893\n",
            "Epoch: 815 Train loss: 0.029152 Validation loss: 0.066537\n",
            "Epoch: 816 Train loss: 0.028334 Validation loss: 0.033774\n",
            "Epoch: 817 Train loss: 0.028965 Validation loss: 0.066222\n",
            "Epoch: 818 Train loss: 0.028162 Validation loss: 0.033655\n",
            "Epoch: 819 Train loss: 0.028777 Validation loss: 0.065904\n",
            "Epoch: 820 Train loss: 0.027988 Validation loss: 0.033536\n",
            "Epoch: 821 Train loss: 0.028588 Validation loss: 0.065585\n",
            "Epoch: 822 Train loss: 0.027814 Validation loss: 0.033416\n",
            "Epoch: 823 Train loss: 0.028398 Validation loss: 0.065264\n",
            "Epoch: 824 Train loss: 0.027637 Validation loss: 0.033295\n",
            "Epoch: 825 Train loss: 0.028207 Validation loss: 0.064942\n",
            "Epoch: 826 Train loss: 0.02746 Validation loss: 0.033175\n",
            "Epoch: 827 Train loss: 0.028015 Validation loss: 0.064618\n",
            "Epoch: 828 Train loss: 0.027281 Validation loss: 0.033054\n",
            "Epoch: 829 Train loss: 0.027822 Validation loss: 0.064292\n",
            "Epoch: 830 Train loss: 0.027102 Validation loss: 0.032932\n",
            "Epoch: 831 Train loss: 0.027628 Validation loss: 0.063965\n",
            "Epoch: 832 Train loss: 0.026921 Validation loss: 0.032811\n",
            "Epoch: 833 Train loss: 0.027433 Validation loss: 0.063636\n",
            "Epoch: 834 Train loss: 0.026739 Validation loss: 0.032689\n",
            "Epoch: 835 Train loss: 0.027237 Validation loss: 0.063306\n",
            "Epoch: 836 Train loss: 0.026556 Validation loss: 0.032568\n",
            "Epoch: 837 Train loss: 0.02704 Validation loss: 0.062975\n",
            "Epoch: 838 Train loss: 0.026373 Validation loss: 0.032446\n",
            "Epoch: 839 Train loss: 0.026843 Validation loss: 0.062642\n",
            "Epoch: 840 Train loss: 0.026188 Validation loss: 0.032323\n",
            "Epoch: 841 Train loss: 0.026644 Validation loss: 0.062308\n",
            "Epoch: 842 Train loss: 0.026002 Validation loss: 0.032201\n",
            "Epoch: 843 Train loss: 0.026445 Validation loss: 0.061973\n",
            "Epoch: 844 Train loss: 0.025815 Validation loss: 0.032079\n",
            "Epoch: 845 Train loss: 0.026246 Validation loss: 0.061637\n",
            "Epoch: 846 Train loss: 0.025628 Validation loss: 0.031957\n",
            "Epoch: 847 Train loss: 0.026045 Validation loss: 0.061299\n",
            "Epoch: 848 Train loss: 0.02544 Validation loss: 0.031835\n",
            "Epoch: 849 Train loss: 0.025844 Validation loss: 0.060961\n",
            "Epoch: 850 Train loss: 0.025251 Validation loss: 0.031713\n",
            "Epoch: 851 Train loss: 0.025643 Validation loss: 0.060621\n",
            "Epoch: 852 Train loss: 0.025061 Validation loss: 0.031591\n",
            "Epoch: 853 Train loss: 0.02544 Validation loss: 0.060281\n",
            "Epoch: 854 Train loss: 0.024871 Validation loss: 0.031469\n",
            "Epoch: 855 Train loss: 0.025238 Validation loss: 0.05994\n",
            "Epoch: 856 Train loss: 0.024679 Validation loss: 0.031347\n",
            "Epoch: 857 Train loss: 0.025035 Validation loss: 0.059598\n",
            "Epoch: 858 Train loss: 0.024488 Validation loss: 0.031226\n",
            "Epoch: 859 Train loss: 0.024832 Validation loss: 0.059255\n",
            "Epoch: 860 Train loss: 0.024296 Validation loss: 0.031105\n",
            "Epoch: 861 Train loss: 0.024628 Validation loss: 0.058912\n",
            "Epoch: 862 Train loss: 0.024103 Validation loss: 0.030984\n",
            "Epoch: 863 Train loss: 0.024424 Validation loss: 0.058568\n",
            "Epoch: 864 Train loss: 0.02391 Validation loss: 0.030863\n",
            "Epoch: 865 Train loss: 0.024221 Validation loss: 0.058225\n",
            "Epoch: 866 Train loss: 0.023717 Validation loss: 0.030743\n",
            "Epoch: 867 Train loss: 0.024016 Validation loss: 0.05788\n",
            "Epoch: 868 Train loss: 0.023523 Validation loss: 0.030624\n",
            "Epoch: 869 Train loss: 0.023812 Validation loss: 0.057535\n",
            "Epoch: 870 Train loss: 0.023329 Validation loss: 0.030505\n",
            "Epoch: 871 Train loss: 0.023608 Validation loss: 0.05719\n",
            "Epoch: 872 Train loss: 0.023135 Validation loss: 0.030386\n",
            "Epoch: 873 Train loss: 0.023404 Validation loss: 0.056845\n",
            "Epoch: 874 Train loss: 0.022941 Validation loss: 0.030268\n",
            "Epoch: 875 Train loss: 0.0232 Validation loss: 0.0565\n",
            "Epoch: 876 Train loss: 0.022747 Validation loss: 0.030151\n",
            "Epoch: 877 Train loss: 0.022997 Validation loss: 0.056155\n",
            "Epoch: 878 Train loss: 0.022553 Validation loss: 0.030034\n",
            "Epoch: 879 Train loss: 0.022793 Validation loss: 0.05581\n",
            "Epoch: 880 Train loss: 0.02236 Validation loss: 0.029918\n",
            "Epoch: 881 Train loss: 0.02259 Validation loss: 0.055465\n",
            "Epoch: 882 Train loss: 0.022166 Validation loss: 0.029803\n",
            "Epoch: 883 Train loss: 0.022387 Validation loss: 0.05512\n",
            "Epoch: 884 Train loss: 0.021972 Validation loss: 0.029689\n",
            "Epoch: 885 Train loss: 0.022185 Validation loss: 0.054777\n",
            "Epoch: 886 Train loss: 0.021779 Validation loss: 0.029575\n",
            "Epoch: 887 Train loss: 0.021983 Validation loss: 0.054433\n",
            "Epoch: 888 Train loss: 0.021586 Validation loss: 0.029463\n",
            "Epoch: 889 Train loss: 0.021781 Validation loss: 0.05409\n",
            "Epoch: 890 Train loss: 0.021393 Validation loss: 0.029351\n",
            "Epoch: 891 Train loss: 0.021581 Validation loss: 0.053748\n",
            "Epoch: 892 Train loss: 0.021201 Validation loss: 0.02924\n",
            "Epoch: 893 Train loss: 0.021381 Validation loss: 0.053407\n",
            "Epoch: 894 Train loss: 0.02101 Validation loss: 0.029131\n",
            "Epoch: 895 Train loss: 0.021182 Validation loss: 0.053066\n",
            "Epoch: 896 Train loss: 0.020819 Validation loss: 0.029022\n",
            "Epoch: 897 Train loss: 0.020983 Validation loss: 0.052726\n",
            "Epoch: 898 Train loss: 0.020628 Validation loss: 0.028915\n",
            "Epoch: 899 Train loss: 0.020786 Validation loss: 0.052388\n",
            "Epoch: 900 Train loss: 0.020439 Validation loss: 0.028808\n",
            "Epoch: 901 Train loss: 0.020589 Validation loss: 0.05205\n",
            "Epoch: 902 Train loss: 0.02025 Validation loss: 0.028703\n",
            "Epoch: 903 Train loss: 0.020394 Validation loss: 0.051714\n",
            "Epoch: 904 Train loss: 0.020063 Validation loss: 0.028599\n",
            "Epoch: 905 Train loss: 0.0202 Validation loss: 0.051379\n",
            "Epoch: 906 Train loss: 0.019876 Validation loss: 0.028497\n",
            "Epoch: 907 Train loss: 0.020006 Validation loss: 0.051046\n",
            "Epoch: 908 Train loss: 0.01969 Validation loss: 0.028395\n",
            "Epoch: 909 Train loss: 0.019814 Validation loss: 0.050713\n",
            "Epoch: 910 Train loss: 0.019505 Validation loss: 0.028295\n",
            "Epoch: 911 Train loss: 0.019623 Validation loss: 0.050383\n",
            "Epoch: 912 Train loss: 0.019321 Validation loss: 0.028197\n",
            "Epoch: 913 Train loss: 0.019433 Validation loss: 0.050054\n",
            "Epoch: 914 Train loss: 0.019138 Validation loss: 0.0281\n",
            "Epoch: 915 Train loss: 0.019245 Validation loss: 0.049726\n",
            "Epoch: 916 Train loss: 0.018956 Validation loss: 0.028004\n",
            "Epoch: 917 Train loss: 0.019058 Validation loss: 0.049401\n",
            "Epoch: 918 Train loss: 0.018776 Validation loss: 0.027909\n",
            "Epoch: 919 Train loss: 0.018873 Validation loss: 0.049077\n",
            "Epoch: 920 Train loss: 0.018597 Validation loss: 0.027817\n",
            "Epoch: 921 Train loss: 0.018689 Validation loss: 0.048756\n",
            "Epoch: 922 Train loss: 0.01842 Validation loss: 0.027725\n",
            "Epoch: 923 Train loss: 0.018507 Validation loss: 0.048436\n",
            "Epoch: 924 Train loss: 0.018244 Validation loss: 0.027635\n",
            "Epoch: 925 Train loss: 0.018326 Validation loss: 0.048118\n",
            "Epoch: 926 Train loss: 0.018069 Validation loss: 0.027547\n",
            "Epoch: 927 Train loss: 0.018147 Validation loss: 0.047802\n",
            "Epoch: 928 Train loss: 0.017896 Validation loss: 0.027461\n",
            "Epoch: 929 Train loss: 0.017969 Validation loss: 0.047489\n",
            "Epoch: 930 Train loss: 0.017724 Validation loss: 0.027376\n",
            "Epoch: 931 Train loss: 0.017793 Validation loss: 0.047178\n",
            "Epoch: 932 Train loss: 0.017554 Validation loss: 0.027292\n",
            "Epoch: 933 Train loss: 0.017619 Validation loss: 0.046869\n",
            "Epoch: 934 Train loss: 0.017386 Validation loss: 0.02721\n",
            "Epoch: 935 Train loss: 0.017447 Validation loss: 0.046563\n",
            "Epoch: 936 Train loss: 0.017219 Validation loss: 0.02713\n",
            "Epoch: 937 Train loss: 0.017277 Validation loss: 0.046259\n",
            "Epoch: 938 Train loss: 0.017054 Validation loss: 0.027052\n",
            "Epoch: 939 Train loss: 0.017108 Validation loss: 0.045957\n",
            "Epoch: 940 Train loss: 0.016891 Validation loss: 0.026975\n",
            "Epoch: 941 Train loss: 0.016942 Validation loss: 0.045658\n",
            "Epoch: 942 Train loss: 0.016729 Validation loss: 0.0269\n",
            "Epoch: 943 Train loss: 0.016777 Validation loss: 0.045362\n",
            "Epoch: 944 Train loss: 0.01657 Validation loss: 0.026827\n",
            "Epoch: 945 Train loss: 0.016614 Validation loss: 0.045068\n",
            "Epoch: 946 Train loss: 0.016412 Validation loss: 0.026755\n",
            "Epoch: 947 Train loss: 0.016453 Validation loss: 0.044777\n",
            "Epoch: 948 Train loss: 0.016256 Validation loss: 0.026685\n",
            "Epoch: 949 Train loss: 0.016295 Validation loss: 0.044489\n",
            "Epoch: 950 Train loss: 0.016102 Validation loss: 0.026617\n",
            "Epoch: 951 Train loss: 0.016138 Validation loss: 0.044204\n",
            "Epoch: 952 Train loss: 0.01595 Validation loss: 0.02655\n",
            "Epoch: 953 Train loss: 0.015983 Validation loss: 0.043921\n",
            "Epoch: 954 Train loss: 0.0158 Validation loss: 0.026485\n",
            "Epoch: 955 Train loss: 0.015831 Validation loss: 0.043641\n",
            "Epoch: 956 Train loss: 0.015651 Validation loss: 0.026422\n",
            "Epoch: 957 Train loss: 0.01568 Validation loss: 0.043364\n",
            "Epoch: 958 Train loss: 0.015505 Validation loss: 0.026361\n",
            "Epoch: 959 Train loss: 0.015532 Validation loss: 0.04309\n",
            "Epoch: 960 Train loss: 0.015361 Validation loss: 0.026301\n",
            "Epoch: 961 Train loss: 0.015385 Validation loss: 0.042818\n",
            "Epoch: 962 Train loss: 0.015219 Validation loss: 0.026243\n",
            "Epoch: 963 Train loss: 0.015241 Validation loss: 0.04255\n",
            "Epoch: 964 Train loss: 0.015079 Validation loss: 0.026187\n",
            "Epoch: 965 Train loss: 0.015099 Validation loss: 0.042285\n",
            "Epoch: 966 Train loss: 0.014941 Validation loss: 0.026133\n",
            "Epoch: 967 Train loss: 0.014959 Validation loss: 0.042022\n",
            "Epoch: 968 Train loss: 0.014804 Validation loss: 0.02608\n",
            "Epoch: 969 Train loss: 0.014821 Validation loss: 0.041763\n",
            "Epoch: 970 Train loss: 0.014671 Validation loss: 0.026029\n",
            "Epoch: 971 Train loss: 0.014686 Validation loss: 0.041507\n",
            "Epoch: 972 Train loss: 0.014539 Validation loss: 0.025979\n",
            "Epoch: 973 Train loss: 0.014552 Validation loss: 0.041254\n",
            "Epoch: 974 Train loss: 0.014409 Validation loss: 0.025932\n",
            "Epoch: 975 Train loss: 0.014421 Validation loss: 0.041004\n",
            "Epoch: 976 Train loss: 0.014281 Validation loss: 0.025886\n",
            "Epoch: 977 Train loss: 0.014292 Validation loss: 0.040757\n",
            "Epoch: 978 Train loss: 0.014155 Validation loss: 0.025841\n",
            "Epoch: 979 Train loss: 0.014165 Validation loss: 0.040513\n",
            "Epoch: 980 Train loss: 0.014032 Validation loss: 0.025798\n",
            "Epoch: 981 Train loss: 0.01404 Validation loss: 0.040271\n",
            "Epoch: 982 Train loss: 0.01391 Validation loss: 0.025757\n",
            "Epoch: 983 Train loss: 0.013918 Validation loss: 0.040033\n",
            "Epoch: 984 Train loss: 0.013791 Validation loss: 0.025717\n",
            "Epoch: 985 Train loss: 0.013797 Validation loss: 0.039798\n",
            "Epoch: 986 Train loss: 0.013673 Validation loss: 0.025679\n",
            "Epoch: 987 Train loss: 0.013679 Validation loss: 0.039567\n",
            "Epoch: 988 Train loss: 0.013558 Validation loss: 0.025643\n",
            "Epoch: 989 Train loss: 0.013562 Validation loss: 0.039338\n",
            "Epoch: 990 Train loss: 0.013445 Validation loss: 0.025608\n",
            "Epoch: 991 Train loss: 0.013448 Validation loss: 0.039112\n",
            "Epoch: 992 Train loss: 0.013333 Validation loss: 0.025574\n",
            "Epoch: 993 Train loss: 0.013336 Validation loss: 0.03889\n",
            "Epoch: 994 Train loss: 0.013224 Validation loss: 0.025542\n",
            "Epoch: 995 Train loss: 0.013226 Validation loss: 0.03867\n",
            "Epoch: 996 Train loss: 0.013117 Validation loss: 0.025512\n",
            "Epoch: 997 Train loss: 0.013118 Validation loss: 0.038453\n",
            "Epoch: 998 Train loss: 0.013012 Validation loss: 0.025483\n",
            "Epoch: 999 Train loss: 0.013012 Validation loss: 0.03824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylr1C2ovWXbO"
      },
      "source": [
        "During the training of the regularized model we can already notice, that, although there is still a difference between training and validation loss, the validation loss decreases as the training loss dreases. The effect of the regularization becomes even more evident if we plot the predictions of the regularized model and the overfitting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdMRV0vAWLmm",
        "outputId": "4c208b46-a34d-4d33-d5a3-7b0db9a90482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We now want to plot the prediction of the regularized and unregularized big model. \"\"\"\n",
        "\n",
        "y_pred = big_reg_mdl(x) # Predict with \"big_reg_mdl\" on \"x\"\n",
        "y_pred_overfit = big_mdl(x) # Predict with \"big_mdl\" on \"x\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.plot(x, y_pred_overfit.numpy())\n",
        "plt.legend([\"Target\", \"Regularization\", \"No regularization\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sePQBaGqZzT6"
      },
      "source": [
        "The model with regularization seems to follow the overall trend of the data, while the model without any regularization very precisely fits the training samples. This is espacilly evident in the interval $\\left[0,0.5\\right]$, where the prediction of the unregularized model shows an oscillating behavior. Such oscillations are however not present in the ground truth and therefore undesirable. The regularized model on the other hand is not as flexible as the unregularized model and therefore does not fit the target function well in the interval $\\left[2.25, 3.0\\right]$.\n",
        "\n",
        "## Conclusion\n",
        "In this exercise we revisited the mathematical background for a simple regression task and covered it's practical implementation in Tensorflow 2. We also explored the phenomenon of overfitting and derived different regularizations from a probabilistic perspective. This exercise covers a very simple task with a very basic neural architecture and is intended as a primer for the second part of the regression exercise, which is dealing with a bigger and more realistic problem. In this second part we will consider the problem of estimating the age of a person from a potrait picture."
      ]
    }
  ]
}