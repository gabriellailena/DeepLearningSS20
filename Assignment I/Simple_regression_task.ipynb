{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_regression_task_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellailena/DeepLearningSS20/blob/master/Simple_regression_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjlEFdXpMgvw"
      },
      "source": [
        "# Deep learning programming I-A: Regression\n",
        "Felix Wiewel, Institute of Signal Processing and System Theory, University of Stuttgart, 24.04.2020\n",
        "\n",
        "## Introduction\n",
        "This programming exercise is the first of a series of exercises, which are intended as a supplement to the theoretical part of the Deep Learning course offered by the ISS. The goal is to introduce you to basic tasks and applications of methods you have encountered in the lecture. After completing the exercise you should be familiar with the basic ideas and one, possibly simple, way of solving the respective task. It is worth mentioning that most of the tasks can be solved in many different, not necessarily deep learning based, ways and the solution presented here is just one of them.\n",
        "\n",
        "## Regression\n",
        "\n",
        "In this exercise we consider the problem of regression, where we are interested in modeling a functional dependence between different variables with, possibly noisy, observations of input-output pairs. Mathematically such a dependence can be formulated as\n",
        "\n",
        "$\\mathbf{y}=f(\\mathbf{x})+\\boldsymbol{\\epsilon}$,\n",
        "\n",
        "where $\\mathbf{y}\\in\\mathbb{R}^{M}$ and $\\mathbf{x}\\in\\mathbb{R}^{N}$ are the input and output observations, $f:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ is the function mapping inputs to outputs and $\\boldsymbol{\\epsilon}\\in\\mathbb{R}^{M}$ is a random vector, which models noise in our observations. Note that this assumes additive noise that only acts on the output and not on the input variable, which might not be true in all practical applications but is a reasonable approximation. For regression we are now interested in estimating the functional relationship $f$ between the inputs and outputs. This can be done in many different ways, not just with neural networks, but for this exercise we focus on approximating this relationship with a neural network $g_{\\boldsymbol{\\theta}}:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ with parameter vector $\\boldsymbol{\\theta}$. The task is now to choose the parameters of the neural network in a way that results in a \"good\" approximation of $f$ with $g_{\\boldsymbol{\\theta}}$.\n",
        "\n",
        "In order to quantify how \"good\" our neural network can approximate $f$, we adopt a probabilistic view. For this we make the assumption that the noise $\\boldsymbol{\\epsilon}$ is a random vector drawn from a known dustribution, which enables us to derive a suitable cost function for training our neural network and also for quantifying a \"good\" approximation.\n",
        "\n",
        "### Mathematical formulation\n",
        "If we assume that the noise $\\boldsymbol{\\epsilon}$ is drawn from a gaussian distribution, e.g. $\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$, we can use\n",
        "\n",
        "$\\mathbf{y}=g_{\\boldsymbol{\\theta}}(\\mathbf{x})+\\boldsymbol{\\epsilon}\\Rightarrow \\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})=\\boldsymbol{\\epsilon}$\n",
        "\n",
        "to derive a log likelihood. Since the probability density function (pdf) of a multivariate normal distribution is given by\n",
        "\n",
        "$p(\\mathbf{x})=\\dfrac{1}{\\sqrt{(2\\pi)^{D}\\vert\\mathbf{C}\\vert}}\\mathrm{e}^{-\\dfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})\\mathbf{C}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})^{T}}$,\n",
        "\n",
        "we get\n",
        "\n",
        "$\\ln{p(\\boldsymbol{\\epsilon})}=\\ln{\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}}}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$.\n",
        "\n",
        "Replacing $\\boldsymbol{\\epsilon}$ by $\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})$ yields the log likelihood for one particular input-output pair:\n",
        "\n",
        "$\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})=\\ln {p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$\n",
        "\n",
        "This log likelihood measures how likely the input-output pair is and we can use it to train our neural network. For this we maximize the expected log likelihood over all input-output pairs under the assumption that the noise is idependent and identically distributed (i.i.d.) over all input-output pairs. This corresponds to finding the parameters $\\boldsymbol{\\theta}^{\\star}$ of our neural network, which maximize the the expected probability for observing the corresponding input-output pairs. Mathematically the optimal parameters for our neural network are given by\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[-\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}\\right]\\approx\\arg\\min_{\\boldsymbol{\\theta}}\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where all terms, which are independent of $\\boldsymbol{\\theta}$, are ignored and the expectation operator is approximated by the mean over all $N_{D}$ input-output pairs. In other words we are maximizing the log likelihood by minimizing the mean squared error loss over all input-output pairs in our dataset, hence this approach is called Maximum Likelihood (ML) estimation. For solving this optimization problem and obtaining the optimal network parameters, stochastic gradient descent (SGD) or one of it's many variants is typically used.\n",
        "\n",
        "It is worth noting, that choosing different distributions for the noise $\\boldsymbol{\\epsilon}$ leads to different log likelihoods and therefore different cost functions for training the neural network. Another commonly used distribution for modelling the noise in regression tasks is the laplace distribution. Deriving the log likelihood and the corresponding costfunction leads to the mean absolute error, which is given by the $l_{1}$-norm of the difference between observations predictions of the neural network. This cost function is considered more robust against outliers since these have less influence on the averall loss compared to the mean squared error.\n",
        "\n",
        "###  Implementation\n",
        "\n",
        "In the following we consider a simple regression task, implement a neural network and train it based on the mathematical fomrulation above. For this we first need to create a set of input-output pairs, which then needs to be partitioned into a training, validation and test set. We also define some constants to be used for partitioning the data and the hyperparameters for our neural network.\n",
        "\n",
        "But before we can start, we need to import the necessary packages tensorflow, numpy and matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPuVp2lyNK2J",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J84v9uucMgv5"
      },
      "source": [
        "Next we define our constants and set the random seeds of tensorflow and numpy in order to get reproducable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwC-1OnHMgv7",
        "colab": {}
      },
      "source": [
        "N_train_samples = 600\n",
        "N_validation_samples = 100\n",
        "N_test_samples = 100\n",
        "N_samples = N_train_samples + N_validation_samples + N_test_samples\n",
        "noise_sig = 0.1\n",
        "N_epochs = 150\n",
        "batch_size = 8\n",
        "learning_rate = 0.01\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngFFSyG-MgwA"
      },
      "source": [
        "We create $600$ training samples, $100$ validation samples to optimize our hyperparameters and $100$ test samples, which are used to check if our model can generalize to unseen data. Furthermore we set the level of noise added to the observations. For training the model we plan to train it for $150$ epochs with a batch size of $8$ and a learning rate of $0.01$. Next we create the actual input-output pairs $\\mathbf{x},\\mathbf{y}$ for which we want to learn the regression model and plot them. In this simple example we choose scalar inputs as well as output but in general $\\mathbf{x}$ and $\\mathbf{y}$ can be vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4s8AtsdQMgwB",
        "outputId": "58361b24-a10c-4400-9c38-c64753b3df6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = np.linspace(0.0, 3.0, N_samples, dtype=np.float32)\n",
        "y = np.expand_dims(np.sin(1.0+x*x) + noise_sig*np.random.randn(N_samples).astype(np.float32), axis=-1)\n",
        "y_true = np.sin(1.0+x*x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.legend([\"Observation\", \"Ground truth\"])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3wx8vJlMgwI"
      },
      "source": [
        "With the input-output pairs created, your first task is now to partition the data in the training, validation and test sets. Keep in mind that we have created the data in a structured way, i.e. the input-output pairs are ordered. This means you need to shuffle the data before partitioning it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDIMUZs0MgwK",
        "colab": {}
      },
      "source": [
        "\"\"\" Shuffle and partition the data set accordingly. you can use the predefined constants \"N_train_samples\", \"N_validation_samples\" and \"N_test_samples\". Use the variable names that are already in the below code \n",
        "to store the final shuffled and partitioned data. Hint: Shuffle the data and the labels in such a way that the pairing between an image and it's label is preserved.\"\"\"\n",
        "# Shuffle the data\n",
        "c = np.column_stack((x, y))\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(c)\n",
        "\n",
        "# Partition the data\n",
        "x_train = c[:N_train_samples, 0]\n",
        "y_train = c[:N_train_samples, 1]\n",
        "x_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 0]\n",
        "y_validation = c[N_train_samples:(N_train_samples + N_validation_samples), 1]\n",
        "x_test = c[(N_train_samples + N_validation_samples):N_samples, 0]\n",
        "y_test = c[(N_train_samples + N_validation_samples):N_samples, 1]\n",
        "# print(c[0, :], x_train[0], y_train[0])\n",
        "# print(c[600, :], x_validation[0], y_validation[0])\n",
        "# print(c[-1, :], x_test[-1], y_test[-1])\n",
        "\n",
        "\n",
        "# Cell testing\n",
        "assert np.array_equal(c[:,0], np.concatenate((x_train, x_validation, x_test))), \"Column 0 of c (x) does not have the same shape and/or elements as its splits.\"\n",
        "assert np.array_equal(c[:,1], np.concatenate((y_train, y_validation, y_test))), \"Column 1 of c (y) does not have the same shape and/or elements as its splits.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ucvKRhOMgwN"
      },
      "source": [
        "In order to feed the data to our model, we will use the Dataset class provided by Tensorflow. This class is simple to use and provides all the functionality we need for shuffling, batching and feeding the data to our model. It is also tightly integrated into the Tensorflow framework, which makes it very performant. Performance is not an aspect we need to worry about in this exercise, but it is important in more demanding applications.\n",
        "\n",
        "In this exercise we instantiate a separate Dataset object for the training, validation and test data sets, where we shuffle and repeat just the training data set. Shuffling the validation and test data sets is not necessary, since we only evaluate the loss on those data sets and do not perform SGD on it. Please fill in the missing part of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HifQ63iPMgwP",
        "colab": {}
      },
      "source": [
        "\"\"\" Create three tensorflow Dataset objects that can be used to feed the training test and validation data to a neural network. Hint: For the training data set use shuffling, batching with the size according to\n",
        "the predefined constant \"batch_size\" and repeat the data set indefinetly. For the validation and test data sets no shuffling or batching is needed.\"\"\"\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(N_train_samples).batch(batch_size).repeat()\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \n",
        "\n",
        "# print(list(validation_ds.as_numpy_iterator()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Crr6fIkMgwT"
      },
      "source": [
        "In this exercise we will create a a simple neural network with two hidden layers containing $10$ neurons. For creating a model and keeping track of its weights a class called MyModel is used. When initializing an instance of this class the necessary variables are created and stored in a list called \"trainable_variables\". This makes it easy to get all trainable variables of the model. We also override the \\__call__ method of this class in order to implement the forward pass of the neural network. This method should accept the inputs to the neural network and should return the result of the forward pass as an output. Please fill in the missing part of the code and select suitable activation functions for the different layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nq8ri416MgwX",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a neural network with two hidden dense layers containing 10 neurons each. As an activation function use the tangens hyperbolicus (tf.nn.tanh()). Since we are not using Keras, we need to create and \n",
        "manage all the variables that we need ourselves. The varaibles are created in the constructor of our model class. Since we want to be able to just call the class with some inputs in order to make a prediction, \n",
        "we implement a __call__ method which computes the forward pass and returns the output of the network.\"\"\"\n",
        "\n",
        "class MyModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,10], mean=0.0, stddev=1.0), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.zeros([10]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([10,10], mean=0.0, stddev=1.0), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.zeros([10]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([10,1], mean=0.0, stddev=1.0), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.zeros([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uf6m8zXoMgwb"
      },
      "source": [
        "Now after the model class is defined we can instantiate a MyModel object by running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSfI8wjLMgwb",
        "colab": {}
      },
      "source": [
        "mdl = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KraeH6MsMgwh"
      },
      "source": [
        "We can now use the model to make predictions by calling it. In the following we predict on the inputs an plot the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1at5RObMgwi",
        "outputId": "688b6ae4-8e8c-4b36-b824-e75898000526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We want to plot a prediction on the complete data set with a model before training. For this make a prediction on the variable \"x\". \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "utFkv4F3NULQ"
      },
      "source": [
        "Since we have initialized the variables of the neural network randomly, it's prediction is also random. In order to fit the model we need to minimize the expected mean squared error over all input-ouput pairs in our training data set. For this we need to create a function, that performs a training step when provided with the model, an optimizer and a batch of input-ouput pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4zFN0-kOdu7",
        "colab": {}
      },
      "source": [
        "\"\"\" For training we need to implement a function that executes one training step. Fill in the missing code pieces for this function.\"\"\"\n",
        "\n",
        "def train_step(model, optimizer, x, y):\n",
        "    y = tf.reshape(y, [-1, 1])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.math.squared_difference(y_pred, y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "    grads = tape.gradient(loss_val, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ax-Kfd-tOm7I"
      },
      "source": [
        "This function uses the GradientTape to record the operations for which gradients have to be calculated. In our case this is the forward pass through our model and the computation of the loss function. After these operations are recoded we can get their gradients and apply these through the use of an optimizer. Finally we return the loss value in order to print it.\n",
        "\n",
        "With the training step function defined we now need to choose a suitable optimizer. Tensorflow offers a wide variety of optimizers but in this exercise we will use the RMSprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PahsqMscPcKD",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.RMSprop(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8_WjHrAwQB9e"
      },
      "source": [
        "We now have everything we need to start training the model. For this we repeatedly sample a batch of input-output pairs from our training data set and use the train_step function to minimize the loss function over this batch. We repeat this until we have iterated over the complete training data set once. After this we compute the loss on the validation data set, print it and repeat with another epoch until we have reached $N\\_epochs$ epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3LqS3d_QrX6",
        "outputId": "14b7748a-dad1-4e46-faf1-0c8f6cf4cf80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" We can now use the train_step function to perform the training. Fill in the missing code parts.\"\"\"\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_ds:\n",
        "    train_loss += train_step(mdl, opt, x_t, y_t) # Perform a training step with the model \"mdl\" and the optimizer \"opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples // batch_size) == 0: # An epoch is completed\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = mdl(x_v) # Compute a prediction with \"mdl\" on the input \"x_v\"\n",
        "            validation_loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0.43812 Validation loss: 0.92038\n",
            "Epoch: 1 Train loss: 0.35826 Validation loss: 1.2416\n",
            "Epoch: 2 Train loss: 0.33091 Validation loss: 0.50993\n",
            "Epoch: 3 Train loss: 0.29476 Validation loss: 0.47495\n",
            "Epoch: 4 Train loss: 0.26221 Validation loss: 0.6253\n",
            "Epoch: 5 Train loss: 0.22259 Validation loss: 0.021068\n",
            "Epoch: 6 Train loss: 0.19842 Validation loss: 0.81773\n",
            "Epoch: 7 Train loss: 0.17753 Validation loss: 0.22124\n",
            "Epoch: 8 Train loss: 0.17328 Validation loss: 0.18453\n",
            "Epoch: 9 Train loss: 0.1705 Validation loss: 0.031602\n",
            "Epoch: 10 Train loss: 0.15118 Validation loss: 0.36881\n",
            "Epoch: 11 Train loss: 0.1484 Validation loss: 0.13477\n",
            "Epoch: 12 Train loss: 0.13393 Validation loss: 0.53517\n",
            "Epoch: 13 Train loss: 0.11545 Validation loss: 0.36467\n",
            "Epoch: 14 Train loss: 0.10413 Validation loss: 0.10849\n",
            "Epoch: 15 Train loss: 0.10011 Validation loss: 0.10842\n",
            "Epoch: 16 Train loss: 0.090285 Validation loss: 0.10239\n",
            "Epoch: 17 Train loss: 0.089267 Validation loss: 0.0073918\n",
            "Epoch: 18 Train loss: 0.086617 Validation loss: 0.12743\n",
            "Epoch: 19 Train loss: 0.084354 Validation loss: 0.16196\n",
            "Epoch: 20 Train loss: 0.070002 Validation loss: 0.022834\n",
            "Epoch: 21 Train loss: 0.063605 Validation loss: 0.0074368\n",
            "Epoch: 22 Train loss: 0.057414 Validation loss: 0.0037647\n",
            "Epoch: 23 Train loss: 0.05004 Validation loss: 0.010298\n",
            "Epoch: 24 Train loss: 0.048401 Validation loss: 0.0018839\n",
            "Epoch: 25 Train loss: 0.042474 Validation loss: 0.0096482\n",
            "Epoch: 26 Train loss: 0.042967 Validation loss: 0.005551\n",
            "Epoch: 27 Train loss: 0.037542 Validation loss: 0.001633\n",
            "Epoch: 28 Train loss: 0.040069 Validation loss: 0.025961\n",
            "Epoch: 29 Train loss: 0.037432 Validation loss: 0.020469\n",
            "Epoch: 30 Train loss: 0.037598 Validation loss: 0.003519\n",
            "Epoch: 31 Train loss: 0.032446 Validation loss: 0.037156\n",
            "Epoch: 32 Train loss: 0.032534 Validation loss: 9.8381e-06\n",
            "Epoch: 33 Train loss: 0.031396 Validation loss: 0.00042045\n",
            "Epoch: 34 Train loss: 0.029965 Validation loss: 1.5312e-07\n",
            "Epoch: 35 Train loss: 0.028008 Validation loss: 0.003345\n",
            "Epoch: 36 Train loss: 0.032355 Validation loss: 0.00028504\n",
            "Epoch: 37 Train loss: 0.030783 Validation loss: 0.00093259\n",
            "Epoch: 38 Train loss: 0.031772 Validation loss: 1.7888e-05\n",
            "Epoch: 39 Train loss: 0.028495 Validation loss: 0.0048444\n",
            "Epoch: 40 Train loss: 0.0318 Validation loss: 0.017015\n",
            "Epoch: 41 Train loss: 0.027979 Validation loss: 0.0040943\n",
            "Epoch: 42 Train loss: 0.028363 Validation loss: 0.00015311\n",
            "Epoch: 43 Train loss: 0.028584 Validation loss: 0.00053807\n",
            "Epoch: 44 Train loss: 0.031566 Validation loss: 0.001644\n",
            "Epoch: 45 Train loss: 0.02773 Validation loss: 0.071833\n",
            "Epoch: 46 Train loss: 0.028567 Validation loss: 0.0034771\n",
            "Epoch: 47 Train loss: 0.025742 Validation loss: 0.0069053\n",
            "Epoch: 48 Train loss: 0.026119 Validation loss: 0.0083898\n",
            "Epoch: 49 Train loss: 0.028179 Validation loss: 0.0015925\n",
            "Epoch: 50 Train loss: 0.024142 Validation loss: 0.009995\n",
            "Epoch: 51 Train loss: 0.027067 Validation loss: 0.0070058\n",
            "Epoch: 52 Train loss: 0.025747 Validation loss: 0.015124\n",
            "Epoch: 53 Train loss: 0.025528 Validation loss: 0.00087973\n",
            "Epoch: 54 Train loss: 0.027529 Validation loss: 0.0034651\n",
            "Epoch: 55 Train loss: 0.025442 Validation loss: 0.0002664\n",
            "Epoch: 56 Train loss: 0.025115 Validation loss: 0.00044706\n",
            "Epoch: 57 Train loss: 0.027402 Validation loss: 0.00013311\n",
            "Epoch: 58 Train loss: 0.024267 Validation loss: 0.00074985\n",
            "Epoch: 59 Train loss: 0.025104 Validation loss: 0.00071041\n",
            "Epoch: 60 Train loss: 0.02558 Validation loss: 0.046773\n",
            "Epoch: 61 Train loss: 0.024736 Validation loss: 0.0099729\n",
            "Epoch: 62 Train loss: 0.025001 Validation loss: 0.0023906\n",
            "Epoch: 63 Train loss: 0.026413 Validation loss: 0.019899\n",
            "Epoch: 64 Train loss: 0.026269 Validation loss: 0.0076679\n",
            "Epoch: 65 Train loss: 0.02311 Validation loss: 0.005754\n",
            "Epoch: 66 Train loss: 0.021781 Validation loss: 0.047629\n",
            "Epoch: 67 Train loss: 0.026123 Validation loss: 0.0013652\n",
            "Epoch: 68 Train loss: 0.024171 Validation loss: 0.00025649\n",
            "Epoch: 69 Train loss: 0.024509 Validation loss: 0.0060965\n",
            "Epoch: 70 Train loss: 0.023984 Validation loss: 0.001192\n",
            "Epoch: 71 Train loss: 0.02548 Validation loss: 0.0038111\n",
            "Epoch: 72 Train loss: 0.025804 Validation loss: 0.00082512\n",
            "Epoch: 73 Train loss: 0.02215 Validation loss: 0.0046584\n",
            "Epoch: 74 Train loss: 0.024846 Validation loss: 0.046022\n",
            "Epoch: 75 Train loss: 0.024112 Validation loss: 0.0013234\n",
            "Epoch: 76 Train loss: 0.021687 Validation loss: 0.0003765\n",
            "Epoch: 77 Train loss: 0.022043 Validation loss: 0.0015354\n",
            "Epoch: 78 Train loss: 0.025066 Validation loss: 0.01736\n",
            "Epoch: 79 Train loss: 0.025672 Validation loss: 0.005343\n",
            "Epoch: 80 Train loss: 0.020543 Validation loss: 0.0040479\n",
            "Epoch: 81 Train loss: 0.024558 Validation loss: 0.0075349\n",
            "Epoch: 82 Train loss: 0.021662 Validation loss: 0.002103\n",
            "Epoch: 83 Train loss: 0.024022 Validation loss: 0.011478\n",
            "Epoch: 84 Train loss: 0.022074 Validation loss: 0.0020035\n",
            "Epoch: 85 Train loss: 0.024732 Validation loss: 0.0021256\n",
            "Epoch: 86 Train loss: 0.023453 Validation loss: 0.0095466\n",
            "Epoch: 87 Train loss: 0.021894 Validation loss: 0.0004992\n",
            "Epoch: 88 Train loss: 0.023696 Validation loss: 0.022922\n",
            "Epoch: 89 Train loss: 0.023367 Validation loss: 0.0038169\n",
            "Epoch: 90 Train loss: 0.022987 Validation loss: 0.010803\n",
            "Epoch: 91 Train loss: 0.023415 Validation loss: 0.0046334\n",
            "Epoch: 92 Train loss: 0.021897 Validation loss: 0.0046721\n",
            "Epoch: 93 Train loss: 0.022945 Validation loss: 0.00026615\n",
            "Epoch: 94 Train loss: 0.022069 Validation loss: 0.0041033\n",
            "Epoch: 95 Train loss: 0.024545 Validation loss: 3.8331e-06\n",
            "Epoch: 96 Train loss: 0.020116 Validation loss: 0.0043846\n",
            "Epoch: 97 Train loss: 0.023069 Validation loss: 0.0065411\n",
            "Epoch: 98 Train loss: 0.022363 Validation loss: 0.0010257\n",
            "Epoch: 99 Train loss: 0.021032 Validation loss: 0.014287\n",
            "Epoch: 100 Train loss: 0.021271 Validation loss: 0.00027029\n",
            "Epoch: 101 Train loss: 0.022134 Validation loss: 0.016651\n",
            "Epoch: 102 Train loss: 0.024332 Validation loss: 0.0071431\n",
            "Epoch: 103 Train loss: 0.0211 Validation loss: 0.047056\n",
            "Epoch: 104 Train loss: 0.021859 Validation loss: 0.0035466\n",
            "Epoch: 105 Train loss: 0.020049 Validation loss: 0.00043724\n",
            "Epoch: 106 Train loss: 0.022963 Validation loss: 0.0017237\n",
            "Epoch: 107 Train loss: 0.023725 Validation loss: 0.0015092\n",
            "Epoch: 108 Train loss: 0.020485 Validation loss: 0.022669\n",
            "Epoch: 109 Train loss: 0.021046 Validation loss: 0.0071816\n",
            "Epoch: 110 Train loss: 0.020396 Validation loss: 0.000103\n",
            "Epoch: 111 Train loss: 0.02194 Validation loss: 0.00022052\n",
            "Epoch: 112 Train loss: 0.019023 Validation loss: 0.015011\n",
            "Epoch: 113 Train loss: 0.022109 Validation loss: 0.01398\n",
            "Epoch: 114 Train loss: 0.021733 Validation loss: 0.0011898\n",
            "Epoch: 115 Train loss: 0.022801 Validation loss: 0.010969\n",
            "Epoch: 116 Train loss: 0.020174 Validation loss: 0.0019971\n",
            "Epoch: 117 Train loss: 0.020836 Validation loss: 0.0016889\n",
            "Epoch: 118 Train loss: 0.021497 Validation loss: 0.00077053\n",
            "Epoch: 119 Train loss: 0.020441 Validation loss: 0.008306\n",
            "Epoch: 120 Train loss: 0.019872 Validation loss: 2.7477e-06\n",
            "Epoch: 121 Train loss: 0.022067 Validation loss: 0.00054335\n",
            "Epoch: 122 Train loss: 0.021756 Validation loss: 0.00079731\n",
            "Epoch: 123 Train loss: 0.021227 Validation loss: 0.0073913\n",
            "Epoch: 124 Train loss: 0.020663 Validation loss: 0.00041247\n",
            "Epoch: 125 Train loss: 0.018804 Validation loss: 0.017997\n",
            "Epoch: 126 Train loss: 0.023235 Validation loss: 0.00093478\n",
            "Epoch: 127 Train loss: 0.019476 Validation loss: 0.012366\n",
            "Epoch: 128 Train loss: 0.022087 Validation loss: 0.00047969\n",
            "Epoch: 129 Train loss: 0.020786 Validation loss: 0.0020582\n",
            "Epoch: 130 Train loss: 0.021482 Validation loss: 0.012084\n",
            "Epoch: 131 Train loss: 0.019549 Validation loss: 0.0026204\n",
            "Epoch: 132 Train loss: 0.021862 Validation loss: 0.0030098\n",
            "Epoch: 133 Train loss: 0.020631 Validation loss: 0.0041374\n",
            "Epoch: 134 Train loss: 0.020034 Validation loss: 0.084134\n",
            "Epoch: 135 Train loss: 0.019066 Validation loss: 0.0020475\n",
            "Epoch: 136 Train loss: 0.020213 Validation loss: 0.00061788\n",
            "Epoch: 137 Train loss: 0.019643 Validation loss: 0.00041488\n",
            "Epoch: 138 Train loss: 0.02189 Validation loss: 0.0063506\n",
            "Epoch: 139 Train loss: 0.020272 Validation loss: 0.00014258\n",
            "Epoch: 140 Train loss: 0.020634 Validation loss: 2.5685e-05\n",
            "Epoch: 141 Train loss: 0.020629 Validation loss: 0.0039411\n",
            "Epoch: 142 Train loss: 0.020261 Validation loss: 0.04399\n",
            "Epoch: 143 Train loss: 0.019246 Validation loss: 0.039932\n",
            "Epoch: 144 Train loss: 0.020966 Validation loss: 0.00086669\n",
            "Epoch: 145 Train loss: 0.020023 Validation loss: 0.00024257\n",
            "Epoch: 146 Train loss: 0.020582 Validation loss: 0.00065977\n",
            "Epoch: 147 Train loss: 0.020153 Validation loss: 7.0312e-05\n",
            "Epoch: 148 Train loss: 0.021503 Validation loss: 0.036722\n",
            "Epoch: 149 Train loss: 0.020497 Validation loss: 0.00012806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DduaR_pCQ0k-"
      },
      "source": [
        "After completion of the training process we use the test data set to test the models generalization to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ofClNnHRAUy",
        "outputId": "41223e69-358f-4e6a-e6e5-c0ae069a8864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for x_t, y_t in test_ds:\n",
        "    y_pred = mdl(x_t) # Compute a prediction with \"mdl\" on the input \"x_t\"\n",
        "    test_loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y_t)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_t\"\n",
        "print(\"Test loss: {:.5}\".format(test_loss))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.00041053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzJ7wOZmRbez"
      },
      "source": [
        "After we have verified that our model achieves a similar loss on the test as on the validation and training data set, we can conclude that our model is not overfitting or underfitting and generalizes to unseen data. We can now predict on the inputs again and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyvFN03bR8ez",
        "outputId": "58d49da9-241d-4278-8bd9-74c93e45ae19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" Now we want to plot the prediction after training. Predict on the variable \"x\" again. \"\"\"\n",
        "\n",
        "y_pred = mdl(x) # Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WKmuAAmLSmiR"
      },
      "source": [
        "Now our model has learned to approximate the function mapping from the input to the output. The capability of neural networks to learn from input-ouput pairs alone and approximate an arbitrary function, see universal approximation theorem, can be very useful if the mapping between the input and output is too complex to be captured with model based approaches. But learning from input-ouput pairs alone implies that the model will only be able to make accurate predictions over input ranges it has seen during training. In order to demonstrate this we will predict on an interval that exeeds the $\\left[0,3\\right]$ interval the model was trained on, i.e. we will predict on the interval $\\left[-2,5\\right]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRF8hAmmVFcH",
        "outputId": "7b8e83e5-aad3-42f4-b49c-890b3d36137f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x_generalize = np.linspace(-2.0, 5.0, N_samples, dtype=np.float32)\n",
        "y_generalize = np.sin(1.0+x_generalize*x_generalize) + noise_sig*np.random.randn(N_samples).astype(np.float32)\n",
        "y_truey_generalize = np.sin(1.0+x_generalize*x_generalize)\n",
        "y_pred = mdl(x_generalize)\n",
        "plt.plot(x_generalize, y_generalize)\n",
        "plt.plot(x_generalize, y_truey_generalize)\n",
        "plt.plot(x_generalize, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J2yr-0UCVIli"
      },
      "source": [
        "As expected, the model is able to make farely accurate predictions on the interval it was trained on but makes unreliable predictions outside this interval.\n",
        "\n",
        "### Regularization\n",
        "In this section we will explore the concept of regularization. As there is no theorem that can be used to determine the required size and structure of a neural network given a certain task, one has to find a suitable neural architecture by trial and error. This can result in choosing a architecture with a capacity that is higher than required for solving the given task and hence overfitting might occur. A common way to prevent large neural networks networks from overfitting is to employ some sort of regularization, e.g. weight norm penalty, dropout, early stopping and data augmentation. In this section we will focus on weight norm penalty as a regularization and derive a probabilistic interpretation for some of those.\n",
        "\n",
        "We start by restating the conditional probability of the output $\\mathbf{y}$ given the input $\\mathbf{x}$ and the networks parameters $\\boldsymbol{\\theta}$\n",
        "\n",
        "$p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})=\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}}$,\n",
        "\n",
        "which we used to derive the log likelihood. If we have some prior knowledge about the parameters of the neural network, which is given by a pdf $p(\\boldsymbol{\\theta})$ over the weights, we can use Bayes theorem to derive a posterior distribution\n",
        "\n",
        "$p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})=\\dfrac{p(\\boldsymbol{\\theta},\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})}=\\dfrac{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p(\\mathbf{y})}$\n",
        "\n",
        "where $p(\\boldsymbol{\\theta})$ is the  prior over the networks parameters. Similar to the derivation at the beginning of the exercise, we can use this posterior distribution to derive a cost function for training the neural network. In this case, however, we are not maximizing the log likelihood but the posterior distribution over the weights, hence this approach is called Maximum A Posteori (MAP) estimation of the parameters. Mathematically we can formulate this as\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\ln{p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})}\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\ln{p(\\boldsymbol{\\theta})}+\\mathbb{E}\\left[\\ln{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}\\right]$,\n",
        "\n",
        "where we used the fact that applying a strictly increasing function, e.g. $\\ln{}$, does not change the position of the maximum of a cost function, ignored $p(\\mathbf{y})$, since it is independent of the network parameters and dropped the expectation operator for $\\ln{p(\\boldsymbol{\\theta})}$, since it is not depending on the random variable $\\mathbf{x}$. Comparing the MAP estimate of the parameters with the ML estimate we derived above, shows that the only difference is the addition of $\\ln{p(\\boldsymbol{\\theta})}$. This term is the regularization, i.e. the weight norm penalty. Depending on the distribution over $\\boldsymbol{\\theta}$ it can have different forms. If we choose a standard normal distribution, i.e. $\\boldsymbol{\\theta\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})}$,  we get\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{2}^{2}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where we have made the same simplifications as for the ML estimation and also introduced the parameter $\\lambda=\\sigma^{2}$, which is used to control the strength of the regularization. This form of regularization is commonly known as $l_{2}$-norm or weight decay regularization. Choosing a prior where the weights follow an i.i.d laplacian distribution, i.e. $p(\\boldsymbol{\\theta})=\\prod_{j}\\dfrac{1}{2}\\mathrm{e}^{\\vert\\theta_{j}\\vert}$, leads to\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{1}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where the strength of the regularization is again controlled by $\\lambda=\\sigma^{2}$. This type of regularization is known as  $l_{1}$-norm and it has the property to induce sparsity in the parameters of the network.\n",
        "\n",
        "With this theoretical background on regularization we can now implement it and observe it's effects on the regression problem covered in this exercise. For this we will define a model with a high capacity and train it for a extended time to provoke overfitting. For this, we will increase the number of hidden neurons in both hidden layers to $100$ and $50$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2Fv2J-VK_vw",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a bigger model with again two hidden layers contatining 100 and 50 neurons. As an activation use the tangens hyperbolicus function where it is appropiate. \"\"\"\n",
        "\n",
        "class MyBigModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.truncated_normal([1,100], mean=0.0, stddev=1.0), trainable=True, name='W0')\n",
        "        self.b0 = tf.Variable(tf.zeros([100]), trainable=True, name='b0')\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([100,50], mean=0.0, stddev=1.0), trainable=True, name='W1')\n",
        "        self.b1 = tf.Variable(tf.zeros([50]), trainable=True, name='b1')\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([50,1], mean=0.0, stddev=1.0), trainable=True, name='W2')\n",
        "        self.b2 = tf.Variable(tf.zeros([1]), trainable=True, name='b2')\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W0) + self.b0)\n",
        "        output = tf.nn.tanh(tf.matmul(output, self.W1) + self.b1)\n",
        "        output = tf.matmul(output, self.W2) + self.b2\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y1XpaZTNLV-p"
      },
      "source": [
        "After creating one instance of this class we can again train it on our data set. We will also create a new optimizer for training this bigger model, since some optimizers adapt the learning rates for individual parameters during a training process and we do not want to train our bigger model with learning rates adopted from an earlier training run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7Yq-a1FLi0X",
        "colab": {}
      },
      "source": [
        "big_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dBrf0I68MnMy"
      },
      "source": [
        "Now we are ready to train this bigger model using the same training step and training loop. In order to provoke overfitting we also reduce the number of samples in the training data set a lot, increase the batch size and train for a more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nz_lXM8LMwXo",
        "outputId": "15ed30d6-03d8-43e8-b70d-752652b604ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model similar to the training of the small model before. \"\"\"\n",
        "\n",
        "N_train_samples_overfit = 30\n",
        "N_epochs = 1000\n",
        "batch_size = 30\n",
        "\n",
        "sel_idx = np.arange(0, N_train_samples)\n",
        "sel_idx = np.random.choice(sel_idx, N_train_samples_overfit)\n",
        "x_train_overfit = x_train[sel_idx]\n",
        "y_train_overfit = y_train[sel_idx]\n",
        "\n",
        "train_overfit_ds = tf.data.Dataset.from_tensor_slices((x_train_overfit, y_train_overfit)).shuffle(N_train_samples_overfit).batch(batch_size).repeat()\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += train_step(big_mdl, big_opt, x_t, y_t) # Perform a training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples_overfit//batch_size) == 0: # An epoch is completed\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_mdl(x_v) # Compute a prediction with \"big_mdl\" on the input \"x_v\"\n",
        "            validation_loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 69.953 Validation loss: 15.348\n",
            "Epoch: 1 Train loss: 41.083 Validation loss: 10.045\n",
            "Epoch: 2 Train loss: 16.696 Validation loss: 0.64489\n",
            "Epoch: 3 Train loss: 1.0084 Validation loss: 0.49843\n",
            "Epoch: 4 Train loss: 0.79228 Validation loss: 0.61964\n",
            "Epoch: 5 Train loss: 0.65175 Validation loss: 0.66017\n",
            "Epoch: 6 Train loss: 0.55236 Validation loss: 0.69443\n",
            "Epoch: 7 Train loss: 0.48618 Validation loss: 0.71019\n",
            "Epoch: 8 Train loss: 0.44567 Validation loss: 0.71275\n",
            "Epoch: 9 Train loss: 0.42139 Validation loss: 0.70531\n",
            "Epoch: 10 Train loss: 0.40575 Validation loss: 0.69234\n",
            "Epoch: 11 Train loss: 0.39451 Validation loss: 0.67712\n",
            "Epoch: 12 Train loss: 0.38569 Validation loss: 0.66158\n",
            "Epoch: 13 Train loss: 0.37833 Validation loss: 0.64663\n",
            "Epoch: 14 Train loss: 0.37197 Validation loss: 0.63264\n",
            "Epoch: 15 Train loss: 0.36633 Validation loss: 0.61969\n",
            "Epoch: 16 Train loss: 0.36126 Validation loss: 0.60775\n",
            "Epoch: 17 Train loss: 0.35663 Validation loss: 0.59674\n",
            "Epoch: 18 Train loss: 0.35236 Validation loss: 0.58655\n",
            "Epoch: 19 Train loss: 0.34841 Validation loss: 0.5771\n",
            "Epoch: 20 Train loss: 0.34471 Validation loss: 0.5683\n",
            "Epoch: 21 Train loss: 0.34122 Validation loss: 0.56007\n",
            "Epoch: 22 Train loss: 0.33793 Validation loss: 0.55236\n",
            "Epoch: 23 Train loss: 0.3348 Validation loss: 0.5451\n",
            "Epoch: 24 Train loss: 0.3318 Validation loss: 0.53824\n",
            "Epoch: 25 Train loss: 0.32893 Validation loss: 0.53174\n",
            "Epoch: 26 Train loss: 0.32616 Validation loss: 0.52556\n",
            "Epoch: 27 Train loss: 0.32348 Validation loss: 0.51967\n",
            "Epoch: 28 Train loss: 0.32088 Validation loss: 0.51404\n",
            "Epoch: 29 Train loss: 0.31836 Validation loss: 0.50864\n",
            "Epoch: 30 Train loss: 0.3159 Validation loss: 0.50345\n",
            "Epoch: 31 Train loss: 0.31351 Validation loss: 0.49846\n",
            "Epoch: 32 Train loss: 0.31117 Validation loss: 0.49365\n",
            "Epoch: 33 Train loss: 0.30888 Validation loss: 0.48901\n",
            "Epoch: 34 Train loss: 0.30663 Validation loss: 0.48453\n",
            "Epoch: 35 Train loss: 0.30444 Validation loss: 0.48018\n",
            "Epoch: 36 Train loss: 0.30228 Validation loss: 0.47599\n",
            "Epoch: 37 Train loss: 0.30016 Validation loss: 0.47192\n",
            "Epoch: 38 Train loss: 0.29807 Validation loss: 0.46798\n",
            "Epoch: 39 Train loss: 0.29602 Validation loss: 0.46416\n",
            "Epoch: 40 Train loss: 0.294 Validation loss: 0.46046\n",
            "Epoch: 41 Train loss: 0.292 Validation loss: 0.45687\n",
            "Epoch: 42 Train loss: 0.29003 Validation loss: 0.4534\n",
            "Epoch: 43 Train loss: 0.28808 Validation loss: 0.45003\n",
            "Epoch: 44 Train loss: 0.28614 Validation loss: 0.44677\n",
            "Epoch: 45 Train loss: 0.28422 Validation loss: 0.44361\n",
            "Epoch: 46 Train loss: 0.28232 Validation loss: 0.44054\n",
            "Epoch: 47 Train loss: 0.28042 Validation loss: 0.43758\n",
            "Epoch: 48 Train loss: 0.27852 Validation loss: 0.4347\n",
            "Epoch: 49 Train loss: 0.27663 Validation loss: 0.43191\n",
            "Epoch: 50 Train loss: 0.27473 Validation loss: 0.42921\n",
            "Epoch: 51 Train loss: 0.27282 Validation loss: 0.4266\n",
            "Epoch: 52 Train loss: 0.2709 Validation loss: 0.42406\n",
            "Epoch: 53 Train loss: 0.26896 Validation loss: 0.42161\n",
            "Epoch: 54 Train loss: 0.26699 Validation loss: 0.41923\n",
            "Epoch: 55 Train loss: 0.26499 Validation loss: 0.41693\n",
            "Epoch: 56 Train loss: 0.26295 Validation loss: 0.4147\n",
            "Epoch: 57 Train loss: 0.26085 Validation loss: 0.41255\n",
            "Epoch: 58 Train loss: 0.25869 Validation loss: 0.41047\n",
            "Epoch: 59 Train loss: 0.25646 Validation loss: 0.40847\n",
            "Epoch: 60 Train loss: 0.25413 Validation loss: 0.40655\n",
            "Epoch: 61 Train loss: 0.2517 Validation loss: 0.40472\n",
            "Epoch: 62 Train loss: 0.24914 Validation loss: 0.40298\n",
            "Epoch: 63 Train loss: 0.24643 Validation loss: 0.40135\n",
            "Epoch: 64 Train loss: 0.24354 Validation loss: 0.39985\n",
            "Epoch: 65 Train loss: 0.24045 Validation loss: 0.39851\n",
            "Epoch: 66 Train loss: 0.23713 Validation loss: 0.39734\n",
            "Epoch: 67 Train loss: 0.23354 Validation loss: 0.39639\n",
            "Epoch: 68 Train loss: 0.22967 Validation loss: 0.39571\n",
            "Epoch: 69 Train loss: 0.22547 Validation loss: 0.39533\n",
            "Epoch: 70 Train loss: 0.22096 Validation loss: 0.39529\n",
            "Epoch: 71 Train loss: 0.21613 Validation loss: 0.3956\n",
            "Epoch: 72 Train loss: 0.21104 Validation loss: 0.39623\n",
            "Epoch: 73 Train loss: 0.20575 Validation loss: 0.39707\n",
            "Epoch: 74 Train loss: 0.20038 Validation loss: 0.39795\n",
            "Epoch: 75 Train loss: 0.19506 Validation loss: 0.39862\n",
            "Epoch: 76 Train loss: 0.18994 Validation loss: 0.39881\n",
            "Epoch: 77 Train loss: 0.18512 Validation loss: 0.3983\n",
            "Epoch: 78 Train loss: 0.18068 Validation loss: 0.39695\n",
            "Epoch: 79 Train loss: 0.17662 Validation loss: 0.39476\n",
            "Epoch: 80 Train loss: 0.17295 Validation loss: 0.39182\n",
            "Epoch: 81 Train loss: 0.16963 Validation loss: 0.3883\n",
            "Epoch: 82 Train loss: 0.16662 Validation loss: 0.38437\n",
            "Epoch: 83 Train loss: 0.16389 Validation loss: 0.38019\n",
            "Epoch: 84 Train loss: 0.16139 Validation loss: 0.37592\n",
            "Epoch: 85 Train loss: 0.1591 Validation loss: 0.37167\n",
            "Epoch: 86 Train loss: 0.157 Validation loss: 0.3675\n",
            "Epoch: 87 Train loss: 0.15506 Validation loss: 0.36347\n",
            "Epoch: 88 Train loss: 0.15327 Validation loss: 0.35961\n",
            "Epoch: 89 Train loss: 0.1516 Validation loss: 0.35592\n",
            "Epoch: 90 Train loss: 0.15004 Validation loss: 0.35243\n",
            "Epoch: 91 Train loss: 0.14859 Validation loss: 0.34912\n",
            "Epoch: 92 Train loss: 0.14722 Validation loss: 0.34599\n",
            "Epoch: 93 Train loss: 0.14593 Validation loss: 0.34302\n",
            "Epoch: 94 Train loss: 0.14471 Validation loss: 0.34022\n",
            "Epoch: 95 Train loss: 0.14356 Validation loss: 0.33756\n",
            "Epoch: 96 Train loss: 0.14246 Validation loss: 0.33503\n",
            "Epoch: 97 Train loss: 0.14141 Validation loss: 0.33263\n",
            "Epoch: 98 Train loss: 0.14041 Validation loss: 0.33035\n",
            "Epoch: 99 Train loss: 0.13944 Validation loss: 0.32818\n",
            "Epoch: 100 Train loss: 0.13852 Validation loss: 0.3261\n",
            "Epoch: 101 Train loss: 0.13763 Validation loss: 0.32411\n",
            "Epoch: 102 Train loss: 0.13677 Validation loss: 0.3222\n",
            "Epoch: 103 Train loss: 0.13594 Validation loss: 0.32038\n",
            "Epoch: 104 Train loss: 0.13514 Validation loss: 0.31862\n",
            "Epoch: 105 Train loss: 0.13435 Validation loss: 0.31692\n",
            "Epoch: 106 Train loss: 0.1336 Validation loss: 0.31529\n",
            "Epoch: 107 Train loss: 0.13286 Validation loss: 0.31371\n",
            "Epoch: 108 Train loss: 0.13214 Validation loss: 0.31218\n",
            "Epoch: 109 Train loss: 0.13144 Validation loss: 0.3107\n",
            "Epoch: 110 Train loss: 0.13075 Validation loss: 0.30926\n",
            "Epoch: 111 Train loss: 0.13008 Validation loss: 0.30786\n",
            "Epoch: 112 Train loss: 0.12943 Validation loss: 0.3065\n",
            "Epoch: 113 Train loss: 0.12879 Validation loss: 0.30518\n",
            "Epoch: 114 Train loss: 0.12816 Validation loss: 0.30388\n",
            "Epoch: 115 Train loss: 0.12754 Validation loss: 0.30262\n",
            "Epoch: 116 Train loss: 0.12693 Validation loss: 0.30138\n",
            "Epoch: 117 Train loss: 0.12633 Validation loss: 0.30017\n",
            "Epoch: 118 Train loss: 0.12575 Validation loss: 0.29899\n",
            "Epoch: 119 Train loss: 0.12517 Validation loss: 0.29782\n",
            "Epoch: 120 Train loss: 0.1246 Validation loss: 0.29668\n",
            "Epoch: 121 Train loss: 0.12404 Validation loss: 0.29556\n",
            "Epoch: 122 Train loss: 0.12348 Validation loss: 0.29445\n",
            "Epoch: 123 Train loss: 0.12294 Validation loss: 0.29337\n",
            "Epoch: 124 Train loss: 0.1224 Validation loss: 0.29229\n",
            "Epoch: 125 Train loss: 0.12186 Validation loss: 0.29124\n",
            "Epoch: 126 Train loss: 0.12134 Validation loss: 0.2902\n",
            "Epoch: 127 Train loss: 0.12081 Validation loss: 0.28917\n",
            "Epoch: 128 Train loss: 0.1203 Validation loss: 0.28815\n",
            "Epoch: 129 Train loss: 0.11979 Validation loss: 0.28715\n",
            "Epoch: 130 Train loss: 0.11928 Validation loss: 0.28616\n",
            "Epoch: 131 Train loss: 0.11878 Validation loss: 0.28517\n",
            "Epoch: 132 Train loss: 0.11829 Validation loss: 0.2842\n",
            "Epoch: 133 Train loss: 0.1178 Validation loss: 0.28324\n",
            "Epoch: 134 Train loss: 0.11731 Validation loss: 0.28228\n",
            "Epoch: 135 Train loss: 0.11683 Validation loss: 0.28133\n",
            "Epoch: 136 Train loss: 0.11635 Validation loss: 0.2804\n",
            "Epoch: 137 Train loss: 0.11587 Validation loss: 0.27947\n",
            "Epoch: 138 Train loss: 0.1154 Validation loss: 0.27854\n",
            "Epoch: 139 Train loss: 0.11494 Validation loss: 0.27762\n",
            "Epoch: 140 Train loss: 0.11447 Validation loss: 0.27671\n",
            "Epoch: 141 Train loss: 0.11401 Validation loss: 0.27581\n",
            "Epoch: 142 Train loss: 0.11356 Validation loss: 0.27491\n",
            "Epoch: 143 Train loss: 0.1131 Validation loss: 0.27402\n",
            "Epoch: 144 Train loss: 0.11265 Validation loss: 0.27313\n",
            "Epoch: 145 Train loss: 0.11221 Validation loss: 0.27225\n",
            "Epoch: 146 Train loss: 0.11176 Validation loss: 0.27137\n",
            "Epoch: 147 Train loss: 0.11132 Validation loss: 0.27049\n",
            "Epoch: 148 Train loss: 0.11088 Validation loss: 0.26963\n",
            "Epoch: 149 Train loss: 0.11045 Validation loss: 0.26876\n",
            "Epoch: 150 Train loss: 0.11001 Validation loss: 0.2679\n",
            "Epoch: 151 Train loss: 0.10958 Validation loss: 0.26704\n",
            "Epoch: 152 Train loss: 0.10916 Validation loss: 0.26619\n",
            "Epoch: 153 Train loss: 0.10873 Validation loss: 0.26534\n",
            "Epoch: 154 Train loss: 0.10831 Validation loss: 0.2645\n",
            "Epoch: 155 Train loss: 0.10789 Validation loss: 0.26365\n",
            "Epoch: 156 Train loss: 0.10747 Validation loss: 0.26282\n",
            "Epoch: 157 Train loss: 0.10706 Validation loss: 0.26198\n",
            "Epoch: 158 Train loss: 0.10664 Validation loss: 0.26115\n",
            "Epoch: 159 Train loss: 0.10623 Validation loss: 0.26032\n",
            "Epoch: 160 Train loss: 0.10583 Validation loss: 0.25949\n",
            "Epoch: 161 Train loss: 0.10542 Validation loss: 0.25867\n",
            "Epoch: 162 Train loss: 0.10502 Validation loss: 0.25785\n",
            "Epoch: 163 Train loss: 0.10461 Validation loss: 0.25703\n",
            "Epoch: 164 Train loss: 0.10422 Validation loss: 0.25621\n",
            "Epoch: 165 Train loss: 0.10382 Validation loss: 0.2554\n",
            "Epoch: 166 Train loss: 0.10342 Validation loss: 0.25459\n",
            "Epoch: 167 Train loss: 0.10303 Validation loss: 0.25378\n",
            "Epoch: 168 Train loss: 0.10264 Validation loss: 0.25297\n",
            "Epoch: 169 Train loss: 0.10225 Validation loss: 0.25217\n",
            "Epoch: 170 Train loss: 0.10187 Validation loss: 0.25137\n",
            "Epoch: 171 Train loss: 0.10148 Validation loss: 0.25057\n",
            "Epoch: 172 Train loss: 0.1011 Validation loss: 0.24977\n",
            "Epoch: 173 Train loss: 0.10072 Validation loss: 0.24898\n",
            "Epoch: 174 Train loss: 0.10034 Validation loss: 0.24819\n",
            "Epoch: 175 Train loss: 0.099965 Validation loss: 0.2474\n",
            "Epoch: 176 Train loss: 0.099591 Validation loss: 0.24661\n",
            "Epoch: 177 Train loss: 0.099219 Validation loss: 0.24582\n",
            "Epoch: 178 Train loss: 0.098849 Validation loss: 0.24504\n",
            "Epoch: 179 Train loss: 0.098481 Validation loss: 0.24426\n",
            "Epoch: 180 Train loss: 0.098114 Validation loss: 0.24348\n",
            "Epoch: 181 Train loss: 0.09775 Validation loss: 0.2427\n",
            "Epoch: 182 Train loss: 0.097387 Validation loss: 0.24193\n",
            "Epoch: 183 Train loss: 0.097027 Validation loss: 0.24115\n",
            "Epoch: 184 Train loss: 0.096668 Validation loss: 0.24038\n",
            "Epoch: 185 Train loss: 0.096311 Validation loss: 0.23961\n",
            "Epoch: 186 Train loss: 0.095956 Validation loss: 0.23885\n",
            "Epoch: 187 Train loss: 0.095603 Validation loss: 0.23808\n",
            "Epoch: 188 Train loss: 0.095251 Validation loss: 0.23732\n",
            "Epoch: 189 Train loss: 0.094902 Validation loss: 0.23656\n",
            "Epoch: 190 Train loss: 0.094554 Validation loss: 0.2358\n",
            "Epoch: 191 Train loss: 0.094208 Validation loss: 0.23504\n",
            "Epoch: 192 Train loss: 0.093864 Validation loss: 0.23428\n",
            "Epoch: 193 Train loss: 0.093522 Validation loss: 0.23353\n",
            "Epoch: 194 Train loss: 0.093182 Validation loss: 0.23278\n",
            "Epoch: 195 Train loss: 0.092843 Validation loss: 0.23203\n",
            "Epoch: 196 Train loss: 0.092506 Validation loss: 0.23128\n",
            "Epoch: 197 Train loss: 0.092171 Validation loss: 0.23053\n",
            "Epoch: 198 Train loss: 0.091837 Validation loss: 0.22979\n",
            "Epoch: 199 Train loss: 0.091506 Validation loss: 0.22905\n",
            "Epoch: 200 Train loss: 0.091176 Validation loss: 0.22831\n",
            "Epoch: 201 Train loss: 0.090848 Validation loss: 0.22757\n",
            "Epoch: 202 Train loss: 0.090521 Validation loss: 0.22683\n",
            "Epoch: 203 Train loss: 0.090197 Validation loss: 0.22609\n",
            "Epoch: 204 Train loss: 0.089874 Validation loss: 0.22536\n",
            "Epoch: 205 Train loss: 0.089552 Validation loss: 0.22463\n",
            "Epoch: 206 Train loss: 0.089233 Validation loss: 0.2239\n",
            "Epoch: 207 Train loss: 0.088915 Validation loss: 0.22317\n",
            "Epoch: 208 Train loss: 0.088599 Validation loss: 0.22245\n",
            "Epoch: 209 Train loss: 0.088284 Validation loss: 0.22172\n",
            "Epoch: 210 Train loss: 0.087971 Validation loss: 0.221\n",
            "Epoch: 211 Train loss: 0.08766 Validation loss: 0.22028\n",
            "Epoch: 212 Train loss: 0.087351 Validation loss: 0.21956\n",
            "Epoch: 213 Train loss: 0.087042 Validation loss: 0.21885\n",
            "Epoch: 214 Train loss: 0.086736 Validation loss: 0.21813\n",
            "Epoch: 215 Train loss: 0.086432 Validation loss: 0.21742\n",
            "Epoch: 216 Train loss: 0.086129 Validation loss: 0.21671\n",
            "Epoch: 217 Train loss: 0.085827 Validation loss: 0.216\n",
            "Epoch: 218 Train loss: 0.085528 Validation loss: 0.2153\n",
            "Epoch: 219 Train loss: 0.085229 Validation loss: 0.21459\n",
            "Epoch: 220 Train loss: 0.084933 Validation loss: 0.21389\n",
            "Epoch: 221 Train loss: 0.084638 Validation loss: 0.21319\n",
            "Epoch: 222 Train loss: 0.084344 Validation loss: 0.21249\n",
            "Epoch: 223 Train loss: 0.084053 Validation loss: 0.21179\n",
            "Epoch: 224 Train loss: 0.083762 Validation loss: 0.21109\n",
            "Epoch: 225 Train loss: 0.083474 Validation loss: 0.2104\n",
            "Epoch: 226 Train loss: 0.083187 Validation loss: 0.20971\n",
            "Epoch: 227 Train loss: 0.082901 Validation loss: 0.20902\n",
            "Epoch: 228 Train loss: 0.082617 Validation loss: 0.20833\n",
            "Epoch: 229 Train loss: 0.082335 Validation loss: 0.20765\n",
            "Epoch: 230 Train loss: 0.082054 Validation loss: 0.20696\n",
            "Epoch: 231 Train loss: 0.081774 Validation loss: 0.20628\n",
            "Epoch: 232 Train loss: 0.081496 Validation loss: 0.2056\n",
            "Epoch: 233 Train loss: 0.08122 Validation loss: 0.20492\n",
            "Epoch: 234 Train loss: 0.080945 Validation loss: 0.20425\n",
            "Epoch: 235 Train loss: 0.080672 Validation loss: 0.20357\n",
            "Epoch: 236 Train loss: 0.0804 Validation loss: 0.2029\n",
            "Epoch: 237 Train loss: 0.080129 Validation loss: 0.20223\n",
            "Epoch: 238 Train loss: 0.07986 Validation loss: 0.20156\n",
            "Epoch: 239 Train loss: 0.079593 Validation loss: 0.20089\n",
            "Epoch: 240 Train loss: 0.079327 Validation loss: 0.20023\n",
            "Epoch: 241 Train loss: 0.079062 Validation loss: 0.19956\n",
            "Epoch: 242 Train loss: 0.078799 Validation loss: 0.1989\n",
            "Epoch: 243 Train loss: 0.078537 Validation loss: 0.19824\n",
            "Epoch: 244 Train loss: 0.078277 Validation loss: 0.19759\n",
            "Epoch: 245 Train loss: 0.078018 Validation loss: 0.19693\n",
            "Epoch: 246 Train loss: 0.077761 Validation loss: 0.19628\n",
            "Epoch: 247 Train loss: 0.077505 Validation loss: 0.19563\n",
            "Epoch: 248 Train loss: 0.07725 Validation loss: 0.19498\n",
            "Epoch: 249 Train loss: 0.076997 Validation loss: 0.19433\n",
            "Epoch: 250 Train loss: 0.076745 Validation loss: 0.19369\n",
            "Epoch: 251 Train loss: 0.076495 Validation loss: 0.19304\n",
            "Epoch: 252 Train loss: 0.076245 Validation loss: 0.1924\n",
            "Epoch: 253 Train loss: 0.075998 Validation loss: 0.19176\n",
            "Epoch: 254 Train loss: 0.075751 Validation loss: 0.19112\n",
            "Epoch: 255 Train loss: 0.075506 Validation loss: 0.19049\n",
            "Epoch: 256 Train loss: 0.075263 Validation loss: 0.18986\n",
            "Epoch: 257 Train loss: 0.07502 Validation loss: 0.18922\n",
            "Epoch: 258 Train loss: 0.074779 Validation loss: 0.18859\n",
            "Epoch: 259 Train loss: 0.07454 Validation loss: 0.18796\n",
            "Epoch: 260 Train loss: 0.074301 Validation loss: 0.18734\n",
            "Epoch: 261 Train loss: 0.074064 Validation loss: 0.18671\n",
            "Epoch: 262 Train loss: 0.073828 Validation loss: 0.18609\n",
            "Epoch: 263 Train loss: 0.073594 Validation loss: 0.18547\n",
            "Epoch: 264 Train loss: 0.07336 Validation loss: 0.18485\n",
            "Epoch: 265 Train loss: 0.073129 Validation loss: 0.18424\n",
            "Epoch: 266 Train loss: 0.072898 Validation loss: 0.18363\n",
            "Epoch: 267 Train loss: 0.072669 Validation loss: 0.18301\n",
            "Epoch: 268 Train loss: 0.07244 Validation loss: 0.1824\n",
            "Epoch: 269 Train loss: 0.072214 Validation loss: 0.18179\n",
            "Epoch: 270 Train loss: 0.071988 Validation loss: 0.18119\n",
            "Epoch: 271 Train loss: 0.071763 Validation loss: 0.18058\n",
            "Epoch: 272 Train loss: 0.07154 Validation loss: 0.17998\n",
            "Epoch: 273 Train loss: 0.071318 Validation loss: 0.17938\n",
            "Epoch: 274 Train loss: 0.071097 Validation loss: 0.17878\n",
            "Epoch: 275 Train loss: 0.070878 Validation loss: 0.17818\n",
            "Epoch: 276 Train loss: 0.07066 Validation loss: 0.17759\n",
            "Epoch: 277 Train loss: 0.070442 Validation loss: 0.177\n",
            "Epoch: 278 Train loss: 0.070226 Validation loss: 0.17641\n",
            "Epoch: 279 Train loss: 0.070012 Validation loss: 0.17582\n",
            "Epoch: 280 Train loss: 0.069798 Validation loss: 0.17523\n",
            "Epoch: 281 Train loss: 0.069585 Validation loss: 0.17464\n",
            "Epoch: 282 Train loss: 0.069374 Validation loss: 0.17406\n",
            "Epoch: 283 Train loss: 0.069164 Validation loss: 0.17348\n",
            "Epoch: 284 Train loss: 0.068955 Validation loss: 0.1729\n",
            "Epoch: 285 Train loss: 0.068747 Validation loss: 0.17233\n",
            "Epoch: 286 Train loss: 0.06854 Validation loss: 0.17175\n",
            "Epoch: 287 Train loss: 0.068335 Validation loss: 0.17118\n",
            "Epoch: 288 Train loss: 0.06813 Validation loss: 0.17061\n",
            "Epoch: 289 Train loss: 0.067927 Validation loss: 0.17004\n",
            "Epoch: 290 Train loss: 0.067724 Validation loss: 0.16947\n",
            "Epoch: 291 Train loss: 0.067523 Validation loss: 0.1689\n",
            "Epoch: 292 Train loss: 0.067323 Validation loss: 0.16834\n",
            "Epoch: 293 Train loss: 0.067124 Validation loss: 0.16778\n",
            "Epoch: 294 Train loss: 0.066926 Validation loss: 0.16722\n",
            "Epoch: 295 Train loss: 0.066729 Validation loss: 0.16666\n",
            "Epoch: 296 Train loss: 0.066533 Validation loss: 0.16611\n",
            "Epoch: 297 Train loss: 0.066338 Validation loss: 0.16555\n",
            "Epoch: 298 Train loss: 0.066144 Validation loss: 0.165\n",
            "Epoch: 299 Train loss: 0.065952 Validation loss: 0.16445\n",
            "Epoch: 300 Train loss: 0.06576 Validation loss: 0.1639\n",
            "Epoch: 301 Train loss: 0.065569 Validation loss: 0.16336\n",
            "Epoch: 302 Train loss: 0.06538 Validation loss: 0.16281\n",
            "Epoch: 303 Train loss: 0.065191 Validation loss: 0.16227\n",
            "Epoch: 304 Train loss: 0.065003 Validation loss: 0.16173\n",
            "Epoch: 305 Train loss: 0.064817 Validation loss: 0.16119\n",
            "Epoch: 306 Train loss: 0.064631 Validation loss: 0.16066\n",
            "Epoch: 307 Train loss: 0.064446 Validation loss: 0.16012\n",
            "Epoch: 308 Train loss: 0.064263 Validation loss: 0.15959\n",
            "Epoch: 309 Train loss: 0.06408 Validation loss: 0.15905\n",
            "Epoch: 310 Train loss: 0.063898 Validation loss: 0.15853\n",
            "Epoch: 311 Train loss: 0.063717 Validation loss: 0.158\n",
            "Epoch: 312 Train loss: 0.063538 Validation loss: 0.15748\n",
            "Epoch: 313 Train loss: 0.063359 Validation loss: 0.15695\n",
            "Epoch: 314 Train loss: 0.063181 Validation loss: 0.15643\n",
            "Epoch: 315 Train loss: 0.063004 Validation loss: 0.15591\n",
            "Epoch: 316 Train loss: 0.062828 Validation loss: 0.15539\n",
            "Epoch: 317 Train loss: 0.062653 Validation loss: 0.15488\n",
            "Epoch: 318 Train loss: 0.062479 Validation loss: 0.15436\n",
            "Epoch: 319 Train loss: 0.062305 Validation loss: 0.15385\n",
            "Epoch: 320 Train loss: 0.062133 Validation loss: 0.15334\n",
            "Epoch: 321 Train loss: 0.061961 Validation loss: 0.15283\n",
            "Epoch: 322 Train loss: 0.061791 Validation loss: 0.15233\n",
            "Epoch: 323 Train loss: 0.061621 Validation loss: 0.15182\n",
            "Epoch: 324 Train loss: 0.061452 Validation loss: 0.15132\n",
            "Epoch: 325 Train loss: 0.061284 Validation loss: 0.15082\n",
            "Epoch: 326 Train loss: 0.061117 Validation loss: 0.15032\n",
            "Epoch: 327 Train loss: 0.060951 Validation loss: 0.14982\n",
            "Epoch: 328 Train loss: 0.060786 Validation loss: 0.14933\n",
            "Epoch: 329 Train loss: 0.060621 Validation loss: 0.14883\n",
            "Epoch: 330 Train loss: 0.060458 Validation loss: 0.14834\n",
            "Epoch: 331 Train loss: 0.060295 Validation loss: 0.14785\n",
            "Epoch: 332 Train loss: 0.060133 Validation loss: 0.14737\n",
            "Epoch: 333 Train loss: 0.059972 Validation loss: 0.14688\n",
            "Epoch: 334 Train loss: 0.059812 Validation loss: 0.1464\n",
            "Epoch: 335 Train loss: 0.059652 Validation loss: 0.14591\n",
            "Epoch: 336 Train loss: 0.059493 Validation loss: 0.14543\n",
            "Epoch: 337 Train loss: 0.059336 Validation loss: 0.14495\n",
            "Epoch: 338 Train loss: 0.059178 Validation loss: 0.14448\n",
            "Epoch: 339 Train loss: 0.059022 Validation loss: 0.144\n",
            "Epoch: 340 Train loss: 0.058867 Validation loss: 0.14353\n",
            "Epoch: 341 Train loss: 0.058712 Validation loss: 0.14306\n",
            "Epoch: 342 Train loss: 0.058558 Validation loss: 0.14259\n",
            "Epoch: 343 Train loss: 0.058405 Validation loss: 0.14212\n",
            "Epoch: 344 Train loss: 0.058253 Validation loss: 0.14165\n",
            "Epoch: 345 Train loss: 0.058101 Validation loss: 0.14119\n",
            "Epoch: 346 Train loss: 0.057951 Validation loss: 0.14072\n",
            "Epoch: 347 Train loss: 0.0578 Validation loss: 0.14026\n",
            "Epoch: 348 Train loss: 0.057651 Validation loss: 0.1398\n",
            "Epoch: 349 Train loss: 0.057503 Validation loss: 0.13935\n",
            "Epoch: 350 Train loss: 0.057355 Validation loss: 0.13889\n",
            "Epoch: 351 Train loss: 0.057208 Validation loss: 0.13844\n",
            "Epoch: 352 Train loss: 0.057062 Validation loss: 0.13798\n",
            "Epoch: 353 Train loss: 0.056916 Validation loss: 0.13753\n",
            "Epoch: 354 Train loss: 0.056771 Validation loss: 0.13708\n",
            "Epoch: 355 Train loss: 0.056627 Validation loss: 0.13664\n",
            "Epoch: 356 Train loss: 0.056484 Validation loss: 0.13619\n",
            "Epoch: 357 Train loss: 0.056341 Validation loss: 0.13575\n",
            "Epoch: 358 Train loss: 0.056199 Validation loss: 0.13531\n",
            "Epoch: 359 Train loss: 0.056058 Validation loss: 0.13487\n",
            "Epoch: 360 Train loss: 0.055917 Validation loss: 0.13443\n",
            "Epoch: 361 Train loss: 0.055777 Validation loss: 0.13399\n",
            "Epoch: 362 Train loss: 0.055638 Validation loss: 0.13356\n",
            "Epoch: 363 Train loss: 0.055499 Validation loss: 0.13313\n",
            "Epoch: 364 Train loss: 0.055361 Validation loss: 0.13269\n",
            "Epoch: 365 Train loss: 0.055224 Validation loss: 0.13226\n",
            "Epoch: 366 Train loss: 0.055088 Validation loss: 0.13183\n",
            "Epoch: 367 Train loss: 0.054952 Validation loss: 0.13141\n",
            "Epoch: 368 Train loss: 0.054817 Validation loss: 0.13098\n",
            "Epoch: 369 Train loss: 0.054682 Validation loss: 0.13056\n",
            "Epoch: 370 Train loss: 0.054548 Validation loss: 0.13013\n",
            "Epoch: 371 Train loss: 0.054415 Validation loss: 0.12972\n",
            "Epoch: 372 Train loss: 0.054283 Validation loss: 0.1293\n",
            "Epoch: 373 Train loss: 0.054151 Validation loss: 0.12888\n",
            "Epoch: 374 Train loss: 0.054019 Validation loss: 0.12847\n",
            "Epoch: 375 Train loss: 0.053889 Validation loss: 0.12805\n",
            "Epoch: 376 Train loss: 0.053759 Validation loss: 0.12764\n",
            "Epoch: 377 Train loss: 0.053629 Validation loss: 0.12723\n",
            "Epoch: 378 Train loss: 0.0535 Validation loss: 0.12682\n",
            "Epoch: 379 Train loss: 0.053372 Validation loss: 0.12642\n",
            "Epoch: 380 Train loss: 0.053245 Validation loss: 0.12601\n",
            "Epoch: 381 Train loss: 0.053118 Validation loss: 0.12561\n",
            "Epoch: 382 Train loss: 0.052991 Validation loss: 0.1252\n",
            "Epoch: 383 Train loss: 0.052866 Validation loss: 0.12481\n",
            "Epoch: 384 Train loss: 0.05274 Validation loss: 0.1244\n",
            "Epoch: 385 Train loss: 0.052616 Validation loss: 0.12401\n",
            "Epoch: 386 Train loss: 0.052492 Validation loss: 0.12361\n",
            "Epoch: 387 Train loss: 0.052368 Validation loss: 0.12322\n",
            "Epoch: 388 Train loss: 0.052246 Validation loss: 0.12282\n",
            "Epoch: 389 Train loss: 0.052123 Validation loss: 0.12244\n",
            "Epoch: 390 Train loss: 0.052002 Validation loss: 0.12204\n",
            "Epoch: 391 Train loss: 0.051881 Validation loss: 0.12166\n",
            "Epoch: 392 Train loss: 0.05176 Validation loss: 0.12127\n",
            "Epoch: 393 Train loss: 0.05164 Validation loss: 0.12089\n",
            "Epoch: 394 Train loss: 0.051521 Validation loss: 0.1205\n",
            "Epoch: 395 Train loss: 0.051402 Validation loss: 0.12012\n",
            "Epoch: 396 Train loss: 0.051284 Validation loss: 0.11974\n",
            "Epoch: 397 Train loss: 0.051166 Validation loss: 0.11937\n",
            "Epoch: 398 Train loss: 0.051048 Validation loss: 0.11898\n",
            "Epoch: 399 Train loss: 0.050932 Validation loss: 0.11861\n",
            "Epoch: 400 Train loss: 0.050816 Validation loss: 0.11823\n",
            "Epoch: 401 Train loss: 0.0507 Validation loss: 0.11787\n",
            "Epoch: 402 Train loss: 0.050585 Validation loss: 0.11748\n",
            "Epoch: 403 Train loss: 0.050471 Validation loss: 0.11713\n",
            "Epoch: 404 Train loss: 0.050357 Validation loss: 0.11674\n",
            "Epoch: 405 Train loss: 0.050243 Validation loss: 0.11639\n",
            "Epoch: 406 Train loss: 0.05013 Validation loss: 0.11601\n",
            "Epoch: 407 Train loss: 0.050018 Validation loss: 0.11567\n",
            "Epoch: 408 Train loss: 0.049906 Validation loss: 0.11528\n",
            "Epoch: 409 Train loss: 0.049794 Validation loss: 0.11494\n",
            "Epoch: 410 Train loss: 0.049684 Validation loss: 0.11456\n",
            "Epoch: 411 Train loss: 0.049573 Validation loss: 0.11423\n",
            "Epoch: 412 Train loss: 0.049463 Validation loss: 0.11384\n",
            "Epoch: 413 Train loss: 0.049354 Validation loss: 0.11352\n",
            "Epoch: 414 Train loss: 0.049245 Validation loss: 0.11313\n",
            "Epoch: 415 Train loss: 0.049137 Validation loss: 0.11282\n",
            "Epoch: 416 Train loss: 0.049029 Validation loss: 0.11243\n",
            "Epoch: 417 Train loss: 0.048921 Validation loss: 0.11212\n",
            "Epoch: 418 Train loss: 0.048814 Validation loss: 0.11173\n",
            "Epoch: 419 Train loss: 0.048708 Validation loss: 0.11143\n",
            "Epoch: 420 Train loss: 0.048602 Validation loss: 0.11103\n",
            "Epoch: 421 Train loss: 0.048496 Validation loss: 0.11074\n",
            "Epoch: 422 Train loss: 0.048391 Validation loss: 0.11034\n",
            "Epoch: 423 Train loss: 0.048286 Validation loss: 0.11006\n",
            "Epoch: 424 Train loss: 0.048182 Validation loss: 0.10965\n",
            "Epoch: 425 Train loss: 0.048079 Validation loss: 0.10939\n",
            "Epoch: 426 Train loss: 0.047975 Validation loss: 0.10897\n",
            "Epoch: 427 Train loss: 0.047873 Validation loss: 0.10873\n",
            "Epoch: 428 Train loss: 0.04777 Validation loss: 0.10829\n",
            "Epoch: 429 Train loss: 0.047669 Validation loss: 0.10807\n",
            "Epoch: 430 Train loss: 0.047567 Validation loss: 0.10761\n",
            "Epoch: 431 Train loss: 0.047466 Validation loss: 0.10743\n",
            "Epoch: 432 Train loss: 0.047366 Validation loss: 0.10694\n",
            "Epoch: 433 Train loss: 0.047266 Validation loss: 0.10679\n",
            "Epoch: 434 Train loss: 0.047166 Validation loss: 0.10627\n",
            "Epoch: 435 Train loss: 0.047067 Validation loss: 0.10616\n",
            "Epoch: 436 Train loss: 0.046968 Validation loss: 0.1056\n",
            "Epoch: 437 Train loss: 0.04687 Validation loss: 0.10554\n",
            "Epoch: 438 Train loss: 0.046772 Validation loss: 0.10492\n",
            "Epoch: 439 Train loss: 0.046674 Validation loss: 0.10493\n",
            "Epoch: 440 Train loss: 0.046577 Validation loss: 0.10425\n",
            "Epoch: 441 Train loss: 0.046481 Validation loss: 0.10433\n",
            "Epoch: 442 Train loss: 0.046385 Validation loss: 0.10357\n",
            "Epoch: 443 Train loss: 0.046289 Validation loss: 0.10375\n",
            "Epoch: 444 Train loss: 0.046194 Validation loss: 0.10289\n",
            "Epoch: 445 Train loss: 0.046099 Validation loss: 0.10319\n",
            "Epoch: 446 Train loss: 0.046004 Validation loss: 0.1022\n",
            "Epoch: 447 Train loss: 0.04591 Validation loss: 0.10266\n",
            "Epoch: 448 Train loss: 0.045816 Validation loss: 0.10149\n",
            "Epoch: 449 Train loss: 0.045723 Validation loss: 0.10214\n",
            "Epoch: 450 Train loss: 0.04563 Validation loss: 0.10076\n",
            "Epoch: 451 Train loss: 0.045538 Validation loss: 0.10166\n",
            "Epoch: 452 Train loss: 0.045446 Validation loss: 0.10001\n",
            "Epoch: 453 Train loss: 0.045354 Validation loss: 0.10122\n",
            "Epoch: 454 Train loss: 0.045263 Validation loss: 0.099219\n",
            "Epoch: 455 Train loss: 0.045173 Validation loss: 0.10084\n",
            "Epoch: 456 Train loss: 0.045083 Validation loss: 0.098384\n",
            "Epoch: 457 Train loss: 0.044993 Validation loss: 0.10051\n",
            "Epoch: 458 Train loss: 0.044904 Validation loss: 0.097488\n",
            "Epoch: 459 Train loss: 0.044815 Validation loss: 0.10027\n",
            "Epoch: 460 Train loss: 0.044727 Validation loss: 0.096509\n",
            "Epoch: 461 Train loss: 0.04464 Validation loss: 0.10014\n",
            "Epoch: 462 Train loss: 0.044554 Validation loss: 0.095423\n",
            "Epoch: 463 Train loss: 0.044468 Validation loss: 0.10014\n",
            "Epoch: 464 Train loss: 0.044384 Validation loss: 0.094197\n",
            "Epoch: 465 Train loss: 0.044301 Validation loss: 0.10032\n",
            "Epoch: 466 Train loss: 0.044219 Validation loss: 0.092787\n",
            "Epoch: 467 Train loss: 0.044139 Validation loss: 0.10074\n",
            "Epoch: 468 Train loss: 0.044061 Validation loss: 0.091136\n",
            "Epoch: 469 Train loss: 0.043987 Validation loss: 0.10147\n",
            "Epoch: 470 Train loss: 0.043916 Validation loss: 0.08917\n",
            "Epoch: 471 Train loss: 0.04385 Validation loss: 0.10262\n",
            "Epoch: 472 Train loss: 0.043789 Validation loss: 0.086799\n",
            "Epoch: 473 Train loss: 0.043737 Validation loss: 0.10431\n",
            "Epoch: 474 Train loss: 0.043693 Validation loss: 0.083898\n",
            "Epoch: 475 Train loss: 0.043665 Validation loss: 0.10676\n",
            "Epoch: 476 Train loss: 0.043651 Validation loss: 0.08032\n",
            "Epoch: 477 Train loss: 0.043664 Validation loss: 0.11021\n",
            "Epoch: 478 Train loss: 0.043699 Validation loss: 0.075878\n",
            "Epoch: 479 Train loss: 0.043784 Validation loss: 0.11506\n",
            "Epoch: 480 Train loss: 0.043903 Validation loss: 0.070357\n",
            "Epoch: 481 Train loss: 0.044113 Validation loss: 0.12182\n",
            "Epoch: 482 Train loss: 0.044377 Validation loss: 0.063526\n",
            "Epoch: 483 Train loss: 0.044808 Validation loss: 0.13127\n",
            "Epoch: 484 Train loss: 0.045315 Validation loss: 0.055172\n",
            "Epoch: 485 Train loss: 0.04614 Validation loss: 0.1445\n",
            "Epoch: 486 Train loss: 0.047055 Validation loss: 0.04519\n",
            "Epoch: 487 Train loss: 0.04858 Validation loss: 0.16304\n",
            "Epoch: 488 Train loss: 0.050157 Validation loss: 0.033747\n",
            "Epoch: 489 Train loss: 0.052917 Validation loss: 0.18901\n",
            "Epoch: 490 Train loss: 0.055519 Validation loss: 0.021552\n",
            "Epoch: 491 Train loss: 0.060413 Validation loss: 0.22502\n",
            "Epoch: 492 Train loss: 0.064447 Validation loss: 0.010177\n",
            "Epoch: 493 Train loss: 0.072873 Validation loss: 0.27352\n",
            "Epoch: 494 Train loss: 0.078514 Validation loss: 0.0021598\n",
            "Epoch: 495 Train loss: 0.092294 Validation loss: 0.33489\n",
            "Epoch: 496 Train loss: 0.098754 Validation loss: 0.00015794\n",
            "Epoch: 497 Train loss: 0.11942 Validation loss: 0.40358\n",
            "Epoch: 498 Train loss: 0.12381 Validation loss: 0.0045503\n",
            "Epoch: 499 Train loss: 0.15083 Validation loss: 0.46479\n",
            "Epoch: 500 Train loss: 0.14789 Validation loss: 0.011123\n",
            "Epoch: 501 Train loss: 0.17682 Validation loss: 0.49798\n",
            "Epoch: 502 Train loss: 0.16191 Validation loss: 0.0134\n",
            "Epoch: 503 Train loss: 0.18572 Validation loss: 0.49052\n",
            "Epoch: 504 Train loss: 0.15984 Validation loss: 0.0093638\n",
            "Epoch: 505 Train loss: 0.17384 Validation loss: 0.44816\n",
            "Epoch: 506 Train loss: 0.14395 Validation loss: 0.0032568\n",
            "Epoch: 507 Train loss: 0.14876 Validation loss: 0.38897\n",
            "Epoch: 508 Train loss: 0.12202 Validation loss: 7.897e-05\n",
            "Epoch: 509 Train loss: 0.12128 Validation loss: 0.32954\n",
            "Epoch: 510 Train loss: 0.10096 Validation loss: 0.0014679\n",
            "Epoch: 511 Train loss: 0.098064 Validation loss: 0.27847\n",
            "Epoch: 512 Train loss: 0.083997 Validation loss: 0.0063495\n",
            "Epoch: 513 Train loss: 0.080849 Validation loss: 0.23788\n",
            "Epoch: 514 Train loss: 0.071554 Validation loss: 0.012953\n",
            "Epoch: 515 Train loss: 0.068882 Validation loss: 0.20676\n",
            "Epoch: 516 Train loss: 0.062829 Validation loss: 0.019896\n",
            "Epoch: 517 Train loss: 0.060772 Validation loss: 0.18318\n",
            "Epoch: 518 Train loss: 0.056811 Validation loss: 0.026385\n",
            "Epoch: 519 Train loss: 0.05529 Validation loss: 0.16532\n",
            "Epoch: 520 Train loss: 0.052654 Validation loss: 0.032065\n",
            "Epoch: 521 Train loss: 0.051543 Validation loss: 0.1517\n",
            "Epoch: 522 Train loss: 0.049746 Validation loss: 0.036844\n",
            "Epoch: 523 Train loss: 0.048932 Validation loss: 0.14121\n",
            "Epoch: 524 Train loss: 0.047674 Validation loss: 0.04076\n",
            "Epoch: 525 Train loss: 0.04707 Validation loss: 0.13307\n",
            "Epoch: 526 Train loss: 0.046163 Validation loss: 0.043905\n",
            "Epoch: 527 Train loss: 0.045708 Validation loss: 0.1267\n",
            "Epoch: 528 Train loss: 0.045035 Validation loss: 0.046382\n",
            "Epoch: 529 Train loss: 0.044686 Validation loss: 0.12168\n",
            "Epoch: 530 Train loss: 0.044173 Validation loss: 0.048291\n",
            "Epoch: 531 Train loss: 0.043901 Validation loss: 0.11771\n",
            "Epoch: 532 Train loss: 0.043499 Validation loss: 0.049719\n",
            "Epoch: 533 Train loss: 0.043285 Validation loss: 0.11459\n",
            "Epoch: 534 Train loss: 0.042963 Validation loss: 0.050735\n",
            "Epoch: 535 Train loss: 0.042792 Validation loss: 0.11214\n",
            "Epoch: 536 Train loss: 0.042529 Validation loss: 0.051397\n",
            "Epoch: 537 Train loss: 0.042393 Validation loss: 0.11027\n",
            "Epoch: 538 Train loss: 0.042175 Validation loss: 0.051749\n",
            "Epoch: 539 Train loss: 0.042068 Validation loss: 0.10889\n",
            "Epoch: 540 Train loss: 0.041886 Validation loss: 0.051822\n",
            "Epoch: 541 Train loss: 0.041804 Validation loss: 0.10794\n",
            "Epoch: 542 Train loss: 0.041651 Validation loss: 0.051641\n",
            "Epoch: 543 Train loss: 0.041593 Validation loss: 0.10738\n",
            "Epoch: 544 Train loss: 0.041465 Validation loss: 0.051221\n",
            "Epoch: 545 Train loss: 0.04143 Validation loss: 0.1072\n",
            "Epoch: 546 Train loss: 0.041325 Validation loss: 0.050571\n",
            "Epoch: 547 Train loss: 0.041315 Validation loss: 0.10738\n",
            "Epoch: 548 Train loss: 0.041232 Validation loss: 0.049694\n",
            "Epoch: 549 Train loss: 0.041248 Validation loss: 0.10793\n",
            "Epoch: 550 Train loss: 0.041187 Validation loss: 0.048589\n",
            "Epoch: 551 Train loss: 0.041234 Validation loss: 0.10887\n",
            "Epoch: 552 Train loss: 0.041196 Validation loss: 0.04725\n",
            "Epoch: 553 Train loss: 0.041279 Validation loss: 0.11022\n",
            "Epoch: 554 Train loss: 0.041267 Validation loss: 0.045667\n",
            "Epoch: 555 Train loss: 0.041393 Validation loss: 0.11202\n",
            "Epoch: 556 Train loss: 0.04141 Validation loss: 0.043831\n",
            "Epoch: 557 Train loss: 0.041592 Validation loss: 0.11433\n",
            "Epoch: 558 Train loss: 0.041643 Validation loss: 0.04173\n",
            "Epoch: 559 Train loss: 0.041892 Validation loss: 0.1172\n",
            "Epoch: 560 Train loss: 0.041984 Validation loss: 0.039351\n",
            "Epoch: 561 Train loss: 0.04232 Validation loss: 0.12073\n",
            "Epoch: 562 Train loss: 0.04246 Validation loss: 0.036688\n",
            "Epoch: 563 Train loss: 0.042907 Validation loss: 0.12501\n",
            "Epoch: 564 Train loss: 0.043104 Validation loss: 0.033741\n",
            "Epoch: 565 Train loss: 0.043694 Validation loss: 0.13014\n",
            "Epoch: 566 Train loss: 0.043959 Validation loss: 0.030521\n",
            "Epoch: 567 Train loss: 0.044732 Validation loss: 0.13625\n",
            "Epoch: 568 Train loss: 0.045074 Validation loss: 0.027055\n",
            "Epoch: 569 Train loss: 0.046082 Validation loss: 0.14347\n",
            "Epoch: 570 Train loss: 0.046509 Validation loss: 0.023396\n",
            "Epoch: 571 Train loss: 0.047816 Validation loss: 0.15191\n",
            "Epoch: 572 Train loss: 0.048329 Validation loss: 0.019622\n",
            "Epoch: 573 Train loss: 0.050012 Validation loss: 0.16168\n",
            "Epoch: 574 Train loss: 0.050601 Validation loss: 0.015847\n",
            "Epoch: 575 Train loss: 0.052745 Validation loss: 0.17278\n",
            "Epoch: 576 Train loss: 0.053377 Validation loss: 0.012215\n",
            "Epoch: 577 Train loss: 0.05607 Validation loss: 0.18514\n",
            "Epoch: 578 Train loss: 0.05668 Validation loss: 0.0088912\n",
            "Epoch: 579 Train loss: 0.059997 Validation loss: 0.19849\n",
            "Epoch: 580 Train loss: 0.060476 Validation loss: 0.0060359\n",
            "Epoch: 581 Train loss: 0.064457 Validation loss: 0.21233\n",
            "Epoch: 582 Train loss: 0.064639 Validation loss: 0.0037725\n",
            "Epoch: 583 Train loss: 0.069261 Validation loss: 0.22591\n",
            "Epoch: 584 Train loss: 0.068934 Validation loss: 0.0021513\n",
            "Epoch: 585 Train loss: 0.074082 Validation loss: 0.2382\n",
            "Epoch: 586 Train loss: 0.073012 Validation loss: 0.0011272\n",
            "Epoch: 587 Train loss: 0.078468 Validation loss: 0.2481\n",
            "Epoch: 588 Train loss: 0.076449 Validation loss: 0.0005736\n",
            "Epoch: 589 Train loss: 0.081907 Validation loss: 0.25457\n",
            "Epoch: 590 Train loss: 0.078833 Validation loss: 0.00033278\n",
            "Epoch: 591 Train loss: 0.083955 Validation loss: 0.2569\n",
            "Epoch: 592 Train loss: 0.079866 Validation loss: 0.00028182\n",
            "Epoch: 593 Train loss: 0.08435 Validation loss: 0.25494\n",
            "Epoch: 594 Train loss: 0.079447 Validation loss: 0.00037899\n",
            "Epoch: 595 Train loss: 0.083099 Validation loss: 0.24905\n",
            "Epoch: 596 Train loss: 0.0777 Validation loss: 0.00066248\n",
            "Epoch: 597 Train loss: 0.080458 Validation loss: 0.24007\n",
            "Epoch: 598 Train loss: 0.074921 Validation loss: 0.0012091\n",
            "Epoch: 599 Train loss: 0.076846 Validation loss: 0.22902\n",
            "Epoch: 600 Train loss: 0.071488 Validation loss: 0.0020826\n",
            "Epoch: 601 Train loss: 0.072721 Validation loss: 0.21693\n",
            "Epoch: 602 Train loss: 0.067774 Validation loss: 0.0032989\n",
            "Epoch: 603 Train loss: 0.068481 Validation loss: 0.20465\n",
            "Epoch: 604 Train loss: 0.064076 Validation loss: 0.0048201\n",
            "Epoch: 605 Train loss: 0.064421 Validation loss: 0.19282\n",
            "Epoch: 606 Train loss: 0.060602 Validation loss: 0.0065685\n",
            "Epoch: 607 Train loss: 0.060717 Validation loss: 0.18183\n",
            "Epoch: 608 Train loss: 0.057467 Validation loss: 0.0084486\n",
            "Epoch: 609 Train loss: 0.057451 Validation loss: 0.17189\n",
            "Epoch: 610 Train loss: 0.054719 Validation loss: 0.010366\n",
            "Epoch: 611 Train loss: 0.05464 Validation loss: 0.16308\n",
            "Epoch: 612 Train loss: 0.052358 Validation loss: 0.012238\n",
            "Epoch: 613 Train loss: 0.05226 Validation loss: 0.1554\n",
            "Epoch: 614 Train loss: 0.050358 Validation loss: 0.013998\n",
            "Epoch: 615 Train loss: 0.050269 Validation loss: 0.14878\n",
            "Epoch: 616 Train loss: 0.048682 Validation loss: 0.015603\n",
            "Epoch: 617 Train loss: 0.048616 Validation loss: 0.14313\n",
            "Epoch: 618 Train loss: 0.047288 Validation loss: 0.01702\n",
            "Epoch: 619 Train loss: 0.047253 Validation loss: 0.13837\n",
            "Epoch: 620 Train loss: 0.046136 Validation loss: 0.018233\n",
            "Epoch: 621 Train loss: 0.046136 Validation loss: 0.13442\n",
            "Epoch: 622 Train loss: 0.04519 Validation loss: 0.019235\n",
            "Epoch: 623 Train loss: 0.045228 Validation loss: 0.13117\n",
            "Epoch: 624 Train loss: 0.044421 Validation loss: 0.020023\n",
            "Epoch: 625 Train loss: 0.044497 Validation loss: 0.12858\n",
            "Epoch: 626 Train loss: 0.043805 Validation loss: 0.0206\n",
            "Epoch: 627 Train loss: 0.043919 Validation loss: 0.12657\n",
            "Epoch: 628 Train loss: 0.043322 Validation loss: 0.020974\n",
            "Epoch: 629 Train loss: 0.043476 Validation loss: 0.1251\n",
            "Epoch: 630 Train loss: 0.042957 Validation loss: 0.021151\n",
            "Epoch: 631 Train loss: 0.043152 Validation loss: 0.12412\n",
            "Epoch: 632 Train loss: 0.0427 Validation loss: 0.021138\n",
            "Epoch: 633 Train loss: 0.042938 Validation loss: 0.12361\n",
            "Epoch: 634 Train loss: 0.042541 Validation loss: 0.020945\n",
            "Epoch: 635 Train loss: 0.042827 Validation loss: 0.12355\n",
            "Epoch: 636 Train loss: 0.042477 Validation loss: 0.020582\n",
            "Epoch: 637 Train loss: 0.042815 Validation loss: 0.12391\n",
            "Epoch: 638 Train loss: 0.042506 Validation loss: 0.020056\n",
            "Epoch: 639 Train loss: 0.0429 Validation loss: 0.12469\n",
            "Epoch: 640 Train loss: 0.042626 Validation loss: 0.019378\n",
            "Epoch: 641 Train loss: 0.043085 Validation loss: 0.12588\n",
            "Epoch: 642 Train loss: 0.04284 Validation loss: 0.018561\n",
            "Epoch: 643 Train loss: 0.04337 Validation loss: 0.12747\n",
            "Epoch: 644 Train loss: 0.04315 Validation loss: 0.017617\n",
            "Epoch: 645 Train loss: 0.043762 Validation loss: 0.12946\n",
            "Epoch: 646 Train loss: 0.043561 Validation loss: 0.016561\n",
            "Epoch: 647 Train loss: 0.044263 Validation loss: 0.13185\n",
            "Epoch: 648 Train loss: 0.044076 Validation loss: 0.01541\n",
            "Epoch: 649 Train loss: 0.04488 Validation loss: 0.13463\n",
            "Epoch: 650 Train loss: 0.0447 Validation loss: 0.014186\n",
            "Epoch: 651 Train loss: 0.045616 Validation loss: 0.13778\n",
            "Epoch: 652 Train loss: 0.045435 Validation loss: 0.012911\n",
            "Epoch: 653 Train loss: 0.046475 Validation loss: 0.14128\n",
            "Epoch: 654 Train loss: 0.046281 Validation loss: 0.011612\n",
            "Epoch: 655 Train loss: 0.047456 Validation loss: 0.14509\n",
            "Epoch: 656 Train loss: 0.047234 Validation loss: 0.010317\n",
            "Epoch: 657 Train loss: 0.048552 Validation loss: 0.14915\n",
            "Epoch: 658 Train loss: 0.048286 Validation loss: 0.0090556\n",
            "Epoch: 659 Train loss: 0.049753 Validation loss: 0.1534\n",
            "Epoch: 660 Train loss: 0.049422 Validation loss: 0.0078567\n",
            "Epoch: 661 Train loss: 0.051038 Validation loss: 0.15773\n",
            "Epoch: 662 Train loss: 0.050617 Validation loss: 0.0067476\n",
            "Epoch: 663 Train loss: 0.052376 Validation loss: 0.16203\n",
            "Epoch: 664 Train loss: 0.05184 Validation loss: 0.0057513\n",
            "Epoch: 665 Train loss: 0.053728 Validation loss: 0.16615\n",
            "Epoch: 666 Train loss: 0.053048 Validation loss: 0.0048843\n",
            "Epoch: 667 Train loss: 0.055043 Validation loss: 0.16995\n",
            "Epoch: 668 Train loss: 0.054194 Validation loss: 0.0041566\n",
            "Epoch: 669 Train loss: 0.056266 Validation loss: 0.17326\n",
            "Epoch: 670 Train loss: 0.055225 Validation loss: 0.0035713\n",
            "Epoch: 671 Train loss: 0.057336 Validation loss: 0.17593\n",
            "Epoch: 672 Train loss: 0.05609 Validation loss: 0.003125\n",
            "Epoch: 673 Train loss: 0.058197 Validation loss: 0.17785\n",
            "Epoch: 674 Train loss: 0.056743 Validation loss: 0.00281\n",
            "Epoch: 675 Train loss: 0.058801 Validation loss: 0.17891\n",
            "Epoch: 676 Train loss: 0.057148 Validation loss: 0.0026174\n",
            "Epoch: 677 Train loss: 0.059115 Validation loss: 0.17907\n",
            "Epoch: 678 Train loss: 0.057284 Validation loss: 0.0025375\n",
            "Epoch: 679 Train loss: 0.059126 Validation loss: 0.17834\n",
            "Epoch: 680 Train loss: 0.057149 Validation loss: 0.0025624\n",
            "Epoch: 681 Train loss: 0.058839 Validation loss: 0.17677\n",
            "Epoch: 682 Train loss: 0.056757 Validation loss: 0.0026854\n",
            "Epoch: 683 Train loss: 0.058279 Validation loss: 0.17446\n",
            "Epoch: 684 Train loss: 0.056136 Validation loss: 0.0029011\n",
            "Epoch: 685 Train loss: 0.057487 Validation loss: 0.17152\n",
            "Epoch: 686 Train loss: 0.055328 Validation loss: 0.0032033\n",
            "Epoch: 687 Train loss: 0.05651 Validation loss: 0.16811\n",
            "Epoch: 688 Train loss: 0.054378 Validation loss: 0.0035848\n",
            "Epoch: 689 Train loss: 0.055404 Validation loss: 0.16437\n",
            "Epoch: 690 Train loss: 0.053333 Validation loss: 0.0040359\n",
            "Epoch: 691 Train loss: 0.05422 Validation loss: 0.16045\n",
            "Epoch: 692 Train loss: 0.052236 Validation loss: 0.0045443\n",
            "Epoch: 693 Train loss: 0.053003 Validation loss: 0.15645\n",
            "Epoch: 694 Train loss: 0.051127 Validation loss: 0.005096\n",
            "Epoch: 695 Train loss: 0.051793 Validation loss: 0.15249\n",
            "Epoch: 696 Train loss: 0.050036 Validation loss: 0.0056748\n",
            "Epoch: 697 Train loss: 0.050623 Validation loss: 0.14867\n",
            "Epoch: 698 Train loss: 0.04899 Validation loss: 0.0062643\n",
            "Epoch: 699 Train loss: 0.049513 Validation loss: 0.14503\n",
            "Epoch: 700 Train loss: 0.048004 Validation loss: 0.0068489\n",
            "Epoch: 701 Train loss: 0.04848 Validation loss: 0.14164\n",
            "Epoch: 702 Train loss: 0.047092 Validation loss: 0.0074135\n",
            "Epoch: 703 Train loss: 0.047534 Validation loss: 0.13851\n",
            "Epoch: 704 Train loss: 0.046259 Validation loss: 0.0079444\n",
            "Epoch: 705 Train loss: 0.046678 Validation loss: 0.13568\n",
            "Epoch: 706 Train loss: 0.045509 Validation loss: 0.0084309\n",
            "Epoch: 707 Train loss: 0.045915 Validation loss: 0.13315\n",
            "Epoch: 708 Train loss: 0.044842 Validation loss: 0.0088638\n",
            "Epoch: 709 Train loss: 0.045243 Validation loss: 0.13092\n",
            "Epoch: 710 Train loss: 0.044257 Validation loss: 0.0092355\n",
            "Epoch: 711 Train loss: 0.044659 Validation loss: 0.12899\n",
            "Epoch: 712 Train loss: 0.043752 Validation loss: 0.0095408\n",
            "Epoch: 713 Train loss: 0.04416 Validation loss: 0.12736\n",
            "Epoch: 714 Train loss: 0.043322 Validation loss: 0.0097769\n",
            "Epoch: 715 Train loss: 0.043743 Validation loss: 0.12601\n",
            "Epoch: 716 Train loss: 0.042966 Validation loss: 0.0099422\n",
            "Epoch: 717 Train loss: 0.043401 Validation loss: 0.12493\n",
            "Epoch: 718 Train loss: 0.042679 Validation loss: 0.010036\n",
            "Epoch: 719 Train loss: 0.043133 Validation loss: 0.12412\n",
            "Epoch: 720 Train loss: 0.042457 Validation loss: 0.010059\n",
            "Epoch: 721 Train loss: 0.042935 Validation loss: 0.12356\n",
            "Epoch: 722 Train loss: 0.042298 Validation loss: 0.010015\n",
            "Epoch: 723 Train loss: 0.042802 Validation loss: 0.12324\n",
            "Epoch: 724 Train loss: 0.042199 Validation loss: 0.0099051\n",
            "Epoch: 725 Train loss: 0.042732 Validation loss: 0.12315\n",
            "Epoch: 726 Train loss: 0.042157 Validation loss: 0.009735\n",
            "Epoch: 727 Train loss: 0.042721 Validation loss: 0.12328\n",
            "Epoch: 728 Train loss: 0.042169 Validation loss: 0.0095087\n",
            "Epoch: 729 Train loss: 0.042769 Validation loss: 0.1236\n",
            "Epoch: 730 Train loss: 0.042233 Validation loss: 0.0092326\n",
            "Epoch: 731 Train loss: 0.04287 Validation loss: 0.12412\n",
            "Epoch: 732 Train loss: 0.042346 Validation loss: 0.0089126\n",
            "Epoch: 733 Train loss: 0.043023 Validation loss: 0.1248\n",
            "Epoch: 734 Train loss: 0.042506 Validation loss: 0.0085556\n",
            "Epoch: 735 Train loss: 0.043224 Validation loss: 0.12564\n",
            "Epoch: 736 Train loss: 0.042708 Validation loss: 0.0081691\n",
            "Epoch: 737 Train loss: 0.04347 Validation loss: 0.12662\n",
            "Epoch: 738 Train loss: 0.04295 Validation loss: 0.0077605\n",
            "Epoch: 739 Train loss: 0.043756 Validation loss: 0.12771\n",
            "Epoch: 740 Train loss: 0.043226 Validation loss: 0.0073382\n",
            "Epoch: 741 Train loss: 0.044077 Validation loss: 0.12889\n",
            "Epoch: 742 Train loss: 0.043531 Validation loss: 0.0069097\n",
            "Epoch: 743 Train loss: 0.044427 Validation loss: 0.13014\n",
            "Epoch: 744 Train loss: 0.04386 Validation loss: 0.0064834\n",
            "Epoch: 745 Train loss: 0.044799 Validation loss: 0.13143\n",
            "Epoch: 746 Train loss: 0.044205 Validation loss: 0.0060656\n",
            "Epoch: 747 Train loss: 0.045185 Validation loss: 0.13271\n",
            "Epoch: 748 Train loss: 0.044558 Validation loss: 0.0056645\n",
            "Epoch: 749 Train loss: 0.045576 Validation loss: 0.13398\n",
            "Epoch: 750 Train loss: 0.044911 Validation loss: 0.0052861\n",
            "Epoch: 751 Train loss: 0.045963 Validation loss: 0.13518\n",
            "Epoch: 752 Train loss: 0.045255 Validation loss: 0.0049349\n",
            "Epoch: 753 Train loss: 0.046334 Validation loss: 0.1363\n",
            "Epoch: 754 Train loss: 0.045579 Validation loss: 0.0046161\n",
            "Epoch: 755 Train loss: 0.046679 Validation loss: 0.13728\n",
            "Epoch: 756 Train loss: 0.045874 Validation loss: 0.0043324\n",
            "Epoch: 757 Train loss: 0.046987 Validation loss: 0.13812\n",
            "Epoch: 758 Train loss: 0.04613 Validation loss: 0.0040869\n",
            "Epoch: 759 Train loss: 0.047249 Validation loss: 0.13877\n",
            "Epoch: 760 Train loss: 0.04634 Validation loss: 0.0038801\n",
            "Epoch: 761 Train loss: 0.047456 Validation loss: 0.13922\n",
            "Epoch: 762 Train loss: 0.046496 Validation loss: 0.0037128\n",
            "Epoch: 763 Train loss: 0.047601 Validation loss: 0.13945\n",
            "Epoch: 764 Train loss: 0.046592 Validation loss: 0.0035849\n",
            "Epoch: 765 Train loss: 0.047678 Validation loss: 0.13945\n",
            "Epoch: 766 Train loss: 0.046625 Validation loss: 0.0034952\n",
            "Epoch: 767 Train loss: 0.047685 Validation loss: 0.13923\n",
            "Epoch: 768 Train loss: 0.046594 Validation loss: 0.0034427\n",
            "Epoch: 769 Train loss: 0.047622 Validation loss: 0.13878\n",
            "Epoch: 770 Train loss: 0.046498 Validation loss: 0.0034252\n",
            "Epoch: 771 Train loss: 0.047489 Validation loss: 0.13812\n",
            "Epoch: 772 Train loss: 0.046342 Validation loss: 0.0034409\n",
            "Epoch: 773 Train loss: 0.047292 Validation loss: 0.13726\n",
            "Epoch: 774 Train loss: 0.046129 Validation loss: 0.003487\n",
            "Epoch: 775 Train loss: 0.047036 Validation loss: 0.13623\n",
            "Epoch: 776 Train loss: 0.045865 Validation loss: 0.0035613\n",
            "Epoch: 777 Train loss: 0.046729 Validation loss: 0.13505\n",
            "Epoch: 778 Train loss: 0.045559 Validation loss: 0.0036603\n",
            "Epoch: 779 Train loss: 0.046378 Validation loss: 0.13375\n",
            "Epoch: 780 Train loss: 0.045217 Validation loss: 0.0037809\n",
            "Epoch: 781 Train loss: 0.045994 Validation loss: 0.13235\n",
            "Epoch: 782 Train loss: 0.044847 Validation loss: 0.00392\n",
            "Epoch: 783 Train loss: 0.045585 Validation loss: 0.13089\n",
            "Epoch: 784 Train loss: 0.044459 Validation loss: 0.0040733\n",
            "Epoch: 785 Train loss: 0.045159 Validation loss: 0.12939\n",
            "Epoch: 786 Train loss: 0.044059 Validation loss: 0.0042375\n",
            "Epoch: 787 Train loss: 0.044726 Validation loss: 0.12787\n",
            "Epoch: 788 Train loss: 0.043655 Validation loss: 0.0044084\n",
            "Epoch: 789 Train loss: 0.044291 Validation loss: 0.12637\n",
            "Epoch: 790 Train loss: 0.043254 Validation loss: 0.0045825\n",
            "Epoch: 791 Train loss: 0.043863 Validation loss: 0.12489\n",
            "Epoch: 792 Train loss: 0.04286 Validation loss: 0.0047558\n",
            "Epoch: 793 Train loss: 0.043446 Validation loss: 0.12346\n",
            "Epoch: 794 Train loss: 0.042478 Validation loss: 0.004925\n",
            "Epoch: 795 Train loss: 0.043045 Validation loss: 0.12209\n",
            "Epoch: 796 Train loss: 0.042113 Validation loss: 0.0050866\n",
            "Epoch: 797 Train loss: 0.042664 Validation loss: 0.12079\n",
            "Epoch: 798 Train loss: 0.041767 Validation loss: 0.0052374\n",
            "Epoch: 799 Train loss: 0.042306 Validation loss: 0.11958\n",
            "Epoch: 800 Train loss: 0.041444 Validation loss: 0.0053753\n",
            "Epoch: 801 Train loss: 0.041972 Validation loss: 0.11845\n",
            "Epoch: 802 Train loss: 0.041143 Validation loss: 0.0054977\n",
            "Epoch: 803 Train loss: 0.041665 Validation loss: 0.11742\n",
            "Epoch: 804 Train loss: 0.040868 Validation loss: 0.0056029\n",
            "Epoch: 805 Train loss: 0.041386 Validation loss: 0.11648\n",
            "Epoch: 806 Train loss: 0.040618 Validation loss: 0.0056893\n",
            "Epoch: 807 Train loss: 0.041134 Validation loss: 0.11564\n",
            "Epoch: 808 Train loss: 0.040393 Validation loss: 0.0057566\n",
            "Epoch: 809 Train loss: 0.04091 Validation loss: 0.1149\n",
            "Epoch: 810 Train loss: 0.040195 Validation loss: 0.0058036\n",
            "Epoch: 811 Train loss: 0.040714 Validation loss: 0.11426\n",
            "Epoch: 812 Train loss: 0.040021 Validation loss: 0.0058302\n",
            "Epoch: 813 Train loss: 0.040544 Validation loss: 0.11371\n",
            "Epoch: 814 Train loss: 0.039872 Validation loss: 0.005837\n",
            "Epoch: 815 Train loss: 0.040401 Validation loss: 0.11325\n",
            "Epoch: 816 Train loss: 0.039747 Validation loss: 0.0058239\n",
            "Epoch: 817 Train loss: 0.040282 Validation loss: 0.11288\n",
            "Epoch: 818 Train loss: 0.039645 Validation loss: 0.005792\n",
            "Epoch: 819 Train loss: 0.040188 Validation loss: 0.11259\n",
            "Epoch: 820 Train loss: 0.039564 Validation loss: 0.0057429\n",
            "Epoch: 821 Train loss: 0.040117 Validation loss: 0.11238\n",
            "Epoch: 822 Train loss: 0.039503 Validation loss: 0.0056773\n",
            "Epoch: 823 Train loss: 0.040066 Validation loss: 0.11224\n",
            "Epoch: 824 Train loss: 0.039462 Validation loss: 0.0055974\n",
            "Epoch: 825 Train loss: 0.040035 Validation loss: 0.11217\n",
            "Epoch: 826 Train loss: 0.039438 Validation loss: 0.0055038\n",
            "Epoch: 827 Train loss: 0.040022 Validation loss: 0.11215\n",
            "Epoch: 828 Train loss: 0.03943 Validation loss: 0.0053993\n",
            "Epoch: 829 Train loss: 0.040025 Validation loss: 0.11219\n",
            "Epoch: 830 Train loss: 0.039435 Validation loss: 0.0052857\n",
            "Epoch: 831 Train loss: 0.040043 Validation loss: 0.11226\n",
            "Epoch: 832 Train loss: 0.039453 Validation loss: 0.0051648\n",
            "Epoch: 833 Train loss: 0.040071 Validation loss: 0.11237\n",
            "Epoch: 834 Train loss: 0.039481 Validation loss: 0.0050388\n",
            "Epoch: 835 Train loss: 0.04011 Validation loss: 0.11251\n",
            "Epoch: 836 Train loss: 0.039516 Validation loss: 0.0049099\n",
            "Epoch: 837 Train loss: 0.040156 Validation loss: 0.11266\n",
            "Epoch: 838 Train loss: 0.039557 Validation loss: 0.0047796\n",
            "Epoch: 839 Train loss: 0.040206 Validation loss: 0.11282\n",
            "Epoch: 840 Train loss: 0.039602 Validation loss: 0.0046499\n",
            "Epoch: 841 Train loss: 0.04026 Validation loss: 0.11298\n",
            "Epoch: 842 Train loss: 0.039648 Validation loss: 0.0045223\n",
            "Epoch: 843 Train loss: 0.040313 Validation loss: 0.11314\n",
            "Epoch: 844 Train loss: 0.039693 Validation loss: 0.0043989\n",
            "Epoch: 845 Train loss: 0.040365 Validation loss: 0.11328\n",
            "Epoch: 846 Train loss: 0.039735 Validation loss: 0.004281\n",
            "Epoch: 847 Train loss: 0.040411 Validation loss: 0.11339\n",
            "Epoch: 848 Train loss: 0.039771 Validation loss: 0.0041699\n",
            "Epoch: 849 Train loss: 0.040451 Validation loss: 0.11347\n",
            "Epoch: 850 Train loss: 0.0398 Validation loss: 0.0040664\n",
            "Epoch: 851 Train loss: 0.040482 Validation loss: 0.11351\n",
            "Epoch: 852 Train loss: 0.03982 Validation loss: 0.0039716\n",
            "Epoch: 853 Train loss: 0.040502 Validation loss: 0.11352\n",
            "Epoch: 854 Train loss: 0.03983 Validation loss: 0.0038864\n",
            "Epoch: 855 Train loss: 0.04051 Validation loss: 0.11347\n",
            "Epoch: 856 Train loss: 0.039827 Validation loss: 0.0038111\n",
            "Epoch: 857 Train loss: 0.040503 Validation loss: 0.11337\n",
            "Epoch: 858 Train loss: 0.03981 Validation loss: 0.0037463\n",
            "Epoch: 859 Train loss: 0.040482 Validation loss: 0.11322\n",
            "Epoch: 860 Train loss: 0.03978 Validation loss: 0.0036921\n",
            "Epoch: 861 Train loss: 0.040445 Validation loss: 0.11302\n",
            "Epoch: 862 Train loss: 0.039735 Validation loss: 0.0036483\n",
            "Epoch: 863 Train loss: 0.040392 Validation loss: 0.11275\n",
            "Epoch: 864 Train loss: 0.039675 Validation loss: 0.0036153\n",
            "Epoch: 865 Train loss: 0.040323 Validation loss: 0.11244\n",
            "Epoch: 866 Train loss: 0.0396 Validation loss: 0.0035923\n",
            "Epoch: 867 Train loss: 0.040238 Validation loss: 0.11207\n",
            "Epoch: 868 Train loss: 0.039511 Validation loss: 0.0035791\n",
            "Epoch: 869 Train loss: 0.040138 Validation loss: 0.11165\n",
            "Epoch: 870 Train loss: 0.039407 Validation loss: 0.0035752\n",
            "Epoch: 871 Train loss: 0.040023 Validation loss: 0.11118\n",
            "Epoch: 872 Train loss: 0.039291 Validation loss: 0.0035805\n",
            "Epoch: 873 Train loss: 0.039894 Validation loss: 0.11067\n",
            "Epoch: 874 Train loss: 0.039163 Validation loss: 0.0035936\n",
            "Epoch: 875 Train loss: 0.039754 Validation loss: 0.11012\n",
            "Epoch: 876 Train loss: 0.039024 Validation loss: 0.0036141\n",
            "Epoch: 877 Train loss: 0.039602 Validation loss: 0.10954\n",
            "Epoch: 878 Train loss: 0.038876 Validation loss: 0.003641\n",
            "Epoch: 879 Train loss: 0.039441 Validation loss: 0.10893\n",
            "Epoch: 880 Train loss: 0.03872 Validation loss: 0.0036738\n",
            "Epoch: 881 Train loss: 0.039273 Validation loss: 0.1083\n",
            "Epoch: 882 Train loss: 0.038557 Validation loss: 0.0037115\n",
            "Epoch: 883 Train loss: 0.039098 Validation loss: 0.10765\n",
            "Epoch: 884 Train loss: 0.03839 Validation loss: 0.0037531\n",
            "Epoch: 885 Train loss: 0.038919 Validation loss: 0.10699\n",
            "Epoch: 886 Train loss: 0.038219 Validation loss: 0.0037976\n",
            "Epoch: 887 Train loss: 0.038737 Validation loss: 0.10632\n",
            "Epoch: 888 Train loss: 0.038046 Validation loss: 0.0038442\n",
            "Epoch: 889 Train loss: 0.038553 Validation loss: 0.10565\n",
            "Epoch: 890 Train loss: 0.037873 Validation loss: 0.0038924\n",
            "Epoch: 891 Train loss: 0.03837 Validation loss: 0.10499\n",
            "Epoch: 892 Train loss: 0.037699 Validation loss: 0.003941\n",
            "Epoch: 893 Train loss: 0.038187 Validation loss: 0.10433\n",
            "Epoch: 894 Train loss: 0.037528 Validation loss: 0.0039889\n",
            "Epoch: 895 Train loss: 0.038007 Validation loss: 0.10368\n",
            "Epoch: 896 Train loss: 0.037359 Validation loss: 0.004036\n",
            "Epoch: 897 Train loss: 0.037831 Validation loss: 0.10304\n",
            "Epoch: 898 Train loss: 0.037194 Validation loss: 0.0040813\n",
            "Epoch: 899 Train loss: 0.037658 Validation loss: 0.10243\n",
            "Epoch: 900 Train loss: 0.037033 Validation loss: 0.004124\n",
            "Epoch: 901 Train loss: 0.037491 Validation loss: 0.10183\n",
            "Epoch: 902 Train loss: 0.036877 Validation loss: 0.004164\n",
            "Epoch: 903 Train loss: 0.03733 Validation loss: 0.10125\n",
            "Epoch: 904 Train loss: 0.036726 Validation loss: 0.0042002\n",
            "Epoch: 905 Train loss: 0.037174 Validation loss: 0.1007\n",
            "Epoch: 906 Train loss: 0.036582 Validation loss: 0.0042328\n",
            "Epoch: 907 Train loss: 0.037025 Validation loss: 0.10017\n",
            "Epoch: 908 Train loss: 0.036443 Validation loss: 0.0042612\n",
            "Epoch: 909 Train loss: 0.036883 Validation loss: 0.09967\n",
            "Epoch: 910 Train loss: 0.036312 Validation loss: 0.0042849\n",
            "Epoch: 911 Train loss: 0.036748 Validation loss: 0.099192\n",
            "Epoch: 912 Train loss: 0.036186 Validation loss: 0.0043042\n",
            "Epoch: 913 Train loss: 0.036621 Validation loss: 0.098739\n",
            "Epoch: 914 Train loss: 0.036068 Validation loss: 0.0043188\n",
            "Epoch: 915 Train loss: 0.0365 Validation loss: 0.098311\n",
            "Epoch: 916 Train loss: 0.035956 Validation loss: 0.0043287\n",
            "Epoch: 917 Train loss: 0.036386 Validation loss: 0.097909\n",
            "Epoch: 918 Train loss: 0.03585 Validation loss: 0.0043342\n",
            "Epoch: 919 Train loss: 0.036279 Validation loss: 0.097531\n",
            "Epoch: 920 Train loss: 0.035751 Validation loss: 0.0043345\n",
            "Epoch: 921 Train loss: 0.036179 Validation loss: 0.097175\n",
            "Epoch: 922 Train loss: 0.035657 Validation loss: 0.0043311\n",
            "Epoch: 923 Train loss: 0.036085 Validation loss: 0.096842\n",
            "Epoch: 924 Train loss: 0.03557 Validation loss: 0.0043233\n",
            "Epoch: 925 Train loss: 0.035997 Validation loss: 0.096527\n",
            "Epoch: 926 Train loss: 0.035487 Validation loss: 0.0043119\n",
            "Epoch: 927 Train loss: 0.035914 Validation loss: 0.096231\n",
            "Epoch: 928 Train loss: 0.03541 Validation loss: 0.0042966\n",
            "Epoch: 929 Train loss: 0.035837 Validation loss: 0.095954\n",
            "Epoch: 930 Train loss: 0.035337 Validation loss: 0.0042783\n",
            "Epoch: 931 Train loss: 0.035764 Validation loss: 0.095691\n",
            "Epoch: 932 Train loss: 0.035269 Validation loss: 0.0042573\n",
            "Epoch: 933 Train loss: 0.035695 Validation loss: 0.095442\n",
            "Epoch: 934 Train loss: 0.035204 Validation loss: 0.0042338\n",
            "Epoch: 935 Train loss: 0.03563 Validation loss: 0.095204\n",
            "Epoch: 936 Train loss: 0.035142 Validation loss: 0.004208\n",
            "Epoch: 937 Train loss: 0.035569 Validation loss: 0.094977\n",
            "Epoch: 938 Train loss: 0.035083 Validation loss: 0.0041807\n",
            "Epoch: 939 Train loss: 0.03551 Validation loss: 0.094758\n",
            "Epoch: 940 Train loss: 0.035026 Validation loss: 0.0041526\n",
            "Epoch: 941 Train loss: 0.035453 Validation loss: 0.094544\n",
            "Epoch: 942 Train loss: 0.034971 Validation loss: 0.004123\n",
            "Epoch: 943 Train loss: 0.035398 Validation loss: 0.094335\n",
            "Epoch: 944 Train loss: 0.034918 Validation loss: 0.0040932\n",
            "Epoch: 945 Train loss: 0.035343 Validation loss: 0.094128\n",
            "Epoch: 946 Train loss: 0.034865 Validation loss: 0.0040632\n",
            "Epoch: 947 Train loss: 0.03529 Validation loss: 0.093922\n",
            "Epoch: 948 Train loss: 0.034812 Validation loss: 0.0040337\n",
            "Epoch: 949 Train loss: 0.035237 Validation loss: 0.093714\n",
            "Epoch: 950 Train loss: 0.03476 Validation loss: 0.0040045\n",
            "Epoch: 951 Train loss: 0.035183 Validation loss: 0.093505\n",
            "Epoch: 952 Train loss: 0.034707 Validation loss: 0.0039762\n",
            "Epoch: 953 Train loss: 0.035129 Validation loss: 0.093292\n",
            "Epoch: 954 Train loss: 0.034654 Validation loss: 0.0039495\n",
            "Epoch: 955 Train loss: 0.035073 Validation loss: 0.093072\n",
            "Epoch: 956 Train loss: 0.034599 Validation loss: 0.0039238\n",
            "Epoch: 957 Train loss: 0.035017 Validation loss: 0.092847\n",
            "Epoch: 958 Train loss: 0.034543 Validation loss: 0.0039\n",
            "Epoch: 959 Train loss: 0.034958 Validation loss: 0.092615\n",
            "Epoch: 960 Train loss: 0.034484 Validation loss: 0.0038783\n",
            "Epoch: 961 Train loss: 0.034898 Validation loss: 0.092374\n",
            "Epoch: 962 Train loss: 0.034424 Validation loss: 0.0038584\n",
            "Epoch: 963 Train loss: 0.034835 Validation loss: 0.092123\n",
            "Epoch: 964 Train loss: 0.034362 Validation loss: 0.0038408\n",
            "Epoch: 965 Train loss: 0.034769 Validation loss: 0.091864\n",
            "Epoch: 966 Train loss: 0.034297 Validation loss: 0.0038253\n",
            "Epoch: 967 Train loss: 0.034701 Validation loss: 0.091595\n",
            "Epoch: 968 Train loss: 0.03423 Validation loss: 0.0038122\n",
            "Epoch: 969 Train loss: 0.034631 Validation loss: 0.091317\n",
            "Epoch: 970 Train loss: 0.034161 Validation loss: 0.0038016\n",
            "Epoch: 971 Train loss: 0.034558 Validation loss: 0.091027\n",
            "Epoch: 972 Train loss: 0.034089 Validation loss: 0.0037934\n",
            "Epoch: 973 Train loss: 0.034482 Validation loss: 0.090727\n",
            "Epoch: 974 Train loss: 0.034014 Validation loss: 0.0037875\n",
            "Epoch: 975 Train loss: 0.034403 Validation loss: 0.090418\n",
            "Epoch: 976 Train loss: 0.033937 Validation loss: 0.0037842\n",
            "Epoch: 977 Train loss: 0.034322 Validation loss: 0.0901\n",
            "Epoch: 978 Train loss: 0.033857 Validation loss: 0.003783\n",
            "Epoch: 979 Train loss: 0.034238 Validation loss: 0.089772\n",
            "Epoch: 980 Train loss: 0.033775 Validation loss: 0.0037841\n",
            "Epoch: 981 Train loss: 0.034151 Validation loss: 0.089435\n",
            "Epoch: 982 Train loss: 0.033691 Validation loss: 0.0037873\n",
            "Epoch: 983 Train loss: 0.034063 Validation loss: 0.089091\n",
            "Epoch: 984 Train loss: 0.033605 Validation loss: 0.0037927\n",
            "Epoch: 985 Train loss: 0.033972 Validation loss: 0.08874\n",
            "Epoch: 986 Train loss: 0.033517 Validation loss: 0.0038\n",
            "Epoch: 987 Train loss: 0.033879 Validation loss: 0.088381\n",
            "Epoch: 988 Train loss: 0.033427 Validation loss: 0.0038091\n",
            "Epoch: 989 Train loss: 0.033784 Validation loss: 0.088016\n",
            "Epoch: 990 Train loss: 0.033335 Validation loss: 0.00382\n",
            "Epoch: 991 Train loss: 0.033688 Validation loss: 0.087646\n",
            "Epoch: 992 Train loss: 0.033242 Validation loss: 0.0038323\n",
            "Epoch: 993 Train loss: 0.033591 Validation loss: 0.087271\n",
            "Epoch: 994 Train loss: 0.033148 Validation loss: 0.0038461\n",
            "Epoch: 995 Train loss: 0.033492 Validation loss: 0.086894\n",
            "Epoch: 996 Train loss: 0.033053 Validation loss: 0.0038607\n",
            "Epoch: 997 Train loss: 0.033393 Validation loss: 0.086514\n",
            "Epoch: 998 Train loss: 0.032958 Validation loss: 0.0038766\n",
            "Epoch: 999 Train loss: 0.033293 Validation loss: 0.086131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gkaUDmA8Ps6w"
      },
      "source": [
        "Predicting with this model shows overfitting. For recognizing overfitting a comparison of the validation and training loss is very useful. If the training loss decreases during training while the validation loss consistently increases, the model you are training is probably overfitting. Plotting the models prediction and the target also shows that there is a significant discrepancy between the target and the prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Sq-9xhWPxI4",
        "outputId": "ec3274ce-87bb-4c83-f702-44134bdc559a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_pred = big_mdl(x) # Predict on x with \"big_mdl\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Target\", \"Prediction\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZ36J2EN85b9"
      },
      "source": [
        "In order to implement a regularization we need to modify the loss function. Since the loss function in this exercise is computed during the training step, we define a new training step with a regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLbcWwlt9Jwl",
        "colab": {}
      },
      "source": [
        "\"\"\" In order to avoid overfitting we implement a training step that also includes a regularization on the weights of our big model. For this we use the Frobenius/squared l2-norm of each weight matrix/vector. \n",
        "Hint: Use the tf.reduce_sum() function on a list of individual regularization terms for each matrix/vector of the network.\"\"\"\n",
        "\n",
        "def regularized_train_step(model, optimizer, x, y, lmbd):\n",
        "    y = tf.reshape(y, [-1,1])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x) # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.math.squared_difference(y_pred, y)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "        regul_val = lmbd * tf.math.sqrt(tf.reduce_sum(tf.math.square(model.trainable_variables[0]))) + lmbd * tf.math.sqrt(tf.reduce_sum(tf.math.square(model.trainable_variables[2]))) + lmbd * tf.math.sqrt(tf.reduce_sum(tf.math.square(model.trainable_variables[4]))) # Compute the regularization based on the list \"model.trainable_variables\"\n",
        "        total_loss = loss_val + regul_val # Add the loss with a the regularization term weighted by \"lmbd\"\n",
        "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExK4FIw89s0M"
      },
      "source": [
        "We can now set the strength of the regularization and retrain the big model with a regularization. We create another instance of the big model in order to compare the big model with and without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PUUBGi496Vt",
        "outputId": "621f1444-e6df-4d5a-b5b5-d079e7dd17c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model with the regularized_train_step function. Note: We are plotting the MSE loss without the regularization in order to compare it with the unregularized model. \"\"\"\n",
        "\n",
        "lmbd = 0.005\n",
        "\n",
        "big_reg_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += regularized_train_step(big_reg_mdl, big_opt, x_t, y_t, lmbd) # Perform a regularized training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\" with the regularization parameter being \"lmbd\"\n",
        "    train_iters += 1\n",
        "    if train_iters % (N_train_samples_overfit//batch_size) == 0: # An epoch is completed\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_reg_mdl(x_v) # Compute a prediction with \"big_reg_mdl\" on the input \"x_v\"\n",
        "            validation_loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y_v)) # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        train_reg = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 9.675 Validation loss: 5.932\n",
            "Epoch: 1 Train loss: 26.6 Validation loss: 40.622\n",
            "Epoch: 2 Train loss: 56.107 Validation loss: 1.8722\n",
            "Epoch: 3 Train loss: 5.8477 Validation loss: 0.54471\n",
            "Epoch: 4 Train loss: 0.43066 Validation loss: 0.38796\n",
            "Epoch: 5 Train loss: 0.31226 Validation loss: 0.43924\n",
            "Epoch: 6 Train loss: 0.29915 Validation loss: 0.45858\n",
            "Epoch: 7 Train loss: 0.29545 Validation loss: 0.46556\n",
            "Epoch: 8 Train loss: 0.29378 Validation loss: 0.46685\n",
            "Epoch: 9 Train loss: 0.29262 Validation loss: 0.46559\n",
            "Epoch: 10 Train loss: 0.29162 Validation loss: 0.46323\n",
            "Epoch: 11 Train loss: 0.29072 Validation loss: 0.46047\n",
            "Epoch: 12 Train loss: 0.28987 Validation loss: 0.4576\n",
            "Epoch: 13 Train loss: 0.28909 Validation loss: 0.45478\n",
            "Epoch: 14 Train loss: 0.28835 Validation loss: 0.45207\n",
            "Epoch: 15 Train loss: 0.28765 Validation loss: 0.44948\n",
            "Epoch: 16 Train loss: 0.287 Validation loss: 0.44703\n",
            "Epoch: 17 Train loss: 0.28638 Validation loss: 0.44472\n",
            "Epoch: 18 Train loss: 0.28579 Validation loss: 0.44254\n",
            "Epoch: 19 Train loss: 0.28522 Validation loss: 0.44048\n",
            "Epoch: 20 Train loss: 0.28468 Validation loss: 0.43855\n",
            "Epoch: 21 Train loss: 0.28416 Validation loss: 0.43674\n",
            "Epoch: 22 Train loss: 0.28366 Validation loss: 0.43503\n",
            "Epoch: 23 Train loss: 0.28317 Validation loss: 0.43342\n",
            "Epoch: 24 Train loss: 0.28269 Validation loss: 0.43192\n",
            "Epoch: 25 Train loss: 0.28222 Validation loss: 0.43051\n",
            "Epoch: 26 Train loss: 0.28176 Validation loss: 0.42918\n",
            "Epoch: 27 Train loss: 0.28131 Validation loss: 0.42794\n",
            "Epoch: 28 Train loss: 0.28086 Validation loss: 0.42678\n",
            "Epoch: 29 Train loss: 0.28041 Validation loss: 0.4257\n",
            "Epoch: 30 Train loss: 0.27996 Validation loss: 0.42468\n",
            "Epoch: 31 Train loss: 0.2795 Validation loss: 0.42374\n",
            "Epoch: 32 Train loss: 0.27905 Validation loss: 0.42285\n",
            "Epoch: 33 Train loss: 0.27859 Validation loss: 0.42203\n",
            "Epoch: 34 Train loss: 0.27813 Validation loss: 0.42127\n",
            "Epoch: 35 Train loss: 0.27766 Validation loss: 0.42056\n",
            "Epoch: 36 Train loss: 0.27719 Validation loss: 0.4199\n",
            "Epoch: 37 Train loss: 0.2767 Validation loss: 0.4193\n",
            "Epoch: 38 Train loss: 0.27621 Validation loss: 0.41873\n",
            "Epoch: 39 Train loss: 0.2757 Validation loss: 0.41822\n",
            "Epoch: 40 Train loss: 0.27518 Validation loss: 0.41774\n",
            "Epoch: 41 Train loss: 0.27465 Validation loss: 0.41731\n",
            "Epoch: 42 Train loss: 0.2741 Validation loss: 0.41691\n",
            "Epoch: 43 Train loss: 0.27354 Validation loss: 0.41654\n",
            "Epoch: 44 Train loss: 0.27296 Validation loss: 0.41621\n",
            "Epoch: 45 Train loss: 0.27236 Validation loss: 0.41591\n",
            "Epoch: 46 Train loss: 0.27174 Validation loss: 0.41564\n",
            "Epoch: 47 Train loss: 0.2711 Validation loss: 0.4154\n",
            "Epoch: 48 Train loss: 0.27044 Validation loss: 0.41518\n",
            "Epoch: 49 Train loss: 0.26975 Validation loss: 0.41498\n",
            "Epoch: 50 Train loss: 0.26903 Validation loss: 0.41481\n",
            "Epoch: 51 Train loss: 0.26829 Validation loss: 0.41465\n",
            "Epoch: 52 Train loss: 0.26752 Validation loss: 0.41452\n",
            "Epoch: 53 Train loss: 0.26671 Validation loss: 0.4144\n",
            "Epoch: 54 Train loss: 0.26587 Validation loss: 0.41429\n",
            "Epoch: 55 Train loss: 0.26499 Validation loss: 0.41419\n",
            "Epoch: 56 Train loss: 0.26407 Validation loss: 0.41411\n",
            "Epoch: 57 Train loss: 0.26312 Validation loss: 0.41404\n",
            "Epoch: 58 Train loss: 0.26212 Validation loss: 0.41397\n",
            "Epoch: 59 Train loss: 0.26107 Validation loss: 0.41392\n",
            "Epoch: 60 Train loss: 0.25997 Validation loss: 0.41387\n",
            "Epoch: 61 Train loss: 0.25882 Validation loss: 0.41383\n",
            "Epoch: 62 Train loss: 0.25762 Validation loss: 0.4138\n",
            "Epoch: 63 Train loss: 0.25636 Validation loss: 0.41377\n",
            "Epoch: 64 Train loss: 0.25504 Validation loss: 0.41376\n",
            "Epoch: 65 Train loss: 0.25366 Validation loss: 0.41377\n",
            "Epoch: 66 Train loss: 0.25222 Validation loss: 0.41379\n",
            "Epoch: 67 Train loss: 0.25071 Validation loss: 0.41384\n",
            "Epoch: 68 Train loss: 0.24913 Validation loss: 0.41391\n",
            "Epoch: 69 Train loss: 0.24748 Validation loss: 0.41402\n",
            "Epoch: 70 Train loss: 0.24576 Validation loss: 0.41416\n",
            "Epoch: 71 Train loss: 0.24398 Validation loss: 0.41436\n",
            "Epoch: 72 Train loss: 0.24213 Validation loss: 0.4146\n",
            "Epoch: 73 Train loss: 0.24022 Validation loss: 0.41489\n",
            "Epoch: 74 Train loss: 0.23826 Validation loss: 0.41524\n",
            "Epoch: 75 Train loss: 0.23625 Validation loss: 0.41564\n",
            "Epoch: 76 Train loss: 0.23421 Validation loss: 0.41607\n",
            "Epoch: 77 Train loss: 0.23215 Validation loss: 0.41653\n",
            "Epoch: 78 Train loss: 0.23008 Validation loss: 0.417\n",
            "Epoch: 79 Train loss: 0.22802 Validation loss: 0.41746\n",
            "Epoch: 80 Train loss: 0.22599 Validation loss: 0.41788\n",
            "Epoch: 81 Train loss: 0.22401 Validation loss: 0.41823\n",
            "Epoch: 82 Train loss: 0.22208 Validation loss: 0.4185\n",
            "Epoch: 83 Train loss: 0.22022 Validation loss: 0.41867\n",
            "Epoch: 84 Train loss: 0.21844 Validation loss: 0.41871\n",
            "Epoch: 85 Train loss: 0.21673 Validation loss: 0.41863\n",
            "Epoch: 86 Train loss: 0.21512 Validation loss: 0.41841\n",
            "Epoch: 87 Train loss: 0.21358 Validation loss: 0.41808\n",
            "Epoch: 88 Train loss: 0.21212 Validation loss: 0.41762\n",
            "Epoch: 89 Train loss: 0.21074 Validation loss: 0.41706\n",
            "Epoch: 90 Train loss: 0.20943 Validation loss: 0.41641\n",
            "Epoch: 91 Train loss: 0.20818 Validation loss: 0.41568\n",
            "Epoch: 92 Train loss: 0.20699 Validation loss: 0.41488\n",
            "Epoch: 93 Train loss: 0.20585 Validation loss: 0.41403\n",
            "Epoch: 94 Train loss: 0.20475 Validation loss: 0.41314\n",
            "Epoch: 95 Train loss: 0.2037 Validation loss: 0.41222\n",
            "Epoch: 96 Train loss: 0.20267 Validation loss: 0.41128\n",
            "Epoch: 97 Train loss: 0.20168 Validation loss: 0.41033\n",
            "Epoch: 98 Train loss: 0.20072 Validation loss: 0.40937\n",
            "Epoch: 99 Train loss: 0.19977 Validation loss: 0.40841\n",
            "Epoch: 100 Train loss: 0.19885 Validation loss: 0.40745\n",
            "Epoch: 101 Train loss: 0.19794 Validation loss: 0.40649\n",
            "Epoch: 102 Train loss: 0.19705 Validation loss: 0.40554\n",
            "Epoch: 103 Train loss: 0.19617 Validation loss: 0.40461\n",
            "Epoch: 104 Train loss: 0.1953 Validation loss: 0.40368\n",
            "Epoch: 105 Train loss: 0.19443 Validation loss: 0.40277\n",
            "Epoch: 106 Train loss: 0.19358 Validation loss: 0.40186\n",
            "Epoch: 107 Train loss: 0.19273 Validation loss: 0.40097\n",
            "Epoch: 108 Train loss: 0.19189 Validation loss: 0.40009\n",
            "Epoch: 109 Train loss: 0.19106 Validation loss: 0.39922\n",
            "Epoch: 110 Train loss: 0.19022 Validation loss: 0.39837\n",
            "Epoch: 111 Train loss: 0.18939 Validation loss: 0.39752\n",
            "Epoch: 112 Train loss: 0.18857 Validation loss: 0.39669\n",
            "Epoch: 113 Train loss: 0.18774 Validation loss: 0.39586\n",
            "Epoch: 114 Train loss: 0.18692 Validation loss: 0.39505\n",
            "Epoch: 115 Train loss: 0.1861 Validation loss: 0.39424\n",
            "Epoch: 116 Train loss: 0.18528 Validation loss: 0.39344\n",
            "Epoch: 117 Train loss: 0.18446 Validation loss: 0.39264\n",
            "Epoch: 118 Train loss: 0.18365 Validation loss: 0.39186\n",
            "Epoch: 119 Train loss: 0.18283 Validation loss: 0.39107\n",
            "Epoch: 120 Train loss: 0.18201 Validation loss: 0.39029\n",
            "Epoch: 121 Train loss: 0.1812 Validation loss: 0.38952\n",
            "Epoch: 122 Train loss: 0.18039 Validation loss: 0.38875\n",
            "Epoch: 123 Train loss: 0.17957 Validation loss: 0.38798\n",
            "Epoch: 124 Train loss: 0.17876 Validation loss: 0.38721\n",
            "Epoch: 125 Train loss: 0.17795 Validation loss: 0.38645\n",
            "Epoch: 126 Train loss: 0.17713 Validation loss: 0.38569\n",
            "Epoch: 127 Train loss: 0.17632 Validation loss: 0.38493\n",
            "Epoch: 128 Train loss: 0.17551 Validation loss: 0.38416\n",
            "Epoch: 129 Train loss: 0.1747 Validation loss: 0.3834\n",
            "Epoch: 130 Train loss: 0.17389 Validation loss: 0.38264\n",
            "Epoch: 131 Train loss: 0.17308 Validation loss: 0.38187\n",
            "Epoch: 132 Train loss: 0.17227 Validation loss: 0.38111\n",
            "Epoch: 133 Train loss: 0.17146 Validation loss: 0.38034\n",
            "Epoch: 134 Train loss: 0.17066 Validation loss: 0.37957\n",
            "Epoch: 135 Train loss: 0.16985 Validation loss: 0.3788\n",
            "Epoch: 136 Train loss: 0.16904 Validation loss: 0.37802\n",
            "Epoch: 137 Train loss: 0.16824 Validation loss: 0.37724\n",
            "Epoch: 138 Train loss: 0.16743 Validation loss: 0.37646\n",
            "Epoch: 139 Train loss: 0.16663 Validation loss: 0.37567\n",
            "Epoch: 140 Train loss: 0.16583 Validation loss: 0.37489\n",
            "Epoch: 141 Train loss: 0.16502 Validation loss: 0.37409\n",
            "Epoch: 142 Train loss: 0.16422 Validation loss: 0.3733\n",
            "Epoch: 143 Train loss: 0.16342 Validation loss: 0.3725\n",
            "Epoch: 144 Train loss: 0.16262 Validation loss: 0.37169\n",
            "Epoch: 145 Train loss: 0.16183 Validation loss: 0.37088\n",
            "Epoch: 146 Train loss: 0.16103 Validation loss: 0.37007\n",
            "Epoch: 147 Train loss: 0.16023 Validation loss: 0.36925\n",
            "Epoch: 148 Train loss: 0.15944 Validation loss: 0.36842\n",
            "Epoch: 149 Train loss: 0.15865 Validation loss: 0.36759\n",
            "Epoch: 150 Train loss: 0.15785 Validation loss: 0.36676\n",
            "Epoch: 151 Train loss: 0.15706 Validation loss: 0.36592\n",
            "Epoch: 152 Train loss: 0.15627 Validation loss: 0.36508\n",
            "Epoch: 153 Train loss: 0.15549 Validation loss: 0.36423\n",
            "Epoch: 154 Train loss: 0.1547 Validation loss: 0.36338\n",
            "Epoch: 155 Train loss: 0.15392 Validation loss: 0.36252\n",
            "Epoch: 156 Train loss: 0.15313 Validation loss: 0.36165\n",
            "Epoch: 157 Train loss: 0.15235 Validation loss: 0.36078\n",
            "Epoch: 158 Train loss: 0.15157 Validation loss: 0.35991\n",
            "Epoch: 159 Train loss: 0.1508 Validation loss: 0.35903\n",
            "Epoch: 160 Train loss: 0.15002 Validation loss: 0.35814\n",
            "Epoch: 161 Train loss: 0.14925 Validation loss: 0.35725\n",
            "Epoch: 162 Train loss: 0.14847 Validation loss: 0.35636\n",
            "Epoch: 163 Train loss: 0.1477 Validation loss: 0.35546\n",
            "Epoch: 164 Train loss: 0.14694 Validation loss: 0.35455\n",
            "Epoch: 165 Train loss: 0.14617 Validation loss: 0.35364\n",
            "Epoch: 166 Train loss: 0.14541 Validation loss: 0.35272\n",
            "Epoch: 167 Train loss: 0.14464 Validation loss: 0.3518\n",
            "Epoch: 168 Train loss: 0.14388 Validation loss: 0.35088\n",
            "Epoch: 169 Train loss: 0.14313 Validation loss: 0.34994\n",
            "Epoch: 170 Train loss: 0.14237 Validation loss: 0.34901\n",
            "Epoch: 171 Train loss: 0.14162 Validation loss: 0.34807\n",
            "Epoch: 172 Train loss: 0.14087 Validation loss: 0.34712\n",
            "Epoch: 173 Train loss: 0.14012 Validation loss: 0.34617\n",
            "Epoch: 174 Train loss: 0.13937 Validation loss: 0.34521\n",
            "Epoch: 175 Train loss: 0.13863 Validation loss: 0.34425\n",
            "Epoch: 176 Train loss: 0.13788 Validation loss: 0.34329\n",
            "Epoch: 177 Train loss: 0.13714 Validation loss: 0.34232\n",
            "Epoch: 178 Train loss: 0.13641 Validation loss: 0.34134\n",
            "Epoch: 179 Train loss: 0.13567 Validation loss: 0.34037\n",
            "Epoch: 180 Train loss: 0.13494 Validation loss: 0.33938\n",
            "Epoch: 181 Train loss: 0.13421 Validation loss: 0.33839\n",
            "Epoch: 182 Train loss: 0.13349 Validation loss: 0.3374\n",
            "Epoch: 183 Train loss: 0.13276 Validation loss: 0.33641\n",
            "Epoch: 184 Train loss: 0.13204 Validation loss: 0.33541\n",
            "Epoch: 185 Train loss: 0.13132 Validation loss: 0.3344\n",
            "Epoch: 186 Train loss: 0.13061 Validation loss: 0.33339\n",
            "Epoch: 187 Train loss: 0.12989 Validation loss: 0.33238\n",
            "Epoch: 188 Train loss: 0.12918 Validation loss: 0.33136\n",
            "Epoch: 189 Train loss: 0.12847 Validation loss: 0.33034\n",
            "Epoch: 190 Train loss: 0.12777 Validation loss: 0.32932\n",
            "Epoch: 191 Train loss: 0.12707 Validation loss: 0.32829\n",
            "Epoch: 192 Train loss: 0.12637 Validation loss: 0.32726\n",
            "Epoch: 193 Train loss: 0.12567 Validation loss: 0.32623\n",
            "Epoch: 194 Train loss: 0.12498 Validation loss: 0.32519\n",
            "Epoch: 195 Train loss: 0.12429 Validation loss: 0.32415\n",
            "Epoch: 196 Train loss: 0.1236 Validation loss: 0.32311\n",
            "Epoch: 197 Train loss: 0.12291 Validation loss: 0.32206\n",
            "Epoch: 198 Train loss: 0.12223 Validation loss: 0.32101\n",
            "Epoch: 199 Train loss: 0.12155 Validation loss: 0.31996\n",
            "Epoch: 200 Train loss: 0.12088 Validation loss: 0.3189\n",
            "Epoch: 201 Train loss: 0.12021 Validation loss: 0.31784\n",
            "Epoch: 202 Train loss: 0.11954 Validation loss: 0.31678\n",
            "Epoch: 203 Train loss: 0.11887 Validation loss: 0.31571\n",
            "Epoch: 204 Train loss: 0.11821 Validation loss: 0.31465\n",
            "Epoch: 205 Train loss: 0.11755 Validation loss: 0.31358\n",
            "Epoch: 206 Train loss: 0.11689 Validation loss: 0.31251\n",
            "Epoch: 207 Train loss: 0.11623 Validation loss: 0.31143\n",
            "Epoch: 208 Train loss: 0.11558 Validation loss: 0.31036\n",
            "Epoch: 209 Train loss: 0.11494 Validation loss: 0.30928\n",
            "Epoch: 210 Train loss: 0.11429 Validation loss: 0.3082\n",
            "Epoch: 211 Train loss: 0.11365 Validation loss: 0.30712\n",
            "Epoch: 212 Train loss: 0.11301 Validation loss: 0.30603\n",
            "Epoch: 213 Train loss: 0.11238 Validation loss: 0.30495\n",
            "Epoch: 214 Train loss: 0.11175 Validation loss: 0.30386\n",
            "Epoch: 215 Train loss: 0.11112 Validation loss: 0.30277\n",
            "Epoch: 216 Train loss: 0.11049 Validation loss: 0.30168\n",
            "Epoch: 217 Train loss: 0.10987 Validation loss: 0.30059\n",
            "Epoch: 218 Train loss: 0.10925 Validation loss: 0.29949\n",
            "Epoch: 219 Train loss: 0.10864 Validation loss: 0.2984\n",
            "Epoch: 220 Train loss: 0.10802 Validation loss: 0.2973\n",
            "Epoch: 221 Train loss: 0.10742 Validation loss: 0.2962\n",
            "Epoch: 222 Train loss: 0.10681 Validation loss: 0.29511\n",
            "Epoch: 223 Train loss: 0.10621 Validation loss: 0.29401\n",
            "Epoch: 224 Train loss: 0.10561 Validation loss: 0.2929\n",
            "Epoch: 225 Train loss: 0.10501 Validation loss: 0.2918\n",
            "Epoch: 226 Train loss: 0.10442 Validation loss: 0.2907\n",
            "Epoch: 227 Train loss: 0.10383 Validation loss: 0.2896\n",
            "Epoch: 228 Train loss: 0.10325 Validation loss: 0.2885\n",
            "Epoch: 229 Train loss: 0.10266 Validation loss: 0.28739\n",
            "Epoch: 230 Train loss: 0.10208 Validation loss: 0.28629\n",
            "Epoch: 231 Train loss: 0.10151 Validation loss: 0.28519\n",
            "Epoch: 232 Train loss: 0.10094 Validation loss: 0.28408\n",
            "Epoch: 233 Train loss: 0.10037 Validation loss: 0.28298\n",
            "Epoch: 234 Train loss: 0.099802 Validation loss: 0.28187\n",
            "Epoch: 235 Train loss: 0.09924 Validation loss: 0.28077\n",
            "Epoch: 236 Train loss: 0.098681 Validation loss: 0.27966\n",
            "Epoch: 237 Train loss: 0.098126 Validation loss: 0.27856\n",
            "Epoch: 238 Train loss: 0.097573 Validation loss: 0.27745\n",
            "Epoch: 239 Train loss: 0.097024 Validation loss: 0.27635\n",
            "Epoch: 240 Train loss: 0.096479 Validation loss: 0.27525\n",
            "Epoch: 241 Train loss: 0.095936 Validation loss: 0.27414\n",
            "Epoch: 242 Train loss: 0.095398 Validation loss: 0.27304\n",
            "Epoch: 243 Train loss: 0.094862 Validation loss: 0.27194\n",
            "Epoch: 244 Train loss: 0.09433 Validation loss: 0.27084\n",
            "Epoch: 245 Train loss: 0.093801 Validation loss: 0.26974\n",
            "Epoch: 246 Train loss: 0.093275 Validation loss: 0.26864\n",
            "Epoch: 247 Train loss: 0.092753 Validation loss: 0.26754\n",
            "Epoch: 248 Train loss: 0.092234 Validation loss: 0.26644\n",
            "Epoch: 249 Train loss: 0.091718 Validation loss: 0.26534\n",
            "Epoch: 250 Train loss: 0.091206 Validation loss: 0.26424\n",
            "Epoch: 251 Train loss: 0.090697 Validation loss: 0.26315\n",
            "Epoch: 252 Train loss: 0.090191 Validation loss: 0.26205\n",
            "Epoch: 253 Train loss: 0.089688 Validation loss: 0.26096\n",
            "Epoch: 254 Train loss: 0.089189 Validation loss: 0.25987\n",
            "Epoch: 255 Train loss: 0.088693 Validation loss: 0.25878\n",
            "Epoch: 256 Train loss: 0.0882 Validation loss: 0.25769\n",
            "Epoch: 257 Train loss: 0.087711 Validation loss: 0.2566\n",
            "Epoch: 258 Train loss: 0.087225 Validation loss: 0.25552\n",
            "Epoch: 259 Train loss: 0.086742 Validation loss: 0.25443\n",
            "Epoch: 260 Train loss: 0.086262 Validation loss: 0.25335\n",
            "Epoch: 261 Train loss: 0.085785 Validation loss: 0.25227\n",
            "Epoch: 262 Train loss: 0.085312 Validation loss: 0.25119\n",
            "Epoch: 263 Train loss: 0.084842 Validation loss: 0.25011\n",
            "Epoch: 264 Train loss: 0.084375 Validation loss: 0.24903\n",
            "Epoch: 265 Train loss: 0.083911 Validation loss: 0.24796\n",
            "Epoch: 266 Train loss: 0.083451 Validation loss: 0.24689\n",
            "Epoch: 267 Train loss: 0.082994 Validation loss: 0.24582\n",
            "Epoch: 268 Train loss: 0.082539 Validation loss: 0.24475\n",
            "Epoch: 269 Train loss: 0.082088 Validation loss: 0.24368\n",
            "Epoch: 270 Train loss: 0.08164 Validation loss: 0.24262\n",
            "Epoch: 271 Train loss: 0.081196 Validation loss: 0.24156\n",
            "Epoch: 272 Train loss: 0.080754 Validation loss: 0.2405\n",
            "Epoch: 273 Train loss: 0.080315 Validation loss: 0.23944\n",
            "Epoch: 274 Train loss: 0.07988 Validation loss: 0.23839\n",
            "Epoch: 275 Train loss: 0.079447 Validation loss: 0.23733\n",
            "Epoch: 276 Train loss: 0.079018 Validation loss: 0.23628\n",
            "Epoch: 277 Train loss: 0.078592 Validation loss: 0.23524\n",
            "Epoch: 278 Train loss: 0.078169 Validation loss: 0.23419\n",
            "Epoch: 279 Train loss: 0.077748 Validation loss: 0.23315\n",
            "Epoch: 280 Train loss: 0.077331 Validation loss: 0.23211\n",
            "Epoch: 281 Train loss: 0.076917 Validation loss: 0.23107\n",
            "Epoch: 282 Train loss: 0.076506 Validation loss: 0.23004\n",
            "Epoch: 283 Train loss: 0.076097 Validation loss: 0.229\n",
            "Epoch: 284 Train loss: 0.075692 Validation loss: 0.22797\n",
            "Epoch: 285 Train loss: 0.07529 Validation loss: 0.22695\n",
            "Epoch: 286 Train loss: 0.07489 Validation loss: 0.22592\n",
            "Epoch: 287 Train loss: 0.074494 Validation loss: 0.2249\n",
            "Epoch: 288 Train loss: 0.074101 Validation loss: 0.22388\n",
            "Epoch: 289 Train loss: 0.07371 Validation loss: 0.22287\n",
            "Epoch: 290 Train loss: 0.073322 Validation loss: 0.22185\n",
            "Epoch: 291 Train loss: 0.072937 Validation loss: 0.22084\n",
            "Epoch: 292 Train loss: 0.072555 Validation loss: 0.21984\n",
            "Epoch: 293 Train loss: 0.072176 Validation loss: 0.21884\n",
            "Epoch: 294 Train loss: 0.0718 Validation loss: 0.21783\n",
            "Epoch: 295 Train loss: 0.071426 Validation loss: 0.21684\n",
            "Epoch: 296 Train loss: 0.071056 Validation loss: 0.21584\n",
            "Epoch: 297 Train loss: 0.070688 Validation loss: 0.21485\n",
            "Epoch: 298 Train loss: 0.070322 Validation loss: 0.21386\n",
            "Epoch: 299 Train loss: 0.06996 Validation loss: 0.21288\n",
            "Epoch: 300 Train loss: 0.0696 Validation loss: 0.2119\n",
            "Epoch: 301 Train loss: 0.069243 Validation loss: 0.21092\n",
            "Epoch: 302 Train loss: 0.068889 Validation loss: 0.20994\n",
            "Epoch: 303 Train loss: 0.068538 Validation loss: 0.20897\n",
            "Epoch: 304 Train loss: 0.068189 Validation loss: 0.208\n",
            "Epoch: 305 Train loss: 0.067843 Validation loss: 0.20703\n",
            "Epoch: 306 Train loss: 0.067499 Validation loss: 0.20607\n",
            "Epoch: 307 Train loss: 0.067158 Validation loss: 0.20511\n",
            "Epoch: 308 Train loss: 0.06682 Validation loss: 0.20416\n",
            "Epoch: 309 Train loss: 0.066484 Validation loss: 0.20321\n",
            "Epoch: 310 Train loss: 0.066151 Validation loss: 0.20226\n",
            "Epoch: 311 Train loss: 0.06582 Validation loss: 0.20131\n",
            "Epoch: 312 Train loss: 0.065492 Validation loss: 0.20037\n",
            "Epoch: 313 Train loss: 0.065167 Validation loss: 0.19943\n",
            "Epoch: 314 Train loss: 0.064844 Validation loss: 0.1985\n",
            "Epoch: 315 Train loss: 0.064524 Validation loss: 0.19757\n",
            "Epoch: 316 Train loss: 0.064206 Validation loss: 0.19664\n",
            "Epoch: 317 Train loss: 0.06389 Validation loss: 0.19571\n",
            "Epoch: 318 Train loss: 0.063577 Validation loss: 0.19479\n",
            "Epoch: 319 Train loss: 0.063267 Validation loss: 0.19387\n",
            "Epoch: 320 Train loss: 0.062959 Validation loss: 0.19296\n",
            "Epoch: 321 Train loss: 0.062653 Validation loss: 0.19205\n",
            "Epoch: 322 Train loss: 0.06235 Validation loss: 0.19114\n",
            "Epoch: 323 Train loss: 0.062049 Validation loss: 0.19024\n",
            "Epoch: 324 Train loss: 0.06175 Validation loss: 0.18934\n",
            "Epoch: 325 Train loss: 0.061454 Validation loss: 0.18844\n",
            "Epoch: 326 Train loss: 0.06116 Validation loss: 0.18755\n",
            "Epoch: 327 Train loss: 0.060869 Validation loss: 0.18666\n",
            "Epoch: 328 Train loss: 0.06058 Validation loss: 0.18578\n",
            "Epoch: 329 Train loss: 0.060293 Validation loss: 0.1849\n",
            "Epoch: 330 Train loss: 0.060008 Validation loss: 0.18402\n",
            "Epoch: 331 Train loss: 0.059726 Validation loss: 0.18315\n",
            "Epoch: 332 Train loss: 0.059446 Validation loss: 0.18228\n",
            "Epoch: 333 Train loss: 0.059168 Validation loss: 0.18141\n",
            "Epoch: 334 Train loss: 0.058892 Validation loss: 0.18055\n",
            "Epoch: 335 Train loss: 0.058619 Validation loss: 0.17969\n",
            "Epoch: 336 Train loss: 0.058347 Validation loss: 0.17883\n",
            "Epoch: 337 Train loss: 0.058078 Validation loss: 0.17798\n",
            "Epoch: 338 Train loss: 0.057811 Validation loss: 0.17713\n",
            "Epoch: 339 Train loss: 0.057546 Validation loss: 0.17629\n",
            "Epoch: 340 Train loss: 0.057284 Validation loss: 0.17545\n",
            "Epoch: 341 Train loss: 0.057023 Validation loss: 0.17461\n",
            "Epoch: 342 Train loss: 0.056765 Validation loss: 0.17378\n",
            "Epoch: 343 Train loss: 0.056508 Validation loss: 0.17294\n",
            "Epoch: 344 Train loss: 0.056254 Validation loss: 0.17212\n",
            "Epoch: 345 Train loss: 0.056002 Validation loss: 0.1713\n",
            "Epoch: 346 Train loss: 0.055751 Validation loss: 0.17048\n",
            "Epoch: 347 Train loss: 0.055503 Validation loss: 0.16966\n",
            "Epoch: 348 Train loss: 0.055257 Validation loss: 0.16885\n",
            "Epoch: 349 Train loss: 0.055012 Validation loss: 0.16804\n",
            "Epoch: 350 Train loss: 0.05477 Validation loss: 0.16724\n",
            "Epoch: 351 Train loss: 0.05453 Validation loss: 0.16644\n",
            "Epoch: 352 Train loss: 0.054291 Validation loss: 0.16564\n",
            "Epoch: 353 Train loss: 0.054055 Validation loss: 0.16485\n",
            "Epoch: 354 Train loss: 0.05382 Validation loss: 0.16406\n",
            "Epoch: 355 Train loss: 0.053588 Validation loss: 0.16328\n",
            "Epoch: 356 Train loss: 0.053357 Validation loss: 0.1625\n",
            "Epoch: 357 Train loss: 0.053128 Validation loss: 0.16172\n",
            "Epoch: 358 Train loss: 0.052901 Validation loss: 0.16094\n",
            "Epoch: 359 Train loss: 0.052676 Validation loss: 0.16017\n",
            "Epoch: 360 Train loss: 0.052452 Validation loss: 0.15941\n",
            "Epoch: 361 Train loss: 0.052231 Validation loss: 0.15864\n",
            "Epoch: 362 Train loss: 0.052011 Validation loss: 0.15788\n",
            "Epoch: 363 Train loss: 0.051793 Validation loss: 0.15713\n",
            "Epoch: 364 Train loss: 0.051577 Validation loss: 0.15638\n",
            "Epoch: 365 Train loss: 0.051362 Validation loss: 0.15563\n",
            "Epoch: 366 Train loss: 0.05115 Validation loss: 0.15488\n",
            "Epoch: 367 Train loss: 0.050939 Validation loss: 0.15414\n",
            "Epoch: 368 Train loss: 0.050729 Validation loss: 0.1534\n",
            "Epoch: 369 Train loss: 0.050522 Validation loss: 0.15267\n",
            "Epoch: 370 Train loss: 0.050316 Validation loss: 0.15194\n",
            "Epoch: 371 Train loss: 0.050112 Validation loss: 0.15122\n",
            "Epoch: 372 Train loss: 0.049909 Validation loss: 0.15049\n",
            "Epoch: 373 Train loss: 0.049708 Validation loss: 0.14977\n",
            "Epoch: 374 Train loss: 0.049509 Validation loss: 0.14906\n",
            "Epoch: 375 Train loss: 0.049312 Validation loss: 0.14835\n",
            "Epoch: 376 Train loss: 0.049116 Validation loss: 0.14764\n",
            "Epoch: 377 Train loss: 0.048921 Validation loss: 0.14693\n",
            "Epoch: 378 Train loss: 0.048728 Validation loss: 0.14623\n",
            "Epoch: 379 Train loss: 0.048537 Validation loss: 0.14553\n",
            "Epoch: 380 Train loss: 0.048347 Validation loss: 0.14484\n",
            "Epoch: 381 Train loss: 0.048159 Validation loss: 0.14415\n",
            "Epoch: 382 Train loss: 0.047973 Validation loss: 0.14346\n",
            "Epoch: 383 Train loss: 0.047787 Validation loss: 0.14278\n",
            "Epoch: 384 Train loss: 0.047604 Validation loss: 0.1421\n",
            "Epoch: 385 Train loss: 0.047422 Validation loss: 0.14142\n",
            "Epoch: 386 Train loss: 0.047241 Validation loss: 0.14075\n",
            "Epoch: 387 Train loss: 0.047062 Validation loss: 0.14008\n",
            "Epoch: 388 Train loss: 0.046884 Validation loss: 0.13941\n",
            "Epoch: 389 Train loss: 0.046708 Validation loss: 0.13875\n",
            "Epoch: 390 Train loss: 0.046533 Validation loss: 0.13809\n",
            "Epoch: 391 Train loss: 0.04636 Validation loss: 0.13744\n",
            "Epoch: 392 Train loss: 0.046188 Validation loss: 0.13678\n",
            "Epoch: 393 Train loss: 0.046017 Validation loss: 0.13614\n",
            "Epoch: 394 Train loss: 0.045848 Validation loss: 0.13549\n",
            "Epoch: 395 Train loss: 0.04568 Validation loss: 0.13485\n",
            "Epoch: 396 Train loss: 0.045514 Validation loss: 0.13421\n",
            "Epoch: 397 Train loss: 0.045349 Validation loss: 0.13358\n",
            "Epoch: 398 Train loss: 0.045185 Validation loss: 0.13294\n",
            "Epoch: 399 Train loss: 0.045022 Validation loss: 0.13232\n",
            "Epoch: 400 Train loss: 0.044861 Validation loss: 0.13169\n",
            "Epoch: 401 Train loss: 0.044701 Validation loss: 0.13107\n",
            "Epoch: 402 Train loss: 0.044543 Validation loss: 0.13045\n",
            "Epoch: 403 Train loss: 0.044386 Validation loss: 0.12984\n",
            "Epoch: 404 Train loss: 0.04423 Validation loss: 0.12923\n",
            "Epoch: 405 Train loss: 0.044075 Validation loss: 0.12862\n",
            "Epoch: 406 Train loss: 0.043922 Validation loss: 0.12801\n",
            "Epoch: 407 Train loss: 0.043769 Validation loss: 0.12741\n",
            "Epoch: 408 Train loss: 0.043618 Validation loss: 0.12681\n",
            "Epoch: 409 Train loss: 0.043469 Validation loss: 0.12622\n",
            "Epoch: 410 Train loss: 0.04332 Validation loss: 0.12563\n",
            "Epoch: 411 Train loss: 0.043173 Validation loss: 0.12504\n",
            "Epoch: 412 Train loss: 0.043027 Validation loss: 0.12445\n",
            "Epoch: 413 Train loss: 0.042882 Validation loss: 0.12387\n",
            "Epoch: 414 Train loss: 0.042738 Validation loss: 0.12329\n",
            "Epoch: 415 Train loss: 0.042595 Validation loss: 0.12271\n",
            "Epoch: 416 Train loss: 0.042454 Validation loss: 0.12214\n",
            "Epoch: 417 Train loss: 0.042313 Validation loss: 0.12157\n",
            "Epoch: 418 Train loss: 0.042174 Validation loss: 0.12101\n",
            "Epoch: 419 Train loss: 0.042036 Validation loss: 0.12044\n",
            "Epoch: 420 Train loss: 0.041899 Validation loss: 0.11988\n",
            "Epoch: 421 Train loss: 0.041763 Validation loss: 0.11933\n",
            "Epoch: 422 Train loss: 0.041628 Validation loss: 0.11877\n",
            "Epoch: 423 Train loss: 0.041494 Validation loss: 0.11822\n",
            "Epoch: 424 Train loss: 0.041362 Validation loss: 0.11767\n",
            "Epoch: 425 Train loss: 0.04123 Validation loss: 0.11713\n",
            "Epoch: 426 Train loss: 0.0411 Validation loss: 0.11659\n",
            "Epoch: 427 Train loss: 0.04097 Validation loss: 0.11605\n",
            "Epoch: 428 Train loss: 0.040842 Validation loss: 0.11551\n",
            "Epoch: 429 Train loss: 0.040714 Validation loss: 0.11498\n",
            "Epoch: 430 Train loss: 0.040588 Validation loss: 0.11445\n",
            "Epoch: 431 Train loss: 0.040462 Validation loss: 0.11392\n",
            "Epoch: 432 Train loss: 0.040338 Validation loss: 0.1134\n",
            "Epoch: 433 Train loss: 0.040214 Validation loss: 0.11288\n",
            "Epoch: 434 Train loss: 0.040092 Validation loss: 0.11236\n",
            "Epoch: 435 Train loss: 0.03997 Validation loss: 0.11185\n",
            "Epoch: 436 Train loss: 0.03985 Validation loss: 0.11134\n",
            "Epoch: 437 Train loss: 0.03973 Validation loss: 0.11083\n",
            "Epoch: 438 Train loss: 0.039612 Validation loss: 0.11032\n",
            "Epoch: 439 Train loss: 0.039494 Validation loss: 0.10982\n",
            "Epoch: 440 Train loss: 0.039377 Validation loss: 0.10932\n",
            "Epoch: 441 Train loss: 0.039261 Validation loss: 0.10882\n",
            "Epoch: 442 Train loss: 0.039146 Validation loss: 0.10833\n",
            "Epoch: 443 Train loss: 0.039032 Validation loss: 0.10783\n",
            "Epoch: 444 Train loss: 0.038919 Validation loss: 0.10734\n",
            "Epoch: 445 Train loss: 0.038807 Validation loss: 0.10686\n",
            "Epoch: 446 Train loss: 0.038696 Validation loss: 0.10637\n",
            "Epoch: 447 Train loss: 0.038585 Validation loss: 0.10589\n",
            "Epoch: 448 Train loss: 0.038475 Validation loss: 0.10541\n",
            "Epoch: 449 Train loss: 0.038367 Validation loss: 0.10494\n",
            "Epoch: 450 Train loss: 0.038259 Validation loss: 0.10447\n",
            "Epoch: 451 Train loss: 0.038152 Validation loss: 0.104\n",
            "Epoch: 452 Train loss: 0.038045 Validation loss: 0.10353\n",
            "Epoch: 453 Train loss: 0.03794 Validation loss: 0.10307\n",
            "Epoch: 454 Train loss: 0.037835 Validation loss: 0.1026\n",
            "Epoch: 455 Train loss: 0.037732 Validation loss: 0.10215\n",
            "Epoch: 456 Train loss: 0.037629 Validation loss: 0.10169\n",
            "Epoch: 457 Train loss: 0.037526 Validation loss: 0.10123\n",
            "Epoch: 458 Train loss: 0.037425 Validation loss: 0.10078\n",
            "Epoch: 459 Train loss: 0.037324 Validation loss: 0.10034\n",
            "Epoch: 460 Train loss: 0.037225 Validation loss: 0.09989\n",
            "Epoch: 461 Train loss: 0.037126 Validation loss: 0.099445\n",
            "Epoch: 462 Train loss: 0.037027 Validation loss: 0.099005\n",
            "Epoch: 463 Train loss: 0.03693 Validation loss: 0.098567\n",
            "Epoch: 464 Train loss: 0.036833 Validation loss: 0.09813\n",
            "Epoch: 465 Train loss: 0.036737 Validation loss: 0.097697\n",
            "Epoch: 466 Train loss: 0.036642 Validation loss: 0.097266\n",
            "Epoch: 467 Train loss: 0.036547 Validation loss: 0.096838\n",
            "Epoch: 468 Train loss: 0.036453 Validation loss: 0.096412\n",
            "Epoch: 469 Train loss: 0.03636 Validation loss: 0.095989\n",
            "Epoch: 470 Train loss: 0.036267 Validation loss: 0.095568\n",
            "Epoch: 471 Train loss: 0.036176 Validation loss: 0.095149\n",
            "Epoch: 472 Train loss: 0.036085 Validation loss: 0.094734\n",
            "Epoch: 473 Train loss: 0.035994 Validation loss: 0.094319\n",
            "Epoch: 474 Train loss: 0.035905 Validation loss: 0.093909\n",
            "Epoch: 475 Train loss: 0.035816 Validation loss: 0.0935\n",
            "Epoch: 476 Train loss: 0.035727 Validation loss: 0.093094\n",
            "Epoch: 477 Train loss: 0.03564 Validation loss: 0.092691\n",
            "Epoch: 478 Train loss: 0.035553 Validation loss: 0.092289\n",
            "Epoch: 479 Train loss: 0.035466 Validation loss: 0.091888\n",
            "Epoch: 480 Train loss: 0.035381 Validation loss: 0.091492\n",
            "Epoch: 481 Train loss: 0.035296 Validation loss: 0.091097\n",
            "Epoch: 482 Train loss: 0.035211 Validation loss: 0.090705\n",
            "Epoch: 483 Train loss: 0.035128 Validation loss: 0.090314\n",
            "Epoch: 484 Train loss: 0.035044 Validation loss: 0.089926\n",
            "Epoch: 485 Train loss: 0.034962 Validation loss: 0.089541\n",
            "Epoch: 486 Train loss: 0.03488 Validation loss: 0.089158\n",
            "Epoch: 487 Train loss: 0.034799 Validation loss: 0.088776\n",
            "Epoch: 488 Train loss: 0.034718 Validation loss: 0.088398\n",
            "Epoch: 489 Train loss: 0.034638 Validation loss: 0.088021\n",
            "Epoch: 490 Train loss: 0.034558 Validation loss: 0.087647\n",
            "Epoch: 491 Train loss: 0.034479 Validation loss: 0.087275\n",
            "Epoch: 492 Train loss: 0.034401 Validation loss: 0.086904\n",
            "Epoch: 493 Train loss: 0.034323 Validation loss: 0.086537\n",
            "Epoch: 494 Train loss: 0.034246 Validation loss: 0.086171\n",
            "Epoch: 495 Train loss: 0.03417 Validation loss: 0.085807\n",
            "Epoch: 496 Train loss: 0.034094 Validation loss: 0.085446\n",
            "Epoch: 497 Train loss: 0.034018 Validation loss: 0.085086\n",
            "Epoch: 498 Train loss: 0.033943 Validation loss: 0.084729\n",
            "Epoch: 499 Train loss: 0.033869 Validation loss: 0.084374\n",
            "Epoch: 500 Train loss: 0.033795 Validation loss: 0.084021\n",
            "Epoch: 501 Train loss: 0.033721 Validation loss: 0.08367\n",
            "Epoch: 502 Train loss: 0.033649 Validation loss: 0.083321\n",
            "Epoch: 503 Train loss: 0.033576 Validation loss: 0.082975\n",
            "Epoch: 504 Train loss: 0.033505 Validation loss: 0.082629\n",
            "Epoch: 505 Train loss: 0.033433 Validation loss: 0.082287\n",
            "Epoch: 506 Train loss: 0.033363 Validation loss: 0.081946\n",
            "Epoch: 507 Train loss: 0.033293 Validation loss: 0.081607\n",
            "Epoch: 508 Train loss: 0.033223 Validation loss: 0.08127\n",
            "Epoch: 509 Train loss: 0.033154 Validation loss: 0.080935\n",
            "Epoch: 510 Train loss: 0.033085 Validation loss: 0.080601\n",
            "Epoch: 511 Train loss: 0.033017 Validation loss: 0.080271\n",
            "Epoch: 512 Train loss: 0.032949 Validation loss: 0.079942\n",
            "Epoch: 513 Train loss: 0.032882 Validation loss: 0.079615\n",
            "Epoch: 514 Train loss: 0.032815 Validation loss: 0.07929\n",
            "Epoch: 515 Train loss: 0.032749 Validation loss: 0.078966\n",
            "Epoch: 516 Train loss: 0.032683 Validation loss: 0.078645\n",
            "Epoch: 517 Train loss: 0.032618 Validation loss: 0.078326\n",
            "Epoch: 518 Train loss: 0.032553 Validation loss: 0.078008\n",
            "Epoch: 519 Train loss: 0.032488 Validation loss: 0.077692\n",
            "Epoch: 520 Train loss: 0.032424 Validation loss: 0.077379\n",
            "Epoch: 521 Train loss: 0.032361 Validation loss: 0.077066\n",
            "Epoch: 522 Train loss: 0.032298 Validation loss: 0.076756\n",
            "Epoch: 523 Train loss: 0.032235 Validation loss: 0.076448\n",
            "Epoch: 524 Train loss: 0.032173 Validation loss: 0.07614\n",
            "Epoch: 525 Train loss: 0.032111 Validation loss: 0.075836\n",
            "Epoch: 526 Train loss: 0.03205 Validation loss: 0.075532\n",
            "Epoch: 527 Train loss: 0.031989 Validation loss: 0.075232\n",
            "Epoch: 528 Train loss: 0.031928 Validation loss: 0.074932\n",
            "Epoch: 529 Train loss: 0.031868 Validation loss: 0.074634\n",
            "Epoch: 530 Train loss: 0.031808 Validation loss: 0.074338\n",
            "Epoch: 531 Train loss: 0.031749 Validation loss: 0.074043\n",
            "Epoch: 532 Train loss: 0.03169 Validation loss: 0.073751\n",
            "Epoch: 533 Train loss: 0.031632 Validation loss: 0.07346\n",
            "Epoch: 534 Train loss: 0.031574 Validation loss: 0.073171\n",
            "Epoch: 535 Train loss: 0.031516 Validation loss: 0.072884\n",
            "Epoch: 536 Train loss: 0.031459 Validation loss: 0.072598\n",
            "Epoch: 537 Train loss: 0.031402 Validation loss: 0.072314\n",
            "Epoch: 538 Train loss: 0.031346 Validation loss: 0.072031\n",
            "Epoch: 539 Train loss: 0.031289 Validation loss: 0.071751\n",
            "Epoch: 540 Train loss: 0.031234 Validation loss: 0.071472\n",
            "Epoch: 541 Train loss: 0.031178 Validation loss: 0.071194\n",
            "Epoch: 542 Train loss: 0.031123 Validation loss: 0.070918\n",
            "Epoch: 543 Train loss: 0.031069 Validation loss: 0.070644\n",
            "Epoch: 544 Train loss: 0.031015 Validation loss: 0.070371\n",
            "Epoch: 545 Train loss: 0.030961 Validation loss: 0.0701\n",
            "Epoch: 546 Train loss: 0.030907 Validation loss: 0.06983\n",
            "Epoch: 547 Train loss: 0.030854 Validation loss: 0.069562\n",
            "Epoch: 548 Train loss: 0.030801 Validation loss: 0.069296\n",
            "Epoch: 549 Train loss: 0.030749 Validation loss: 0.069031\n",
            "Epoch: 550 Train loss: 0.030697 Validation loss: 0.068767\n",
            "Epoch: 551 Train loss: 0.030645 Validation loss: 0.068505\n",
            "Epoch: 552 Train loss: 0.030594 Validation loss: 0.068246\n",
            "Epoch: 553 Train loss: 0.030542 Validation loss: 0.067987\n",
            "Epoch: 554 Train loss: 0.030492 Validation loss: 0.067729\n",
            "Epoch: 555 Train loss: 0.030441 Validation loss: 0.067474\n",
            "Epoch: 556 Train loss: 0.030391 Validation loss: 0.067219\n",
            "Epoch: 557 Train loss: 0.030341 Validation loss: 0.066966\n",
            "Epoch: 558 Train loss: 0.030292 Validation loss: 0.066714\n",
            "Epoch: 559 Train loss: 0.030243 Validation loss: 0.066465\n",
            "Epoch: 560 Train loss: 0.030194 Validation loss: 0.066216\n",
            "Epoch: 561 Train loss: 0.030146 Validation loss: 0.06597\n",
            "Epoch: 562 Train loss: 0.030098 Validation loss: 0.065724\n",
            "Epoch: 563 Train loss: 0.03005 Validation loss: 0.06548\n",
            "Epoch: 564 Train loss: 0.030002 Validation loss: 0.065236\n",
            "Epoch: 565 Train loss: 0.029955 Validation loss: 0.064995\n",
            "Epoch: 566 Train loss: 0.029908 Validation loss: 0.064755\n",
            "Epoch: 567 Train loss: 0.029861 Validation loss: 0.064517\n",
            "Epoch: 568 Train loss: 0.029815 Validation loss: 0.06428\n",
            "Epoch: 569 Train loss: 0.029769 Validation loss: 0.064044\n",
            "Epoch: 570 Train loss: 0.029723 Validation loss: 0.063809\n",
            "Epoch: 571 Train loss: 0.029678 Validation loss: 0.063577\n",
            "Epoch: 572 Train loss: 0.029633 Validation loss: 0.063344\n",
            "Epoch: 573 Train loss: 0.029588 Validation loss: 0.063114\n",
            "Epoch: 574 Train loss: 0.029543 Validation loss: 0.062884\n",
            "Epoch: 575 Train loss: 0.029499 Validation loss: 0.062657\n",
            "Epoch: 576 Train loss: 0.029455 Validation loss: 0.06243\n",
            "Epoch: 577 Train loss: 0.029411 Validation loss: 0.062205\n",
            "Epoch: 578 Train loss: 0.029367 Validation loss: 0.061981\n",
            "Epoch: 579 Train loss: 0.029324 Validation loss: 0.061758\n",
            "Epoch: 580 Train loss: 0.029281 Validation loss: 0.061538\n",
            "Epoch: 581 Train loss: 0.029239 Validation loss: 0.061317\n",
            "Epoch: 582 Train loss: 0.029196 Validation loss: 0.061099\n",
            "Epoch: 583 Train loss: 0.029154 Validation loss: 0.060881\n",
            "Epoch: 584 Train loss: 0.029112 Validation loss: 0.060664\n",
            "Epoch: 585 Train loss: 0.02907 Validation loss: 0.060449\n",
            "Epoch: 586 Train loss: 0.029029 Validation loss: 0.060235\n",
            "Epoch: 587 Train loss: 0.028988 Validation loss: 0.060022\n",
            "Epoch: 588 Train loss: 0.028947 Validation loss: 0.059811\n",
            "Epoch: 589 Train loss: 0.028906 Validation loss: 0.059602\n",
            "Epoch: 590 Train loss: 0.028866 Validation loss: 0.059392\n",
            "Epoch: 591 Train loss: 0.028826 Validation loss: 0.059184\n",
            "Epoch: 592 Train loss: 0.028786 Validation loss: 0.058977\n",
            "Epoch: 593 Train loss: 0.028746 Validation loss: 0.058772\n",
            "Epoch: 594 Train loss: 0.028707 Validation loss: 0.058568\n",
            "Epoch: 595 Train loss: 0.028668 Validation loss: 0.058364\n",
            "Epoch: 596 Train loss: 0.028629 Validation loss: 0.058162\n",
            "Epoch: 597 Train loss: 0.02859 Validation loss: 0.057962\n",
            "Epoch: 598 Train loss: 0.028552 Validation loss: 0.057762\n",
            "Epoch: 599 Train loss: 0.028513 Validation loss: 0.057564\n",
            "Epoch: 600 Train loss: 0.028475 Validation loss: 0.057366\n",
            "Epoch: 601 Train loss: 0.028438 Validation loss: 0.05717\n",
            "Epoch: 602 Train loss: 0.0284 Validation loss: 0.056974\n",
            "Epoch: 603 Train loss: 0.028363 Validation loss: 0.05678\n",
            "Epoch: 604 Train loss: 0.028325 Validation loss: 0.056587\n",
            "Epoch: 605 Train loss: 0.028288 Validation loss: 0.056395\n",
            "Epoch: 606 Train loss: 0.028252 Validation loss: 0.056204\n",
            "Epoch: 607 Train loss: 0.028215 Validation loss: 0.056014\n",
            "Epoch: 608 Train loss: 0.028179 Validation loss: 0.055825\n",
            "Epoch: 609 Train loss: 0.028143 Validation loss: 0.055638\n",
            "Epoch: 610 Train loss: 0.028107 Validation loss: 0.055451\n",
            "Epoch: 611 Train loss: 0.028071 Validation loss: 0.055265\n",
            "Epoch: 612 Train loss: 0.028036 Validation loss: 0.055081\n",
            "Epoch: 613 Train loss: 0.028001 Validation loss: 0.054897\n",
            "Epoch: 614 Train loss: 0.027966 Validation loss: 0.054715\n",
            "Epoch: 615 Train loss: 0.027931 Validation loss: 0.054533\n",
            "Epoch: 616 Train loss: 0.027896 Validation loss: 0.054353\n",
            "Epoch: 617 Train loss: 0.027862 Validation loss: 0.054173\n",
            "Epoch: 618 Train loss: 0.027828 Validation loss: 0.053995\n",
            "Epoch: 619 Train loss: 0.027794 Validation loss: 0.053817\n",
            "Epoch: 620 Train loss: 0.02776 Validation loss: 0.05364\n",
            "Epoch: 621 Train loss: 0.027726 Validation loss: 0.053465\n",
            "Epoch: 622 Train loss: 0.027693 Validation loss: 0.05329\n",
            "Epoch: 623 Train loss: 0.027659 Validation loss: 0.053117\n",
            "Epoch: 624 Train loss: 0.027626 Validation loss: 0.052944\n",
            "Epoch: 625 Train loss: 0.027593 Validation loss: 0.052772\n",
            "Epoch: 626 Train loss: 0.027561 Validation loss: 0.052602\n",
            "Epoch: 627 Train loss: 0.027528 Validation loss: 0.052432\n",
            "Epoch: 628 Train loss: 0.027496 Validation loss: 0.052264\n",
            "Epoch: 629 Train loss: 0.027464 Validation loss: 0.052095\n",
            "Epoch: 630 Train loss: 0.027431 Validation loss: 0.051929\n",
            "Epoch: 631 Train loss: 0.0274 Validation loss: 0.051763\n",
            "Epoch: 632 Train loss: 0.027368 Validation loss: 0.051597\n",
            "Epoch: 633 Train loss: 0.027337 Validation loss: 0.051433\n",
            "Epoch: 634 Train loss: 0.027305 Validation loss: 0.05127\n",
            "Epoch: 635 Train loss: 0.027274 Validation loss: 0.051107\n",
            "Epoch: 636 Train loss: 0.027243 Validation loss: 0.050946\n",
            "Epoch: 637 Train loss: 0.027212 Validation loss: 0.050785\n",
            "Epoch: 638 Train loss: 0.027182 Validation loss: 0.050626\n",
            "Epoch: 639 Train loss: 0.027151 Validation loss: 0.050466\n",
            "Epoch: 640 Train loss: 0.027121 Validation loss: 0.050308\n",
            "Epoch: 641 Train loss: 0.027091 Validation loss: 0.050151\n",
            "Epoch: 642 Train loss: 0.027061 Validation loss: 0.049995\n",
            "Epoch: 643 Train loss: 0.027031 Validation loss: 0.049839\n",
            "Epoch: 644 Train loss: 0.027001 Validation loss: 0.049685\n",
            "Epoch: 645 Train loss: 0.026972 Validation loss: 0.049531\n",
            "Epoch: 646 Train loss: 0.026943 Validation loss: 0.049378\n",
            "Epoch: 647 Train loss: 0.026914 Validation loss: 0.049226\n",
            "Epoch: 648 Train loss: 0.026884 Validation loss: 0.049075\n",
            "Epoch: 649 Train loss: 0.026856 Validation loss: 0.048924\n",
            "Epoch: 650 Train loss: 0.026827 Validation loss: 0.048775\n",
            "Epoch: 651 Train loss: 0.026798 Validation loss: 0.048626\n",
            "Epoch: 652 Train loss: 0.02677 Validation loss: 0.048477\n",
            "Epoch: 653 Train loss: 0.026742 Validation loss: 0.04833\n",
            "Epoch: 654 Train loss: 0.026714 Validation loss: 0.048184\n",
            "Epoch: 655 Train loss: 0.026686 Validation loss: 0.048038\n",
            "Epoch: 656 Train loss: 0.026658 Validation loss: 0.047893\n",
            "Epoch: 657 Train loss: 0.02663 Validation loss: 0.04775\n",
            "Epoch: 658 Train loss: 0.026603 Validation loss: 0.047605\n",
            "Epoch: 659 Train loss: 0.026575 Validation loss: 0.047464\n",
            "Epoch: 660 Train loss: 0.026548 Validation loss: 0.047322\n",
            "Epoch: 661 Train loss: 0.026521 Validation loss: 0.047181\n",
            "Epoch: 662 Train loss: 0.026494 Validation loss: 0.04704\n",
            "Epoch: 663 Train loss: 0.026467 Validation loss: 0.0469\n",
            "Epoch: 664 Train loss: 0.02644 Validation loss: 0.046762\n",
            "Epoch: 665 Train loss: 0.026414 Validation loss: 0.046624\n",
            "Epoch: 666 Train loss: 0.026388 Validation loss: 0.046486\n",
            "Epoch: 667 Train loss: 0.026361 Validation loss: 0.04635\n",
            "Epoch: 668 Train loss: 0.026335 Validation loss: 0.046213\n",
            "Epoch: 669 Train loss: 0.026309 Validation loss: 0.046079\n",
            "Epoch: 670 Train loss: 0.026283 Validation loss: 0.045943\n",
            "Epoch: 671 Train loss: 0.026258 Validation loss: 0.04581\n",
            "Epoch: 672 Train loss: 0.026232 Validation loss: 0.045677\n",
            "Epoch: 673 Train loss: 0.026206 Validation loss: 0.045545\n",
            "Epoch: 674 Train loss: 0.026181 Validation loss: 0.045413\n",
            "Epoch: 675 Train loss: 0.026156 Validation loss: 0.045282\n",
            "Epoch: 676 Train loss: 0.026131 Validation loss: 0.045151\n",
            "Epoch: 677 Train loss: 0.026106 Validation loss: 0.045022\n",
            "Epoch: 678 Train loss: 0.026081 Validation loss: 0.044894\n",
            "Epoch: 679 Train loss: 0.026056 Validation loss: 0.044765\n",
            "Epoch: 680 Train loss: 0.026032 Validation loss: 0.044638\n",
            "Epoch: 681 Train loss: 0.026007 Validation loss: 0.04451\n",
            "Epoch: 682 Train loss: 0.025983 Validation loss: 0.044384\n",
            "Epoch: 683 Train loss: 0.025959 Validation loss: 0.044258\n",
            "Epoch: 684 Train loss: 0.025934 Validation loss: 0.044134\n",
            "Epoch: 685 Train loss: 0.02591 Validation loss: 0.04401\n",
            "Epoch: 686 Train loss: 0.025887 Validation loss: 0.043886\n",
            "Epoch: 687 Train loss: 0.025863 Validation loss: 0.043762\n",
            "Epoch: 688 Train loss: 0.025839 Validation loss: 0.043641\n",
            "Epoch: 689 Train loss: 0.025816 Validation loss: 0.043519\n",
            "Epoch: 690 Train loss: 0.025792 Validation loss: 0.043397\n",
            "Epoch: 691 Train loss: 0.025769 Validation loss: 0.043277\n",
            "Epoch: 692 Train loss: 0.025746 Validation loss: 0.043157\n",
            "Epoch: 693 Train loss: 0.025723 Validation loss: 0.043037\n",
            "Epoch: 694 Train loss: 0.0257 Validation loss: 0.042919\n",
            "Epoch: 695 Train loss: 0.025677 Validation loss: 0.042801\n",
            "Epoch: 696 Train loss: 0.025654 Validation loss: 0.042684\n",
            "Epoch: 697 Train loss: 0.025631 Validation loss: 0.042567\n",
            "Epoch: 698 Train loss: 0.025609 Validation loss: 0.042451\n",
            "Epoch: 699 Train loss: 0.025586 Validation loss: 0.042334\n",
            "Epoch: 700 Train loss: 0.025564 Validation loss: 0.04222\n",
            "Epoch: 701 Train loss: 0.025542 Validation loss: 0.042105\n",
            "Epoch: 702 Train loss: 0.02552 Validation loss: 0.041991\n",
            "Epoch: 703 Train loss: 0.025498 Validation loss: 0.041878\n",
            "Epoch: 704 Train loss: 0.025476 Validation loss: 0.041766\n",
            "Epoch: 705 Train loss: 0.025454 Validation loss: 0.041653\n",
            "Epoch: 706 Train loss: 0.025432 Validation loss: 0.041542\n",
            "Epoch: 707 Train loss: 0.025411 Validation loss: 0.04143\n",
            "Epoch: 708 Train loss: 0.025389 Validation loss: 0.04132\n",
            "Epoch: 709 Train loss: 0.025368 Validation loss: 0.04121\n",
            "Epoch: 710 Train loss: 0.025346 Validation loss: 0.041101\n",
            "Epoch: 711 Train loss: 0.025325 Validation loss: 0.040992\n",
            "Epoch: 712 Train loss: 0.025304 Validation loss: 0.040883\n",
            "Epoch: 713 Train loss: 0.025283 Validation loss: 0.040776\n",
            "Epoch: 714 Train loss: 0.025262 Validation loss: 0.040668\n",
            "Epoch: 715 Train loss: 0.025241 Validation loss: 0.040562\n",
            "Epoch: 716 Train loss: 0.025221 Validation loss: 0.040456\n",
            "Epoch: 717 Train loss: 0.0252 Validation loss: 0.04035\n",
            "Epoch: 718 Train loss: 0.02518 Validation loss: 0.040246\n",
            "Epoch: 719 Train loss: 0.025159 Validation loss: 0.04014\n",
            "Epoch: 720 Train loss: 0.025139 Validation loss: 0.040036\n",
            "Epoch: 721 Train loss: 0.025119 Validation loss: 0.039932\n",
            "Epoch: 722 Train loss: 0.025098 Validation loss: 0.03983\n",
            "Epoch: 723 Train loss: 0.025078 Validation loss: 0.039728\n",
            "Epoch: 724 Train loss: 0.025058 Validation loss: 0.039626\n",
            "Epoch: 725 Train loss: 0.025038 Validation loss: 0.039523\n",
            "Epoch: 726 Train loss: 0.025019 Validation loss: 0.039423\n",
            "Epoch: 727 Train loss: 0.024999 Validation loss: 0.039322\n",
            "Epoch: 728 Train loss: 0.024979 Validation loss: 0.039222\n",
            "Epoch: 729 Train loss: 0.02496 Validation loss: 0.039123\n",
            "Epoch: 730 Train loss: 0.02494 Validation loss: 0.039023\n",
            "Epoch: 731 Train loss: 0.024921 Validation loss: 0.038925\n",
            "Epoch: 732 Train loss: 0.024902 Validation loss: 0.038827\n",
            "Epoch: 733 Train loss: 0.024883 Validation loss: 0.038729\n",
            "Epoch: 734 Train loss: 0.024864 Validation loss: 0.038632\n",
            "Epoch: 735 Train loss: 0.024844 Validation loss: 0.038536\n",
            "Epoch: 736 Train loss: 0.024826 Validation loss: 0.03844\n",
            "Epoch: 737 Train loss: 0.024807 Validation loss: 0.038344\n",
            "Epoch: 738 Train loss: 0.024788 Validation loss: 0.038249\n",
            "Epoch: 739 Train loss: 0.024769 Validation loss: 0.038154\n",
            "Epoch: 740 Train loss: 0.024751 Validation loss: 0.038059\n",
            "Epoch: 741 Train loss: 0.024732 Validation loss: 0.037965\n",
            "Epoch: 742 Train loss: 0.024714 Validation loss: 0.037872\n",
            "Epoch: 743 Train loss: 0.024695 Validation loss: 0.037779\n",
            "Epoch: 744 Train loss: 0.024677 Validation loss: 0.037687\n",
            "Epoch: 745 Train loss: 0.024659 Validation loss: 0.037594\n",
            "Epoch: 746 Train loss: 0.024641 Validation loss: 0.037503\n",
            "Epoch: 747 Train loss: 0.024623 Validation loss: 0.037411\n",
            "Epoch: 748 Train loss: 0.024605 Validation loss: 0.037321\n",
            "Epoch: 749 Train loss: 0.024587 Validation loss: 0.03723\n",
            "Epoch: 750 Train loss: 0.024569 Validation loss: 0.03714\n",
            "Epoch: 751 Train loss: 0.024551 Validation loss: 0.037051\n",
            "Epoch: 752 Train loss: 0.024534 Validation loss: 0.036962\n",
            "Epoch: 753 Train loss: 0.024516 Validation loss: 0.036873\n",
            "Epoch: 754 Train loss: 0.024499 Validation loss: 0.036785\n",
            "Epoch: 755 Train loss: 0.024481 Validation loss: 0.036697\n",
            "Epoch: 756 Train loss: 0.024464 Validation loss: 0.03661\n",
            "Epoch: 757 Train loss: 0.024447 Validation loss: 0.036523\n",
            "Epoch: 758 Train loss: 0.024429 Validation loss: 0.036436\n",
            "Epoch: 759 Train loss: 0.024412 Validation loss: 0.03635\n",
            "Epoch: 760 Train loss: 0.024395 Validation loss: 0.036264\n",
            "Epoch: 761 Train loss: 0.024378 Validation loss: 0.036178\n",
            "Epoch: 762 Train loss: 0.024361 Validation loss: 0.036093\n",
            "Epoch: 763 Train loss: 0.024345 Validation loss: 0.036009\n",
            "Epoch: 764 Train loss: 0.024328 Validation loss: 0.035925\n",
            "Epoch: 765 Train loss: 0.024311 Validation loss: 0.035841\n",
            "Epoch: 766 Train loss: 0.024294 Validation loss: 0.035757\n",
            "Epoch: 767 Train loss: 0.024278 Validation loss: 0.035674\n",
            "Epoch: 768 Train loss: 0.024261 Validation loss: 0.035591\n",
            "Epoch: 769 Train loss: 0.024245 Validation loss: 0.035509\n",
            "Epoch: 770 Train loss: 0.024229 Validation loss: 0.035427\n",
            "Epoch: 771 Train loss: 0.024212 Validation loss: 0.035345\n",
            "Epoch: 772 Train loss: 0.024196 Validation loss: 0.035265\n",
            "Epoch: 773 Train loss: 0.02418 Validation loss: 0.035184\n",
            "Epoch: 774 Train loss: 0.024164 Validation loss: 0.035104\n",
            "Epoch: 775 Train loss: 0.024148 Validation loss: 0.035023\n",
            "Epoch: 776 Train loss: 0.024132 Validation loss: 0.034944\n",
            "Epoch: 777 Train loss: 0.024116 Validation loss: 0.034864\n",
            "Epoch: 778 Train loss: 0.0241 Validation loss: 0.034785\n",
            "Epoch: 779 Train loss: 0.024084 Validation loss: 0.034707\n",
            "Epoch: 780 Train loss: 0.024069 Validation loss: 0.034629\n",
            "Epoch: 781 Train loss: 0.024053 Validation loss: 0.03455\n",
            "Epoch: 782 Train loss: 0.024037 Validation loss: 0.034473\n",
            "Epoch: 783 Train loss: 0.024022 Validation loss: 0.034396\n",
            "Epoch: 784 Train loss: 0.024007 Validation loss: 0.034319\n",
            "Epoch: 785 Train loss: 0.023991 Validation loss: 0.034242\n",
            "Epoch: 786 Train loss: 0.023976 Validation loss: 0.034166\n",
            "Epoch: 787 Train loss: 0.023961 Validation loss: 0.03409\n",
            "Epoch: 788 Train loss: 0.023945 Validation loss: 0.034015\n",
            "Epoch: 789 Train loss: 0.02393 Validation loss: 0.033939\n",
            "Epoch: 790 Train loss: 0.023915 Validation loss: 0.033865\n",
            "Epoch: 791 Train loss: 0.0239 Validation loss: 0.03379\n",
            "Epoch: 792 Train loss: 0.023885 Validation loss: 0.033716\n",
            "Epoch: 793 Train loss: 0.02387 Validation loss: 0.033642\n",
            "Epoch: 794 Train loss: 0.023855 Validation loss: 0.033569\n",
            "Epoch: 795 Train loss: 0.023841 Validation loss: 0.033496\n",
            "Epoch: 796 Train loss: 0.023826 Validation loss: 0.033423\n",
            "Epoch: 797 Train loss: 0.023811 Validation loss: 0.03335\n",
            "Epoch: 798 Train loss: 0.023797 Validation loss: 0.033278\n",
            "Epoch: 799 Train loss: 0.023782 Validation loss: 0.033207\n",
            "Epoch: 800 Train loss: 0.023768 Validation loss: 0.033135\n",
            "Epoch: 801 Train loss: 0.023753 Validation loss: 0.033064\n",
            "Epoch: 802 Train loss: 0.023739 Validation loss: 0.032993\n",
            "Epoch: 803 Train loss: 0.023724 Validation loss: 0.032922\n",
            "Epoch: 804 Train loss: 0.02371 Validation loss: 0.032852\n",
            "Epoch: 805 Train loss: 0.023696 Validation loss: 0.032782\n",
            "Epoch: 806 Train loss: 0.023682 Validation loss: 0.032712\n",
            "Epoch: 807 Train loss: 0.023668 Validation loss: 0.032642\n",
            "Epoch: 808 Train loss: 0.023654 Validation loss: 0.032573\n",
            "Epoch: 809 Train loss: 0.02364 Validation loss: 0.032505\n",
            "Epoch: 810 Train loss: 0.023626 Validation loss: 0.032436\n",
            "Epoch: 811 Train loss: 0.023612 Validation loss: 0.032368\n",
            "Epoch: 812 Train loss: 0.023598 Validation loss: 0.0323\n",
            "Epoch: 813 Train loss: 0.023584 Validation loss: 0.032232\n",
            "Epoch: 814 Train loss: 0.023571 Validation loss: 0.032165\n",
            "Epoch: 815 Train loss: 0.023557 Validation loss: 0.032098\n",
            "Epoch: 816 Train loss: 0.023543 Validation loss: 0.032031\n",
            "Epoch: 817 Train loss: 0.02353 Validation loss: 0.031965\n",
            "Epoch: 818 Train loss: 0.023516 Validation loss: 0.031898\n",
            "Epoch: 819 Train loss: 0.023503 Validation loss: 0.031832\n",
            "Epoch: 820 Train loss: 0.023489 Validation loss: 0.031767\n",
            "Epoch: 821 Train loss: 0.023476 Validation loss: 0.031701\n",
            "Epoch: 822 Train loss: 0.023463 Validation loss: 0.031636\n",
            "Epoch: 823 Train loss: 0.023449 Validation loss: 0.031572\n",
            "Epoch: 824 Train loss: 0.023436 Validation loss: 0.031507\n",
            "Epoch: 825 Train loss: 0.023423 Validation loss: 0.031443\n",
            "Epoch: 826 Train loss: 0.02341 Validation loss: 0.031378\n",
            "Epoch: 827 Train loss: 0.023397 Validation loss: 0.031315\n",
            "Epoch: 828 Train loss: 0.023384 Validation loss: 0.031251\n",
            "Epoch: 829 Train loss: 0.023371 Validation loss: 0.031188\n",
            "Epoch: 830 Train loss: 0.023358 Validation loss: 0.031125\n",
            "Epoch: 831 Train loss: 0.023345 Validation loss: 0.031062\n",
            "Epoch: 832 Train loss: 0.023332 Validation loss: 0.031\n",
            "Epoch: 833 Train loss: 0.02332 Validation loss: 0.030938\n",
            "Epoch: 834 Train loss: 0.023307 Validation loss: 0.030876\n",
            "Epoch: 835 Train loss: 0.023294 Validation loss: 0.030814\n",
            "Epoch: 836 Train loss: 0.023281 Validation loss: 0.030753\n",
            "Epoch: 837 Train loss: 0.023269 Validation loss: 0.030692\n",
            "Epoch: 838 Train loss: 0.023256 Validation loss: 0.030631\n",
            "Epoch: 839 Train loss: 0.023244 Validation loss: 0.030571\n",
            "Epoch: 840 Train loss: 0.023231 Validation loss: 0.03051\n",
            "Epoch: 841 Train loss: 0.023219 Validation loss: 0.03045\n",
            "Epoch: 842 Train loss: 0.023207 Validation loss: 0.03039\n",
            "Epoch: 843 Train loss: 0.023194 Validation loss: 0.03033\n",
            "Epoch: 844 Train loss: 0.023182 Validation loss: 0.030271\n",
            "Epoch: 845 Train loss: 0.02317 Validation loss: 0.030212\n",
            "Epoch: 846 Train loss: 0.023158 Validation loss: 0.030153\n",
            "Epoch: 847 Train loss: 0.023146 Validation loss: 0.030095\n",
            "Epoch: 848 Train loss: 0.023134 Validation loss: 0.030036\n",
            "Epoch: 849 Train loss: 0.023121 Validation loss: 0.029977\n",
            "Epoch: 850 Train loss: 0.02311 Validation loss: 0.029919\n",
            "Epoch: 851 Train loss: 0.023098 Validation loss: 0.029862\n",
            "Epoch: 852 Train loss: 0.023086 Validation loss: 0.029804\n",
            "Epoch: 853 Train loss: 0.023074 Validation loss: 0.029747\n",
            "Epoch: 854 Train loss: 0.023062 Validation loss: 0.029689\n",
            "Epoch: 855 Train loss: 0.02305 Validation loss: 0.029633\n",
            "Epoch: 856 Train loss: 0.023038 Validation loss: 0.029577\n",
            "Epoch: 857 Train loss: 0.023027 Validation loss: 0.02952\n",
            "Epoch: 858 Train loss: 0.023015 Validation loss: 0.029464\n",
            "Epoch: 859 Train loss: 0.023003 Validation loss: 0.029409\n",
            "Epoch: 860 Train loss: 0.022992 Validation loss: 0.029353\n",
            "Epoch: 861 Train loss: 0.02298 Validation loss: 0.029297\n",
            "Epoch: 862 Train loss: 0.022969 Validation loss: 0.029242\n",
            "Epoch: 863 Train loss: 0.022957 Validation loss: 0.029186\n",
            "Epoch: 864 Train loss: 0.022946 Validation loss: 0.029132\n",
            "Epoch: 865 Train loss: 0.022935 Validation loss: 0.029077\n",
            "Epoch: 866 Train loss: 0.022923 Validation loss: 0.029023\n",
            "Epoch: 867 Train loss: 0.022912 Validation loss: 0.028969\n",
            "Epoch: 868 Train loss: 0.022901 Validation loss: 0.028915\n",
            "Epoch: 869 Train loss: 0.022889 Validation loss: 0.028861\n",
            "Epoch: 870 Train loss: 0.022878 Validation loss: 0.028807\n",
            "Epoch: 871 Train loss: 0.022867 Validation loss: 0.028754\n",
            "Epoch: 872 Train loss: 0.022856 Validation loss: 0.028701\n",
            "Epoch: 873 Train loss: 0.022845 Validation loss: 0.028648\n",
            "Epoch: 874 Train loss: 0.022834 Validation loss: 0.028595\n",
            "Epoch: 875 Train loss: 0.022823 Validation loss: 0.028543\n",
            "Epoch: 876 Train loss: 0.022812 Validation loss: 0.02849\n",
            "Epoch: 877 Train loss: 0.022801 Validation loss: 0.028439\n",
            "Epoch: 878 Train loss: 0.02279 Validation loss: 0.028386\n",
            "Epoch: 879 Train loss: 0.022779 Validation loss: 0.028334\n",
            "Epoch: 880 Train loss: 0.022769 Validation loss: 0.028283\n",
            "Epoch: 881 Train loss: 0.022758 Validation loss: 0.028232\n",
            "Epoch: 882 Train loss: 0.022747 Validation loss: 0.028181\n",
            "Epoch: 883 Train loss: 0.022737 Validation loss: 0.02813\n",
            "Epoch: 884 Train loss: 0.022726 Validation loss: 0.028079\n",
            "Epoch: 885 Train loss: 0.022715 Validation loss: 0.028028\n",
            "Epoch: 886 Train loss: 0.022705 Validation loss: 0.027978\n",
            "Epoch: 887 Train loss: 0.022694 Validation loss: 0.027928\n",
            "Epoch: 888 Train loss: 0.022684 Validation loss: 0.027878\n",
            "Epoch: 889 Train loss: 0.022673 Validation loss: 0.027828\n",
            "Epoch: 890 Train loss: 0.022663 Validation loss: 0.027778\n",
            "Epoch: 891 Train loss: 0.022652 Validation loss: 0.027729\n",
            "Epoch: 892 Train loss: 0.022642 Validation loss: 0.02768\n",
            "Epoch: 893 Train loss: 0.022632 Validation loss: 0.02763\n",
            "Epoch: 894 Train loss: 0.022621 Validation loss: 0.027582\n",
            "Epoch: 895 Train loss: 0.022611 Validation loss: 0.027533\n",
            "Epoch: 896 Train loss: 0.022601 Validation loss: 0.027485\n",
            "Epoch: 897 Train loss: 0.022591 Validation loss: 0.027436\n",
            "Epoch: 898 Train loss: 0.022581 Validation loss: 0.027388\n",
            "Epoch: 899 Train loss: 0.02257 Validation loss: 0.02734\n",
            "Epoch: 900 Train loss: 0.02256 Validation loss: 0.027293\n",
            "Epoch: 901 Train loss: 0.02255 Validation loss: 0.027245\n",
            "Epoch: 902 Train loss: 0.02254 Validation loss: 0.027198\n",
            "Epoch: 903 Train loss: 0.02253 Validation loss: 0.02715\n",
            "Epoch: 904 Train loss: 0.02252 Validation loss: 0.027103\n",
            "Epoch: 905 Train loss: 0.02251 Validation loss: 0.027056\n",
            "Epoch: 906 Train loss: 0.0225 Validation loss: 0.027009\n",
            "Epoch: 907 Train loss: 0.022491 Validation loss: 0.026963\n",
            "Epoch: 908 Train loss: 0.022481 Validation loss: 0.026917\n",
            "Epoch: 909 Train loss: 0.022471 Validation loss: 0.02687\n",
            "Epoch: 910 Train loss: 0.022461 Validation loss: 0.026824\n",
            "Epoch: 911 Train loss: 0.022452 Validation loss: 0.026778\n",
            "Epoch: 912 Train loss: 0.022442 Validation loss: 0.026733\n",
            "Epoch: 913 Train loss: 0.022432 Validation loss: 0.026687\n",
            "Epoch: 914 Train loss: 0.022423 Validation loss: 0.026642\n",
            "Epoch: 915 Train loss: 0.022413 Validation loss: 0.026596\n",
            "Epoch: 916 Train loss: 0.022403 Validation loss: 0.026552\n",
            "Epoch: 917 Train loss: 0.022394 Validation loss: 0.026507\n",
            "Epoch: 918 Train loss: 0.022384 Validation loss: 0.026462\n",
            "Epoch: 919 Train loss: 0.022375 Validation loss: 0.026417\n",
            "Epoch: 920 Train loss: 0.022365 Validation loss: 0.026373\n",
            "Epoch: 921 Train loss: 0.022356 Validation loss: 0.026329\n",
            "Epoch: 922 Train loss: 0.022347 Validation loss: 0.026285\n",
            "Epoch: 923 Train loss: 0.022337 Validation loss: 0.026241\n",
            "Epoch: 924 Train loss: 0.022328 Validation loss: 0.026197\n",
            "Epoch: 925 Train loss: 0.022318 Validation loss: 0.026153\n",
            "Epoch: 926 Train loss: 0.022309 Validation loss: 0.02611\n",
            "Epoch: 927 Train loss: 0.0223 Validation loss: 0.026066\n",
            "Epoch: 928 Train loss: 0.022291 Validation loss: 0.026023\n",
            "Epoch: 929 Train loss: 0.022282 Validation loss: 0.02598\n",
            "Epoch: 930 Train loss: 0.022272 Validation loss: 0.025937\n",
            "Epoch: 931 Train loss: 0.022263 Validation loss: 0.025894\n",
            "Epoch: 932 Train loss: 0.022254 Validation loss: 0.025852\n",
            "Epoch: 933 Train loss: 0.022245 Validation loss: 0.02581\n",
            "Epoch: 934 Train loss: 0.022236 Validation loss: 0.025767\n",
            "Epoch: 935 Train loss: 0.022227 Validation loss: 0.025725\n",
            "Epoch: 936 Train loss: 0.022218 Validation loss: 0.025683\n",
            "Epoch: 937 Train loss: 0.022209 Validation loss: 0.025641\n",
            "Epoch: 938 Train loss: 0.0222 Validation loss: 0.025599\n",
            "Epoch: 939 Train loss: 0.022191 Validation loss: 0.025558\n",
            "Epoch: 940 Train loss: 0.022182 Validation loss: 0.025517\n",
            "Epoch: 941 Train loss: 0.022174 Validation loss: 0.025476\n",
            "Epoch: 942 Train loss: 0.022165 Validation loss: 0.025434\n",
            "Epoch: 943 Train loss: 0.022156 Validation loss: 0.025394\n",
            "Epoch: 944 Train loss: 0.022147 Validation loss: 0.025353\n",
            "Epoch: 945 Train loss: 0.022138 Validation loss: 0.025312\n",
            "Epoch: 946 Train loss: 0.02213 Validation loss: 0.025271\n",
            "Epoch: 947 Train loss: 0.022121 Validation loss: 0.025231\n",
            "Epoch: 948 Train loss: 0.022112 Validation loss: 0.025191\n",
            "Epoch: 949 Train loss: 0.022104 Validation loss: 0.025151\n",
            "Epoch: 950 Train loss: 0.022095 Validation loss: 0.025111\n",
            "Epoch: 951 Train loss: 0.022086 Validation loss: 0.025071\n",
            "Epoch: 952 Train loss: 0.022078 Validation loss: 0.025031\n",
            "Epoch: 953 Train loss: 0.022069 Validation loss: 0.024991\n",
            "Epoch: 954 Train loss: 0.022061 Validation loss: 0.024952\n",
            "Epoch: 955 Train loss: 0.022052 Validation loss: 0.024913\n",
            "Epoch: 956 Train loss: 0.022044 Validation loss: 0.024873\n",
            "Epoch: 957 Train loss: 0.022036 Validation loss: 0.024835\n",
            "Epoch: 958 Train loss: 0.022027 Validation loss: 0.024795\n",
            "Epoch: 959 Train loss: 0.022019 Validation loss: 0.024757\n",
            "Epoch: 960 Train loss: 0.02201 Validation loss: 0.024718\n",
            "Epoch: 961 Train loss: 0.022002 Validation loss: 0.024679\n",
            "Epoch: 962 Train loss: 0.021994 Validation loss: 0.024641\n",
            "Epoch: 963 Train loss: 0.021985 Validation loss: 0.024603\n",
            "Epoch: 964 Train loss: 0.021977 Validation loss: 0.024565\n",
            "Epoch: 965 Train loss: 0.021969 Validation loss: 0.024527\n",
            "Epoch: 966 Train loss: 0.021961 Validation loss: 0.024489\n",
            "Epoch: 967 Train loss: 0.021953 Validation loss: 0.024451\n",
            "Epoch: 968 Train loss: 0.021944 Validation loss: 0.024413\n",
            "Epoch: 969 Train loss: 0.021936 Validation loss: 0.024376\n",
            "Epoch: 970 Train loss: 0.021928 Validation loss: 0.024338\n",
            "Epoch: 971 Train loss: 0.02192 Validation loss: 0.024301\n",
            "Epoch: 972 Train loss: 0.021912 Validation loss: 0.024264\n",
            "Epoch: 973 Train loss: 0.021904 Validation loss: 0.024227\n",
            "Epoch: 974 Train loss: 0.021896 Validation loss: 0.02419\n",
            "Epoch: 975 Train loss: 0.021888 Validation loss: 0.024154\n",
            "Epoch: 976 Train loss: 0.02188 Validation loss: 0.024117\n",
            "Epoch: 977 Train loss: 0.021872 Validation loss: 0.02408\n",
            "Epoch: 978 Train loss: 0.021864 Validation loss: 0.024044\n",
            "Epoch: 979 Train loss: 0.021856 Validation loss: 0.024007\n",
            "Epoch: 980 Train loss: 0.021848 Validation loss: 0.023971\n",
            "Epoch: 981 Train loss: 0.02184 Validation loss: 0.023935\n",
            "Epoch: 982 Train loss: 0.021833 Validation loss: 0.023899\n",
            "Epoch: 983 Train loss: 0.021825 Validation loss: 0.023863\n",
            "Epoch: 984 Train loss: 0.021817 Validation loss: 0.023827\n",
            "Epoch: 985 Train loss: 0.021809 Validation loss: 0.023792\n",
            "Epoch: 986 Train loss: 0.021801 Validation loss: 0.023756\n",
            "Epoch: 987 Train loss: 0.021794 Validation loss: 0.023721\n",
            "Epoch: 988 Train loss: 0.021786 Validation loss: 0.023686\n",
            "Epoch: 989 Train loss: 0.021778 Validation loss: 0.023651\n",
            "Epoch: 990 Train loss: 0.021771 Validation loss: 0.023616\n",
            "Epoch: 991 Train loss: 0.021763 Validation loss: 0.023581\n",
            "Epoch: 992 Train loss: 0.021755 Validation loss: 0.023546\n",
            "Epoch: 993 Train loss: 0.021748 Validation loss: 0.023511\n",
            "Epoch: 994 Train loss: 0.02174 Validation loss: 0.023477\n",
            "Epoch: 995 Train loss: 0.021733 Validation loss: 0.023442\n",
            "Epoch: 996 Train loss: 0.021725 Validation loss: 0.023408\n",
            "Epoch: 997 Train loss: 0.021717 Validation loss: 0.023373\n",
            "Epoch: 998 Train loss: 0.02171 Validation loss: 0.023339\n",
            "Epoch: 999 Train loss: 0.021702 Validation loss: 0.023305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylr1C2ovWXbO"
      },
      "source": [
        "During the training of the regularized model we can already notice, that, although there is still a difference between training and validation loss, the validation loss decreases as the training loss dreases. The effect of the regularization becomes even more evident if we plot the predictions of the regularized model and the overfitting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdMRV0vAWLmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d5ac8f4e-40ab-4090-fbe0-75dc19b2de66"
      },
      "source": [
        "\"\"\" We now want to plot the prediction of the regularized and unregularized big model. \"\"\"\n",
        "\n",
        "y_pred = big_reg_mdl(x) # Predict with \"big_reg_mdl\" on \"x\"\n",
        "y_pred_overfit = big_mdl(x) # Predict with \"big_mdl\" on \"x\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.plot(x, y_pred_overfit.numpy())\n",
        "plt.legend([\"Target\", \"Regularization\", \"No regularization\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sePQBaGqZzT6"
      },
      "source": [
        "The model with regularization seems to follow the overall trend of the data, while the model without any regularization very precisely fits the training samples. This is espacilly evident in the interval $\\left[0,0.5\\right]$, where the prediction of the unregularized model shows an oscillating behavior. Such oscillations are however not present in the ground truth and therefore undesirable. The regularized model on the other hand is not as flexible as the unregularized model and therefore does not fit the target function well in the interval $\\left[2.25, 3.0\\right]$.\n",
        "\n",
        "## Conclusion\n",
        "In this exercise we revisited the mathematical background for a simple regression task and covered it's practical implementation in Tensorflow 2. We also explored the phenomenon of overfitting and derived different regularizations from a probabilistic perspective. This exercise covers a very simple task with a very basic neural architecture and is intended as a primer for the second part of the regression exercise, which is dealing with a bigger and more realistic problem. In this second part we will consider the problem of estimating the age of a person from a potrait picture."
      ]
    }
  ]
}
